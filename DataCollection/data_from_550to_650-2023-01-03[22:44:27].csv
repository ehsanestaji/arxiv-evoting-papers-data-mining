,Title,Summary,DOI,Categories,Publish Time,Authors,Journal
0,The Correlation between Si III] 1892/ C III] 1909 and Fe II 4500/ H beta in low redshift QSOs,"HST archival FOS spectra of 40 QSOs with z <= 0.5 in the Bright Quasar Survey
have been analyzed. The spectra cover the region 1800-2000 A in the QSOs' rest
frames, including the Al III 1859, Si III] 1892, C III] 1909, and Fe III UV34
emission-lines. We measured the flux of these UV emission-lines, and analyzed
the correlations among UV and optical (H beta, Fe II, and [O III])
emission-line properties as well as soft X-ray photon indices. We found a
significant correlation between Si III]/C III] and Fe II/H beta.
  Si III and C III have similar ionization potentials, but Si III] has one
order magnitude larger critical density than C III]. Si III]/C III] is thus a
density indicator and becomes larger when density is higher. The correlation
between Si III]/C III] and Fe II/H beta indicates that optical Fe II becomes
strong when the density of the broad line region becomes high.
  Our correlation analysis shows that large Si III]/C III] associates with weak
[O III] 5007, large soft X-ray photon index, and narrow H beta width as well as
with large Fe II/H beta. Our results support the previous suggestions that the
density of the broad line region gas and the mass accretion rate govern this
correlation.",astro-ph/9812364v1,astro-ph,1998-12-19 10:52:22+00:00,"[arxiv.Result.Author('K. Aoki'), arxiv.Result.Author('M. Yoshida')]",
1,First observation of the solar Type III burst decay and its interpretation,"A decay of Type III burst into two Type III bursts was registered during
solar observations by GURT and URAN-2 radio telescopes on April 18, 2017. Such
phenomenon was observed for the first time. Newborn Type III bursts have drift
rates smaller than that of decaying Type III burst. Such decays of Type III
bursts were predicted by a gas-dynamic theory of high-energy electron beams
propagating through the thermal background plasma. In the frame of this theory
Type III sources are beam-plasma structures moving with constant velocities. In
our case the sum of velocities of newborn Type III sources equals the velocity
of decaying Type III source. The last one is 0.33c in the case of fundamental
radio emission and 0.2c at the harmonic radio emission of Type III burst. The
density ratio of slow and fast newborn Type III sources is about 3.",1909.13073v1,astro-ph.SR,2019-09-28 11:31:41+00:00,"[arxiv.Result.Author('Valentin N. Melnik'), arxiv.Result.Author('Alexandr A. Konovalenko'), arxiv.Result.Author('Sergey M. Yerin'), arxiv.Result.Author('Igor M. Bubnov'), arxiv.Result.Author('Anatoliy I. Brazhenko'), arxiv.Result.Author('Anatoliy V. Frantsuzenko'), arxiv.Result.Author('Vladimir V. Dorovskyy'), arxiv.Result.Author('Mykola V. Shevchuk'), arxiv.Result.Author('Helmut O. Rucker')]",
2,Following the Cosmic Evolution of Pristine Gas III: The Observational Consequences of the Unknown Properties of Population III Stars,"We study the observational consequences of several unknown properties of
Population III (Pop III) stars using large-scale cosmological simulations that
include a subgrid model to track the unresolved mixing of pollutants. Varying
the value of the critical metallicity that marks the boundary between Pop III
and Population II (Pop II) star formation across 2 dex has a negligible effect
on the fraction of Pop III stars formed and the subsequent fraction of Pop III
flux from high-redshift galaxies. However, adopting a log normal initial mass
function (IMF) for Pop III stars, in place of a baseline Salpeter IMF, results
in a Pop III star formation rate density (SFRD) that is 1/4 of the baseline
rate. The flux from high-redshift galaxies modeled with this IMF is highly
bimodal, resulting in a tiny fraction of $z \leq 8$ galaxies with more than
75\% of their flux coming from Pop III stars. However, at $z=9$, right before
reionization in our simulations, $\approx$ 20\% of galaxies are Pop III-bright
with $m_{\rm UV} \le 31.4$ mag and at least 75\% of their flux generated by Pop
III stars . Additionally, the log normal Pop III IMF results in a population of
carbon enhanced, metal poor stars in reasonable agreement with MW halo
observations. Our analysis supports the conclusion that the Pop III IMF was
dominated by stars in the 20-120$M_{\odot}$ range that generate SN with
carbon-enhanced ejecta.",1901.03727v1,astro-ph.GA,2019-01-11 19:44:32+00:00,"[arxiv.Result.Author('Richard Sarmento'), arxiv.Result.Author('Evan Scannapieco'), arxiv.Result.Author('Benoit Côté')]",
3,Baseline Metal Enrichment from Population III Star Formation in Cosmological Volume Simulations,"We utilize the hydrodynamic and N-body code {\small GIZMO} coupled with our
newly developed sub-grid Population~III (Pop~III) Legacy model, designed
specifically for cosmological volume simulations, to study the baseline metal
enrichment from Pop~III star formation at $z>7$. In this idealized numerical
experiment, we only consider Pop~III star formation. We find that our model
Pop~III star formation rate density (SFRD), which peaks at $\sim 10^{-3}\ {\rm
M_\odot yr^{-1} Mpc^{-1}}$ near $z\sim10$, agrees well with previous numerical
studies and is consistent with the observed estimates for Pop~II SFRDs. The
mean Pop~III metallicity rises smoothly from $z=25-7$, but does not reach the
critical metallicity value, $Z_{\rm crit}=10^{-4}\ Z_\odot$, required for the
Pop~III to Pop~II transition in star formation mode until $z\simeq7$. This
suggests that, while individual halos can suppress in-situ Pop~III star
formation, the external enrichment is insufficient to globally terminate
Pop~III star formation. The maximum enrichment from Pop~III star formation in
star forming dark matter halos is $Z\sim10^{-2}\ Z_\odot$, whereas the minimum
found in externally enriched haloes is $Z\gtrsim10^{-7}\ Z_\odot$. Finally,
mock observations of our simulated IGM enriched with Pop~III metals produce
equivalent widths similar to observations of an extremely metal poor damped
Lyman alpha (DLA) system at $z=7.04$, which is thought to be enriched by
Pop~III star formation only.",1705.08059v2,astro-ph.GA,2017-05-23 02:46:15+00:00,"[arxiv.Result.Author('Jason Jaacks'), arxiv.Result.Author('Robert Thompson'), arxiv.Result.Author('Steven L. Finkelstein'), arxiv.Result.Author('Volker Bromm')]",
4,Bianchi III and V Einstein metrics,"We present diagonal Einstein metrics for Bianchi III and V, both for
minkowskian and euclidean signatures and we show that the Einstein Bianchi III
metrics have an integrable geodesic flow.",0806.2930v1,gr-qc,2008-06-18 09:00:17+00:00,[arxiv.Result.Author('Galliano Valent')],
5,Population III Star Formation In Large Cosmological Simulations I. Halo Temporal and Physical Environment,"We present a semi-analytic, computationally inexpensive model to identify
halos capable of forming a Population III star in cosmological simulations
across a wide range of times and environments. This allows for a much more
complete and representative set of Population III star forming halos to be
constructed, which will lead to Population III star formation simulations that
more accurately reflect the diversity of Population III stars, both in time and
halo mass. This model shows that Population III and chemically enriched stars
coexist beyond the formation of the first generation of stars in a cosmological
simulation until at least z~10, and likely beyond, though Population III stars
form at rates that are 4-6 orders of magnitude lower than chemically enriched
stars by z=10. A catalog of more than 40,000 candidate Population III forming
halos were identified, with formation times temporally ranging from z=30 to
z=10, and ranging in mass from 2.3x10^5 M_sun to 1.2x10^10 M_sun. At early
times, the environment that Population III stars form in is very similar to
that of halos hosting chemically enriched star formation. At later times
Population III stars are found to form in low-density regions that are not yet
chemically polluted due to a lack of previous star formation in the area.
Population III star forming halos become increasingly spatially isolated from
one another at later times, and are generally closer to halos hosting
chemically enriched star formation than to another halo hosting Population III
star formation by z~10.",1306.4679v1,astro-ph.CO,2013-06-19 20:00:01+00:00,"[arxiv.Result.Author('Brian D. Crosby'), arxiv.Result.Author(""Brian W. O'Shea""), arxiv.Result.Author('Britton D. Smith'), arxiv.Result.Author('Matthew J. Turk'), arxiv.Result.Author('Oliver Hahn')]",
6,Photoionization Models for the Semi-Forbidden C III] 1909 Emission in Star-Forming Galaxies,"The increasing neutrality of the intergalactic medium at z>6 suppresses
Ly-alpha emission, and spectroscopic confirmation of galaxy redshifts requires
detecting alternative UV lines. The strong [C III] 1907 + C III] 1909 doublet
frequently observed in low-metallicity, actively star-forming galaxies is a
promising emission feature. We present CLOUDY photoionization model predictions
for C III] equivalent widths (EWs) and line ratios as a function of starburst
age, metallicity, and ionization parameter. Our models include a range of C/O
abundances, dust content, and gas density. We also examine the effects of
varying the nebular geometry and optical depth. Only the stellar models that
incorporate binary interaction effects reproduce the highest observed C III]
EWs. The spectral energy distributions from the binary stellar population
models also generate observable C III] over a longer timescale relative to
single-star models. We show that diagnostics using C III] and nebular He II
1640 can separate star-forming regions from shock-ionized gas. We also find
that density-bounded systems should exhibit weaker C III] EWs at a given
ionization parameter, and C III] EWs could therefore select candidate Lyman
continuum-leaking systems. In almost all models, C III] is the next strongest
line at < 2700 Angstroms after Ly-alpha, and C III] reaches detectable levels
for a wide range of conditions at low metallicity. C III] may therefore serve
as an important diagnostic for characterizing galaxies at z>6.",1610.03778v1,astro-ph.GA,2016-10-12 16:39:12+00:00,"[arxiv.Result.Author('Anne Jaskot'), arxiv.Result.Author('Swara Ravindranath')]",
7,Modelling Population III stars for semi-numerical simulations,"Theoretically modelling the 21-cm signals caused by Population III stars (Pop
III stars) is the key to extracting fruitful information on Pop III stars from
current and forthcoming 21-cm observations. In this work we develop a new
module of Pop III stars in which the escape fractions of ionizing photons and
Lyman-Werner (LW) photons, photo-heating by UV radiation, and LW feedback are
consistently incorporated. By implementing the module into a public 21-cm
semi-numerical simulation code, 21CMFAST, we demonstrate 21-cm signal
calculations and investigate the importance of Pop III star modelling. What we
find is that the contribution from Pop III stars to cosmic reionization
significantly depends on the treatment of the escape fraction. With our escape
fraction model, Pop III stars hardly contribute to reionization because less
massive halos, whose escape fraction are high, cannot host Pop III stars due to
LW feedback. On the other hand, Pop III stars well contribute to reionization
with the conventional constant escape fraction. We also find that UV
photo-heating has non-negligible impact on the 21-cm global signal and the
21-cm power spectrum if the ionization fraction of the Universe is higher than
roughly 1 percent. In this case, the strength of the 21-cm global signal
depends on the photo-heating efficiency and thus on the Pop III star mass. We
conclude that detailed modelling of Pop III stars is imperative to predict
21-cm observables accurately for future observations.",2011.13504v1,astro-ph.GA,2020-11-27 00:13:51+00:00,"[arxiv.Result.Author('Toshiyuki Tanaka'), arxiv.Result.Author('Kenji Hasegawa')]",
8,Canonical extension of endomorphisms of type III factors,"We extend the notion of the canonical extension of automorphisms of type III
factors to the case of endomorphisms with finite statistical dimensions.
Following the automorphism case, we introduce two notions for endomorphisms of
type III factors: modular endomorphisms and Connes-Takesaki modules. Several
applications to compact groups of automorphisms and subfactors of type III
factors are given from the viewpoint of ergodic theory.",math/0104228v1,math.OA,2001-04-24 21:12:18+00:00,[arxiv.Result.Author('Masaki Izumi')],
9,Coronal type III radio bursts and their X-ray flare and interplanetary type III counterparts,"Type III bursts and hard X-rays are both produced by flare energetic electron
beams. The link between both emissions has been investigated in many previous
studies, but no statistical studies have compared both coronal and
interplanetary type III bursts with X-ray flares. Using coronal radio events
above 100 MHz exclusively from type III bursts, we revisited long-standing
questions: Do all coronal type III bursts have X-ray counterparts. What
correlation, if any, occurs between radio and X-ray intensities. What X-ray and
radio signatures above 100 MHz occur in connection with interplanetary type III
bursts below 14 MHz. We analysed data from 2002 to 2011 starting with coronal
type III bursts above 100 MHz. We used RHESSI X-ray data greater than 6 keV to
make a list of 321 events that have associated type III bursts and X-ray
flares, encompassing at least 28 percent of the initial sample of type III
events. We examined the timings, intensities, associated GOES class, and any
interplanetary radio signature. For our 321 events, the X-ray emission at 6 keV
usually lasted longer than type III burst groups at frequencies greater than
100 MHz. A weak correlation was found between the type III radio flux at
frequencies below 327 MHz and the X-ray intensity at 25-50 keV, with an absence
of events at high X-ray intensity and low type III radio flux. Interplanetary
type III bursts less than 14 MHz were observed for 54 percent of the events,
increasing when events were observed with 25-50 keV X-rays. A stronger
interplanetary association was present when 25-50 keV count rates were above
250 counts per second or 170 MHz fluxes were greater than 1000 SFU, relating to
more energetic electrons above 25 keV and events where magnetic flux tubes
extend into the high corona. On average type III bursts increase in flux with
decreasing frequency, the rate varies from event to event.",1609.04743v1,astro-ph.SR,2016-09-15 17:19:24+00:00,"[arxiv.Result.Author('Hamish A. S. Reid'), arxiv.Result.Author('Nicole Vilmer')]","A&A 597, A77 (2017)"
10,Metal Pollution of Low-Mass Population III Stars through Accretion of Interstellar Objects like `Oumuamua,"We calculate accretion mass of interstellar objects (ISOs) like `Oumuamua
onto low-mass population III stars (Pop.~III survivors), and estimate surface
pollution of Pop.~III survivors. An ISO number density estimated from the
discovery of `Oumuamua is so high ($\sim 0.2$~au$^{-3}$) that Pop.~III
survivors have chances at colliding with ISOs $\gtrsim 10^5$ times per $1$~Gyr.
`Oumuamua itself would be sublimated near Pop.~III survivors, since it has
small size, $\sim 100$~m. However, ISOs with size $\gtrsim 3$~km would reach
the Pop.~III survivor surfaces. Supposing an ISO cumulative number density with
size larger than $D$ is $n \propto D^{-\alpha}$, Pop.~III survivors can accrete
ISO mass $\gtrsim 10^{-16}M_\odot$, or ISO iron mass $\gtrsim 10^{-17}M_\odot$,
if $\alpha < 4$. This iron mass is larger than the accretion mass of
interstellar medium (ISM) by several orders of magnitude. Taking into account
material mixing in a convection zone of Pop.~III survivors, we obtain their
surface pollution is typically [Fe/H] $\lesssim -8$ in most cases, however the
surface pollution of Pop.~III survivors with $0.8M_\odot$ can be [Fe/H]
$\gtrsim -6$ because of the very shallow convective layer. If we apply to
Pop.III survivors located at the Galactocentric distance of 8 kpc, the
dependence of the metal pollustion is as follows. If $\alpha > 4$, Pop.~III
survivors have no chance at colliding with ISOs with $D \gtrsim 3$~km, and keep
metal-free. If $3 < \alpha < 4$, Pop.~III survivors would be most polluted by
ISOs up to [Fe/H] $\sim -7$. If $\alpha < 3$ up to $D \sim 10$~km, Pop.~III
survivors could hide in metal-poor stars so far discovered. Pop.~III survivors
would be more polluted with decreasing the Galactocentric distance. Although
the metal pollution depends on $\alpha$ and the Galactocentric distance, we
first show the importance of ISOs for the metal pollution of Pop.~III
survivors.",1804.08200v2,astro-ph.SR,2018-04-23 00:26:47+00:00,"[arxiv.Result.Author('Ataru Tanikawa'), arxiv.Result.Author('Takeru K. Suzuki'), arxiv.Result.Author('Yasuo Doi')]",
11,Long Duration X-Ray Flash and X-Ray Rich Gamma Ray Burst from Low Mass Population III Star,"Recent numerical simulations suggest that Population III (Pop III) stars were
born with masses not larger than $\sim 100 M_{\odot}$ but typically $\sim
40M_{\odot}$. By self-consistently considering the jet generation and
propagation in the envelope of these low mass Pop III stars, we find that a Pop
III blue super giant star has the possibility to raise a gamma-ray burst (GRB)
even though it keeps a massive hydrogen envelope. We evaluate observational
characters of Pop III GRBs and predict that Pop III GRBs have the duration of
$\sim 10^5$ sec in the observer frame and the peak luminosity of $\sim 5 \times
10^{50} {\rm erg} {\rm sec}^{-1}$. Assuming that the $E_p-L_p$ (or
$E_p-E_{\gamma, \rm iso}$) correlation holds for Pop III GRBs, we find that the
spectrum peak energy falls $\sim$ a few keV (or $\sim 100$ keV) in the observer
frame. We discuss the detectability of Pop III GRBs by future satellite
missions such as EXIST and Lobster. If the $E_p-E_{\gamma, \rm iso}$
correlation holds, we have the possibility to detect Pop III GRBs at $z \sim 9$
as long duration X-ray rich GRBs by EXIST. On the other hand, if the $E_p-L_p$
correlation holds, we have the possibility to detect Pop III GRBs up to $z \sim
19$ as long duration X-ray flashes by Lobster.",1207.2835v2,astro-ph.HE,2012-07-12 03:27:33+00:00,"[arxiv.Result.Author('Daisuke Nakauchi'), arxiv.Result.Author('Yudai Suwa'), arxiv.Result.Author('Takanori Sakamoto'), arxiv.Result.Author('Kazumi Kashiyama'), arxiv.Result.Author('Takashi Nakamura')]",
12,"Cradles of the first stars: self-shielding, halo masses, and multiplicity","The formation of Population III (Pop III) stars is a critical step in the
evolution of the early universe. To understand how these stars affected their
metal-enriched descendants, the details of how, why and where Pop III formation
takes place needs to be determined. One of the processes that is assumed to
greatly affect the formation of Pop III stars is the presence of a Lyman-Werner
(LW) radiation background, that destroys H$_2$, a necessary coolant in the
creation of Pop III stars. Self-shielding can alleviate the effect the LW
background has on the H$_2$ within haloes. In this work, we perform a
cosmological simulation to study the birthplaces of Pop III stars, using the
adaptive mesh refinement code Enzo. We investigate the distribution of host
halo masses and its relationship to the LW background intensity. Compared to
previous work, haloes form Pop III stars at much lower masses, up to a factor
of a few, due to the inclusion of H$_2$ self-shielding. We see no relationship
between the LW intensity and host halo mass. Most haloes form multiple Pop III
stars, with a median number of four, up to a maximum of 16, at the instance of
Pop III formation. Our results suggest that Pop III star formation may be less
affected by LW radiation feedback than previously thought and that Pop III
multiple systems are common.",2001.04480v1,astro-ph.GA,2020-01-13 19:00:09+00:00,"[arxiv.Result.Author('Danielle Skinner'), arxiv.Result.Author('John H. Wise')]",
13,Dynamical evolution of Population III stellar systems and the resulting binary statistics,"We use N-body simulations to study the dynamical evolution of Population III
(Pop III) stellar systems and the resulting binary statistics. We design a
physically-motivated framework for the initial conditions of Pop III star
clusters, based on small-scale hydrodynamic simulations and the scale-free
nature of disk evolution during Pop III star formation. Our novel approach
enables us to explore the dependence of binary statistics on initial conditions
and arrive at more robust predictions for the signals of Pop III X-ray binaries
(XRBs) and binary black hole (BBH) mergers, compared to simple extrapolations
of Pop III protostar systems. We find that binary properties are highly
sensitive to the initial cluster size and distribution of binary separation,
while the effect of initial mass function is relatively minor. Our simulations
predict less close binaries, and thus, significantly lower efficiencies (by a
factor of $\sim 10-10^{4}$) for the formation and accretion of Pop III XRBs,
than found in previous studies, implying that the contribution of Pop III XRBs
to the cosmic X-ray background is negligible and their feedback effects are
unimportant. We estimate the efficiency of Pop III BBH mergers as $\sim
10^{-5}-10^{-4}\ \rm M_{\odot}^{-1}$, for which 3-body hardening by surrounding
stars in dense star clusters or close binary interactions is required to
facilitate in-spirals of BBHs. All simulation data, including catalogs of Pop
III binaries and multiple systems, are publicly available.",2010.05824v2,astro-ph.GA,2020-10-12 16:17:47+00:00,"[arxiv.Result.Author('Boyuan Liu'), arxiv.Result.Author('Georges Meynet'), arxiv.Result.Author('Volker Bromm')]",
14,C III] Emission in Star-Forming Galaxies Near and Far,"We measure C III] 1907,1909 A emission lines in eleven
gravitationally--lensed star-forming galaxies at z~1.6--3, finding much lower
equivalent widths than previously reported for fainter lensed galaxies (Stark
et al. 2014). While it is not yet clear what causes some galaxies to be strong
C III] emitters, CIII] emission is not a universal property of distant
star-forming galaxies. We also examine C III] emission in 46 star-forming
galaxies in the local universe, using archival spectra from GHRS, FOS, and STIS
on HST, and IUE. Twenty percent of these local galaxies show strong C III]
emission, with equivalent widths <-5 A. Three nearby galaxies show C III]
emission equivalent widths as large as the most extreme emitters yet observed
in the distant universe; all three are Wolf-Rayet galaxies. At all redshifts,
strong C III] emission may pick out low-metallicity galaxies experiencing
intense bursts of star formation. Such local C III] emitters may shed light on
the conditions of star formation in certain extreme high-redshift galaxies.",1510.02542v1,astro-ph.GA,2015-10-09 01:46:09+00:00,"[arxiv.Result.Author('Jane R. Rigby'), arxiv.Result.Author('Matthew B. Bayliss'), arxiv.Result.Author('Michael D. Gladders'), arxiv.Result.Author('Keren Sharon'), arxiv.Result.Author('Eva Wuyts'), arxiv.Result.Author('Hakon Dahle'), arxiv.Result.Author('Traci Johnson'), arxiv.Result.Author('Maria Pena-Guerrero')]",
15,Current signatures and search for Pop. III stars in the Local Universe,"Recent numerical studies argue that low-mass stars can be formed even at
zero-metallicity environment. These low-mass Population III(Pop.~III) stars are
thought to be still shining and able to be observed in the Local Universe. Most
low-mass Pop.~III stars are thought to be formed as secondary companions in
binary systems. They can be escaped from their host mini-halos when their
primary companions explode as supernovae. In this paper, we estimate the escape
probability of the low-mass Pop.~III stars from their host mini-halos. We find
that $\sim 100$ Pop.~III stars are expected. We also compute spatial
distribution of these escaped Pop.~III survivors by means of the semi-analytic
hierarchical chemical evolution model. Typically, they are distributed around
$\sim 2$Mpc away from the Milky Way but 5 -- $35\%$ of the escaped stars fall
into the Milky Way halo. These escaped Pop.~III stars are possibly detected by
very large scaled surveys being planned.",1312.5069v1,astro-ph.GA,2013-12-18 09:22:59+00:00,"[arxiv.Result.Author('Yutaka Komiya'), arxiv.Result.Author('Takuma Suda'), arxiv.Result.Author('Masayuki Fujimoto')]",
16,The type III stress-energy tensor: Ugly Duckling of the Hawking-Ellis classification,"We present some advances in the understanding of type III stress-energy
tensors as per the Hawking-Ellis classification. Type I and type II naturally
appear in classical situations, and can also describe semiclassical effects.
Type IV often shows up in semiclassical gravity. Type III is much more subtle.
We focus our attention on type III$_0$ stress-energy tensors, which capture the
essence (""essential core"") of type III. Reflecting on known purely
phenomenological examples, (""gyratons""), we are able to generalize the geometry
generated by those type III$_0$ stress-energy tensors. Moreover, we also
succeed in extending work by Griffiths based on massless Weyl spinors by
finding a fundamental classical bosonic Lagrangian description of these type
III$_0$ stress-energy tensors. To the best of our knowledge this is the first
time in the literature that a consistent classical bosonic Lagrangian
formulation for type III$_0$ stress-energy has been found.",1907.01269v3,gr-qc,2019-07-02 10:01:24+00:00,"[arxiv.Result.Author('Prado Martín-Moruno'), arxiv.Result.Author('Matt Visser')]",
17,How to confirm the existence of population III stars by observations of gravitational waves,"We propose a method for confirmation of the existence of Population III (Pop
III) stars with massive black hole binaries as GW150914 in gravitational wave
(GW) observation. When we get enough number of events, we want to determine
which model is closer to reality, with and without Pop III stars. We need to
prepare various ""Pop I/II models"" and various ""Pop I/II/III models"" and
investigate which model is consistent with the events. To demonstrate our
analysis, we simulate detections of GW events for some examples of population
synthesis models with and without Pop III stars. We calculate the likelihood
ratio with the realistic number of events and evaluate the probability of
identifying the existence of Pop III stars. In typical cases, our analysis can
distinguish between Pop I/II model and Pop I/II/III model with 90% probability
by 22 GW signals from black hole-black hole binary mergers.",1709.08437v1,astro-ph.HE,2017-09-25 11:54:05+00:00,"[arxiv.Result.Author('Akinobu Miyamoto'), arxiv.Result.Author('Tomoya Kinugawa'), arxiv.Result.Author('Takashi Nakamura'), arxiv.Result.Author('Nobuyuki Kanda')]","Phys. Rev. D 96, 064025 (2017)"
18,How the Population III Initial Mass Function Governs the Properties of the First Galaxies,"The properties of Population III (Pop III) stars impact many aspects of
primeval structure formation such as the onset of cosmological reionization and
early chemical enrichment. However, in spite of over twenty years of numerical
simulations and attempts to constrain the Pop III initial mass function (IMF)
by stellar archaelogy, little is known of the masses of the first stars for
certain. Here, we model the effect of Pop III IMF on the properties of primeval
galaxies with a suite of high-resolution radiation-hydrodynamical simulations
with ENZO. We find that a top-heavy Pop III IMF results in earlier star
formation but dimmer galaxies than a more conventional Salpeter-type IMF
because explosions of massive Pop III stars produce more turbulence that
suppresses high-mass second-generation star formation. Our models suggest that
the Pop III IMF could therefore be inferred from detections of primordial
galaxies, which will be principal targets of the James Webb Space Telescope and
extremely large telecopes on the ground in the coming decade.",2010.02212v1,astro-ph.GA,2020-10-05 18:00:00+00:00,"[arxiv.Result.Author('Li-Hsin Chen'), arxiv.Result.Author('Ke-Jung Chen'), arxiv.Result.Author('Sung-han Tsai'), arxiv.Result.Author('Daniel Whalen')]",
19,Detectability of Population III stellar remnants as X-ray binaries from tidal captures in the local Universe,"We assess the feasibility of detecting the compact object remnants from
Population III (Pop III) stars in nearby dense star clusters, where they become
luminous again as X-ray binaries (XRBs) and tidal disruption events (TDEs) via
strong tidal encounters. Analytically modelling the formation of Pop III stars,
coupled with a top-heavy initial mass function predicted by numerical
simulations, we derive the number of (active) Pop III XRBs and TDEs in the
present-day Milky Way (MW) nuclear star cluster as $\sim 0.06-0.3$ and
$\lesssim 4\times 10^{-6}$, rendering any detection unlikely. The detection
probability, however, can be significantly boosted when surveying all massive
star clusters from the MW and neighboring galaxy clusters. Specifically, we
predict $\sim 1.5-6.5$ and $\sim 40-2800$ active Pop III XRBs in the MW and the
Virgo cluster, respectively. Our Pop III XRBs are dominated ($\sim 99\%$) by
black holes with a typical mass and luminosity of $\sim 45$ $\rm M_{\odot}$ and
$\sim 10^{36}$ $\rm erg\ s^{-1}$. Deep surveys of nearby ($\lesssim 30-300$
$\rm Mpc$) galaxy clusters for such Pop III XRBs are well within reach of
next-generation X-ray telescopes, such as ATHENA and LYNX.",2109.10321v1,astro-ph.HE,2021-09-21 17:16:02+00:00,"[arxiv.Result.Author('Rabia Husain'), arxiv.Result.Author('Boyuan Liu'), arxiv.Result.Author('Volker Bromm')]",
20,Risk Automatic Prediction for Social Economy Companies using Camels,"Governments have to supervise and inspect social economy enterprises (SEEs).
However, inspecting all SEEs is not possible due to the large number of SEEs
and the low number of inspectors in general. We proposed a prediction model
based on a machine learning approach. The method was trained with the random
forest algorithm with historical data provided by each SEE. Three consecutive
periods of data were concatenated. The proposed method uses these periods as
input data and predicts the risk of each SEE in the fourth period. The model
achieved 76\% overall accuracy. In addition, it obtained good accuracy in
predicting the high risk of a SEE. We found that the legal nature and the
variation of the past-due portfolio are good predictors of the future risk of a
SEE. Thus, the risk of a SEE in a future period can be predicted by a
supervised machine learning method. Predicting the high risk of a SEE improves
the daily work of each inspector by focusing only on high-risk SEEs.",2210.05052v1,cs.LG,2022-10-10 23:50:02+00:00,"[arxiv.Result.Author('Joseph Gallego-Mejia'), arxiv.Result.Author('Daniela Martin-Vega'), arxiv.Result.Author('Fabio Gonzalez')]",
21,Triviality and the (Supersymmetric) See-Saw,"For the D=5 Majorana neutrino mass operator to have a see-saw ultraviolet
completion that is viable up to the Planck scale, the see-saw scale is bounded
above due to triviality limits on the see-saw couplings. For supersymmetric
see-saw models, with realistic neutrino mass textures, we compare constraints
on the see-saw scale from triviality bounds, with those arising from
experimental limits on induced charged-lepton flavour violation, for both the
CMSSM and for models with split supersymmetry.",hep-ph/0603053v2,hep-ph,2006-03-07 16:47:09+00:00,"[arxiv.Result.Author('Bruce A. Campbell'), arxiv.Result.Author('David W. Maybury')]","JHEP 0704:077,2007"
22,Astronomical Seeing at Maidanak Observatory during the year 2018,"Astronomical seeing measurements were carried out at Maidanak observatory
during the period from August to November 2018 using DIMM (Differential Image
Motion Monitor). The median value of seeing for the entire period was
determined as 0.54 arcseconds. This value was compared to the seeing data of
the period 1996-2002.",2012.08110v1,astro-ph.IM,2020-12-15 06:19:17+00:00,"[arxiv.Result.Author('Y. A. Tillayev'), arxiv.Result.Author('A. M. Azimov'), arxiv.Result.Author('A. R. Hafizov')]",
23,"The see-saw mechanism: neutrino mixing, leptogenesis and lepton flavor violation","The see-saw mechanism to generate small neutrino masses is reviewed. After
summarizing our current knowledge about the low energy neutrino mass matrix we
consider reconstructing the see-saw mechanism. Low energy neutrino physics is
not sufficient to reconstruct see-saw, a feature which we refer to as ``see-saw
degeneracy''. Indirect tests of see-saw are leptogenesis and lepton flavor
violation in supersymmetric scenarios, which together with neutrino mass and
mixing define the framework of see-saw phenomenology. Several examples are
given, both phenomenological and GUT-related. Variants of the see-saw mechanism
like the type II or triplet see-saw are also discussed. In particular, we
compare many general aspects regarding the dependence of LFV on low energy
neutrino parameters in the extreme cases of a dominating conventional see-saw
term or a dominating triplet term. For instance, the absence of mu -> e gamma
or tau -> e gamma in the pure triplet case means that CP is conserved in
neutrino oscillations. Scanning models, we also find that among the decays mu
-> e gamma, tau -> e gamma and tau -> mu gamma the latter one has the largest
branching ratio in (i) SO(10) type I see-saw models and in (ii) scenarios in
which the triplet term dominates in the neutrino mass matrix.",0804.3925v3,hep-ph,2008-04-24 13:44:29+00:00,[arxiv.Result.Author('Werner Rodejohann')],"Pramana 72:217-227,2009"
24,Statistics of turbulence profile at Cerro Tololo,"Results of 3-month continuous monitoring of turbulence profile and seeing at
Cerro Tololo (Chile) in May-July 2002 are presented. Some 28000 low-resolution
profiles were measured by a new MASS single-star turbulence monitor,
accompanied by seeing data from DIMM. The median seeing was 0.95 arcseconds.
The first 500 m contribute 60% to the total seeing, the free-atmosphere median
seeing was 0.55 arcseconds. Free-atmosphere seeing is almost never better than
0.15 arcseconds because there is always some turbulence above 12 km. A 4-day
period of calm upper atmosphere with a stable free-atmosphere seeing of 0.2-0.3
arcseconds was noted. A gain in resolution from adaptive compensation of ground
layer will be 1.7 times typically and 2-3 times during such calm periods.
Correlations of the free-atmosphere turbulence with the wind speed at
tropopause and of the ground-layer turbulence with ground wind are studied.
Temporal evolution of turbulence is characterized by recurrent bursts, their
typical duration increases from 15 minutes in low layers to 1-2 hours in high
layers. The large data base of turbulence profiles can be used to test
meso-scale modeling of astronomical seeing.",astro-ph/0209432v1,astro-ph,2002-09-20 16:32:20+00:00,"[arxiv.Result.Author('A. Tokovinin'), arxiv.Result.Author('S. Baumont'), arxiv.Result.Author('J. Vasquez')]",Mon.Not.Roy.Astron.Soc. 340 (2003) 52
25,The Spectrum of HD 3651B: An Extrasolar Nemesis?,This article has been withdrawn; see astro-ph/0611542,astro-ph/0609556v2,astro-ph,2006-09-20 00:36:50+00:00,[arxiv.Result.Author('Adam J. Burgasser')],
26,Criticality versus q in the 2+1-dimensional $Z_q$ clock model,"Paper has been withdrawn, see comment.",cond-mat/0212255v2,cond-mat.supr-con,2002-12-11 17:32:31+00:00,"[arxiv.Result.Author('J. Hove'), arxiv.Result.Author('A. Sudbo')]",
27,Closedness of the Space of AHE Metrics on 4-Manifolds,See comment above.,math/0012167v2,math.DG,2000-12-18 19:05:21+00:00,[arxiv.Result.Author('Michael T. Anderson')],
28,A Machine Learning Approach to Correcting Atmospheric Seeing in Solar Flare Observations,"Current post-processing techniques for the correction of atmospheric seeing
in solar observations -- such as Speckle interferometry and Phase Diversity
methods -- have limitations when it comes to their reconstructive capabilities
of solar flare observations. This, combined with the sporadic nature of flares
meaning observers cannot wait until seeing conditions are optimal before taking
measurements, means that many ground-based solar flare observations are marred
with bad seeing. To combat this, we propose a method for dedicated flare seeing
correction based on training a deep neural network to learn to correct
artificial seeing from flare observations taken during good seeing conditions.
This model uses transfer learning, a novel technique in solar physics, to help
learn these corrections. Transfer learning is when another network already
trained on similar data is used to influence the learning of the new network.
Once trained, the model has been applied to two flare datasets: one from
AR12157 on 2014/09/06 and one from AR12673 on 2017/09/06. The results show good
corrections to images with bad seeing with a relative error assigned to the
estimate based on the performance of the model. Further discussion takes place
of improvements to the robustness of the error on these estimates.",2011.12814v1,astro-ph.SR,2020-11-25 15:17:26+00:00,"[arxiv.Result.Author('John A. Armstrong'), arxiv.Result.Author('Lyndsay Fletcher')]",
29,Daytime Seeing and Solar Limb Positions,"A method to measure the seeing from video made during drift-scan solar
transits is proposed. The limb of the Sun is projected over a regular grid
evenly spaced. The temporal dispersion of the time intervals among the contacts
between solar limb and grid's rows is proportional to the atmospheric seeing.
Seeing effects on the position of the inflexion point of the limb's luminosity
profile are calculated numerically with Fast Fourier Transform. Observational
examples from Locarno and Paris Observatories are presented to show the
asymmetric contributions of the seeing at the beginning and the end of each
drift-scan transit.",1106.2539v1,astro-ph.IM,2011-06-13 19:58:47+00:00,[arxiv.Result.Author('Costantino Sigismondi')],
30,The effect of aperture and seeing on the visibility of sunspots when using early modern and modern telescopes of modest size,"Using the convolution of seeing and diffraction, the relation between seeing
and aperture in the visibility of sunspots is explored. It is shown that even
telescopes with apertures smaller than 5 centimetres are significantly affected
by seeing. Although larger aperture instruments suffer more from seeing than
smaller ones, their level of detail always remains better under the same
atmospheric conditions.",2208.07244v3,astro-ph.SR,2022-08-15 15:00:51+00:00,"[arxiv.Result.Author('Nicolàs de Hilster'), arxiv.Result.Author('Siebren van der Werf')]",
31,Typical duration of good seeing sequences at Concordia,"Context: The winter seeing at Concordia is essentially bimodal, excellent or
quite poor, with relative proportions that depend on altitude above the snow
surface. This paper studies the temporal behavior of the good seeing sequences.
Aims: An efficient exploitation of extremely good seeing with an adaptive
optics system needs long integrations. It is then important to explore the
temporal distribution of the fraction of time providing excellent seeing.
Methods: Temporal windows of good seeing are created by a simple binary
process. Good or bad. Their autocorrelations are corrected for those of the
existing data sets, since these are not continuous, being often interrupted by
technical problems in addition to the adverse weather gaps. At the end these
corrected autocorrelations provide the typical duration of good seeing
sequences. This study has to be a little detailed as its results depend on the
season, summer or winter. Results: Using a threshold of 0.5 arcsec to define
the ""good seeing"", three characteristic numbers are found to describe the
temporal evolution of the good seeing windows. The first number is the mean
duration of an uninterrupted good seeing sequence: it is $\tau_0=7.5$ hours at
8 m above the ground (15 hours at 20 m). These sequences are randomly
distributed in time, with a negative exponential law of damping time
$\tau_1=29$ hours (at elevation 8 m and 20 m). The third number is the mean
time between two 29 hours episodes. It is T=10 days at 8 m high (5 days at 20
m).",1003.3583v1,astro-ph.IM,2010-03-18 14:09:06+00:00,"[arxiv.Result.Author('Eric Fossat'), arxiv.Result.Author('Eric Aristidi'), arxiv.Result.Author('Karim Agabi'), arxiv.Result.Author('Erick Bondoux'), arxiv.Result.Author('Zalpha Challita'), arxiv.Result.Author('Francois Jeanneaux'), arxiv.Result.Author('Djamel Mekarnia')]",
32,Excellent daytime seeing at Dome Fuji on the Antarctic plateau,"Context. Dome Fuji, the second highest region on the Antarctic plateau, is
expected to have some of the best astronomical seeing on Earth. However, site
testing at Dome Fuji is still in its very early stages.
  Aims. To investigate the astronomical seeing in the free atmosphere above
Dome Fuji, and to determine the height of the surface boundary layer.
  Methods. A Differential Image Motion Monitor was used to measure the seeing
in the visible (472 nm) at a height of 11 m above the snow surface at Dome Fuji
during the austral summer of 2012/2013.
  Results. Seeing below 0.2'' has been observed. The seeing often has a local
minimum of ~0.3'' near 18 h local time. Some periods of excellent seeing, 0.3''
or smaller, were also observed, sometimes extending for several hours at local
midnight. The median seeing is higher, at 0.52''---this large value is believed
to be caused by periods when the telescope was within the turbulent boundary
layer.
  Conclusions. The diurnal variation of the daytime seeing at Dome Fuji is
similar to that reported for Dome C, and the height of the surface boundary
layer is consistent with previous simulations for Dome Fuji. The free
atmosphere seeing is ~0.2'', and the height of the surface boundary layer can
be as low as ~11 m.",1305.5109v1,astro-ph.IM,2013-05-22 12:38:07+00:00,"[arxiv.Result.Author('H. Okita'), arxiv.Result.Author('T. Ichikawa'), arxiv.Result.Author('M. C. B. Ashley'), arxiv.Result.Author('N. Takato')]",
33,Night-time measurements of astronomical seeing at Dome A in Antarctica,"Seeing, the angular size of stellar images blurred by atmospheric turbulence,
is a critical parameter used to assess the quality of astronomical sites.
Median values at the best mid-latitude sites are generally in the range of
0.6--0.8\,arcsec. Sites on the Antarctic plateau are characterized by
comparatively-weak turbulence in the free-atmosphere above a strong but thin
boundary layer. The median seeing at Dome C is estimated to be 0.23--0.36
arcsec above a boundary layer that has a typical height of 30\,m. At Dome A and
F, the only previous seeing measurements were made during daytime. Here we
report the first direct measurements of night-time seeing at Dome A, using a
Differential Image Motion Monitor. Located at a height of just 8\,m, it
recorded seeing as low as 0.13\,arcsec, and provided seeing statistics that are
comparable to those for a 20\,m height at Dome C. It indicates that the
boundary layer was below 8\,m 31\% of the time. At such times the median seeing
was 0.31\,arcsec, consistent with free-atmosphere seeing. The seeing and
boundary layer thickness are found to be strongly correlated with the
near-surface temperature gradient. The correlation confirms a median thickness
of approximately 14\,m for the boundary layer at Dome A, as found from a sonic
radar. The thinner boundary layer makes it less challenging to locate a
telescope above it, thereby giving greater access to the free-atmosphere.",2007.15365v1,astro-ph.IM,2020-07-30 10:36:24+00:00,"[arxiv.Result.Author('Bin Ma'), arxiv.Result.Author('Zhaohui Shang'), arxiv.Result.Author('Yi Hu'), arxiv.Result.Author('Keliang Hu'), arxiv.Result.Author('Yongjiang Wang'), arxiv.Result.Author('Xu Yang'), arxiv.Result.Author('Michael C. B. Ashley'), arxiv.Result.Author('Paul Hickson'), arxiv.Result.Author('Peng Jiang')]","Nature 583, 771-774 (2020)"
34,Gaze-Vergence-Controlled See-Through Vision in Augmented Reality,"Augmented Reality (AR) see-through vision is an interesting research topic
since it enables users to see through a wall and see the occluded objects. Most
existing research focuses on the visual effects of see-through vision, while
the interaction method is less studied. However, we argue that using common
interaction modalities, e.g., midair click and speech, may not be the optimal
way to control see-through vision. This is because when we want to see through
something, it is physically related to our gaze depth/vergence and thus should
be naturally controlled by the eyes. Following this idea, this paper proposes a
novel gaze-vergence-controlled (GVC) see-through vision technique in AR. Since
gaze depth is needed, we build a gaze tracking module with two infrared cameras
and the corresponding algorithm and assemble it into the Microsoft HoloLens 2
to achieve gaze depth estimation. We then propose two different GVC modes for
see-through vision to fit different scenarios. Extensive experimental results
demonstrate that our gaze depth estimation is efficient and accurate. By
comparing with conventional interaction modalities, our GVC techniques are also
shown to be superior in terms of efficiency and more preferred by users.
Finally, we present four example applications of gaze-vergence-controlled
see-through vision.",2207.02645v1,cs.CV,2022-07-06 13:11:34+00:00,"[arxiv.Result.Author('Zhimin Wang'), arxiv.Result.Author('Yuxin Zhao'), arxiv.Result.Author('Feng Lu')]",
35,Vlasov Simulation of Emissive Plasma Sheath with Energy-Dependent Secondary Emission Coefficient and Improved Modeling for Dielectric Charging Effects,"A one dimensional Vlasov Poisson simulation code is employed to investigate
the plasma sheath considering electron induced secondary electron emission
(SEE) and backscattering. The SEE coefficient is commonly treated as constant
in a range of plasma simulations, here improved SEE model of a charged
dielectric wall is constructed which includes the wall charging effect on SEE
coefficient and the energy dependency of SEE coefficient. Pertinent algorithms
to implement above SEE model in plasma simulation are studied in detail. It is
found that the SEE coefficient increases with the amount of negative wall
charges, which in turn reduces the emissive sheath potential. With energy
dependent SEE coefficient, the sheath potential is a nonlinear function of the
plasma electron temperature, as opposed to the linear relation predicted by
classic emissive sheath theory. Simulation combining both wall charging effect
and SEE coefficient energy dependency suggests that the space charged limited
sheath is formed at high plasma electron temperature levels, where both sheath
potential and surface charging saturate. Additionally, different algorithms to
implement the backscattering in kinetic simulation are tested and compared.
Converting backscattered electron to secondary electron via an effective SEE
coefficient barely affects the sheath properties. The simulation results are
shown to be commensurate with the upgraded sheath theory predictions.",2209.09567v1,physics.plasm-ph,2022-09-20 09:13:56+00:00,"[arxiv.Result.Author('Guang-Yu Sun'), arxiv.Result.Author('Shu Zhang'), arxiv.Result.Author('Bao-Hong Guo'), arxiv.Result.Author('An-Bang Sun'), arxiv.Result.Author('Guan-Jun Zhang')]",
36,Leptogenesis and LHC Physics with Type III See-Saw,"The See-Saw mechanism provides a nice way to explain why neutrino masses are
so much lighter than their charged lepton partners. It also provides a nice way
to explain baryon asymmetry in our universe via the leptogenesis mechanism. In
this talk we review leptogenesis and LHC physics in a See-Saw model proposed in
1989, now termed the Type III See-Saw model. In this model, $SU(2)_L$ triplet
leptons are introduced with the neutral particles of the triplets playing the
role of See-Saw. The triplet leptons have charged partners with standard model
gauge interactions resulting in many new features. The gauge interactions of
these particles make it easier for leptognesis with low masses, as low as a TeV
is possible. The gauge interactions also make the production and detection of
triplet leptons at LHC possible. The See-Saw mechanism and leptogenesis due to
Type III See-Saw may be tested at LHC.",0901.1264v2,hep-ph,2009-01-09 16:14:07+00:00,"[arxiv.Result.Author('Shao-Long Chen'), arxiv.Result.Author('Xiao-Gang He')]",
37,Avoiding the gauge heirarchy problem with see-sawed neutrino masses,"We show that the see-saw neutrino mass mechanism can coexist naturally with
an extended gauge symmetry (i.e. without any gauge heirarchy problem) provided
that the gauge symmetry contains gauged lepton number differences. The simplest
such `natural' see-saw models are constructed and their implications for
neutrino anomalies discussed.",hep-ph/0505154v1,hep-ph,2005-05-18 00:16:53+00:00,[arxiv.Result.Author('R. Foot')],Mod.Phys.Lett. A20 (2005) 3035-3044
38,On the F-expanding of Homoclinic class,"We establish a closing property for thin trapped homoclinic classes. Taking
advantage of this property, we proved that if the homoclinic class $H(p)$
admits a dominated splitting $T_{H(p)}M=E\oplus_{<}F$, where $E$ is thin
trapped (see Definition \ref{Def:TP}) and all periodic points homoclinically
related to $p$ are uniformly $F$-expanding at the period (see Definition
\ref{Def:expanding}), then $F$ is expanded (see Definition \ref{Def:TP}).",1710.08487v1,math.DS,2017-10-23 20:06:47+00:00,"[arxiv.Result.Author('Wanlou Wu'), arxiv.Result.Author('Bo Li')]",
39,See-saw Enhancement of Neutrino Mixing due to the Right-handed Phases,"We study the see-saw enhancement mechanism in presence of the right-handed
phases of the Dirac neutrino mass matrix and the Majorana mass matrix. The
enhancement condition given by Smirnov is modified. We point out that the
see-saw enhancement could be obtained due to the right-handed phases even if
the Majorana matrix is proportional to the unit matrix. We show a realistic
Dirac mass matrix which causes the see-saw enhancement.",hep-ph/9503318v1,hep-ph,1995-03-14 01:47:22+00:00,[arxiv.Result.Author('Morimitsu Tanimoto')],Phys.Lett. B345 (1995) 477-482
40,The Schulze Method of Voting,"We propose a new single-winner election method (""Schulze method"") and prove
that it satisfies many academic criteria (e.g. monotonicity, reversal symmetry,
resolvability, independence of clones, Condorcet criterion, k-consistency,
polynomial runtime). We then generalize this method to proportional
representation by the single transferable vote (""Schulze STV"") and to methods
to calculate a proportional ranking (""Schulze proportional ranking"").
Furthermore, we propose a generalization of the Condorcet criterion to
multi-winner elections. This paper contains a large number of examples to
illustrate the proposed methods.",1804.02973v11,cs.GT,2018-03-15 20:12:08+00:00,[arxiv.Result.Author('Markus Schulze')],
41,Rigorous constraint satisfaction for sampled linear systems,"We address a specific but recurring problem related to sampled linear
systems. In particular, we provide a numerical method for the rigorous
verification of constraint satisfaction for linear continuous-time systems
between sampling instances. The proposed algorithm combines elements of
classical branch and bound schemes from global optimization with a recently
published procedure to bound the exponential of interval matrices.",1603.08851v1,math.OC,2016-03-29 17:10:56+00:00,[arxiv.Result.Author('Moritz Schulze Darup')],
42,Unconditional existence of conformally hyperbolic Yamabe flows,"We prove global existence of instantaneously complete Yamabe flows on
hyperbolic space of arbitrary dimension $m\geq3$ starting from any smooth,
conformally hyperbolic initial metric. We do not require initial completeness
or curvature bounds. With the same methods, we show rigidity of hyperbolic
space under the Yamabe flow.",1811.08798v2,math.AP,2018-11-21 15:52:37+00:00,[arxiv.Result.Author('Mario B. Schulz')],Analysis & PDE 13 (2020) 1579-1590
43,Fine-Grained Complexity and Algorithms for the Schulze Voting Method,"We study computational aspects of a well-known single-winner voting rule
called the Schulze method [Schulze, 2003] which is used broadly in practice. In
this method the voters give (weak) ordinal preference ballots which are used to
define the weighted majority graph (WMG) of direct comparisons between pairs of
candidates. The choice of the winner comes from indirect comparisons in the
graph, and more specifically from considering directed paths instead of direct
comparisons between candidates.
  When the input is the WMG, to our knowledge, the fastest algorithm for
computing all winners in the Schulze method uses a folklore reduction to the
All-Pairs Bottleneck Paths problem and runs in $O(m^{2.69})$ time, where $m$ is
the number of candidates. It is an interesting open question whether this can
be improved. Our first result is a combinatorial algorithm with a nearly
quadratic running time for computing all winners. This running time is
essentially optimal. If the input to the Schulze winners problem is not the WMG
but the preference profile, then constructing the WMG is a bottleneck that
increases the running time significantly; in the special case when there are
$m$ candidates and $n=O(m)$ voters, the running time is $O(m^{2.69})$, or
$O(m^{2.5})$ if there is a nearly-linear time algorithm for multiplying dense
square matrices. To address this bottleneck, we prove a formal equivalence
between the well-studied Dominance Product problem and the problem of computing
the WMG. We prove a similar connection between the so called Dominating Pairs
problem and the problem of finding a winner in the Schulze method.
  Our paper is the first to bring fine-grained complexity into the field of
computational social choice. Using it we can identify voting protocols that are
unlikely to be practical for large numbers of candidates and/or voters, as
their complexity is likely, say at least cubic.",2103.03959v2,cs.DS,2021-03-05 22:27:36+00:00,"[arxiv.Result.Author('Krzysztof Sornat'), arxiv.Result.Author('Virginia Vassilevska Williams'), arxiv.Result.Author('Yinzhan Xu')]",
44,A Riemannian View on Shape Optimization,"Shape optimization based on the shape calculus is numerically mostly
performed by means of steepest descent methods. This paper provides a novel
framework to analyze shape-Newton optimization methods by exploiting a
Riemannian perspective. A Riemannian shape Hessian is defined yielding often
sought properties like symmetry and quadratic convergence for Newton
optimization methods.",1203.1493v2,math.OC,2012-03-07 15:13:08+00:00,[arxiv.Result.Author('Volker Schulz')],"Foundations of Computational Mathematics, 14:483-501, 2014"
45,Functional Integrals for Correlated Fermions,"Functional integral methods provide a way to define mean--field theories and
to systematically improve them. For the Hubbard model and similar
strong--correlation problems, methods based in particular on the
Hubbard--Stratonovich transformation have however been plagued by difficulties
to formulate the problem in a spin--rotation invariant way. Here a formalism
circumventing this problem by using a space-- and time--dependent spin
reference axis is discussed. This formulation is then used to suggest a
possible alternative to Nagaoka ferromagnetism in the strongly correlated
Hubbard model in the vicinity of half--filling. Finally, some aspects of
single--particle spectra in a simplified model for a short--range ordered
antiferromagnet are discussed.",cond-mat/9411059v1,cond-mat,1994-11-16 13:38:48+00:00,[arxiv.Result.Author('H. J. Schulz')],
46,Monodromy of Hypersurface Singularities,"We describe algorithmic methods for the Gauss-Manin connection of an isolated
hypersurface singularity based on the microlocal structure of the Brieskorn
lattice. They lead to algorithms for computing invariants like the monodromy,
the spectrum, and the spectral pairs. These algorithms use a normal form
algorithm for the Brieskorn lattice, standard basis methods for localized
polynomial rings, and univariate factorization. We give a detailed description
of the algorithm to compute the monodromy.",math/0108145v4,math.CV,2001-08-21 18:54:06+00:00,[arxiv.Result.Author('Mathias Schulze')],"Acta Appl. Math. 75 (2003), 3-13"
47,Efficient Computation of Spectral Bounds for Hessian Matrices on Hyperrectangles for Global Optimization,"We compare two established and a new method for the calculation of spectral
bounds for Hessian matrices on hyperrectangles by applying them to a large
collection of 1522 objective and constraint functions extracted from benchmark
global optimization problems. Both the tightness of the spectral bounds and the
computational effort are assessed. Specifically, we compare eigenvalue bounds
obtained with the interval variant of Gershgorin's circle criterion [2,6],
Hertz and Rohn's [7,16] method for tight bounds of interval matrices, and a
recently proposed Hessian matrix eigenvalue arithmetic [12], which deliberately
avoids the computation of interval Hessians.",1206.0196v1,math.OC,2012-06-01 14:28:15+00:00,"[arxiv.Result.Author('Moritz Schulze Darup'), arxiv.Result.Author('Martin Kastsian'), arxiv.Result.Author('Stefan Mross'), arxiv.Result.Author('Martin Mönnigmann')]",
48,"ViZDoom: DRQN with Prioritized Experience Replay, Double-Q Learning, & Snapshot Ensembling","ViZDoom is a robust, first-person shooter reinforcement learning environment,
characterized by a significant degree of latent state information. In this
paper, double-Q learning and prioritized experience replay methods are tested
under a certain ViZDoom combat scenario using a competitive deep recurrent
Q-network (DRQN) architecture. In addition, an ensembling technique known as
snapshot ensembling is employed using a specific annealed learning rate to
observe differences in ensembling efficacy under these two methods. Annealed
learning rates are important in general to the training of deep neural network
models, as they shake up the status-quo and counter a model's tending towards
local optima. While both variants show performance exceeding those of built-in
AI agents of the game, the known stabilizing effects of double-Q learning are
illustrated, and priority experience replay is again validated in its
usefulness by showing immediate results early on in agent development, with the
caveat that value overestimation is accelerated in this case. In addition, some
unique behaviors are observed to develop for priority experience replay (PER)
and double-Q (DDQ) variants, and snapshot ensembling of both PER and DDQ proves
a valuable method for improving performance of the ViZDoom Marine.",1801.01000v1,cs.AI,2018-01-03 13:49:08+00:00,"[arxiv.Result.Author('Christopher Schulze'), arxiv.Result.Author('Marcus Schulze')]",
49,Structured inverse modeling in parabolic diffusion processess,"Often, the unknown diffusivity in diffusive processes is structured by
piecewise constant patches. This paper is devoted to efficient methods for the
determination of such structured diffusion parameters by exploiting shape
calculus. A novel shape gradient is derived in parabolic processes. Furthermore
quasi-Newton techniques are used in order to accelerate shape gradient based
iterations in shape space. Numerical investigations support the theoretical
results.",1409.3464v2,math.OC,2014-09-11 14:57:23+00:00,"[arxiv.Result.Author('Volker Schulz'), arxiv.Result.Author('Martin Siebenborn'), arxiv.Result.Author('Kathrin Welker')]",
50,BAT.jl -- A Julia-based tool for Bayesian inference,"We describe the development of a multi-purpose software for Bayesian
statistical inference, BAT.jl, written in the Julia language. The major design
considerations and implemented algorithms are summarized here, together with a
test suite that ensures the proper functioning of the algorithms. We also give
an extended example from the realm of physics that demonstrates the
functionalities of BAT.jl.",2008.03132v1,stat.CO,2020-08-07 12:55:52+00:00,"[arxiv.Result.Author('Oliver Schulz'), arxiv.Result.Author('Frederik Beaujean'), arxiv.Result.Author('Allen Caldwell'), arxiv.Result.Author('Cornelius Grunwald'), arxiv.Result.Author('Vasyl Hafych'), arxiv.Result.Author('Kevin Kröninger'), arxiv.Result.Author('Salvatore La Cagnina'), arxiv.Result.Author('Lars Röhrig'), arxiv.Result.Author('Lolian Shtembari')]",
51,Systematic Review of Newton-Schulz Iterations with Unified Factorizations : Integration in the Richardson Method and Application to Robust Failure Detection in Electrical Networks,"Systematic overview of Newton-Schulz and Durand iterations with convergence
analysis and factorizations is presented in the chronological sequence in
unified framework. Practical recommendations for the choice of the order and
factorizations of the algorithms and integration into Richardson iteration are
given. The simplest combination of Newton-Schulz and Richardson iteration is
applied to the parameter estimation problem associated with the failure
detection via evaluation of the frequency content of the signals in electrical
network. The detection is performed on real data for which the software failure
was simulated, which resulted in the rank deficient information matrix. Robust
preconditioning for rank deficient matrices is proposed and the efficiency of
the approach is demonstrated by simulations via comparison with standard LU
decomposition method.",2208.04068v1,math.OC,2022-08-08 11:39:57+00:00,[arxiv.Result.Author('Alexander Stotsky')],
52,Stochastic Gradient Descent Captures How Children Learn About Physics,"As children grow older, they develop an intuitive understanding of the
physical processes around them. They move along developmental trajectories,
which have been mapped out extensively in previous empirical research. We
investigate how children's developmental trajectories compare to the learning
trajectories of artificial systems. Specifically, we examine the idea that
cognitive development results from some form of stochastic optimization
procedure. For this purpose, we train a modern generative neural network model
using stochastic gradient descent. We then use methods from the developmental
psychology literature to probe the physical understanding of this model at
different degrees of optimization. We find that the model's learning trajectory
captures the developmental trajectories of children, thereby providing support
to the idea of development as stochastic optimization.",2209.12344v1,cs.LG,2022-09-25 22:56:14+00:00,"[arxiv.Result.Author('Luca M. Schulze Buschoff'), arxiv.Result.Author('Eric Schulz'), arxiv.Result.Author('Marcel Binz')]",
53,Fast Differentiable Matrix Square Root,"Computing the matrix square root or its inverse in a differentiable manner is
important in a variety of computer vision tasks. Previous methods either adopt
the Singular Value Decomposition (SVD) to explicitly factorize the matrix or
use the Newton-Schulz iteration (NS iteration) to derive the approximate
solution. However, both methods are not computationally efficient enough in
either the forward pass or in the backward pass. In this paper, we propose two
more efficient variants to compute the differentiable matrix square root. For
the forward propagation, one method is to use Matrix Taylor Polynomial (MTP),
and the other method is to use Matrix Pad\'e Approximants (MPA). The backward
gradient is computed by iteratively solving the continuous-time Lyapunov
equation using the matrix sign function. Both methods yield considerable
speed-up compared with the SVD or the Newton-Schulz iteration. Experimental
results on the de-correlated batch normalization and second-order vision
transformer demonstrate that our methods can also achieve competitive and even
slightly better performances. The code is available at
\href{https://github.com/KingJamesSong/FastDifferentiableMatSqrt}{https://github.com/KingJamesSong/FastDifferentiableMatSqrt}.",2201.08663v1,cs.CV,2022-01-21 12:18:06+00:00,"[arxiv.Result.Author('Yue Song'), arxiv.Result.Author('Nicu Sebe'), arxiv.Result.Author('Wei Wang')]",
54,Some Constructions of Divisible Designs from Laguerre Geometries,"In the nineties, A.G. Spera introduced a construction principle for divisible
designs. Using this method, we get series of divisible designs from finite
Laguerre geometries. We show a close connection between some of these divisible
designs and divisible designs whose construction was based on a conic in a
plane of a 3-dimensional projective space.",1304.0221v1,math.CO,2013-03-31 16:25:09+00:00,"[arxiv.Result.Author('Sabine Giese'), arxiv.Result.Author('Hans Havlicek'), arxiv.Result.Author('Ralph-Hardo Schulz')]","Discrete Math. 301 (2005), 74-82"
55,Optimal Longest Paths by Dynamic Programming,"We propose an optimal algorithm for solving the longest path problem in
undirected weighted graphs. By using graph partitioning and dynamic
programming, we obtain an algorithm that is significantly faster than other
state-of-the-art methods. This enables us to solve instances that have
previously been unsolved.",1702.04170v1,cs.DS,2017-02-14 12:05:58+00:00,"[arxiv.Result.Author('Tomas Balyo'), arxiv.Result.Author('Kai Fieger'), arxiv.Result.Author('Christian Schulz')]",
56,Local foliation of manifolds by surfaces of Willmore type,"We show the existence of a local foliation of a three dimensional Riemannian
manifold by critical points of the Willmore functional subject to a small area
constraint around non-degenerate critical points of the scalar curvature. This
adapts a method developed by Rugang Ye to construct foliations by surfaces of
constant mean curvature.",1806.00465v2,math.DG,2018-06-01 17:48:30+00:00,"[arxiv.Result.Author('Tobias Lamm'), arxiv.Result.Author('Jan Metzger'), arxiv.Result.Author('Felix Schulze')]",
57,Shape optimization for interface identification in nonlocal models,"Shape optimization methods have been proven useful for identifying interfaces
in models governed by partial differential equations. Here we consider a class
of shape optimization problems constrained by nonlocal equations which involve
interface-dependent kernels. We derive a novel shape derivative associated to
the nonlocal system model and solve the problem by established numerical
techniques.",1909.08884v2,math.OC,2019-09-19 09:32:39+00:00,"[arxiv.Result.Author('Volker Schulz'), arxiv.Result.Author('Matthias Schuster'), arxiv.Result.Author('Christian Vollmann')]",
58,Anomaly Detection by Recombining Gated Unsupervised Experts,"Anomaly detection has been considered under several extents of prior
knowledge. Unsupervised methods do not require any labelled data, whereas
semi-supervised methods leverage some known anomalies. Inspired by
mixture-of-experts models and the analysis of the hidden activations of neural
networks, we introduce a novel data-driven anomaly detection method called
ARGUE. Our method is not only applicable to unsupervised and semi-supervised
environments, but also profits from prior knowledge of self-supervised
settings. We designed ARGUE as a combination of dedicated expert networks,
which specialise on parts of the input data. For its final decision, ARGUE
fuses the distributed knowledge across the expert systems using a gated
mixture-of-experts architecture. Our evaluation motivates that prior knowledge
about the normal data distribution may be as valuable as known anomalies.",2008.13763v5,cs.LG,2020-08-31 17:35:57+00:00,"[arxiv.Result.Author('J. -P. Schulze'), arxiv.Result.Author('P. Sperl'), arxiv.Result.Author('K. Böttinger')]",
59,Double-Adversarial Activation Anomaly Detection: Adversarial Autoencoders are Anomaly Generators,"Anomaly detection is a challenging task for machine learning algorithms due
to the inherent class imbalance. It is costly and time-demanding to manually
analyse the observed data, thus usually only few known anomalies if any are
available. Inspired by generative models and the analysis of the hidden
activations of neural networks, we introduce a novel unsupervised anomaly
detection method called DA3D. Here, we use adversarial autoencoders to generate
anomalous counterexamples based on the normal data only. These artificial
anomalies used during training allow the detection of real, yet unseen
anomalies. With our novel generative approach, we transform the unsupervised
task of anomaly detection to a supervised one, which is more tractable by
machine learning and especially deep learning methods. DA3D surpasses the
performance of state-of-the-art anomaly detection methods in a purely
data-driven way, where no domain knowledge is required.",2101.04645v4,cs.LG,2021-01-12 18:07:34+00:00,"[arxiv.Result.Author('J. -P. Schulze'), arxiv.Result.Author('P. Sperl'), arxiv.Result.Author('K. Böttinger')]",
60,Blind proxy voting,"A secret ballot mechanism that enables voting in absence is proposed. It
amends standard vote collection methods that use ballot box as anonymizer,
adding the option for absent voters to vote by a proxy blinded to the content
of the ballot paper. Votes are cast under unique and hidden identification
numbers generated solely for the purpose of that election. Voters prepare their
ballot papers from scratch and submit them to the tallying authority in two
parts via separate routes, each part being meaningless without the other.",1812.11128v1,cs.CR,2018-12-28 17:41:13+00:00,[arxiv.Result.Author('Zuzana Haniková')],
61,Universal Voting Protocol Tweaks to Make Manipulation Hard,"Voting is a general method for preference aggregation in multiagent settings,
but seminal results have shown that all (nondictatorial) voting protocols are
manipulable. One could try to avoid manipulation by using voting protocols
where determining a beneficial manipulation is hard computationally. A number
of recent papers study the complexity of manipulating existing protocols. This
paper is the first work to take the next step of designing new protocols that
are especially hard to manipulate. Rather than designing these new protocols
from scratch, we instead show how to tweak existing protocols to make
manipulation hard, while leaving much of the original nature of the protocol
intact. The tweak studied consists of adding one elimination preround to the
election. Surprisingly, this extremely simple and universal tweak makes typical
protocols hard to manipulate! The protocols become NP-hard, #P-hard, or
PSPACE-hard to manipulate, depending on whether the schedule of the preround is
determined before the votes are collected, after the votes are collected, or
the scheduling and the vote collecting are interleaved, respectively. We prove
general sufficient conditions on the protocols for this tweak to introduce the
hardness, and show that the most common voting protocols satisfy those
conditions. These are the first results in voting settings where manipulation
is in a higher complexity class than NP (presuming PSPACE $\neq$ NP).",cs/0307018v1,cs.GT,2003-07-07 20:41:26+00:00,"[arxiv.Result.Author('Vincent Conitzer'), arxiv.Result.Author('Tuomas Sandholm')]","In Proceedings of the 18th International Joint Conference on
  Artificial Intelligence (IJCAI-03), Acapulco, Mexico, 2003"
62,"Improving OCR Accuracy on Early Printed Books by combining Pretraining, Voting, and Active Learning","We combine three methods which significantly improve the OCR accuracy of OCR
models trained on early printed books: (1) The pretraining method utilizes the
information stored in already existing models trained on a variety of typesets
(mixed models) instead of starting the training from scratch. (2) Performing
cross fold training on a single set of ground truth data (line images and their
transcriptions) with a single OCR engine (OCRopus) produces a committee whose
members then vote for the best outcome by also taking the top-N alternatives
and their intrinsic confidence values into account. (3) Following the principle
of maximal disagreement we select additional training lines which the voters
disagree most on, expecting them to offer the highest information gain for a
subsequent training (active learning). Evaluations on six early printed books
yielded the following results: On average the combination of pretraining and
voting improved the character accuracy by 46% when training five folds starting
from the same mixed model. This number rose to 53% when using different models
for pretraining, underlining the importance of diverse voters. Incorporating
active learning improved the obtained results by another 16% on average
(evaluated on three of the six books). Overall, the proposed methods lead to an
average error rate of 2.5% when training on only 60 lines. Using a substantial
ground truth pool of 1,000 lines brought the error rate down even further to
less than 1% on average.",1802.10038v2,cs.CV,2018-02-27 17:35:36+00:00,"[arxiv.Result.Author('Christian Reul'), arxiv.Result.Author('Uwe Springmann'), arxiv.Result.Author('Christoph Wick'), arxiv.Result.Author('Frank Puppe')]",
63,Image Inpainting by Multiscale Spline Interpolation,"Recovering the missing regions of an image is a task that is called image
inpainting. Depending on the shape of missing areas, different methods are
presented in the literature. One of the challenges of this problem is
extracting features that lead to better results. Experimental results show that
both global and local features are useful for this purpose. In this paper, we
propose a multi-scale image inpainting method that utilizes both local and
global features. The first step of this method is to determine how many scales
we need to use, which depends on the width of the lines in the map of the
missing region. Then we apply adaptive image inpainting to the damaged areas of
the image, and the lost pixels are predicted. Each scale is inpainted and the
result is resized to the original size. Then a voting process produces the
final result. The proposed method is tested on damaged images with scratches
and creases. The metric that we use to evaluate our approach is PSNR. On
average, we achieved 1.2 dB improvement over some existing inpainting
approaches.",2001.03270v1,cs.CV,2020-01-10 01:15:14+00:00,"[arxiv.Result.Author('Ghazale Ghorbanzade'), arxiv.Result.Author('Zahra Nabizadeh'), arxiv.Result.Author('Nader Karimi'), arxiv.Result.Author('Shadrokh Samavi')]",
64,Specialists Outperform Generalists in Ensemble Classification,"Consider an ensemble of $k$ individual classifiers whose accuracies are
known. Upon receiving a test point, each of the classifiers outputs a predicted
label and a confidence in its prediction for this particular test point. In
this paper, we address the question of whether we can determine the accuracy of
the ensemble. Surprisingly, even when classifiers are combined in the
statistically optimal way in this setting, the accuracy of the resulting
ensemble classifier cannot be computed from the accuracies of the individual
classifiers-as would be the case in the standard setting of confidence weighted
majority voting. We prove tight upper and lower bounds on the ensemble
accuracy. We explicitly construct the individual classifiers that attain the
upper and lower bounds: specialists and generalists. Our theoretical results
have very practical consequences: (1) If we use ensemble methods and have the
choice to construct our individual (independent) classifiers from scratch, then
we should aim for specialist classifiers rather than generalists. (2) Our
bounds can be used to determine how many classifiers are at least required to
achieve a desired ensemble accuracy. Finally, we improve our bounds by
considering the mutual information between the true label and the individual
classifier's output.",2107.04381v1,cs.LG,2021-07-09 12:16:10+00:00,"[arxiv.Result.Author('Sascha Meyen'), arxiv.Result.Author('Frieder Göppert'), arxiv.Result.Author('Helen Alber'), arxiv.Result.Author('Ulrike von Luxburg'), arxiv.Result.Author('Volker H. Franz')]",
65,Generating Single Peaked Votes,"We discuss how to generate singled peaked votes uniformly from the Impartial
Culture model.",1503.02766v1,cs.GT,2015-03-10 04:15:23+00:00,[arxiv.Result.Author('Toby Walsh')],
66,Normalized Range Voting Broadly Resists Control,"We study the behavior of Range Voting and Normalized Range Voting with
respect to electoral control. Electoral control encompasses attempts from an
election chair to alter the structure of an election in order to change the
outcome. We show that a voting system resists a case of control by proving that
performing that case of control is computationally infeasible. Range Voting is
a natural extension of approval voting, and Normalized Range Voting is a simple
variant which alters each vote to maximize the potential impact of each voter.
We show that Normalized Range Voting has among the largest number of control
resistances among natural voting systems.",1005.5698v3,cs.GT,2010-05-31 15:34:11+00:00,[arxiv.Result.Author('Curtis Menton')],
67,Strategic Voting Under Uncertainty About the Voting Method,"Much of the theoretical work on strategic voting makes strong assumptions
about what voters know about the voting situation. A strategizing voter is
typically assumed to know how other voters will vote and to know the rules of
the voting method. A growing body of literature explores strategic voting when
there is uncertainty about how others will vote. In this paper, we study
strategic voting when there is uncertainty about the voting method. We
introduce three notions of manipulability for a set of voting methods: sure,
safe, and expected manipulability. With the help of a computer program, we
identify voting scenarios in which uncertainty about the voting method may
reduce or even eliminate a voter's incentive to misrepresent her preferences.
Thus, it may be in the interest of an election designer who wishes to reduce
strategic voting to leave voters uncertain about which of several reasonable
voting methods will be used to determine the winners of an election.",1907.09110v1,cs.MA,2019-07-22 03:17:19+00:00,"[arxiv.Result.Author('Wesley H. Holliday'), arxiv.Result.Author('Eric Pacuit')]","EPTCS 297, 2019, pp. 252-272"
68,Vote Delegation and Misbehavior,"We study vote delegation with ""well-behaving"" and ""misbehaving"" agents and
compare it with conventional voting. Typical examples for vote delegation are
validation or governance tasks on blockchains. There is a majority of
well-behaving agents, but they may abstain or delegate their vote to other
agents since voting is costly. Misbehaving agents always vote. We compare
conventional voting allowing for abstention with vote delegation. Preferences
of voters are private information and a positive outcome is achieved if
well-behaving agents win. We illustrate that vote delegation leads to quite
different outcomes than conventional voting with abstention. In particular, we
obtain three insights: First, if the number of misbehaving voters, denoted by f
, is high, both voting methods fail to deliver a positive outcome. Second, if f
takes an intermediate value, conventional voting delivers a positive outcome,
while vote delegation fails with probability one. Third, if f is low,
delegation delivers a positive outcome with higher probability than
conventional voting. Finally, our results characterize worst-case outcomes that
can happen in a liquid democracy.",2102.08823v2,cs.GT,2021-02-17 15:32:32+00:00,"[arxiv.Result.Author('Hans Gersbach'), arxiv.Result.Author('Akaki Mamageishvili'), arxiv.Result.Author('Manvir Schneider')]",
69,Voting Power of Teams Working Together,"Voting power determines the ""power"" of individuals who cast votes; their
power is based on their ability to influence the winning-ness of a coalition.
Usually each individual acts alone, casting either all or none of their votes
and is equally likely to do either. This paper extends this standard ""random
voting"" model to allow probabilistic voting, partial voting, and correlated
team voting. We extend the standard Banzhaf metric to account for these cases;
our generalization reduces to the standard metric under ""random voting"", This
new paradigm allows us to answer questions such as ""In the 2013 US Senate, how
much more unified would the Republicans have to be in order to have the same
power as the Democrats in attaining cloture?""",1312.3394v1,cs.GT,2013-12-12 03:19:17+00:00,[arxiv.Result.Author('Daniel Zwillinger')],
70,The Computational Impact of Partial Votes on Strategic Voting,"In many real world elections, agents are not required to rank all candidates.
We study three of the most common methods used to modify voting rules to deal
with such partial votes. These methods modify scoring rules (like the Borda
count), elimination style rules (like single transferable vote) and rules based
on the tournament graph (like Copeland) respectively. We argue that with an
elimination style voting rule like single transferable vote, partial voting
does not change the situations where strategic voting is possible. However,
with scoring rules and rules based on the tournament graph, partial voting can
increase the situations where strategic voting is possible. As a consequence,
the computational complexity of computing a strategic vote can change. For
example, with Borda count, the complexity of computing a strategic vote can
decrease or stay the same depending on how we score partial votes.",1405.7714v1,cs.GT,2014-05-28 12:13:52+00:00,"[arxiv.Result.Author('Nina Narodytska'), arxiv.Result.Author('Toby Walsh')]",
71,FASTEN: Fair and Secure Distributed Voting Using Smart Contracts,"Electing democratic representatives via voting has been a common mechanism
since the 17th century. However, these mechanisms raise concerns about
fairness, privacy, vote concealment, fair calculations of tally, and proxies
voting on their behalf for the voters. Ballot voting, and in recent times,
electronic voting via electronic voting machines (EVMs) improves fairness by
relying on centralized trust. Homomorphic encryption-based voting protocols
also assure fairness but cannot scale to large scale elections such as
presidential elections. In this paper, we leverage the blockchain technology of
distributing trust to propose a smart contract-based protocol, namely, \proto.
There are many existing protocols for voting using smart contracts. We observe
that these either are not scalable or leak the vote tally during the voting
stage, i.e., do not provide vote concealment. In contrast, we show that FASTEN
preserves voter's privacy ensures vote concealment, immutability, and avoids
double voting. We prove that the probability of privacy breaches is negligibly
small. Further, our cost analysis of executing FASTEN over Ethereum is
comparable to most of the existing cost of elections.",2102.10594v1,cs.CR,2021-02-21 12:29:23+00:00,"[arxiv.Result.Author('Sankarshan Damle'), arxiv.Result.Author('Sujit Gujar'), arxiv.Result.Author('Moin Hussain Moti')]",
72,Exploring Weak Strategy-Proofness in Voting Theory,"Voting is the aggregation of individual preferences in order to select a
winning alternative. Selection of a winner is accomplished via a voting rule,
e.g., rank-order voting, majority rule, plurality rule, approval voting. Which
voting rule should be used? In social choice theory, desirable properties of
voting rules are expressed as axioms to be satisfied. This thesis focuses on
axioms concerning strategic manipulation by voters. Sometimes, voters may
intentionally misstate their true preferences in order to alter the outcome for
their own advantage. For example, in plurality rule, if a voter knows that
their top-choice candidate will lose, then they might instead vote for their
second-choice candidate just to avoid an even less desirable result. When no
coalition of voters can strategically manipulate, then the voting rule is said
to satisfy the axiom of Strategy-Proofness. A less restrictive axiom is Weak
Strategy-Proofness (as defined by Dasgupta and Maskin (2019)), which allows for
strategic manipulation by all but the smallest coalitions. Under certain
intuitive conditions, Dasgupta and Maskin (2019) proved that the only voting
rules satisfying Strategy-Proofness are rank-order voting and majority rule. In
my thesis, I generalize their result, by proving that rank-order voting and
majority rule are surprisingly still the only voting rules satisfying Weak
Strategy-Proofness.",2005.07521v1,econ.TH,2020-05-13 19:53:08+00:00,[arxiv.Result.Author('Anne Carlstein')],
73,Designing Stable Elections: A Survey,"We survey the design of elections that are resilient to attempted
interference by third parties. For example, suppose votes have been cast in an
election between two candidates, and then each vote is randomly changed with a
small probability, independently of the other votes. It is desirable to keep
the outcome of the election the same, regardless of the changes to the votes.
It is well known that the US electoral college system is about 5 times more
likely to have a changed outcome due to vote corruption, when compared to a
majority vote. In fact, Mossel, O'Donnell and Oleszkiewicz proved in 2005 that
the majority voting method is most stable to this random vote corruption, among
voting methods where each person has a small influence on the election. We
discuss some recent progress on the analogous result for elections between more
than two candidates. In this case, plurality should be most stable to
corruption in votes. We also survey results on adversarial election
manipulation (where an adversary can select particular votes to change, perhaps
in a non-random way), and we briefly discuss ranked choice voting methods
(where a vote is a ranked list of candidates).",2006.05460v2,math.PR,2020-06-09 18:59:48+00:00,[arxiv.Result.Author('Steven Heilman')],
74,Mixed Model OCR Training on Historical Latin Script for Out-of-the-Box Recognition and Finetuning,"In order to apply Optical Character Recognition (OCR) to historical printings
of Latin script fully automatically, we report on our efforts to construct a
widely-applicable polyfont recognition model yielding text with a Character
Error Rate (CER) around 2% when applied out-of-the-box. Moreover, we show how
this model can be further finetuned to specific classes of printings with
little manual and computational effort. The mixed or polyfont model is trained
on a wide variety of materials, in terms of age (from the 15th to the 19th
century), typography (various types of Fraktur and Antiqua), and languages
(among others, German, Latin, and French). To optimize the results we combined
established techniques of OCR training like pretraining, data augmentation, and
voting. In addition, we used various preprocessing methods to enrich the
training data and obtain more robust models. We also implemented a two-stage
approach which first trains on all available, considerably unbalanced data and
then refines the output by training on a selected more balanced subset.
Evaluations on 29 previously unseen books resulted in a CER of 1.73%,
outperforming a widely used standard model with a CER of 2.84% by almost 40%.
Training a more specialized model for some unseen Early Modern Latin books
starting from our mixed model led to a CER of 1.47%, an improvement of up to
50% compared to training from scratch and up to 30% compared to training from
the aforementioned standard model. Our new mixed model is made openly available
to the community.",2106.07881v1,cs.CV,2021-06-15 04:51:54+00:00,"[arxiv.Result.Author('Christian Reul'), arxiv.Result.Author('Christoph Wick'), arxiv.Result.Author('Maximilian Nöth'), arxiv.Result.Author('Andreas Büttner'), arxiv.Result.Author('Maximilian Wehner'), arxiv.Result.Author('Uwe Springmann')]",
75,Vulnerability analysis of three remote voting methods,"This article analyses three methods of remote voting in an uncontrolled
environment: postal voting, internet voting and hybrid voting. It breaks down
the voting process into different stages and compares their vulnerabilities
considering criteria that must be respected in any democratic vote:
confidentiality, anonymity, transparency, vote unicity and authenticity.
Whether for safety or reliability, each vulnerability is quantified by three
parameters: size, visibility and difficulty to achieve. The study concludes
that the automatisation of treatments combined with the dematerialisation of
the objects used during an election tends to substitute visible vulnerabilities
of a lesser magnitude by invisible and widespread vulnerabilities.",0908.1059v1,cs.CY,2009-08-07 14:02:40+00:00,"[arxiv.Result.Author('Chantal Enguehard'), arxiv.Result.Author('Rémi Lehn')]","XXI IPSA World Congress of Political Science, RC10 Electronic
  Democracy - Dilemmas of Change?, Santiago : Chile (2009)"
76,Equation of States for Elections,"In the US 2008 presidential election, Barack Obama was elected as the 44th
president of United States, winning the 53% of popular votes and 68% of
electoral votes; in the election of 2000, Al Gore lost the election receiving
49 % of electoral votes, although he had more popular votes. It is generally
believed that the electoral votes and the popular votes are correlated; however
the detailed quantitative relationship for these two quantities is unclear.
Here, we found an interesting relationship between fractions of electoral votes
and fractions of popular votes in the presidential elections of the United
States by examining the election results from 1932 to 2004. Moreover, this
curve could provide an interesting explanation for the results of other
elections that have taken place in Taiwan.",1211.1825v1,physics.soc-ph,2012-11-08 10:59:50+00:00,[arxiv.Result.Author('Bih-Yaw Jin')],
77,"Voting power and Qualified Majority Voting with a ""no vote"" option","In recent years, enlargement of the European Union has led to increased
interest in the allocation of voting weights to member states with hugely
differing population numbers. While the eventually agreed voting scheme lacks
any strict mathematical basis, the Polish government suggested a voting scheme
based on the Penrose definition of voting power, leading to an allocation of
voting weights proportional to the square root of the population (the
""Jagiellonian Compromise""). The Penrose definition of voting power is derived
from the citizens' freedom to vote either ""yes"" or ""no"". This paper defines a
corresponding voting power based on ""yes"", ""no"" and ""abstain"" options, and it
is found that this definition also leads to a square root law, and to the same
optimal vote allocation as the Penrose scheme.",0805.3251v2,math.GM,2008-05-21 10:57:28+00:00,[arxiv.Result.Author('Martin Kurth')],
78,Transparent Voting Platform Based on Permissioned Blockchain,"Since 2004, different research was handling the challenges in the centralized
voting systems, e-voting protocols and recently the decentralized voting. So
electronic voting puts forward some difficulties regarding the voter anonymity,
the secure casting of the votes and to prevent the voting process from
frauding. The Decentralized property of the technology called ""blockchain""
could have the solution for many of the challenges in voting research area and
brings a new secure mechanism of safe and transparent voting. In this paper, a
broad comparison between ongoing voting systems has studied by analyzing their
structure and the drawbacks that should consider in future to improve the whole
election process from keeping the privacy of the voter, casting a vote with the
possibility to check if it was counted correctly to publishing the results. The
result of the paper will give a new approach to extend the target of the
election from small scale to large scale despite the fact of Ethereum
limitation which can cast on the blockchain just five votes per minute. The
primary challenge is to find an answer for this question: ""How to balance
between voter privacy and transparency without breaking the important rule
where the voter can proof for a specific candidate that he voted for him in a
bribe situation?"".",1802.10134v1,cs.CY,2018-02-22 14:20:35+00:00,[arxiv.Result.Author('Nazim Faour')],
79,Distributed Voting/Ranking with Optimal Number of States per Node,"Considering a network with $n$ nodes, where each node initially votes for one
(or more) choices out of $K$ possible choices, we present a Distributed
Multi-choice Voting/Ranking (DMVR) algorithm to determine either the choice
with maximum vote (the voting problem) or to rank all the choices in terms of
their acquired votes (the ranking problem). The algorithm consolidates node
votes across the network by updating the states of interacting nodes using two
key operations, the union and the intersection. The proposed algorithm is
simple, independent from network size, and easily scalable in terms of the
number of choices $K$, using only $K\times 2^{K-1}$ nodal states for voting,
and $K\times K!$ nodal states for ranking. We prove the number of states to be
optimal in the ranking case, this optimality is conjectured to also apply to
the voting case. The time complexity of the algorithm is analyzed in complete
graphs. We show that the time complexity for both ranking and voting is
$O(\log(n))$ for given vote percentages, and is inversely proportional to the
minimum of the vote percentage differences among various choices.",1703.08838v1,cs.DC,2017-03-26 16:19:31+00:00,"[arxiv.Result.Author('Saber Salehkaleybar'), arxiv.Result.Author('Arsalan Sharif-Nassab'), arxiv.Result.Author('S. Jamaloddin Golestani')]",
80,Blind proxy voting,"A secret ballot mechanism that enables voting in absence is proposed. It
amends standard vote collection methods that use ballot box as anonymizer,
adding the option for absent voters to vote by a proxy blinded to the content
of the ballot paper. Votes are cast under unique and hidden identification
numbers generated solely for the purpose of that election. Voters prepare their
ballot papers from scratch and submit them to the tallying authority in two
parts via separate routes, each part being meaningless without the other.",1812.11128v1,cs.CR,2018-12-28 17:41:13+00:00,[arxiv.Result.Author('Zuzana Haniková')],
81,Universal Voting Protocol Tweaks to Make Manipulation Hard,"Voting is a general method for preference aggregation in multiagent settings,
but seminal results have shown that all (nondictatorial) voting protocols are
manipulable. One could try to avoid manipulation by using voting protocols
where determining a beneficial manipulation is hard computationally. A number
of recent papers study the complexity of manipulating existing protocols. This
paper is the first work to take the next step of designing new protocols that
are especially hard to manipulate. Rather than designing these new protocols
from scratch, we instead show how to tweak existing protocols to make
manipulation hard, while leaving much of the original nature of the protocol
intact. The tweak studied consists of adding one elimination preround to the
election. Surprisingly, this extremely simple and universal tweak makes typical
protocols hard to manipulate! The protocols become NP-hard, #P-hard, or
PSPACE-hard to manipulate, depending on whether the schedule of the preround is
determined before the votes are collected, after the votes are collected, or
the scheduling and the vote collecting are interleaved, respectively. We prove
general sufficient conditions on the protocols for this tweak to introduce the
hardness, and show that the most common voting protocols satisfy those
conditions. These are the first results in voting settings where manipulation
is in a higher complexity class than NP (presuming PSPACE $\neq$ NP).",cs/0307018v1,cs.GT,2003-07-07 20:41:26+00:00,"[arxiv.Result.Author('Vincent Conitzer'), arxiv.Result.Author('Tuomas Sandholm')]","In Proceedings of the 18th International Joint Conference on
  Artificial Intelligence (IJCAI-03), Acapulco, Mexico, 2003"
82,Proxy Voting for Better Outcomes,"We consider a social choice problem where only a small number of people out
of a large population are sufficiently available or motivated to vote. A common
solution to increase participation is to allow voters use a proxy, that is,
transfer their voting rights to another voter. Considering social choice
problems on metric spaces, we compare voting with and without the use of
proxies to see which mechanism better approximates the optimal outcome, and
characterize the regimes in which proxy voting is beneficial. When voters'
opinions are located on an interval, both the median mechanism and the mean
mechanism are substantially improved by proxy voting. When voters vote on many
binary issues, proxy voting is better when the sample of active voters is too
small to provide a good outcome. Our theoretical results extend to situations
where available voters choose strategically whether to participate. We support
our theoretical findings with empirical results showing substantial benefits of
proxy voting on simulated and real preference data.",1611.08308v1,cs.GT,2016-11-24 21:05:50+00:00,"[arxiv.Result.Author('Gal Cohensius'), arxiv.Result.Author('Shie Manor'), arxiv.Result.Author('Reshef Meir'), arxiv.Result.Author('Eli Meirom'), arxiv.Result.Author('Ariel Orda')]",
83,"Improving OCR Accuracy on Early Printed Books by combining Pretraining, Voting, and Active Learning","We combine three methods which significantly improve the OCR accuracy of OCR
models trained on early printed books: (1) The pretraining method utilizes the
information stored in already existing models trained on a variety of typesets
(mixed models) instead of starting the training from scratch. (2) Performing
cross fold training on a single set of ground truth data (line images and their
transcriptions) with a single OCR engine (OCRopus) produces a committee whose
members then vote for the best outcome by also taking the top-N alternatives
and their intrinsic confidence values into account. (3) Following the principle
of maximal disagreement we select additional training lines which the voters
disagree most on, expecting them to offer the highest information gain for a
subsequent training (active learning). Evaluations on six early printed books
yielded the following results: On average the combination of pretraining and
voting improved the character accuracy by 46% when training five folds starting
from the same mixed model. This number rose to 53% when using different models
for pretraining, underlining the importance of diverse voters. Incorporating
active learning improved the obtained results by another 16% on average
(evaluated on three of the six books). Overall, the proposed methods lead to an
average error rate of 2.5% when training on only 60 lines. Using a substantial
ground truth pool of 1,000 lines brought the error rate down even further to
less than 1% on average.",1802.10038v2,cs.CV,2018-02-27 17:35:36+00:00,"[arxiv.Result.Author('Christian Reul'), arxiv.Result.Author('Uwe Springmann'), arxiv.Result.Author('Christoph Wick'), arxiv.Result.Author('Frank Puppe')]",
84,Enhancing Engagement in Token-Curated Registries via an Inflationary Mechanism,"Token Curated Registries (TCR) are decentralized recommendation systems that
can be implemented using Blockchain smart contracts. They allow participants to
vote for or against adding items to a list through a process that involves
staking tokens intrinsic to the registry, with winners receiving the staked
tokens for each vote. A TCR aims to provide incentives to create a well-curated
list. In this work, we consider a challenge for these systems - incentivizing
token-holders to actually engage and participate in the voting process. We
propose a novel token-inflation mechanism for enhancing engagement, whereby
only voting participants see their token supply increased by a pre-defined
multiple after each round of voting. To evaluate this proposal, we propose a
simple 4-class model of voters that captures all possible combinations of two
key dimensions: whether they are engaged (likely to vote at all for a given
item) or disengaged, and whether they are informed (likely to vote in a way
that increases the quality of the list) or uninformed, and a simple metric to
evaluate the quality of the list as a function of the vote outcomes. We conduct
simulations using this model of voters and show that implementing
token-inflation results in greater wealth accumulation for engaged voters. In
particular, when the number of informed voters is sufficiently high, our
simulations show that voters that are both informed and engaged see the
greatest benefits from participating in the registry when our proposed
token-inflation mechanism is employed. We further validate this finding using a
simplified mathematical analysis.",1811.09680v1,cs.GT,2018-11-23 20:51:13+00:00,"[arxiv.Result.Author('Yi Lucy Wang'), arxiv.Result.Author('Bhaskar Krishnamachari')]",
85,Measuring Violations of Positive Involvement in Voting,"In the context of computational social choice, we study voting methods that
assign a set of winners to each profile of voter preferences. A voting method
satisfies the property of positive involvement (PI) if for any election in
which a candidate x would be among the winners, adding another voter to the
election who ranks x first does not cause x to lose. Surprisingly, a number of
standard voting methods violate this natural property. In this paper, we
investigate different ways of measuring the extent to which a voting method
violates PI, using computer simulations. We consider the probability (under
different probability models for preferences) of PI violations in randomly
drawn profiles vs. profile-coalition pairs (involving coalitions of different
sizes). We argue that in order to choose between a voting method that satisfies
PI and one that does not, we should consider the probability of PI violation
conditional on the voting methods choosing different winners. We should also
relativize the probability of PI violation to what we call voter potency, the
probability that a voter causes a candidate to lose. Although absolute
frequencies of PI violations may be low, after this conditioning and
relativization, we see that under certain voting methods that violate PI, much
of a voter's potency is turned against them - in particular, against their
desire to see their favorite candidate elected.",2106.11502v1,cs.GT,2021-06-22 02:46:37+00:00,"[arxiv.Result.Author('Wesley H. Holliday'), arxiv.Result.Author('Eric Pacuit')]","EPTCS 335, 2021, pp. 189-209"
86,Image Inpainting by Multiscale Spline Interpolation,"Recovering the missing regions of an image is a task that is called image
inpainting. Depending on the shape of missing areas, different methods are
presented in the literature. One of the challenges of this problem is
extracting features that lead to better results. Experimental results show that
both global and local features are useful for this purpose. In this paper, we
propose a multi-scale image inpainting method that utilizes both local and
global features. The first step of this method is to determine how many scales
we need to use, which depends on the width of the lines in the map of the
missing region. Then we apply adaptive image inpainting to the damaged areas of
the image, and the lost pixels are predicted. Each scale is inpainted and the
result is resized to the original size. Then a voting process produces the
final result. The proposed method is tested on damaged images with scratches
and creases. The metric that we use to evaluate our approach is PSNR. On
average, we achieved 1.2 dB improvement over some existing inpainting
approaches.",2001.03270v1,cs.CV,2020-01-10 01:15:14+00:00,"[arxiv.Result.Author('Ghazale Ghorbanzade'), arxiv.Result.Author('Zahra Nabizadeh'), arxiv.Result.Author('Nader Karimi'), arxiv.Result.Author('Shadrokh Samavi')]",
87,Specialists Outperform Generalists in Ensemble Classification,"Consider an ensemble of $k$ individual classifiers whose accuracies are
known. Upon receiving a test point, each of the classifiers outputs a predicted
label and a confidence in its prediction for this particular test point. In
this paper, we address the question of whether we can determine the accuracy of
the ensemble. Surprisingly, even when classifiers are combined in the
statistically optimal way in this setting, the accuracy of the resulting
ensemble classifier cannot be computed from the accuracies of the individual
classifiers-as would be the case in the standard setting of confidence weighted
majority voting. We prove tight upper and lower bounds on the ensemble
accuracy. We explicitly construct the individual classifiers that attain the
upper and lower bounds: specialists and generalists. Our theoretical results
have very practical consequences: (1) If we use ensemble methods and have the
choice to construct our individual (independent) classifiers from scratch, then
we should aim for specialist classifiers rather than generalists. (2) Our
bounds can be used to determine how many classifiers are at least required to
achieve a desired ensemble accuracy. Finally, we improve our bounds by
considering the mutual information between the true label and the individual
classifier's output.",2107.04381v1,cs.LG,2021-07-09 12:16:10+00:00,"[arxiv.Result.Author('Sascha Meyen'), arxiv.Result.Author('Frieder Göppert'), arxiv.Result.Author('Helen Alber'), arxiv.Result.Author('Ulrike von Luxburg'), arxiv.Result.Author('Volker H. Franz')]",
88,A practical multi-party computation algorithm for a secure distributed online voting system,"We present an online voting architecture based on partitioning the election
in small clusters of voters and using a new Multi-party Computation algorithm
for obtaining voting results from the clusters. This new algorithm has some
practical advantages over other previously known algorithms and isn't bound to
any specific cryptographic concept; so it can be adapted to future
cryptographic exigencies. Compared with other online voting technologies, we
see that this new architecture is less vulnerable to hacker attacks and attacks
from dishonest authorities, given that no sensitive information is stored in
any public server and there is no need for any trustee to safeguard the
legality of the election process. Even in case of an attack succeeding, the
risks associated with the overall election are far lower than with any other
voting system. This architecture can also be combined with any other voting
system, inheriting advantages from both systems.",1603.04228v1,cs.CR,2016-03-14 12:10:47+00:00,[arxiv.Result.Author('Juanjo Bermúdez')],
89,VoteAgain: A scalable coercion-resistant voting system,"The strongest threat model for voting systems considers coercion resistance:
protection against coercers that force voters to modify their votes, or to
abstain. Existing remote voting systems either do not provide this property;
require an expensive tallying phase; or burden users with the need to store
cryptographic key material and with the responsibility to deceive their
coercers. We propose VoteAgain, a scalable voting scheme that relies on the
revoting paradigm to provide coercion resistance. VoteAgain uses a novel
deterministic ballot padding mechanism to ensure that coercers cannot see
whether a vote has been replaced. This mechanism ensures tallies take
quasilinear time, making VoteAgain the first revoting scheme that can handle
elections with millions of voters. We prove that VoteAgain provides ballot
privacy, coercion resistance, and verifiability; and we demonstrate its
scalability using a prototype implementation of all cryptographic primitives.",2005.11189v3,cs.CR,2020-05-22 13:51:34+00:00,"[arxiv.Result.Author('Wouter Lueks'), arxiv.Result.Author('Iñigo Querejeta-Azurmendi'), arxiv.Result.Author('Carmela Troncoso')]",
90,Proportionality and Strategyproofness in Multiwinner Elections,"Multiwinner voting rules can be used to select a fixed-size committee from a
larger set of candidates. We consider approval-based committee rules, which
allow voters to approve or disapprove candidates. In this setting, several
voting rules such as Proportional Approval Voting (PAV) and Phragm\'en's rules
have been shown to produce committees that are proportional, in the sense that
they proportionally represent voters' preferences; all of these rules are
strategically manipulable by voters. On the other hand, a generalisation of
Approval Voting gives a non-proportional but strategyproof voting rule. We show
that there is a fundamental tradeoff between these two properties: we prove
that no multiwinner voting rule can simultaneously satisfy a weak form of
proportionality (a weakening of justified representation) and a weak form of
strategyproofness. Our impossibility is obtained using a formulation of the
problem in propositional logic and applying SAT solvers; a human-readable
version of the computer-generated proof is obtained by extracting a minimal
unsatisfiable set (MUS). We also discuss several related axiomatic questions in
the domain of committee elections.",2104.08594v1,cs.GT,2021-04-17 16:40:45+00:00,[arxiv.Result.Author('Dominik Peters')],
91,Generating Single Peaked Votes,"We discuss how to generate singled peaked votes uniformly from the Impartial
Culture model.",1503.02766v1,cs.GT,2015-03-10 04:15:23+00:00,[arxiv.Result.Author('Toby Walsh')],
92,Normalized Range Voting Broadly Resists Control,"We study the behavior of Range Voting and Normalized Range Voting with
respect to electoral control. Electoral control encompasses attempts from an
election chair to alter the structure of an election in order to change the
outcome. We show that a voting system resists a case of control by proving that
performing that case of control is computationally infeasible. Range Voting is
a natural extension of approval voting, and Normalized Range Voting is a simple
variant which alters each vote to maximize the potential impact of each voter.
We show that Normalized Range Voting has among the largest number of control
resistances among natural voting systems.",1005.5698v3,cs.GT,2010-05-31 15:34:11+00:00,[arxiv.Result.Author('Curtis Menton')],
93,Strategic Voting Under Uncertainty About the Voting Method,"Much of the theoretical work on strategic voting makes strong assumptions
about what voters know about the voting situation. A strategizing voter is
typically assumed to know how other voters will vote and to know the rules of
the voting method. A growing body of literature explores strategic voting when
there is uncertainty about how others will vote. In this paper, we study
strategic voting when there is uncertainty about the voting method. We
introduce three notions of manipulability for a set of voting methods: sure,
safe, and expected manipulability. With the help of a computer program, we
identify voting scenarios in which uncertainty about the voting method may
reduce or even eliminate a voter's incentive to misrepresent her preferences.
Thus, it may be in the interest of an election designer who wishes to reduce
strategic voting to leave voters uncertain about which of several reasonable
voting methods will be used to determine the winners of an election.",1907.09110v1,cs.MA,2019-07-22 03:17:19+00:00,"[arxiv.Result.Author('Wesley H. Holliday'), arxiv.Result.Author('Eric Pacuit')]","EPTCS 297, 2019, pp. 252-272"
94,Vote Delegation and Misbehavior,"We study vote delegation with ""well-behaving"" and ""misbehaving"" agents and
compare it with conventional voting. Typical examples for vote delegation are
validation or governance tasks on blockchains. There is a majority of
well-behaving agents, but they may abstain or delegate their vote to other
agents since voting is costly. Misbehaving agents always vote. We compare
conventional voting allowing for abstention with vote delegation. Preferences
of voters are private information and a positive outcome is achieved if
well-behaving agents win. We illustrate that vote delegation leads to quite
different outcomes than conventional voting with abstention. In particular, we
obtain three insights: First, if the number of misbehaving voters, denoted by f
, is high, both voting methods fail to deliver a positive outcome. Second, if f
takes an intermediate value, conventional voting delivers a positive outcome,
while vote delegation fails with probability one. Third, if f is low,
delegation delivers a positive outcome with higher probability than
conventional voting. Finally, our results characterize worst-case outcomes that
can happen in a liquid democracy.",2102.08823v2,cs.GT,2021-02-17 15:32:32+00:00,"[arxiv.Result.Author('Hans Gersbach'), arxiv.Result.Author('Akaki Mamageishvili'), arxiv.Result.Author('Manvir Schneider')]",
95,Emergence of scale invariance and efficiency in a racetrack betting market,"We study the time change of the relation between the rank of a racehorse in
the Japan Racing Association and the result of victory or defeat. Horses are
ranked according to the win bet fractions. As the vote progresses, the
racehorses are mixed on the win bet fraction axis. We see the emergence of a
scale invariant relation between the cumulative distribution function of the
winning horse $x_{1}$ and that of the losing horse $x_{0}$. $x_{1}\propto
x_{0}^{\alpha}$ holds in the small win bet fraction region. We also see the
efficiency of the market as the vote proceeds. However, the convergence to the
efficient state is not monotonic. The time change of the distribution of a vote
is complicated. Votes resume concentration on popular horses, after the
distribution spreads to a certain extent. In order to explain scale invariance,
we introduce a simple voting model. In a `double' scaling limit, we show that
the exact scale invariance relation $x_{1}=x_{0}^{\alpha}$ holds over the
entire range $0\le x_{0},x_{1}\le 1$.",0911.3249v1,physics.soc-ph,2009-11-17 10:16:29+00:00,"[arxiv.Result.Author('Shintaro Mori'), arxiv.Result.Author('Masato Hisakado')]",
96,Sincere-Strategy Preference-Based Approval Voting Fully Resists Constructive Control and Broadly Resists Destructive Control,"We study sincere-strategy preference-based approval voting (SP-AV), a system
proposed by Brams and Sanver [Electoral Studies, 25(2):287-305, 2006], and here
adjusted so as to coerce admissibility of the votes (rather than excluding
inadmissible votes a priori), with respect to procedural control. In such
control scenarios, an external agent seeks to change the outcome of an election
via actions such as adding/deleting/partitioning either candidates or voters.
SP-AV combines the voters' preference rankings with their approvals of
candidates, where in elections with at least two candidates the voters'
approval strategies are adjusted--if needed--to approve of their most-preferred
candidate and to disapprove of their least-preferred candidate. This rule
coerces admissibility of the votes even in the presence of control actions, and
hybridizes, in effect, approval with pluralitiy voting.
  We prove that this system is computationally resistant (i.e., the
corresponding control problems are NP-hard) to 19 out of 22 types of
constructive and destructive control. Thus, SP-AV has more resistances to
control than is currently known for any other natural voting system with a
polynomial-time winner problem. In particular, SP-AV is (after Copeland voting,
see Faliszewski et al. [AAIM-2008, Springer LNCS 5034, pp. 165-176, 2008]) the
second natural voting system with an easy winner-determination procedure that
is known to have full resistance to constructive control, and unlike Copeland
voting it in addition displays broad resistance to destructive control.",0806.0535v5,cs.GT,2008-06-03 13:27:16+00:00,"[arxiv.Result.Author('Gabor Erdelyi'), arxiv.Result.Author('Markus Nowak'), arxiv.Result.Author('Joerg Rothe')]",
97,Voting Power of Teams Working Together,"Voting power determines the ""power"" of individuals who cast votes; their
power is based on their ability to influence the winning-ness of a coalition.
Usually each individual acts alone, casting either all or none of their votes
and is equally likely to do either. This paper extends this standard ""random
voting"" model to allow probabilistic voting, partial voting, and correlated
team voting. We extend the standard Banzhaf metric to account for these cases;
our generalization reduces to the standard metric under ""random voting"", This
new paradigm allows us to answer questions such as ""In the 2013 US Senate, how
much more unified would the Republicans have to be in order to have the same
power as the Democrats in attaining cloture?""",1312.3394v1,cs.GT,2013-12-12 03:19:17+00:00,[arxiv.Result.Author('Daniel Zwillinger')],
98,The Computational Impact of Partial Votes on Strategic Voting,"In many real world elections, agents are not required to rank all candidates.
We study three of the most common methods used to modify voting rules to deal
with such partial votes. These methods modify scoring rules (like the Borda
count), elimination style rules (like single transferable vote) and rules based
on the tournament graph (like Copeland) respectively. We argue that with an
elimination style voting rule like single transferable vote, partial voting
does not change the situations where strategic voting is possible. However,
with scoring rules and rules based on the tournament graph, partial voting can
increase the situations where strategic voting is possible. As a consequence,
the computational complexity of computing a strategic vote can change. For
example, with Borda count, the complexity of computing a strategic vote can
decrease or stay the same depending on how we score partial votes.",1405.7714v1,cs.GT,2014-05-28 12:13:52+00:00,"[arxiv.Result.Author('Nina Narodytska'), arxiv.Result.Author('Toby Walsh')]",
99,FASTEN: Fair and Secure Distributed Voting Using Smart Contracts,"Electing democratic representatives via voting has been a common mechanism
since the 17th century. However, these mechanisms raise concerns about
fairness, privacy, vote concealment, fair calculations of tally, and proxies
voting on their behalf for the voters. Ballot voting, and in recent times,
electronic voting via electronic voting machines (EVMs) improves fairness by
relying on centralized trust. Homomorphic encryption-based voting protocols
also assure fairness but cannot scale to large scale elections such as
presidential elections. In this paper, we leverage the blockchain technology of
distributing trust to propose a smart contract-based protocol, namely, \proto.
There are many existing protocols for voting using smart contracts. We observe
that these either are not scalable or leak the vote tally during the voting
stage, i.e., do not provide vote concealment. In contrast, we show that FASTEN
preserves voter's privacy ensures vote concealment, immutability, and avoids
double voting. We prove that the probability of privacy breaches is negligibly
small. Further, our cost analysis of executing FASTEN over Ethereum is
comparable to most of the existing cost of elections.",2102.10594v1,cs.CR,2021-02-21 12:29:23+00:00,"[arxiv.Result.Author('Sankarshan Damle'), arxiv.Result.Author('Sujit Gujar'), arxiv.Result.Author('Moin Hussain Moti')]",
100,Optical Inspection of the Silicon Micro-strip Sensors for the CBM Experiment employing Artificial Intelligence,"Optical inspection of 1191 silicon micro-strip sensors was performed using a
custom made optical inspection setup, employing a machine-learning based
approach for the defect analysis and subsequent quality assurance. Furthermore,
metrological control of the sensor's surface was performed. In this manuscript,
we present the analysis of various sensor surface defects. Among these are
implant breaks, p-stop breaks, aluminium strip opens, aluminium strip shorts,
surface scratches, double metallization layer defects, passivation layer
defects, bias resistor defects as well as dust particle identification. The
defect detection was done using the application of Convolutional Deep Neural
Networks (CDNNs). From this, defective strips and defect clusters were
identified, as well as a 2D map of the defects using their geometrical
positions on the sensor was performed. Based on the total number of defects
found on the sensor's surface, a method for the estimation of sensor's overall
quality grade and quality score was proposed.",2107.07714v2,physics.ins-det,2021-07-16 05:48:22+00:00,"[arxiv.Result.Author('E. Lavrik'), arxiv.Result.Author('M. Shiroya'), arxiv.Result.Author('H. R. Schmidt'), arxiv.Result.Author('A. Toia'), arxiv.Result.Author('J. M. Heuser')]",
101,Learning Domain-Independent Planning Heuristics with Hypergraph Networks,"We present the first approach capable of learning domain-independent planning
heuristics entirely from scratch. The heuristics we learn map the hypergraph
representation of the delete-relaxation of the planning problem at hand, to a
cost estimate that approximates that of the least-cost path from the current
state to the goal through the hypergraph. We generalise Graph Networks to
obtain a new framework for learning over hypergraphs, which we specialise to
learn planning heuristics by training over state/value pairs obtained from
optimal cost plans. Our experiments show that the resulting architecture,
STRIPS-HGNs, is capable of learning heuristics that are competitive with
existing delete-relaxation heuristics including LM-cut. We show that the
heuristics we learn are able to generalise across different problems and
domains, including to domains that were not seen during training.",1911.13101v1,cs.AI,2019-11-29 13:24:48+00:00,"[arxiv.Result.Author('William Shen'), arxiv.Result.Author('Felipe Trevizan'), arxiv.Result.Author('Sylvie Thiébaux')]",
102,Elastic strips,"Motivated by the problem of finding an explicit description of a developable
narrow Moebius strip of minimal bending energy, which was first formulated by
M. Sadowsky in 1930, we will develop the theory of elastic strips. Recently
E.L. Starostin and G.H.M. van der Heijden found a numerical description for an
elastic Moebius strip, but did not give an integrable solution. We derive two
conservation laws, which describe the equilibrium equations of elastic strips.
In applying these laws we find two new classes of integrable elastic strips
which correspond to spherical elastic curves. We establish a connection between
Hopf tori and force--free strips, which are defined by one of the integrable
strips, we have found. We introduce the P--functional and relate it to elastic
strips.",1001.4025v1,math.DG,2010-01-22 15:52:44+00:00,"[arxiv.Result.Author('David Chubelaschwili'), arxiv.Result.Author('Ulrich Pinkall')]",
103,A longitudinal dataset of five years of public activity in the Scratch online community,"Scratch is a programming environment and an online community where young
people can create, share, learn, and communicate. In collaboration with the
Scratch Team at MIT, we created a longitudinal dataset of public activity in
the Scratch online community during its first five years (2007-2012). The
dataset comprises 32 tables with information on more than 1 million Scratch
users, nearly 2 million Scratch projects, more than 10 million comments, more
than 30 million visits to Scratch projects, and more. To help researchers
understand this dataset, and to establish the validity of the data, we also
include the source code of every version of the software that operated the
website, as well as the software used to generate this dataset. We believe this
is the largest and most comprehensive downloadable dataset of youth programming
artifacts and communication.",1702.01184v1,cs.CY,2017-02-03 22:02:24+00:00,"[arxiv.Result.Author('Benjamin Mako Hill'), arxiv.Result.Author('Andrés Monroy-Hernández')]","Scientific Data 4, Article number: 170002, 2017"
104,Search-based Testing for Scratch Programs,"Block-based programming languages enable young learners to quickly implement
fun programs and games. The Scratch programming environment is particularly
successful at this, with more than 50 million registered users at the time of
this writing. Although Scratch simplifies creating syntactically correct
programs, learners and educators nevertheless frequently require feedback and
support. Dynamic program analysis could enable automation of this support, but
the test suites necessary for dynamic analysis do not usually exist for Scratch
programs. It is, however, possible to cast test generation for Scratch as a
search problem. In this paper, we introduce an approach for automatically
generating test suites for Scratch programs using grammatical evolution. The
use of grammatical evolution clearly separates the search encoding from
framework-specific implementation details, and allows us to use advanced test
acceleration techniques. We implemented our approach as an extension of the
Whisker test framework. Evaluation on sample Scratch programs demonstrates the
potential of the approach.",2009.04115v1,cs.SE,2020-09-09 05:59:31+00:00,"[arxiv.Result.Author('Adina Deiner'), arxiv.Result.Author('Christoph Frädrich'), arxiv.Result.Author('Gordon Fraser'), arxiv.Result.Author('Sophia Geserer'), arxiv.Result.Author('Niklas Zantner')]",
105,Automated Test Generation for Scratch Programs,"The importance of programming education has lead to dedicated educational
programming environments, where users visually arrange block-based programming
constructs that typically control graphical, interactive game-like programs.
The Scratch programming environment is particularly popular, with more than 70
million registered users at the time of this writing. While the block-based
nature of Scratch helps learners by preventing syntactical mistakes, there
nevertheless remains a need to provide feedback and support in order to
implement desired functionality. To support individual learning and classroom
settings, this feedback and support should ideally be provided in an automated
fashion, which requires tests to enable dynamic program analysis. The Whisker
framework enables automated testing of Scratch programs, but creating these
automated tests for Scratch programs is challenging. In this paper, we
therefore investigate how to automatically generate Whisker tests. This raises
important challenges: First, game-like programs are typically randomised,
leading to flaky tests. Second, Scratch programs usually consist of animations
and interactions with long delays, inhibiting the application of classical test
generation approaches. Evaluation on common programming exercises, a random
sample of 1000 Scratch user programs, and the 1000 most popular Scratch
programs demonstrates that our approach enables Whisker to reliably accelerate
test executions, and even though many Scratch programs are small and easy to
cover, there are many unique challenges for which advanced search-based test
generation using many-objective algorithms is needed in order to achieve high
coverage.",2202.06274v2,cs.SE,2022-02-13 09:59:28+00:00,"[arxiv.Result.Author('Adina Deiner'), arxiv.Result.Author('Patric Feldmeier'), arxiv.Result.Author('Gordon Fraser'), arxiv.Result.Author('Sebastian Schweikl'), arxiv.Result.Author('Wengran Wang')]",
106,Scratch as Social Network: Topic Modeling and Sentiment Analysis in Scratch Projects,"Societal matters like the Black Lives Matter (BLM) movement influence
software engineering, as the recent debate on replacing certain discriminatory
terms such as whitelist/blacklist has shown. Identifying relevant and trending
societal matters is important, and often done using social network analysis for
traditional social media channels such as twitter. In this paper we explore
whether this type of analysis can also be used for introspection of the
software world, by looking at the thriving scene of young Scratch programmers.
The educational programming language Scratch is not only used for teaching
programming concepts, but offers a platform for young programmers to express
and share their creativity on any topics of relevance. By analyzing titles and
project comments in a dataset of 106.032 Scratch projects, we explore which
topics are common in the Scratch community, whether socially relevant events
are reflected and how how the sentiment in the comments is. It turns out that
the diversity of topics within the Scratch projects make the analysis process
challenging. Our results nevertheless show that topics from pop and net culture
in particular are present, and even recent societal events such as the Covid-19
pandemic or BLM are to some extent reflected in Scratch. The tone in the
comments is mostly positive with catchy youth language. Hence, despite the
challenges, Scratch projects can be studied in the same way as social networks,
which opens up new possibilities to improve our understanding of the behavior
and motivation of novice programmers.",2204.05902v1,cs.SE,2022-04-12 15:55:52+00:00,"[arxiv.Result.Author('Isabella Graßl'), arxiv.Result.Author('Gordon Fraser')]",
107,On Automating the Doctrine of Double Effect,"The doctrine of double effect ($\mathcal{DDE}$) is a long-studied ethical
principle that governs when actions that have both positive and negative
effects are to be allowed. The goal in this paper is to automate
$\mathcal{DDE}$. We briefly present $\mathcal{DDE}$, and use a first-order
modal logic, the deontic cognitive event calculus, as our framework to
formalize the doctrine. We present formalizations of increasingly stronger
versions of the principle, including what is known as the doctrine of triple
effect. We then use our framework to simulate successfully scenarios that have
been used to test for the presence of the principle in human subjects. Our
framework can be used in two different modes: One can use it to build
$\mathcal{DDE}$-compliant autonomous systems from scratch, or one can use it to
verify that a given AI system is $\mathcal{DDE}$-compliant, by applying a
$\mathcal{DDE}$ layer on an existing system or model. For the latter mode, the
underlying AI system can be built using any architecture (planners, deep neural
networks, bayesian networks, knowledge-representation systems, or a hybrid); as
long as the system exposes a few parameters in its model, such verification is
possible. The role of the $\mathcal{DDE}$ layer here is akin to a (dynamic or
static) software verifier that examines existing software modules. Finally, we
end by presenting initial work on how one can apply our $\mathcal{DDE}$ layer
to the STRIPS-style planning model, and to a modified POMDP model.This is
preliminary work to illustrate the feasibility of the second mode, and we hope
that our initial sketches can be useful for other researchers in incorporating
DDE in their own frameworks.",1703.08922v5,cs.AI,2017-03-27 04:03:56+00:00,"[arxiv.Result.Author('Naveen Sundar Govindarajulu'), arxiv.Result.Author('Selmer Bringsjord')]",
108,A Morera type theorem in the strip,"We prove the following result. Let f be a continuous function in the closed
infinite strip in complex plane. Suppose the restriction of f to every circle
inscribed in the strip extends holomorphically inside the circle. Then f is
holomorphic in the open strip.",math/0208136v1,math.CV,2002-08-19 16:26:28+00:00,[arxiv.Result.Author('Alexander Tumanov')],
109,Analytical investigation of magnetic field distributions around superconducting strips on ferromagnetic substrates,"The complex-field approach is developed to derive analytical expressions of
the magnetic field distributions around superconducting strips on ferromagnetic
substrates (SC/FM strips). We consider the ferromagnetic substrates as ideal
soft magnets with an infinite magnetic permeability, neglecting the
ferromagnetic hysteresis. On the basis of the critical state model for a
superconducting strip, the ac susceptibility $\chi_1'+i\chi_1''$ of a SC/FM
strip exposed to a perpendicular ac magnetic field is theoretically
investigated, and the results are compared with those for superconducting
strips on nonmagnetic substrates (SC/NM strips). The real part $\chi_1'$ for
$H_0/j_cd_s\to 0$ (where $H_0$ is the amplitude of the ac magnetic field, $j_c$
is the critical current density, and $d_s$ is the thickness of the
superconducting strip) of a SC/FM strip is 3/4 of that of a SC/NM strip. The
imaginary part $\chi_1''$ (or ac loss $Q$) for $H_0/j_cd_s<0.14$ of a SC/FM
strip is larger than that of a SC/NM strip, even when the ferromagnetic
hysteresis is neglected, and this enhancement of $\chi_1''$ (or $Q$) is due to
the edge effect of the ferromagnetic substrate.",0710.2151v1,cond-mat.supr-con,2007-10-11 02:40:12+00:00,[arxiv.Result.Author('Yasunori Mawatari')],
110,Morphologies and dynamics of micro-droplet impact onto an idealised scratch,"As inkjet technology develops to produce smaller droplets, substrate features
such as accidental scratches or manufacturing defects can potentially affect
the outcome of printing, particularly for printed electronics where continuous
tracks are required. Here, the deposition of micro-droplets onto a scratch of
commensurate size is studied. The scratch is considered as a groove of
rectangular cross-section, with rectangular side ridges representing material
displaced from the substrate, and seven equilibrium morphologies are identified
as a result of inertial spreading, contact-line pinning, imbibition into the
scratch and capillary flow. A regime map is constructed in terms of scratch
depth and width, and theoretical estimates of the regime boundaries are
developed by adapting droplet spreading laws for flat surfaces to account for
liquid entering the scratches. Good agreement is seen with numerical results
obtained using a GPU-accelerated three-dimensional multiphase lattice Boltzmann
model validated against published experiments, and the influences of Reynolds
number, Weber number and advancing and receding contact angles are explored.
Negative and positive implications of the results for printing applications are
discussed and illustrated via multiple-droplet simulations of printing across
and along scratches.",2007.01727v2,physics.flu-dyn,2020-07-03 14:49:08+00:00,"[arxiv.Result.Author('Khaled H. A. Al-Ghaithi'), arxiv.Result.Author('Oliver G. Harlen'), arxiv.Result.Author('Nikil Kapur'), arxiv.Result.Author('Mark C. T. Wilson')]","Journal of Fluid Mechanics, 2021, 925, A23"
111,Improving Readability of Scratch Programs with Search-based Refactoring,"Block-based programming languages like Scratch have become increasingly
popular as introductory languages for novices. These languages are intended to
be used with a ""tinkering"" approach which allows learners and teachers to
quickly assemble working programs and games, but this often leads to low code
quality. Such code can be hard to comprehend, changing it is error-prone, and
learners may struggle and lose interest. The general solution to improve code
quality is to refactor the code. However, Scratch lacks many of the common
abstraction mechanisms used when refactoring programs written in higher
programming languages. In order to improve Scratch code, we therefore propose a
set of atomic code transformations to optimise readability by (1) rewriting
control structures and (2) simplifying scripts using the inherently concurrent
nature of Scratch programs. By automating these transformations it is possible
to explore the space of possible variations of Scratch programs. In this paper,
we describe a multi-objective search-based approach that determines sequences
of code transformations which improve the readability of a given Scratch
program and therefore form refactorings. Evaluation on a random sample of 1000
Scratch programs demonstrates that the generated refactorings reduce complexity
and entropy in 70.4% of the cases, and 354 projects are improved in at least
one metric without making any other metric worse. The refactored programs can
help both novices and their teachers to improve their code.",2108.07114v1,cs.SE,2021-08-16 14:35:07+00:00,"[arxiv.Result.Author('Felix Adler'), arxiv.Result.Author('Gordon Fraser'), arxiv.Result.Author('Eva Gründinger'), arxiv.Result.Author('Nina Körber'), arxiv.Result.Author('Simon Labrenz'), arxiv.Result.Author('Jonas Lerchenberger'), arxiv.Result.Author('Stephan Lukasczyk'), arxiv.Result.Author('Sebastian Schweikl')]",
112,Alternating current loss in radially arranged superconducting strips,"Analytic expressions for alternating current (ac) loss in radially arranged
superconducting strips are presented. We adopt the weight-function approach to
obtain the field distributions in the critical state model, and we have
developed an analytic method to calculate hysteretic ac loss in superconducting
strips for small-current amplitude. We present the dependence of the ac loss in
radial strips upon the configuration of the strips and upon the number of
strips. The results show that behavior of the ac loss of radial strips carrying
bidirectional currents differs significantly from that carrying unidirectional
currents.",cond-mat/0602377v1,cond-mat.supr-con,2006-02-16 09:31:34+00:00,"[arxiv.Result.Author('Yasunori Mawatari'), arxiv.Result.Author('Kazuhiro Kajikawa')]",
113,Model-based Testing of Scratch Programs,"Learners are often introduced to programming via dedicated languages such as
Scratch, where block-based commands are assembled visually in order to control
the interactions of graphical sprites. Automated testing of such programs is an
important prerequisite for supporting debugging, providing hints, or assessing
learning outcomes. However, writing tests for Scratch programs can be
challenging: The game-like and randomised nature of typical Scratch programs
makes it difficult to identify specific timed input sequences used to control
the programs. Furthermore, precise test assertions to check the resulting
program states are incompatible with the fundamental principle of creative
freedom in programming in Scratch, where correct program behaviour may be
implemented with deviations in the graphical appearance or timing of the
program. The event-driven and actor-oriented nature of Scratch programs,
however, makes them a natural fit for describing program behaviour using finite
state machines. In this paper, we introduce a model-based testing approach by
extending Whisker, an automated testing framework for Scratch programs. The
model-based extension describes expected program behaviour in terms of state
machines, which makes it feasible to check the abstract behaviour of a program
independent of exact timing and pixel-precise graphical details, and to
automatically derive test inputs testing even challenging programs. A video
demonstrating model-based testing with Whisker is available at the following
URL: https://youtu.be/edgCNbGSGEY",2202.06271v1,cs.SE,2022-02-13 09:42:13+00:00,"[arxiv.Result.Author('Katharina Götz'), arxiv.Result.Author('Patric Feldmeier'), arxiv.Result.Author('Gordon Fraser')]",
114,Minimal resonances in annular non-Euclidean strips,"Differential growth processes play a prominent role in shaping leaves and
biological tissues. Using both analytical and numerical calculations, we
consider the shapes of closed, elastic strips which have been subjected to an
inhomogeneous pattern of swelling. The stretching and bending energies of a
closed strip are frustrated by compatibility constraints between the curvatures
and metric of the strip. To analyze this frustration, we study the class of
""conical"" closed strips with a prescribed metric tensor on their center line.
The resulting strip shapes can be classified according to their number of
wrinkles and the prescribed pattern of swelling. We use this class of strips as
a variational ansatz to obtain the minimal energy shapes of closed strips and
find excellent agreement with the results of a numerical bead-spring model.
Within this class of strips, we derive a condition under which a strip can have
vanishing mean curvature along the center line.",1007.2862v2,cond-mat.mtrl-sci,2010-07-16 20:27:24+00:00,"[arxiv.Result.Author('Bryan Gin-ge Chen'), arxiv.Result.Author('Christian D. Santangelo')]","Phys. Rev. E 82, 056601 (2010)"
115,Nanoscratching of iron: a novel approach to characterize dislocation microstructures,"A new approach for characterizing the dislocation microstructure obtained
from atomistic simulations is introduced, which relies on converting properties
of discrete lines to continuous data. This data is represented by a number of
density and density-like field variables containing detailed information about
properties of the dislocation microstructure. Applying this methodology to
atomistic simulations of nanoscratching in iron reveals a pronounced ""length
scale effect"": With increasing scratching length the number of dislocations
increases but the density of geometrically necessary dislocations remains
constant resulting in decreasing shear stress. During scratching dislocations
are mostly generated at the scratch front. The nucleation rate versus
scratching length has an approximately antisymmetric shape with respect to the
scratch front leading to an almost constant curvature.",1702.00457v3,cond-mat.mtrl-sci,2017-02-01 21:25:10+00:00,"[arxiv.Result.Author('Nina Gunkelmann'), arxiv.Result.Author('Iyad Alabd Alhafez'), arxiv.Result.Author('Dominik Steinberger'), arxiv.Result.Author('Herbert M. Urbassek'), arxiv.Result.Author('Stefan Sandfeld')]",
116,Scratching the surface: Elastic rotations beneath nanoscratch and nanoindentation tests,"In this paper, we investigate the residual deformation field in the vicinity
of nano-scratch tests using two orientations of a Berkovich tip on an (001) Cu
single crystal. We compare the deformation with that from indentation, in an
attempt to understand the mechanisms of deformation in tangential sliding. The
lattice rotation fields are mapped experimentally using high-resolution
electron backscatter diffraction (HR-EBSD) on cross-sections prepared using
focused ion beam (FIB). A physically-based crystal plasticity finite element
model (CPFEM) is used to simulate the lattice rotation fields, and provide
insight into the 3D rotation field surrounding nano-scratch experiments, as it
transitions from an initial static indentation to a steady-state scratch. The
CPFEM simulations capture the experimental rotation fields with good fidelity,
and show how the rotations about the scratch direction are reversed as the
indenter moves away from the initial indentation.",2006.12554v2,cond-mat.mtrl-sci,2020-06-22 18:28:42+00:00,"[arxiv.Result.Author('Anna Kareer'), arxiv.Result.Author('Edmund Tarleton'), arxiv.Result.Author('Christopher Hardie'), arxiv.Result.Author('Sarah V Hainsworth'), arxiv.Result.Author('Angus Wilkinson')]","Acta Materialia Volume 200, November 2020, Pages 116-126"
117,Electron microscopy study of scratch-induced surface microstructures in an Al-Cu-Fe icosahedral quasicrystal,"Microstructure modifications induced by sliding a WC-Co indenter in scratch
tests on the surface of a single phase AlCuFe icosahedral quasicrystal (IQC)
was studied by scanning electron microscopy (SEM) and transmission electron
microscopy (TEM). The scratch track was shown tocomprise many smaller tracks.
Dislocations were discovered to emerge from the edges of the smaller scratch
tracks. Along a small track where shear stress is concentrated, a phase
transition from IQC to a body-centered cubic (b.c.c.) phase with lattice
parameter a=0.29 nm was pointed out. A modulated quasicrystal state as well as
a deformation twin of IQC were determined in the region beneath the scratch.",2010.13406v1,cond-mat.mtrl-sci,2020-10-26 08:05:08+00:00,"[arxiv.Result.Author('J. Wu'), arxiv.Result.Author('Valerie Brien'), arxiv.Result.Author('P. Brunet'), arxiv.Result.Author('C. Dong'), arxiv.Result.Author('J. Dubois')]","Philosophical Magazine a, Informa UK (Taylor & Francis), 2009, 80
  (7), pp.1645-1655"
118,LitterBox: A Linter for Scratch Programs,"Creating programs with block-based programming languages like Scratch is easy
and fun. Block-based programs can nevertheless contain bugs, in particular when
learners have misconceptions about programming. Even when they do not, Scratch
code is often of low quality and contains code smells, further inhibiting
understanding, reuse, and fun. To address this problem, in this paper we
introduce LitterBox, a linter for Scratch programs. Given a program or its
public project ID, LitterBox checks the program against patterns of known bugs
and code smells. For each issue identified, LitterBox provides not only the
location in the code, but also a helpful explanation of the underlying reason
and possible misconceptions. Learners can access LitterBox through an easy to
use web interface with visual information about the errors in the block-code,
while for researchers LitterBox provides a general, open source, and extensible
framework for static analysis of Scratch programs.",2102.07440v1,cs.SE,2021-02-15 10:24:32+00:00,"[arxiv.Result.Author('Gordon Fraser'), arxiv.Result.Author('Ute Heuer'), arxiv.Result.Author('Nina Körber'), arxiv.Result.Author('Florian Obermüller'), arxiv.Result.Author('Ewald Wasmeier')]",
119,Thin Ohmic or superconducting strip with an applied ac electric current,"The complex impedance, currents, and electric and magnetic fields are
calculated as functions of resistivity and frequency or London depth for a long
thin strip with applied ac current. Both Ohmic and superconducting strips are
considered. While the inductance per unit length of the strip depends on the
strip length logarithmically, the sheet current, magnetic field, resistance,
and magnetic susceptibility are independent of this length. It is found that
the enhancement of resistance by the skin effect in thin Ohmic strips is much
weaker (logarithmic) than in thick wires.",cond-mat/0603416v1,cond-mat.supr-con,2006-03-15 22:45:13+00:00,[arxiv.Result.Author('Ernst Helmut Brandt')],
120,Blind proxy voting,"A secret ballot mechanism that enables voting in absence is proposed. It
amends standard vote collection methods that use ballot box as anonymizer,
adding the option for absent voters to vote by a proxy blinded to the content
of the ballot paper. Votes are cast under unique and hidden identification
numbers generated solely for the purpose of that election. Voters prepare their
ballot papers from scratch and submit them to the tallying authority in two
parts via separate routes, each part being meaningless without the other.",1812.11128v1,cs.CR,2018-12-28 17:41:13+00:00,[arxiv.Result.Author('Zuzana Haniková')],
121,Universal Voting Protocol Tweaks to Make Manipulation Hard,"Voting is a general method for preference aggregation in multiagent settings,
but seminal results have shown that all (nondictatorial) voting protocols are
manipulable. One could try to avoid manipulation by using voting protocols
where determining a beneficial manipulation is hard computationally. A number
of recent papers study the complexity of manipulating existing protocols. This
paper is the first work to take the next step of designing new protocols that
are especially hard to manipulate. Rather than designing these new protocols
from scratch, we instead show how to tweak existing protocols to make
manipulation hard, while leaving much of the original nature of the protocol
intact. The tweak studied consists of adding one elimination preround to the
election. Surprisingly, this extremely simple and universal tweak makes typical
protocols hard to manipulate! The protocols become NP-hard, #P-hard, or
PSPACE-hard to manipulate, depending on whether the schedule of the preround is
determined before the votes are collected, after the votes are collected, or
the scheduling and the vote collecting are interleaved, respectively. We prove
general sufficient conditions on the protocols for this tweak to introduce the
hardness, and show that the most common voting protocols satisfy those
conditions. These are the first results in voting settings where manipulation
is in a higher complexity class than NP (presuming PSPACE $\neq$ NP).",cs/0307018v1,cs.GT,2003-07-07 20:41:26+00:00,"[arxiv.Result.Author('Vincent Conitzer'), arxiv.Result.Author('Tuomas Sandholm')]","In Proceedings of the 18th International Joint Conference on
  Artificial Intelligence (IJCAI-03), Acapulco, Mexico, 2003"
122,"Improving OCR Accuracy on Early Printed Books by combining Pretraining, Voting, and Active Learning","We combine three methods which significantly improve the OCR accuracy of OCR
models trained on early printed books: (1) The pretraining method utilizes the
information stored in already existing models trained on a variety of typesets
(mixed models) instead of starting the training from scratch. (2) Performing
cross fold training on a single set of ground truth data (line images and their
transcriptions) with a single OCR engine (OCRopus) produces a committee whose
members then vote for the best outcome by also taking the top-N alternatives
and their intrinsic confidence values into account. (3) Following the principle
of maximal disagreement we select additional training lines which the voters
disagree most on, expecting them to offer the highest information gain for a
subsequent training (active learning). Evaluations on six early printed books
yielded the following results: On average the combination of pretraining and
voting improved the character accuracy by 46% when training five folds starting
from the same mixed model. This number rose to 53% when using different models
for pretraining, underlining the importance of diverse voters. Incorporating
active learning improved the obtained results by another 16% on average
(evaluated on three of the six books). Overall, the proposed methods lead to an
average error rate of 2.5% when training on only 60 lines. Using a substantial
ground truth pool of 1,000 lines brought the error rate down even further to
less than 1% on average.",1802.10038v2,cs.CV,2018-02-27 17:35:36+00:00,"[arxiv.Result.Author('Christian Reul'), arxiv.Result.Author('Uwe Springmann'), arxiv.Result.Author('Christoph Wick'), arxiv.Result.Author('Frank Puppe')]",
123,Image Inpainting by Multiscale Spline Interpolation,"Recovering the missing regions of an image is a task that is called image
inpainting. Depending on the shape of missing areas, different methods are
presented in the literature. One of the challenges of this problem is
extracting features that lead to better results. Experimental results show that
both global and local features are useful for this purpose. In this paper, we
propose a multi-scale image inpainting method that utilizes both local and
global features. The first step of this method is to determine how many scales
we need to use, which depends on the width of the lines in the map of the
missing region. Then we apply adaptive image inpainting to the damaged areas of
the image, and the lost pixels are predicted. Each scale is inpainted and the
result is resized to the original size. Then a voting process produces the
final result. The proposed method is tested on damaged images with scratches
and creases. The metric that we use to evaluate our approach is PSNR. On
average, we achieved 1.2 dB improvement over some existing inpainting
approaches.",2001.03270v1,cs.CV,2020-01-10 01:15:14+00:00,"[arxiv.Result.Author('Ghazale Ghorbanzade'), arxiv.Result.Author('Zahra Nabizadeh'), arxiv.Result.Author('Nader Karimi'), arxiv.Result.Author('Shadrokh Samavi')]",
124,Specialists Outperform Generalists in Ensemble Classification,"Consider an ensemble of $k$ individual classifiers whose accuracies are
known. Upon receiving a test point, each of the classifiers outputs a predicted
label and a confidence in its prediction for this particular test point. In
this paper, we address the question of whether we can determine the accuracy of
the ensemble. Surprisingly, even when classifiers are combined in the
statistically optimal way in this setting, the accuracy of the resulting
ensemble classifier cannot be computed from the accuracies of the individual
classifiers-as would be the case in the standard setting of confidence weighted
majority voting. We prove tight upper and lower bounds on the ensemble
accuracy. We explicitly construct the individual classifiers that attain the
upper and lower bounds: specialists and generalists. Our theoretical results
have very practical consequences: (1) If we use ensemble methods and have the
choice to construct our individual (independent) classifiers from scratch, then
we should aim for specialist classifiers rather than generalists. (2) Our
bounds can be used to determine how many classifiers are at least required to
achieve a desired ensemble accuracy. Finally, we improve our bounds by
considering the mutual information between the true label and the individual
classifier's output.",2107.04381v1,cs.LG,2021-07-09 12:16:10+00:00,"[arxiv.Result.Author('Sascha Meyen'), arxiv.Result.Author('Frieder Göppert'), arxiv.Result.Author('Helen Alber'), arxiv.Result.Author('Ulrike von Luxburg'), arxiv.Result.Author('Volker H. Franz')]",
125,Generating Single Peaked Votes,"We discuss how to generate singled peaked votes uniformly from the Impartial
Culture model.",1503.02766v1,cs.GT,2015-03-10 04:15:23+00:00,[arxiv.Result.Author('Toby Walsh')],
126,Normalized Range Voting Broadly Resists Control,"We study the behavior of Range Voting and Normalized Range Voting with
respect to electoral control. Electoral control encompasses attempts from an
election chair to alter the structure of an election in order to change the
outcome. We show that a voting system resists a case of control by proving that
performing that case of control is computationally infeasible. Range Voting is
a natural extension of approval voting, and Normalized Range Voting is a simple
variant which alters each vote to maximize the potential impact of each voter.
We show that Normalized Range Voting has among the largest number of control
resistances among natural voting systems.",1005.5698v3,cs.GT,2010-05-31 15:34:11+00:00,[arxiv.Result.Author('Curtis Menton')],
127,Strategic Voting Under Uncertainty About the Voting Method,"Much of the theoretical work on strategic voting makes strong assumptions
about what voters know about the voting situation. A strategizing voter is
typically assumed to know how other voters will vote and to know the rules of
the voting method. A growing body of literature explores strategic voting when
there is uncertainty about how others will vote. In this paper, we study
strategic voting when there is uncertainty about the voting method. We
introduce three notions of manipulability for a set of voting methods: sure,
safe, and expected manipulability. With the help of a computer program, we
identify voting scenarios in which uncertainty about the voting method may
reduce or even eliminate a voter's incentive to misrepresent her preferences.
Thus, it may be in the interest of an election designer who wishes to reduce
strategic voting to leave voters uncertain about which of several reasonable
voting methods will be used to determine the winners of an election.",1907.09110v1,cs.MA,2019-07-22 03:17:19+00:00,"[arxiv.Result.Author('Wesley H. Holliday'), arxiv.Result.Author('Eric Pacuit')]","EPTCS 297, 2019, pp. 252-272"
128,Vote Delegation and Misbehavior,"We study vote delegation with ""well-behaving"" and ""misbehaving"" agents and
compare it with conventional voting. Typical examples for vote delegation are
validation or governance tasks on blockchains. There is a majority of
well-behaving agents, but they may abstain or delegate their vote to other
agents since voting is costly. Misbehaving agents always vote. We compare
conventional voting allowing for abstention with vote delegation. Preferences
of voters are private information and a positive outcome is achieved if
well-behaving agents win. We illustrate that vote delegation leads to quite
different outcomes than conventional voting with abstention. In particular, we
obtain three insights: First, if the number of misbehaving voters, denoted by f
, is high, both voting methods fail to deliver a positive outcome. Second, if f
takes an intermediate value, conventional voting delivers a positive outcome,
while vote delegation fails with probability one. Third, if f is low,
delegation delivers a positive outcome with higher probability than
conventional voting. Finally, our results characterize worst-case outcomes that
can happen in a liquid democracy.",2102.08823v2,cs.GT,2021-02-17 15:32:32+00:00,"[arxiv.Result.Author('Hans Gersbach'), arxiv.Result.Author('Akaki Mamageishvili'), arxiv.Result.Author('Manvir Schneider')]",
129,Voting Power of Teams Working Together,"Voting power determines the ""power"" of individuals who cast votes; their
power is based on their ability to influence the winning-ness of a coalition.
Usually each individual acts alone, casting either all or none of their votes
and is equally likely to do either. This paper extends this standard ""random
voting"" model to allow probabilistic voting, partial voting, and correlated
team voting. We extend the standard Banzhaf metric to account for these cases;
our generalization reduces to the standard metric under ""random voting"", This
new paradigm allows us to answer questions such as ""In the 2013 US Senate, how
much more unified would the Republicans have to be in order to have the same
power as the Democrats in attaining cloture?""",1312.3394v1,cs.GT,2013-12-12 03:19:17+00:00,[arxiv.Result.Author('Daniel Zwillinger')],
130,The Computational Impact of Partial Votes on Strategic Voting,"In many real world elections, agents are not required to rank all candidates.
We study three of the most common methods used to modify voting rules to deal
with such partial votes. These methods modify scoring rules (like the Borda
count), elimination style rules (like single transferable vote) and rules based
on the tournament graph (like Copeland) respectively. We argue that with an
elimination style voting rule like single transferable vote, partial voting
does not change the situations where strategic voting is possible. However,
with scoring rules and rules based on the tournament graph, partial voting can
increase the situations where strategic voting is possible. As a consequence,
the computational complexity of computing a strategic vote can change. For
example, with Borda count, the complexity of computing a strategic vote can
decrease or stay the same depending on how we score partial votes.",1405.7714v1,cs.GT,2014-05-28 12:13:52+00:00,"[arxiv.Result.Author('Nina Narodytska'), arxiv.Result.Author('Toby Walsh')]",
131,FASTEN: Fair and Secure Distributed Voting Using Smart Contracts,"Electing democratic representatives via voting has been a common mechanism
since the 17th century. However, these mechanisms raise concerns about
fairness, privacy, vote concealment, fair calculations of tally, and proxies
voting on their behalf for the voters. Ballot voting, and in recent times,
electronic voting via electronic voting machines (EVMs) improves fairness by
relying on centralized trust. Homomorphic encryption-based voting protocols
also assure fairness but cannot scale to large scale elections such as
presidential elections. In this paper, we leverage the blockchain technology of
distributing trust to propose a smart contract-based protocol, namely, \proto.
There are many existing protocols for voting using smart contracts. We observe
that these either are not scalable or leak the vote tally during the voting
stage, i.e., do not provide vote concealment. In contrast, we show that FASTEN
preserves voter's privacy ensures vote concealment, immutability, and avoids
double voting. We prove that the probability of privacy breaches is negligibly
small. Further, our cost analysis of executing FASTEN over Ethereum is
comparable to most of the existing cost of elections.",2102.10594v1,cs.CR,2021-02-21 12:29:23+00:00,"[arxiv.Result.Author('Sankarshan Damle'), arxiv.Result.Author('Sujit Gujar'), arxiv.Result.Author('Moin Hussain Moti')]",
132,Exploring Weak Strategy-Proofness in Voting Theory,"Voting is the aggregation of individual preferences in order to select a
winning alternative. Selection of a winner is accomplished via a voting rule,
e.g., rank-order voting, majority rule, plurality rule, approval voting. Which
voting rule should be used? In social choice theory, desirable properties of
voting rules are expressed as axioms to be satisfied. This thesis focuses on
axioms concerning strategic manipulation by voters. Sometimes, voters may
intentionally misstate their true preferences in order to alter the outcome for
their own advantage. For example, in plurality rule, if a voter knows that
their top-choice candidate will lose, then they might instead vote for their
second-choice candidate just to avoid an even less desirable result. When no
coalition of voters can strategically manipulate, then the voting rule is said
to satisfy the axiom of Strategy-Proofness. A less restrictive axiom is Weak
Strategy-Proofness (as defined by Dasgupta and Maskin (2019)), which allows for
strategic manipulation by all but the smallest coalitions. Under certain
intuitive conditions, Dasgupta and Maskin (2019) proved that the only voting
rules satisfying Strategy-Proofness are rank-order voting and majority rule. In
my thesis, I generalize their result, by proving that rank-order voting and
majority rule are surprisingly still the only voting rules satisfying Weak
Strategy-Proofness.",2005.07521v1,econ.TH,2020-05-13 19:53:08+00:00,[arxiv.Result.Author('Anne Carlstein')],
133,Designing Stable Elections: A Survey,"We survey the design of elections that are resilient to attempted
interference by third parties. For example, suppose votes have been cast in an
election between two candidates, and then each vote is randomly changed with a
small probability, independently of the other votes. It is desirable to keep
the outcome of the election the same, regardless of the changes to the votes.
It is well known that the US electoral college system is about 5 times more
likely to have a changed outcome due to vote corruption, when compared to a
majority vote. In fact, Mossel, O'Donnell and Oleszkiewicz proved in 2005 that
the majority voting method is most stable to this random vote corruption, among
voting methods where each person has a small influence on the election. We
discuss some recent progress on the analogous result for elections between more
than two candidates. In this case, plurality should be most stable to
corruption in votes. We also survey results on adversarial election
manipulation (where an adversary can select particular votes to change, perhaps
in a non-random way), and we briefly discuss ranked choice voting methods
(where a vote is a ranked list of candidates).",2006.05460v2,math.PR,2020-06-09 18:59:48+00:00,[arxiv.Result.Author('Steven Heilman')],
134,Mixed Model OCR Training on Historical Latin Script for Out-of-the-Box Recognition and Finetuning,"In order to apply Optical Character Recognition (OCR) to historical printings
of Latin script fully automatically, we report on our efforts to construct a
widely-applicable polyfont recognition model yielding text with a Character
Error Rate (CER) around 2% when applied out-of-the-box. Moreover, we show how
this model can be further finetuned to specific classes of printings with
little manual and computational effort. The mixed or polyfont model is trained
on a wide variety of materials, in terms of age (from the 15th to the 19th
century), typography (various types of Fraktur and Antiqua), and languages
(among others, German, Latin, and French). To optimize the results we combined
established techniques of OCR training like pretraining, data augmentation, and
voting. In addition, we used various preprocessing methods to enrich the
training data and obtain more robust models. We also implemented a two-stage
approach which first trains on all available, considerably unbalanced data and
then refines the output by training on a selected more balanced subset.
Evaluations on 29 previously unseen books resulted in a CER of 1.73%,
outperforming a widely used standard model with a CER of 2.84% by almost 40%.
Training a more specialized model for some unseen Early Modern Latin books
starting from our mixed model led to a CER of 1.47%, an improvement of up to
50% compared to training from scratch and up to 30% compared to training from
the aforementioned standard model. Our new mixed model is made openly available
to the community.",2106.07881v1,cs.CV,2021-06-15 04:51:54+00:00,"[arxiv.Result.Author('Christian Reul'), arxiv.Result.Author('Christoph Wick'), arxiv.Result.Author('Maximilian Nöth'), arxiv.Result.Author('Andreas Büttner'), arxiv.Result.Author('Maximilian Wehner'), arxiv.Result.Author('Uwe Springmann')]",
135,Vulnerability analysis of three remote voting methods,"This article analyses three methods of remote voting in an uncontrolled
environment: postal voting, internet voting and hybrid voting. It breaks down
the voting process into different stages and compares their vulnerabilities
considering criteria that must be respected in any democratic vote:
confidentiality, anonymity, transparency, vote unicity and authenticity.
Whether for safety or reliability, each vulnerability is quantified by three
parameters: size, visibility and difficulty to achieve. The study concludes
that the automatisation of treatments combined with the dematerialisation of
the objects used during an election tends to substitute visible vulnerabilities
of a lesser magnitude by invisible and widespread vulnerabilities.",0908.1059v1,cs.CY,2009-08-07 14:02:40+00:00,"[arxiv.Result.Author('Chantal Enguehard'), arxiv.Result.Author('Rémi Lehn')]","XXI IPSA World Congress of Political Science, RC10 Electronic
  Democracy - Dilemmas of Change?, Santiago : Chile (2009)"
136,Equation of States for Elections,"In the US 2008 presidential election, Barack Obama was elected as the 44th
president of United States, winning the 53% of popular votes and 68% of
electoral votes; in the election of 2000, Al Gore lost the election receiving
49 % of electoral votes, although he had more popular votes. It is generally
believed that the electoral votes and the popular votes are correlated; however
the detailed quantitative relationship for these two quantities is unclear.
Here, we found an interesting relationship between fractions of electoral votes
and fractions of popular votes in the presidential elections of the United
States by examining the election results from 1932 to 2004. Moreover, this
curve could provide an interesting explanation for the results of other
elections that have taken place in Taiwan.",1211.1825v1,physics.soc-ph,2012-11-08 10:59:50+00:00,[arxiv.Result.Author('Bih-Yaw Jin')],
137,"Voting power and Qualified Majority Voting with a ""no vote"" option","In recent years, enlargement of the European Union has led to increased
interest in the allocation of voting weights to member states with hugely
differing population numbers. While the eventually agreed voting scheme lacks
any strict mathematical basis, the Polish government suggested a voting scheme
based on the Penrose definition of voting power, leading to an allocation of
voting weights proportional to the square root of the population (the
""Jagiellonian Compromise""). The Penrose definition of voting power is derived
from the citizens' freedom to vote either ""yes"" or ""no"". This paper defines a
corresponding voting power based on ""yes"", ""no"" and ""abstain"" options, and it
is found that this definition also leads to a square root law, and to the same
optimal vote allocation as the Penrose scheme.",0805.3251v2,math.GM,2008-05-21 10:57:28+00:00,[arxiv.Result.Author('Martin Kurth')],
138,Transparent Voting Platform Based on Permissioned Blockchain,"Since 2004, different research was handling the challenges in the centralized
voting systems, e-voting protocols and recently the decentralized voting. So
electronic voting puts forward some difficulties regarding the voter anonymity,
the secure casting of the votes and to prevent the voting process from
frauding. The Decentralized property of the technology called ""blockchain""
could have the solution for many of the challenges in voting research area and
brings a new secure mechanism of safe and transparent voting. In this paper, a
broad comparison between ongoing voting systems has studied by analyzing their
structure and the drawbacks that should consider in future to improve the whole
election process from keeping the privacy of the voter, casting a vote with the
possibility to check if it was counted correctly to publishing the results. The
result of the paper will give a new approach to extend the target of the
election from small scale to large scale despite the fact of Ethereum
limitation which can cast on the blockchain just five votes per minute. The
primary challenge is to find an answer for this question: ""How to balance
between voter privacy and transparency without breaking the important rule
where the voter can proof for a specific candidate that he voted for him in a
bribe situation?"".",1802.10134v1,cs.CY,2018-02-22 14:20:35+00:00,[arxiv.Result.Author('Nazim Faour')],
139,Distributed Voting/Ranking with Optimal Number of States per Node,"Considering a network with $n$ nodes, where each node initially votes for one
(or more) choices out of $K$ possible choices, we present a Distributed
Multi-choice Voting/Ranking (DMVR) algorithm to determine either the choice
with maximum vote (the voting problem) or to rank all the choices in terms of
their acquired votes (the ranking problem). The algorithm consolidates node
votes across the network by updating the states of interacting nodes using two
key operations, the union and the intersection. The proposed algorithm is
simple, independent from network size, and easily scalable in terms of the
number of choices $K$, using only $K\times 2^{K-1}$ nodal states for voting,
and $K\times K!$ nodal states for ranking. We prove the number of states to be
optimal in the ranking case, this optimality is conjectured to also apply to
the voting case. The time complexity of the algorithm is analyzed in complete
graphs. We show that the time complexity for both ranking and voting is
$O(\log(n))$ for given vote percentages, and is inversely proportional to the
minimum of the vote percentage differences among various choices.",1703.08838v1,cs.DC,2017-03-26 16:19:31+00:00,"[arxiv.Result.Author('Saber Salehkaleybar'), arxiv.Result.Author('Arsalan Sharif-Nassab'), arxiv.Result.Author('S. Jamaloddin Golestani')]",
140,Limiting Risk by Turning Manifest Phantoms into Evil Zombies,"Drawing a random sample of ballots to conduct a risk-limiting audit generally
requires knowing how the ballots cast in an election are organized into groups,
for instance, how many containers of ballots there are in all and how many
ballots are in each container. A list of the ballot group identifiers along
with number of ballots in each group is called a ballot manifest. What if the
ballot manifest is not accurate? Surprisingly, even if ballots are known to be
missing from the manifest, it is not necessary to make worst-case assumptions
about those ballots--for instance, to adjust the margin by the number of
missing ballots--to ensure that the audit remains conservative. Rather, it
suffices to make worst-case assumptions about the individual randomly selected
ballots that the audit cannot find. This observation provides a simple
modification to some risk-limiting audit procedures that makes them
automatically become more conservative if the ballot manifest has errors. The
modification--phantoms to evil zombies (~2EZ)--requires only an upper bound on
the total number of ballots cast. ~2EZ makes the audit P-value stochastically
larger than it would be had the manifest been accurate, automatically requiring
more than enough ballots to be audited to offset the manifest errors. This
ensures that the true risk limit remains smaller than the nominal risk limit.
On the other hand, if the manifest is in fact accurate and the upper bound on
the total number of ballots equals the total according to the manifest, ~2EZ
has no effect at all on the number of ballots audited nor on the true risk
limit.",1207.3413v1,stat.AP,2012-07-14 11:26:02+00:00,"[arxiv.Result.Author('Jorge H. Banuelos'), arxiv.Result.Author('Philip B. Stark')]",
141,A Complete Enumeration of Ballot Permutations Avoiding Sets of Small Patterns,"Permutations whose prefixes contain at least as many ascents as descents are
called ballot permutations. Lin, Wang, and Zhao have previously enumerated
ballot permutations avoiding small patterns and have proposed the problem of
enumerating ballot permutations avoiding a pair of permutations of length $3$.
We completely enumerate ballot permutations avoiding two patterns of length $3$
and we relate these avoidance classes with their respective recurrence
relations and formulas, which leads to an interesting bijection between ballot
permutations avoiding $132$ and $312$ with left factors of Dyck paths. In
addition, we also conclude the Wilf-classification of ballot permutations
avoiding sets of two patterns of length $3$, and we then extend our results to
completely enumerate ballot permutations avoiding three patterns of length $3$.",2209.06087v1,math.CO,2022-09-13 15:37:45+00:00,[arxiv.Result.Author('Nathan Sun')],
142,Can Voters Detect Errors on Their Printed Ballots? Absolutely,"There is still debate on whether voters can detect malicious changes in their
printed ballot after making their selections on a Ballot Marking Device (BMD).
In this study, we altered votes on a voter's ballot after they had made their
selections on a BMD. We then required them to examine their ballots for any
changes from the slate they used to vote. Overall accuracy was exceptionally
high. Participants saw 1440 total contests, and of those 1440, there were a
total of 4 errors, so total accuracy was 99.8%. Participants were able to
perform with near-perfect accuracy regardless of ballot length, ballot type,
number of altered races, and location of altered races. Detection performance
was extremely robust. We conclude that with proper direction and resources,
voters can be near-perfect detectors of ballot changes on printed paper ballots
after voting with a BMD. This finding has significant implications for the
voting community as BMD use continues to grow. Research should now focus on
identifying administrative and behavioral methods that will prompt and
encourage voters to check their BMD-generated ballots before they drop them in
the ballot box.",2204.09780v1,cs.HC,2022-04-20 20:40:32+00:00,"[arxiv.Result.Author('Philip Kortum'), arxiv.Result.Author('Michael D. Byrne'), arxiv.Result.Author('Chidera O. Azubike'), arxiv.Result.Author('Laura E. Roty')]",
143,Secure quantum string seal exists,"It was claimed that all quantum string seals are insecure [H. F. Chau,
quant-ph/0602099]. However, here it will be shown that for imperfect quantum
string seals, the information obtained by the measurement proposed in that
reference is trivial. Therefore imperfect quantum string seals can be
unconditionally secure.",quant-ph/0602159v1,quant-ph,2006-02-18 06:17:08+00:00,[arxiv.Result.Author('Guang Ping He')],
144,Ballot tilings and increasing trees,"We study enumerations of Dyck and ballot tilings, which are tilings of a
region determined by two Dyck or ballot paths. We give bijective proofs to two
formulae of enumerations of Dyck tilings through Hermite histories. We show
that one of the formulae is equal to a certain Kazhdan--Lusztig polynomial. For
a ballot tiling, we establish formulae which are analogues of formulae for Dyck
tilings. Especially, the generating functions have factorized expressions. The
key tool is a planted plane tree and its increasing labellings. We also
introduce a generalized perfect matching which is bijective to an Hermite
history for a ballot tiling. By combining these objects, we obtain various
expressions of a generating function of ballot tilings with a fixed lower path.",1705.06434v1,math-ph,2017-05-18 06:46:09+00:00,[arxiv.Result.Author('Keiichi Shigechi')],
145,Sophisticated Attacks on Decoy Ballots: The Devil's Menu and the Market for Lemons,"Decoy ballots do not count in election outcomes, but otherwise they are
indistinguishable from real ballots. By means of a game-theoretical model, we
show that decoy ballots may not provide effective protection against a
malevolent adversary trying to buy real ballots. If the citizenry is divided
into subgroups (or districts), the adversary can construct a so-called ""Devil's
Menu"" consisting of several prices. In equilibrium, the adversary can buy the
real ballots of any strict subset of districts at a price corresponding to the
willingness to sell on the part of the citizens holding such ballots. By
contrast, decoy voters are trapped into selling their ballots at a low, or even
negligible, price. Blowing up the adversary's budget by introducing decoy
ballots may thus turn out to be futile. The Devil's Menu can also be applied to
the well-known ""Lemons Problem"".",1712.05477v1,cs.GT,2017-12-14 23:54:58+00:00,"[arxiv.Result.Author('Hans Gersbach'), arxiv.Result.Author('Akaki Mamageishvili'), arxiv.Result.Author('Oriol Tejada')]",
146,Quantum bit string sealing,"Though it was proven that secure quantum sealing of a single classical bit is
impossible in principle, here we propose an unconditionally secure quantum
sealing protocol which seals a classical bit string. Any reader can obtain each
bit of the sealed string with an arbitrarily small error rate, while reading
the string is detectable. The protocol is simple and easy to be implemented.
The possibility of using this protocol to seal a single bit in practical is
also discussed.",quant-ph/0502091v3,quant-ph,2005-02-15 09:25:47+00:00,[arxiv.Result.Author('Guang-Ping He')],"International Journal of Quantum Information, 4, 677 (2006)."
147,The ATHENA Class of Risk-Limiting Ballot Polling Audits,"The main risk-limiting ballot polling audit in use today, BRAVO, is designed
for use when single ballots are drawn at random and a decision regarding
whether to stop the audit or draw another ballot is taken after each ballot
draw (ballot-by-ballot (B2) audits). On the other hand, real ballot polling
audits draw many ballots in a single round before determining whether to stop
(round-by-round (R2) audits). We show that BRAVO results in significant
inefficiency when directly applied to real R2 audits. We present the ATHENA
class of R2 stopping rules, which we show are risk-limiting if the round
schedule is pre-determined (before the audit begins). We prove that each rule
is at least as efficient as the corresponding BRAVO stopping rule applied at
the end of the round. We have open-source software libraries implementing most
of our results.
  We show that ATHENA halves the number of ballots required, for all state
margins in the 2016 US Presidential election and a first round with $90\%$
stopping probability, when compared to BRAVO (stopping rule applied at the end
of the round). We present simulation results supporting the 90% stopping
probability claims and our claims for the risk accrued in the first round.
Further, ATHENA reduces the number of ballots by more than a quarter for low
margins, when compared to the BRAVO stopping rule applied on ballots in
selection order. This implies that keeping track of the order when drawing
ballots R2 is not beneficial, because ATHENA is more efficient even without
information on selection order. These results are significant because current
approaches to real ballot polling election audits use the B2 BRAVO rules,
requiring about twice as much work on the part of election officials. Applying
the rules in selection order requires fewer ballots, but keeping track of the
order, and entering it into audit software, adds to the effort.",2008.02315v5,cs.CR,2020-08-05 18:47:37+00:00,"[arxiv.Result.Author('Filip Zagórski'), arxiv.Result.Author('Grant McClearn'), arxiv.Result.Author('Sarah Morin'), arxiv.Result.Author('Neal McBurnett'), arxiv.Result.Author('Poorvi L. Vora')]",
148,$k$-Cut: A Simple Approximately-Uniform Method for Sampling Ballots in Post-Election Audits,"We present an approximate sampling framework and discuss how risk-limiting
audits can compensate for these approximations, while maintaining their
""risk-limiting"" properties. Our framework is general and can compensate for
counting mistakes made during audits.
  Moreover, we present and analyze a simple approximate sampling
method,""$k$-cut"", for picking a ballot randomly from a stack, without counting.
Our method involves doing $k$ ""cuts"", each involving moving a random portion of
ballots from the top to the bottom of the stack, and then picking the ballot on
top. Unlike conventional methods of picking a ballot at random, $k$-cut does
not require identification numbers on the ballots or counting many ballots per
draw. We analyze how close the distribution of chosen ballots is to the uniform
distribution, and design different mitigation procedures. We show that $k=6$
cuts is enough for an risk-limiting election audit, based on empirical data,
which would provide a significant increase in efficiency.",1811.08811v3,cs.DS,2018-11-21 16:26:33+00:00,"[arxiv.Result.Author('Mayuri Sridhar'), arxiv.Result.Author('Ronald L. Rivest')]",
149,Bernoulli Ballot Polling: A Manifest Improvement for Risk-Limiting Audits,"We present a method and software for ballot-polling risk-limiting audits
(RLAs) based on Bernoulli sampling: ballots are included in the sample with
probability $p$, independently. Bernoulli sampling has several advantages: (1)
it does not require a ballot manifest; (2) it can be conducted independently at
different locations, rather than requiring a central authority to select the
sample from the whole population of cast ballots or requiring stratified
sampling; (3) it can start in polling places on election night, before margins
are known. If the reported margins for the 2016 U.S. Presidential election are
correct, a Bernoulli ballot-polling audit with a risk limit of 5% and a
sampling rate of $p_0 = 1\%$ would have had at least a 99% probability of
confirming the outcome in 42 states. (The other states were more likely to have
needed to examine additional ballots.) Logistical and security advantages that
auditing in the polling place affords may outweigh the cost of examining more
ballots than some other methods might require.",1812.06361v1,stat.AP,2018-12-15 21:57:23+00:00,"[arxiv.Result.Author('Kellie Ottoboni'), arxiv.Result.Author('Matthew Bernhard'), arxiv.Result.Author('J. Alex Halderman'), arxiv.Result.Author('Ronald L. Rivest'), arxiv.Result.Author('Philip B. Stark')]",
150,"Symmetric Dyck tilings, ballot tableaux and tree-like tableaux of shifted shapes","Symmetric Dyck tilings and ballot tilings are certain tilings in the region
surrounded by two ballot paths. We study the relations of combinatorial objects
which are bijective to symmetric Dyck tilings such as labeled trees, Hermite
histories, and perfect matchings. We also introduce two operations on labeled
trees for symmetric Dyck tilings: symmetric Dyck tiling strip (symDTS) and
symmetric Dyck tiling ribbon (symDTR). We give two definitions of Hermite
histories for symmetric Dyck tilings, and show that they are equivalent by use
of the correspondence between symDTS operation and an Hermite history. Since
ballot tilings form a subset in the set of symmetric Dyck tilings, we construct
an inclusive map from labeled trees for ballot tilings to labeled trees for
symmetric Dyck tilings. By this inclusive map, the results for symmetric Dyck
tilings can be applied to those of ballot tilings. We introduce and study the
notions of ballot tableaux and tree-like tableaux of shifted shapes, which are
generalizations of Dyck tableaux and tree-like tableaux, respectively. The
correspondence between ballot tableaux and tree-like tableaux of shifted shapes
is given by using the symDTR operation and the structure of labeled trees for
symmetric Dyck tilings.",2011.07296v1,math.CO,2020-11-14 13:15:14+00:00,[arxiv.Result.Author('Keiichi Shigechi')],
151,SOBA: Secrecy-preserving Observable Ballot-level Audit,"SOBA is an approach to election verification that provides observers with
justifiably high confidence that the reported results of an election are
consistent with an audit trail (""ballots""), which can be paper or electronic.
SOBA combines three ideas: (1) publishing cast vote records (CVRs) separately
for each contest, so that anyone can verify that each reported contest outcome
is correct, if the CVRs reflect voters' intentions with sufficient accuracy;
(2) shrouding a mapping between ballots and the CVRs for those ballots to
prevent the loss of privacy that could occur otherwise; (3) assessing the
accuracy with which the CVRs reflect voters' intentions for a collection of
contests while simultaneously assessing the integrity of the shrouded mapping
between ballots and CVRs by comparing randomly selected ballots to the CVRs
that purport to represent them. Step (1) is related to work by the Humboldt
County Election Transparency Project, but publishing CVRs separately for
individual contests rather than images of entire ballots preserves privacy.
Step (2) requires a cryptographic commitment from elections officials.
Observers participate in step (3), which relies on the ""super-simple
simultaneous single-ballot risk-limiting audit."" Step (3) is designed to reveal
relatively few ballots if the shrouded mapping is proper and the CVRs
accurately reflect voter intent. But if the reported outcomes of the contests
differ from the outcomes that a full hand count would show, step (3) is
guaranteed to have a large chance of requiring all the ballots to be counted by
hand, thereby limiting the risk that an incorrect outcome will become official
and final.",1105.5803v2,stat.AP,2011-05-29 17:00:20+00:00,"[arxiv.Result.Author('Josh Benaloh'), arxiv.Result.Author('Douglas Jones'), arxiv.Result.Author('Eric Lazarus'), arxiv.Result.Author('Mark Lindeman'), arxiv.Result.Author('Philip B. Stark')]",
152,"Voter Verification of BMD Ballots Is a Two-Part Question: Can They? Mostly, They Can. Do They? Mostly, They Don't","The question of whether or not voters actually verify ballots produced by
ballot marking devices (BMDs) is presently the subject of some controversy.
Recent studies (e.g., Bernhard, et al. 2020) suggest the verification rate is
low. What is not clear from previous research is whether this is more a result
of voters being unable to do so accurately or whether this is because voters
simply choose not to attempt verification in the first place. In order to
understand this problem, we conducted an experiment in which 108 participants
participated in a mock election where the BMD displayed the voters' true
choices, but then changed a subset of those choices on the printed ballot. The
design of the printed ballot, the length of the ballot, the number of changes
that were made to the ballot, the location of those changes, and the
instructions provided to the voters were manipulated as part of the experiment.
Results indicated that of those voters who chose to examine the printed ballot,
76% detected anomalies, indicating that voters can reliably detect errors on
their ballot if they will simply review it. This suggests that administrative
remedies, rather than attempts to alter fundamental human perceptual
capabilities, could be employed to encourage voters to check their ballots,
which could prove as an effective countermeasure.",2003.04997v1,cs.HC,2020-03-10 21:06:42+00:00,"[arxiv.Result.Author('Philip Kortum'), arxiv.Result.Author('Michael D. Byrne'), arxiv.Result.Author('Julie Whitmore')]",
153,Applications of quantum message sealing,"In 2003, Bechmann-Pasquinucci introduced the concept of quantum seals, a
quantum analogue to wax seals used to close letters and envelopes. Since then,
some improvements on the method have been found. We first review the current
quantum sealing techniques, then introduce and discuss potential applications
of quantum message sealing, and conclude with some discussion of the
limitations of quantum seals.",quant-ph/0504207v1,quant-ph,2005-04-27 19:10:09+00:00,[arxiv.Result.Author('G Gordon Worley III')],
154,Leak-rate of seals: effective medium theory and comparison with experiment,"Seals are extremely useful devices to prevent fluid leakage. We present an
effective medium theory of the leak-rate of rubber seals, which is based on a
recently developed contact mechanics theory. We compare the theory with
experimental results for seals consisting of silicon rubber in contact with
sandpaper and sand-blasted PMMA surfaces.",0911.3019v1,cond-mat.soft,2009-11-16 12:10:37+00:00,"[arxiv.Result.Author('B. Lorenz'), arxiv.Result.Author('B. N. J. Persson')]",
155,Next Steps for the Colorado Risk-Limiting Audit (CORLA) Program,"Colorado conducted risk-limiting tabulation audits (RLAs) across the state in
2017, including both ballot-level comparison audits and ballot-polling audits.
Those audits only covered contests restricted to a single county; methods to
efficiently audit contests that cross county boundaries and combine ballot
polling and ballot-level comparisons have not been available.
  Colorado's current audit software (RLATool) needs to be improved to audit
these contests that cross county lines and to audit small contests efficiently.
  This paper addresses these needs. It presents extremely simple but
inefficient methods, more efficient methods that combine ballot polling and
ballot-level comparisons using stratified samples, and methods that combine
ballot-level comparison and variable-size batch comparison audits in a way that
does not require stratified sampling.
  We conclude with some recommendations, and illustrate our recommended method
using examples that compare them to existing approaches. Exemplar open-source
code and interactive Jupyter notebooks are provided that implement the methods
and allow further exploration.",1803.00698v1,stat.AP,2018-03-02 03:46:37+00:00,"[arxiv.Result.Author('Mark Lindeman'), arxiv.Result.Author('Neal McBurnett'), arxiv.Result.Author('Kellie Ottoboni'), arxiv.Result.Author('Philip B. Stark')]",
156,RAIRE: Risk-Limiting Audits for IRV Elections,"Risk-limiting post election audits guarantee a high probability of correcting
incorrect election results, independent of why the result was incorrect.
Ballot-polling audits select ballots at random and interpret those ballots as
evidence for and against the reported result, continuing this process until
either they support the recorded result, or they fall back to a full manual
recount. For elections with digitised scanning and counting of ballots, a
comparison audit compares randomly selected digital ballots with their paper
versions. Discrepancies are referred to as errors, and are used to build
evidence against or in support of the recorded result. Risk-limiting audits for
first-past-the-post elections are well understood, and used in some US
elections. We define a number of approaches to ballot-polling and comparison
risk-limiting audits for Instant Runoff Voting (IRV) elections. We show that
for almost all real elections we found, we can perform a risk-limiting audit by
looking at only a small fraction of the total ballots (assuming no errors were
made in the tallying and distribution of votes).",1903.08804v2,cs.DS,2019-03-20 06:19:10+00:00,"[arxiv.Result.Author('Michelle Blom'), arxiv.Result.Author('Peter J. Stuckey'), arxiv.Result.Author('Vanessa Teague')]",
157,"A decomposition of ballot permutations, pattern avoidance and Gessel walks","A permutation whose any prefix has no more descents than ascents is called a
ballot permutation. In this paper, we present a decomposition of ballot
permutations that enables us to construct a bijection between ballot
permutations and odd order permutations, which proves a set-valued extension of
a conjecture due to Spiro using the statistic of peak values. This bijection
also preserves the neighbors of the largest letter in permutations and thus
resolves a refinement of Spiro' s conjecture proposed by Wang and Zhang. Our
decomposition can be extended to well-labelled positive paths, a class of
generalized ballot permutations arising from polytope theory, that were
enumerated by Bernardi, Duplantier and Nadeau. We will also investigate the
enumerative aspect of ballot permutations avoiding a single pattern of length 3
and establish a connection between 213-avoiding ballot permutations and Gessel
walks.",2103.04599v1,math.CO,2021-03-08 08:37:08+00:00,"[arxiv.Result.Author('Zhicong Lin'), arxiv.Result.Author('David G. L. Wang'), arxiv.Result.Author('Tongyuan Zhao')]",
158,Ballot Length in Instant Runoff Voting,"Instant runoff voting (IRV) is an increasingly-popular alternative to
traditional plurality voting in which voters submit rankings over the
candidates rather than single votes. In practice, elections using IRV often
restrict the ballot length, the number of candidates a voter is allowed to rank
on their ballot. We theoretically and empirically analyze how ballot length can
influence the outcome of an election, given fixed voter preferences. We show
that there exist preference profiles over $k$ candidates such that up to $k-1$
different candidates win at different ballot lengths. We derive exact lower
bounds on the number of voters required for such profiles and provide a
construction matching the lower bound for unrestricted voter preferences.
Additionally, we characterize which sequences of winners are possible over
ballot lengths and provide explicit profile constructions achieving any
feasible winner sequence. We also examine how classic preference restrictions
influence our results--for instance, single-peakedness makes $k-1$ different
winners impossible but still allows at least $\Omega(\sqrt k)$. Finally, we
analyze a collection of 168 real-world elections, where we truncate rankings to
simulate shorter ballots. We find that shorter ballots could have changed the
outcome in one quarter of these elections. Our results highlight ballot length
as a consequential degree of freedom in the design of IRV elections.",2207.08958v3,cs.MA,2022-07-18 22:01:13+00:00,"[arxiv.Result.Author('Kiran Tomlinson'), arxiv.Result.Author('Johan Ugander'), arxiv.Result.Author('Jon Kleinberg')]",
159,A modular eballot system - V0.6,"We consider a reasonably simple voting system which can be implemented for
web-based ballots. Simplicity, modularity and the requirement of compatibility
with current web browsers leads to a system which satisfies a set of security
requirements for a ballot system which is not complete but sufficient in many
cases. Due to weak-eligibility and vote-selling, this system cannot be used for
political or similar ballots.",cs/0611066v2,cs.CR,2006-11-15 09:33:58+00:00,[arxiv.Result.Author('Andrea Pasquinucci')],
160,Achieving both positive secrecy rates of the users in two-way wiretap channel by individual secrecy,"In this paper, the individual secrecy of two-way wiretap channel is
investigated, where two legitimate users' messages are separately guaranteed
secure against an external eavesdropper. For one thing, in some communication
scenarios, the joint secrecy is impossible to achieve both positive secrecy
rates of two users. For another, the individual secrecy satisfies the secrecy
demand of many practical communication systems. Thus, firstly, an achievable
secrecy rate region is derived for the general two-way wiretap channel with
individual secrecy. In a deterministic channel, the region with individual
secrecy is shown to be larger than that with joint secrecy.Secondly, outer
bounds on the secrecy capacity region are obtained for the general two-way
wiretap channel and for two classes of special two-way wiretap channels.The gap
between inner and outer bounds on the secrecy capacity region is explored via
the binary input two-way wiretap channels and the degraded Gaussian two-way
wiretap. Most notably, the secrecy capacity regions are established for the XOR
channel and the degraded Gaussian two-way wiretap channel.Furthermore, the
secure sum-rate of the degraded Gaussian two-way wiretap channel under the
individual secrecy constraint is demonstrated to be strictly larger than that
under the joint secrecy constraint.",1707.05930v1,cs.IT,2017-07-19 03:40:28+00:00,"[arxiv.Result.Author('Chao Qi'), arxiv.Result.Author('Bin Dai'), arxiv.Result.Author('Xiaohu Tang')]",
161,Effects of Feedback on the One-sided Secrecy of Two-way Wiretap through Multiple Transmissions,"In this paper, the one-sided secrecy of two-way wiretap channel with feedback
is investigated, where the confidential messages of one user through multiple
transmissions is guaranteed secure against an external eavesdropper. For one
thing, one-sided secrecy satisfies the secure demand of many practical
scenarios. For another, the secrecy is measured over many blocks since the
correlation between eavesdropper's observation and the confidential messages in
successive blocks, instead of secrecy measurement of one block in previous
works. Thus, firstly, an achievable secrecy rate region is derived for the
general two-way wiretap channel with feedback through multiple transmissions
under one-sided secrecy. Secondly, outer bounds on the secrecy capacity region
are also obtained. The gap between inner and outer bounds on the secrecy
capacity region is explored via the binary input two-way wiretap channels. Most
notably, the secrecy capacity regions are established for the XOR channel.
Furthermore, the result shows that the achievable rate region with feedback is
larger than that without feedback. Therefore, the benefit role of feedback is
precisely characterized for two-way wiretap channel with feedback under
one-sided secrecy.",1707.05932v1,cs.IT,2017-07-19 03:47:51+00:00,"[arxiv.Result.Author('Chao Qi'), arxiv.Result.Author('Yanling Chen'), arxiv.Result.Author('A. J. Han Vinck'), arxiv.Result.Author('Xiaohu Tang')]",
162,Secrecy Transmission in Large-Scale UAV-Enabled Wireless Networks,"This paper considers the secrecy transmission in a large-scale unmanned
aerial vehicle (UAV)-enabled wireless network, in which a set of UAVs in the
sky transmit confidential information to their respective legitimate receivers
on the ground, in the presence of another set of randomly distributed
suspicious ground eavesdroppers. We assume that the horizontal locations of
legitimate receivers and eavesdroppers are distributed as two independent
homogeneous Possion point processes (PPPs), and each of the UAVs is positioned
exactly above its corresponding legitimate receiver for efficient secrecy
communication. Furthermore, we consider an elevation-angle-dependent
line-of-sight (LoS)/non-LoS (NLoS) path-loss model for air-to-ground (A2G)
wireless channels and employ the wiretap code for secrecy transmission. Under
such setups, we first characterize the secrecy communication performance (in
terms of the connection probability, secrecy outage probability, and secrecy
transmission capacity) in mathematically tractable forms, and accordingly
optimize the system configurations (i.e., the wiretap code rates and UAV
positioning altitude) to maximize the secrecy transmission capacity, subject to
a maximum secrecy outage probability constraint. Next, we propose to use the
secrecy guard zone technique for further secrecy protection, and analyze the
correspondingly achieved secrecy communication performance. Finally, we present
numerical results to validate the theoretical analysis. It is shown that the
employment of secrecy guard zone significantly improves the secrecy
transmission capacity of this network, and the desirable guard zone radius
generally decreases monotonically as the UAVs' and/or the eavesdroppers'
densities increase.",1902.00836v2,cs.IT,2019-02-03 03:32:45+00:00,"[arxiv.Result.Author('Jianping Yao'), arxiv.Result.Author('Jie Xu')]",
163,On Secrecy Rate Analysis of MIMO Wiretap Channels Driven by Finite-Alphabet Input,"This work investigates the effect of finite-alphabet source input on the
secrecy rate of a multi-antenna wiretap system. Existing works have
characterized maximum achievable secrecy rate or secrecy capacity for single
and multiple antenna systems based on Gaussian source signals and secrecy code.
Despite the impracticality of Gaussian sources, the compact closed-form
expression of mutual information between linear channel Gaussian input and
corresponding output has led to broad application of Gaussian input assumption
in physical secrecy analysis. For practical considerations, we study the effect
of finite discrete-constellation on the achievable secrecy rate of
multiple-antenna wire-tap channels. Our proposed precoding scheme converts the
multi-antenna system into a bank of parallel channels. Based on this precoding
strategy, we propose a decentralized power allocation algorithm based on dual
decomposition for maximizing the achievable secrecy rate. In addition, we
analyze the achievable secrecy rate for finite-alphabet inputs in low and high
SNR cases. Our results demonstrate substantial difference in secrecy rate
between systems given finite-alphabet inputs and systems with Gaussian inputs.",1104.1014v2,cs.IT,2011-04-06 06:12:46+00:00,"[arxiv.Result.Author('Shafi Bashar'), arxiv.Result.Author('Zhi Ding'), arxiv.Result.Author('Chengshan Xiao')]",
164,Physical Layer Security of Autonomous Driving: Secure Vehicle-to-Vehicle Communication in A Security Cluster,"We suggest secure Vehicle-to-Vehicle communications in a secure cluster.
Here, the security cluster refers to a group of vehicles having a certain level
or more of secrecy capacity. Usually, there are many difficulties in defining
secrecy capacity, but we define vehicular secrecy capacity for the vehicle
defined only by SNR values. Defined vehicular secrecy capacity is practical and
efficient in achieving physical layer security in V2V. Typically, secrecy
capacity may be changed by antenna related parameters, path related parameters,
and noise related parameters. In addition to these conventional parameters, we
address unique vehicle-related parameters, such as vehicle speed, safety
distance, speed limit, response time, etc. in connection with autonomous
driving. We confirm the relationship between vehicle-related secrecy parameters
and secrecy capacity through modeling in highway and urban traffic situations.
These vehicular secrecy parameters enable real-time control of vehicle secrecy
capacity of V2V communications. We can use vehicular secrecy capacity to
achieve secure vehicle communications from attackers such as quantum computers.
Our research enables economic, effective and efficient physical layer security
in autonomous driving.",1912.06527v1,eess.SP,2019-12-13 14:31:21+00:00,"[arxiv.Result.Author('Na-Young Ahn'), arxiv.Result.Author('Dong Hoon Lee')]","Ad Hoc and Sensor Wireless Networks, 45 (3-4), 293-336, 2019"
165,Individual Secrecy for the Broadcast Channel,"This paper studies the problem of secure communication over broadcast
channels under the individual secrecy constraints. That is, the transmitter
wants to send two independent messages to two legitimate receivers in the
presence of an eavesdropper, while keeping the eavesdropper ignorant of each
message (i.e., the information leakage from each message to the eavesdropper is
made vanishing). Building upon Carleial-Hellman's secrecy coding, Wyner's
secrecy coding, the frameworks of superposition coding and Marton's coding
together with techniques such as rate splitting and indirect decoding,
achievable rate regions are developed. The proposed regions are compared with
those satisfying joint secrecy and without secrecy constraints, and the
individual secrecy capacity regions for special cases are characterized. In
particular, capacity region for the deterministic case is established, and for
the Gaussian model, a constant gap (i.e., 0.5 bits within the individual
secrecy capacity region) result is obtained. Overall, when compared with the
joint secrecy constraint, the results allow for trading-off secrecy level and
throughput in the system.",1511.09070v1,cs.IT,2015-11-29 19:23:12+00:00,"[arxiv.Result.Author('Yanling Chen'), arxiv.Result.Author('O. Ozan Koyluoglu'), arxiv.Result.Author('Aydin Sezgin')]",
166,On Secrecy above Secrecy Capacity,"We consider secrecy obtained when one transmits on a Gaussian Wiretap channel
above the secrecy capacity. Instead of equivocation, we consider probability of
error as the criterion of secrecy. The usual channel codes are considered for
transmission. The rates obtained can reach the channel capacity. We show that
the ""confusion"" caused to the Eve when the rate of transmission is above
capacity of the Eve's channel is similar to the confusion caused by using the
wiretap channel codes used below the secrecy capacity.",1203.2456v3,cs.IT,2012-03-12 10:50:53+00:00,"[arxiv.Result.Author('R. Rajesh'), arxiv.Result.Author('Shahid M. Shah'), arxiv.Result.Author('Vinod Sharma')]",
167,Sum Secrecy Rate in Full-Duplex Wiretap Channel with Imperfect CSI,"In this paper, we consider the achievable sum secrecy rate in full-duplex
wiretap channel in the presence of an eavesdropper and imperfect channel state
information (CSI). We assume that the users participating in full-duplex
communication and the eavesdropper have single antenna each. The users have
individual transmit power constraints. They also transmit jamming signals to
improve the secrecy rates. We obtain the achievable perfect secrecy rate region
by maximizing the sum secrecy rate. We also obtain the corresponding optimum
powers of the message signals and the jamming signals. Numerical results that
show the impact of imperfect CSI on the achievable secrecy rate region are
presented.",1311.3918v2,cs.IT,2013-11-15 16:40:55+00:00,"[arxiv.Result.Author('Sanjay Vishwakarma'), arxiv.Result.Author('A. Chockalingam')]",
168,An Overview of Generic Tools for Information-Theoretic Secrecy Performance Analysis over Wiretap Fading Channels,"An alternative or supplementary approach named as physical layer security has
been proposed to afford an extra security layer on top of the conventional
cryptography technique. In this paper, an overview of secrecy performance
investigations over the classic Alice-Bob-Eve wiretap fading channels is
conducted. On the basis of the classic wiretap channel model, we have
comprehensively listed and thereafter compared the existing works on physical
layer secrecy analysis considering the small-scale, large-scale, composite, and
cascaded fading channel models. Exact secrecy metrics expressions, including
secrecy outage probability (SOP), the probability of non-zero secrecy capacity
(PNZ), average secrecy capacity (ASC), and secrecy bounds, including the lower
bound of SOP and ergodic secrecy capacity, are presented. In order to encompass
the aforementioned four kinds of fading channel models with a more generic and
flexible distribution, the mixture gamma (MG), mixture of Gaussian (MoG), and
Fox's $H$-function distributions are three useful candidates to largely include
the above-mentioned four kinds of fading channel models. It is shown that they
are flexible and general when assisting the secrecy analysis to obtain
closed-form expressions. Their advantages and limitations are also highlighted.
Conclusively, these three approaches are proven to provide a unified secrecy
analysis framework and can cover all types of independent wiretap fading
channel models. Apart from those, revisiting the existing secrecy enhancement
techniques based on our system configuration, the on-off transmission scheme,
jamming approach (including artificial noise (AN) & artificial fast fading
(AFF)), antenna selection, and security region are presented.",2009.05976v2,cs.IT,2020-09-13 10:36:10+00:00,"[arxiv.Result.Author('Long Kong'), arxiv.Result.Author('Yun Ai'), arxiv.Result.Author('Lei Lei'), arxiv.Result.Author('Georges Kaddoum'), arxiv.Result.Author('Symeon Chatzinotas'), arxiv.Result.Author('Björn Ottersten')]",
169,On Secrecy Metrics for Physical Layer Security over Quasi-Static Fading Channels,"Theoretical studies on physical layer security often adopt the secrecy outage
probability as the performance metric for wireless communications over
quasi-static fading channels. The secrecy outage probability has two
limitations from a practical point of view: a) it does not give any insight
into the eavesdropper's decodability of confidential messages; b) it cannot
characterize the amount of information leakage to the eavesdropper when an
outage occurs. Motivated by the limitations of the secrecy outage probability,
we propose three new secrecy metrics for secure transmissions over quasi-static
fading channels. The first metric establishes a link between the concept of
secrecy outage and the decodability of messages at the eavesdropper. The second
metric provides an error-probability-based secrecy metric which is typically
used for the practical implementation of secure wireless systems. The third
metric characterizes how much or how fast the confidential information is
leaked to the eavesdropper. We show that the proposed secrecy metrics
collectively give a more comprehensive understanding of physical layer security
over fading channels and enable one to appropriately design secure
communication systems with different views on how secrecy is measured.",1607.05457v1,cs.IT,2016-07-19 08:34:46+00:00,"[arxiv.Result.Author('Biao He'), arxiv.Result.Author('Xiangyun Zhou'), arxiv.Result.Author('A. Lee Swindlehurst')]",
170,On the Secrecy Performance and Power Allocation in Relaying Networks with Untrusted Relay in the Partial Secrecy Regime,"Recently, three useful secrecy metrics based on the partial secrecy regime
were proposed to analyze secure transmissions on wireless systems over
quasi-static fading channels, namely: generalized secrecy outage probability,
average fractional equivocation, and average information leakage. These metrics
were devised from the concept of fractional equivocation, which is related to
the decoding error probability at the eavesdropper, so as to provide a
comprehensive insight on the practical implementation of wireless systems with
different levels of secrecy requirements. Considering the partial secrecy
regime, in this paper we examine the secrecy performance of an
amplify-and-forward relaying network with an untrusted relay node, where a
destination-based jamming is employed to enable secure transmissions. In this
regard, a closed-form approximation is derived for the generalized secrecy
outage probability, and integral-form expressions are obtained for the average
fractional equivocation and the average information leakage rate. Additionally,
equal and optimal power allocation schemes are investigated and compared for
the three metrics. From this analysis, we show that different power allocation
approaches lead to different system design criteria. The obtained expressions
are validated via Monte Carlo simulations.",1912.03853v1,eess.SP,2019-12-09 04:56:02+00:00,"[arxiv.Result.Author('Diana P. M. Osorio'), arxiv.Result.Author('Hirley Alves'), arxiv.Result.Author('Edgar E. B. Olivo')]",IEEE Transactions on Information Forensics and Security 2020
171,On the Relationship Between the Multi-antenna Secrecy Communications and Cognitive Radio Communications,"This paper studies the capacity of the multi-antenna or multiple-input
multiple-output (MIMO) secrecy channels with multiple eavesdroppers having
single/multiple antennas. It is known that the MIMO secrecy capacity is
achievable with the optimal transmit covariance matrix that maximizes the
minimum difference between the channel mutual information of the secrecy user
and those of the eavesdroppers. The MIMO secrecy capacity computation can thus
be formulated as a non-convex max-min problem, which cannot be solved
efficiently by standard convex optimization techniques. To handle this
difficulty, we explore a relationship between the MIMO secrecy channel and the
recently developed MIMO cognitive radio (CR) channel, in which the
multi-antenna secondary user transmits over the same spectrum simultaneously
with multiple primary users, subject to the received interference power
constraints at the primary users, or the so-called ``interference temperature
(IT)'' constraints. By constructing an auxiliary CR MIMO channel that has the
same channel responses as the MIMO secrecy channel, we prove that the optimal
transmit covariance matrix to achieve the secrecy capacity is the same as that
to achieve the CR spectrum sharing capacity with properly selected IT
constraints. Based on this relationship, several algorithms are proposed to
solve the non-convex secrecy capacity computation problem by transforming it
into a sequence of CR spectrum sharing capacity computation problems that are
convex. For the case with single-antenna eavesdroppers, the proposed algorithms
obtain the exact capacity of the MIMO secrecy channel, while for the case with
multi-antenna eavesdroppers, the proposed algorithms obtain both upper and
lower bounds on the MIMO secrecy capacity.",0901.4830v1,cs.IT,2009-01-30 06:56:00+00:00,"[arxiv.Result.Author('Lan Zhang'), arxiv.Result.Author('Rui Zhang'), arxiv.Result.Author('Ying-Chang Liang'), arxiv.Result.Author('Yan Xin'), arxiv.Result.Author('Shuguang Cui')]",
172,Physical-Layer Security in the Finite Blocklength Regime over Fading Channels,"This paper studies physical-layer secure transmissions from a transmitter to
a legitimate receiver against an eavesdropper over slow fading channels, taking
into account the impact of finite blocklength secrecy coding. A comprehensive
analysis and optimization framework is established to investigate secrecy
throughput for both single- and multi-antenna transmitter scenarios. Both
adaptive and non-adaptive design schemes are devised, in which the secrecy
throughput is maximized by exploiting the instantaneous and statistical channel
state information of the legitimate receiver, respectively. Specifically,
optimal transmission policy, blocklength, and code rates are jointly designed
to maximize the secrecy throughput. Additionally, null-space artificial noise
is employed to improve the secrecy throughput for the multi-antenna setup with
the optimal power allocation derived.Various important insights are developed.
In particular, 1) increasing blocklength benefits both reliability and secrecy
under the proposed transmission policy; 2) secrecy throughput monotonically
increases with blocklength; 3) secrecy throughput initially increases but then
decreases as secrecy rate increases, and the optimal secrecy rate maximizing
the secrecy throughput should be carefully chosen in order to strike a good
balance between rate and decoding correctness. Numerical results are eventually
presented to verify theoretical findings.",2002.03106v1,cs.IT,2020-02-08 07:12:42+00:00,"[arxiv.Result.Author('Tong-Xing Zheng'), arxiv.Result.Author('Hui-Ming Wang'), arxiv.Result.Author('Derrick Wing Kwan Ng'), arxiv.Result.Author('Jinhong Yuan')]",
173,Secrecy Outage of Dual-hop Regenerative Multi-relay System with Relay Selection,"Relay selection is considered to enhance the secrecy of a dual-hop
regenerative multi-relay system with an eavesdropper. Without assuming perfect
decoding at the relays, the secrecy outage probability of a single relay system
is obtained first. Secrecy outage of optimal, traditional and suboptimal relay
selection schemes is then evaluated. To reduce the power consumption, partial
relay selection schemes based only on either of the source-relay or
relay-destination instantaneous channel state information (ICSI) are
introduced. Its secrecy outage is evaluated and compared with the other
schemes. Secrecy outage of all the selection schemes are obtained in
closed-form. An optimal relay selection scheme is proposed using secrecy outage
which does not require any ICSI. Asymptotic and diversity gain analysis of the
secrecy outage is presented when source-relay and relay-destination average
SNRs are same or different. We observe that the improvement in eavesdropper
link quality affects the secrecy outage more when required secrecy rate is low
as compared to the case when rate is high. We also observe that relay selection
improves performance more when number of relays are more. It is important to
note that either of the source-relay or the relay-destination link quality can
equally limit the secrecy outage performance even if the other link quality is
infinitely good.",2103.04478v1,eess.SP,2021-03-07 23:11:34+00:00,"[arxiv.Result.Author('Chinmoy Kundu'), arxiv.Result.Author('Sarbani Ghose'), arxiv.Result.Author('Ranjan Bose')]",
174,Achievable Rates for the General Gaussian Multiple Access Wire-Tap Channel with Collective Secrecy,"We consider the General Gaussian Multiple Access Wire-Tap Channel (GGMAC-WT).
In this scenario, multiple users communicate with an intended receiver in the
presence of an intelligent and informed eavesdropper who is as capable as the
intended receiver, but has different channel parameters. We aim to provide
perfect secrecy for the transmitters in this multi-access environment. Using
Gaussian codebooks, an achievable secrecy region is determined and the power
allocation that maximizes the achievable sum-rate is found. Numerical results
showing the new rate region are presented. It is shown that the multiple-access
nature of the channel may be utilized to allow users with zero single-user
secrecy capacity to be able to transmit in perfect secrecy. In addition, a new
collaborative scheme is shown that may increase the achievable sum-rate. In
this scheme, a user who would not transmit to maximize the sum rate can help
another user who (i) has positive secrecy capacity to increase its rate, or
(ii) has zero secrecy capacity to achieve a positive secrecy capacity.",cs/0612084v1,cs.IT,2006-12-18 15:33:15+00:00,"[arxiv.Result.Author('Ender Tekin'), arxiv.Result.Author('Aylin Yener')]",
175,Relating two standard notions of secrecy,"Two styles of definitions are usually considered to express that a security
protocol preserves the confidentiality of a data s. Reachability-based secrecy
means that s should never be disclosed while equivalence-based secrecy states
that two executions of a protocol with distinct instances for s should be
indistinguishable to an attacker. Although the second formulation ensures a
higher level of security and is closer to cryptographic notions of secrecy,
decidability results and automatic tools have mainly focused on the first
definition so far.
  This paper initiates a systematic investigation of the situations where
syntactic secrecy entails strong secrecy. We show that in the passive case,
reachability-based secrecy actually implies equivalence-based secrecy for
digital signatures, symmetric and asymmetric encryption provided that the
primitives are probabilistic. For active adversaries, we provide sufficient
(and rather tight) conditions on the protocol for this implication to hold.",0706.0502v2,cs.CR,2007-06-04 19:30:33+00:00,"[arxiv.Result.Author('Veronique Cortier'), arxiv.Result.Author('Michael Rusinovitch'), arxiv.Result.Author('Eugen Zalinescu')]","Logical Methods in Computer Science, Volume 3, Issue 3 (July 6,
  2007) lmcs:1093"
176,Enhancement of Secrecy of Block Ciphered Systems by Deliberate Noise,"This paper considers the problem of end-end security enhancement by resorting
to deliberate noise injected in ciphertexts. The main goal is to generate a
degraded wiretap channel in application layer over which Wyner-type secrecy
encoding is invoked to deliver additional secure information. More
specifically, we study secrecy enhancement of DES block cipher working in
cipher feedback model (CFB) when adjustable and intentional noise is introduced
into encrypted data in application layer. A verification strategy in exhaustive
search step of linear attack is designed to allow Eve to mount a successful
attack in the noisy environment. Thus, a controllable wiretap channel is
created over multiple frames by taking advantage of errors in Eve's
cryptanalysis, whose secrecy capacity is found for the case of known channel
states at receivers. As a result, additional secure information can be
delivered by performing Wyner type secrecy encoding over super-frames ahead of
encryption, namely, our proposed secrecy encoding-then-encryption scheme. These
secrecy bits could be taken as symmetric keys for upcoming frames. Numerical
results indicate that a sufficiently large secrecy rate can be achieved by
selective noise addition.",1204.0153v1,cs.CR,2012-04-01 01:52:36+00:00,"[arxiv.Result.Author('Yahya S. Khiabani'), arxiv.Result.Author('Shuangqing Wei'), arxiv.Result.Author('Jian Yuan'), arxiv.Result.Author('Jian Wang')]",
177,Secrecy Capacity of Two-Hop Relay Assisted Wiretap Channels,"Incorporating the physical layer characteristics to secure communications has
received considerable attention in recent years. Moreover, cooperation with
some nodes of network can give benefits of multiple-antenna systems, increasing
the secrecy capacity of such channels. In this paper, we consider cooperative
wiretap channel with the help of an Amplify and Forward (AF) relay to transmit
confidential messages from source to legitimate receiver in the presence of an
eavesdropper. In this regard, the secrecy capacity of AF relying is derived,
assuming the relay is subject to a peak power constraint. To this end, an
achievable secrecy rate for Gaussian input is evaluated through solving a
non-convex optimization problem. Then, it is proved that any rates greater than
this secrecy rate is not achievable. To do this, the capacity of a genie-aided
channel as an upper bound for the secrecy capacity of the underlying channel is
derived, showing this upper bound is equal to the computed achievable secrecy
rate with Gaussian input. Accordingly, the corresponding secrecy capacity is
compared to the Decode and Forward (DF) strategy which is served as the
benchmark in the current work.",1301.1701v1,cs.IT,2013-01-08 21:46:21+00:00,"[arxiv.Result.Author('Meysam Mirzaee'), arxiv.Result.Author('Soroush Akhlaghi')]",
178,Study of Relay Selection for Physical-Layer Security in Buffer-Aided Relay Networks Based on the Secrecy Rate Criterion,"In this paper, we investigate an opportunistic relay and jammer scheme along
with relay selection algorithms based on the secrecy rate criterion in
multiple-input multiple-output buffer-aided down link relay networks, which
consist of one source, a number of relay nodes, legitimate users and
eavesdroppers, with the constraints of physical layer security. The
opportunistic relay and jammer scheme is employed to improve the transmission
rate and different relay selection policies are performed to achieve better
secrecy rate with the consideration of eavesdroppers. Among all the
investigated relay selection policies, a relay selection policy which is
developed to maximize the secrecy rate based on exhaustive searches outperforms
other relay selection policies in terms of secrecy rate. Based on the secrecy
rate criterion, we develop a relay selection algorithm without knowledge of the
channels of the eavesdroppers. We also devise a greedy search algorithm based
on the secrecy rate criterion to reduce the computational complexity of the
exhaustive search technique. Simulations show the superiority of the secrecy
rate criterion over competing approaches.",1605.04487v1,cs.IT,2016-05-15 01:37:37+00:00,"[arxiv.Result.Author('X. Luo'), arxiv.Result.Author('R. C. de Lamare')]",
179,Vehicle Communication using Secrecy Capacity,"We address secure vehicle communication using secrecy capacity. In
particular, we research the relationship between secrecy capacity and various
types of parameters that determine secrecy capacity in the vehicular wireless
network. For example, we examine the relationship between vehicle speed and
secrecy capacity, the relationship between the response time and secrecy
capacity of an autonomous vehicle, and the relationship between transmission
power and secrecy capacity. In particular, the autonomous vehicle has set the
system modeling on the assumption that the speed of the vehicle is related to
the safety distance. We propose new vehicle communication to maintain a certain
level of secrecy capacity according to various parameters. As a result, we can
expect safer communication security of autonomous vehicles in 5G
communications.",1807.09757v1,cs.IT,2018-07-24 04:40:05+00:00,"[arxiv.Result.Author('Na-Young Ahn'), arxiv.Result.Author('Donghoon Lee'), arxiv.Result.Author('Seong-Jun Oh')]",Future Technologies Conference 2018 (13-14 November 2018)
180,On cryptological schemes for r-person secret vote and r-person authentication,"We introduce a scheme for the membership verification, a scheme for a secret
ballot, a scheme for the unanimity rule which can hide the number of voter
using some partition number identities.",2008.06224v1,math.CO,2020-08-14 07:43:22+00:00,[arxiv.Result.Author('BongJu Kim')],
181,A quantum secret ballot,"The paper concerns the protection of the secrecy of ballots, so that the
identity of the voters cannot be matched with their vote. To achieve this we
use an entangled quantum state to represent the ballots. Each ballot includes
the identity of the voter, explicitly marked on the ""envelope"" containing it.
Measuring the content of the envelope yields a random number which reveals no
information about the vote. However, the outcome of the elections can be
unambiguously decided after adding the random numbers from all envelopes. We
consider a few versions of the protocol and their complexity of implementation.",quant-ph/0602087v2,quant-ph,2006-02-09 21:03:35+00:00,"[arxiv.Result.Author('Shahar Dolev'), arxiv.Result.Author('Itamar Pitowsky'), arxiv.Result.Author('Boaz Tamir')]",
182,Blind proxy voting,"A secret ballot mechanism that enables voting in absence is proposed. It
amends standard vote collection methods that use ballot box as anonymizer,
adding the option for absent voters to vote by a proxy blinded to the content
of the ballot paper. Votes are cast under unique and hidden identification
numbers generated solely for the purpose of that election. Voters prepare their
ballot papers from scratch and submit them to the tallying authority in two
parts via separate routes, each part being meaningless without the other.",1812.11128v1,cs.CR,2018-12-28 17:41:13+00:00,[arxiv.Result.Author('Zuzana Haniková')],
183,Boardroom Voting: Verifiable Voting with Ballot Privacy Using Low-Tech Cryptography in a Single Room,"A boardroom election is an election that takes place in a single room -- the
boardroom -- in which all voters can see and hear each other. We present an
initial exploration of boardroom elections with ballot privacy and voter
verifiability that use only ""low-tech cryptography"" without using computers to
mark or collect ballots. Specifically, we define the problem, introduce several
building blocks, and propose a new protocol that combines these blocks in novel
ways. Our new building blocks include ""foldable ballots"" that can be rotated to
hide the alignment of ballot choices with voting marks, and ""visual secrets""
that are easy to remember and use but hard to describe. Although closely seated
participants in a boardroom election have limited privacy, the protocol ensures
that no one can determine how others voted. Moreover, each voter can verify
that their ballot was correctly cast, collected, and counted, without being
able to prove how they voted, providing assurance against undue influence.
Low-tech cryptography is useful in situations where constituents do not trust
computer technology, and it avoids the complex auditing requirements of
end-to-end cryptographic voting systems such as Pr\^{e}t-\`{a}-Voter. This
paper's building blocks and protocol are meant to be a proof of concept that
might be tested for usability and improved.",2007.14916v2,cs.CR,2020-07-29 15:40:51+00:00,"[arxiv.Result.Author('Enka Blanchard'), arxiv.Result.Author('Ted Selker'), arxiv.Result.Author('Alan T. Sherman')]",
184,Keep Ballots Secret: On the Futility of Social Learning in Decision Making by Voting,"We show that social learning is not useful in a model of team binary decision
making by voting, where each vote carries equal weight. Specifically, we
consider Bayesian binary hypothesis testing where agents have any
conditionally-independent observation distribution and their local decisions
are fused by any L-out-of-N fusion rule. The agents make local decisions
sequentially, with each allowed to use its own private signal and all precedent
local decisions. Though social learning generally occurs in that precedent
local decisions affect an agent's belief, optimal team performance is obtained
when all precedent local decisions are ignored. Thus, social learning is
futile, and secret ballots are optimal. This contrasts with typical studies of
social learning because we include a fusion center rather than concentrating on
the performance of the latest-acting agents.",1212.5855v1,cs.IT,2012-12-24 02:28:29+00:00,"[arxiv.Result.Author('Joong Bum Rhim'), arxiv.Result.Author('Vivek K. Goyal')]",
185,SHARVOT: secret SHARe-based VOTing on the blockchain,"Recently, there has been a growing interest in using online technologies to
design protocols for secure electronic voting. The main challenges include vote
privacy and anonymity, ballot irrevocability and transparency throughout the
vote counting process. The introduction of the blockchain as a basis for
cryptocurrency protocols, provides for the exploitation of the immutability and
transparency properties of these distributed ledgers.
  In this paper, we discuss possible uses of the blockchain technology to
implement a secure and fair voting system. In particular, we introduce a secret
share-based voting system on the blockchain, the so-called SHARVOT protocol.
Our solution uses Shamir's Secret Sharing to enable on-chain, i.e. within the
transactions script, votes submission and winning candidate determination. The
protocol is also using a shuffling technique, Circle Shuffle, to de-link voters
from their submissions.",1803.04861v1,cs.CY,2018-03-13 14:57:55+00:00,"[arxiv.Result.Author('Silvia Bartolucci'), arxiv.Result.Author('Pauline Bernat'), arxiv.Result.Author('Daniel Joseph')]",
186,Public Evidence from Secret Ballots,"Elections seem simple---aren't they just counting? But they have a unique,
challenging combination of security and privacy requirements. The stakes are
high; the context is adversarial; the electorate needs to be convinced that the
results are correct; and the secrecy of the ballot must be ensured. And they
have practical constraints: time is of the essence, and voting systems need to
be affordable and maintainable, and usable by voters, election officials, and
pollworkers. It is thus not surprising that voting is a rich research area
spanning theory, applied cryptography, practical systems analysis, usable
security, and statistics. Election integrity involves two key concepts:
convincing evidence that outcomes are correct and privacy, which amounts to
convincing assurance that there is no evidence about how any given person
voted. These are obviously in tension. We examine how current systems walk this
tightrope.",1707.08619v2,cs.CR,2017-07-26 19:31:31+00:00,"[arxiv.Result.Author('Matthew Bernhard'), arxiv.Result.Author('Josh Benaloh'), arxiv.Result.Author('J. Alex Halderman'), arxiv.Result.Author('Ronald L. Rivest'), arxiv.Result.Author('Peter Y. A. Ryan'), arxiv.Result.Author('Philip B. Stark'), arxiv.Result.Author('Vanessa Teague'), arxiv.Result.Author('Poorvi L. Vora'), arxiv.Result.Author('Dan S. Wallach')]",
187,Secure and Verifiable Electronic Voting in Practice: the use of vVote in the Victorian State Election,"The November 2014 Australian State of Victoria election was the first
statutory political election worldwide at State level which deployed an
end-to-end verifiable electronic voting system in polling places. This was the
first time blind voters have been able to cast a fully secret ballot in a
verifiable way, and the first time a verifiable voting system has been used to
collect remote votes in a political election. The code is open source, and the
output from the election is verifiable. The system took 1121 votes from these
particular groups, an increase on 2010 and with fewer polling places.",1504.07098v1,cs.CR,2015-04-27 14:08:24+00:00,"[arxiv.Result.Author('Craig Burton'), arxiv.Result.Author('Chris Culnane'), arxiv.Result.Author('Steve Schneider')]",
188,Multi-party quantum privacy comparison of size based on d-level GHZ states,"Quantum privacy comparison(QPC) plays an important role in secret ballot
elections, private auctions and so on. To date, many multi-party QPC(MQPC)
protocols have been proposed to compare the equality of $k(k\geq 3)$
participants. However, there are few examples of MQPC used to compare the sizes
or values of their privacies. In this paper, we propose a MQPC protocol by
which any $k(k\geq 3)$ participants can compare the sizes of their privacies
with executing the protocol just once. The proposed MQPC protocol takes the
$d-level$ GHZ states as quantum resources, and a semi-honest $TP$ is introduced
to help the participants to determine the relationship of their privacies.
Further more, only single-particle unitary transformations and measurements are
involved, and the participants need not to share common secrets with each other
beforehand which makes the proposed protocol much more efficient. Analysis
shows that our protocol is secure against internal and external attack in
theory.",1902.03595v1,quant-ph,2019-02-10 13:21:05+00:00,"[arxiv.Result.Author('Hao Cao'), arxiv.Result.Author('Wenping Ma'), arxiv.Result.Author('Liangdong Lyu'), arxiv.Result.Author('Yefeng He'), arxiv.Result.Author('Ge Liu')]",
189,Limiting Risk by Turning Manifest Phantoms into Evil Zombies,"Drawing a random sample of ballots to conduct a risk-limiting audit generally
requires knowing how the ballots cast in an election are organized into groups,
for instance, how many containers of ballots there are in all and how many
ballots are in each container. A list of the ballot group identifiers along
with number of ballots in each group is called a ballot manifest. What if the
ballot manifest is not accurate? Surprisingly, even if ballots are known to be
missing from the manifest, it is not necessary to make worst-case assumptions
about those ballots--for instance, to adjust the margin by the number of
missing ballots--to ensure that the audit remains conservative. Rather, it
suffices to make worst-case assumptions about the individual randomly selected
ballots that the audit cannot find. This observation provides a simple
modification to some risk-limiting audit procedures that makes them
automatically become more conservative if the ballot manifest has errors. The
modification--phantoms to evil zombies (~2EZ)--requires only an upper bound on
the total number of ballots cast. ~2EZ makes the audit P-value stochastically
larger than it would be had the manifest been accurate, automatically requiring
more than enough ballots to be audited to offset the manifest errors. This
ensures that the true risk limit remains smaller than the nominal risk limit.
On the other hand, if the manifest is in fact accurate and the upper bound on
the total number of ballots equals the total according to the manifest, ~2EZ
has no effect at all on the number of ballots audited nor on the true risk
limit.",1207.3413v1,stat.AP,2012-07-14 11:26:02+00:00,"[arxiv.Result.Author('Jorge H. Banuelos'), arxiv.Result.Author('Philip B. Stark')]",
190,A Complete Enumeration of Ballot Permutations Avoiding Sets of Small Patterns,"Permutations whose prefixes contain at least as many ascents as descents are
called ballot permutations. Lin, Wang, and Zhao have previously enumerated
ballot permutations avoiding small patterns and have proposed the problem of
enumerating ballot permutations avoiding a pair of permutations of length $3$.
We completely enumerate ballot permutations avoiding two patterns of length $3$
and we relate these avoidance classes with their respective recurrence
relations and formulas, which leads to an interesting bijection between ballot
permutations avoiding $132$ and $312$ with left factors of Dyck paths. In
addition, we also conclude the Wilf-classification of ballot permutations
avoiding sets of two patterns of length $3$, and we then extend our results to
completely enumerate ballot permutations avoiding three patterns of length $3$.",2209.06087v1,math.CO,2022-09-13 15:37:45+00:00,[arxiv.Result.Author('Nathan Sun')],
191,Can Voters Detect Errors on Their Printed Ballots? Absolutely,"There is still debate on whether voters can detect malicious changes in their
printed ballot after making their selections on a Ballot Marking Device (BMD).
In this study, we altered votes on a voter's ballot after they had made their
selections on a BMD. We then required them to examine their ballots for any
changes from the slate they used to vote. Overall accuracy was exceptionally
high. Participants saw 1440 total contests, and of those 1440, there were a
total of 4 errors, so total accuracy was 99.8%. Participants were able to
perform with near-perfect accuracy regardless of ballot length, ballot type,
number of altered races, and location of altered races. Detection performance
was extremely robust. We conclude that with proper direction and resources,
voters can be near-perfect detectors of ballot changes on printed paper ballots
after voting with a BMD. This finding has significant implications for the
voting community as BMD use continues to grow. Research should now focus on
identifying administrative and behavioral methods that will prompt and
encourage voters to check their BMD-generated ballots before they drop them in
the ballot box.",2204.09780v1,cs.HC,2022-04-20 20:40:32+00:00,"[arxiv.Result.Author('Philip Kortum'), arxiv.Result.Author('Michael D. Byrne'), arxiv.Result.Author('Chidera O. Azubike'), arxiv.Result.Author('Laura E. Roty')]",
192,Ballot tilings and increasing trees,"We study enumerations of Dyck and ballot tilings, which are tilings of a
region determined by two Dyck or ballot paths. We give bijective proofs to two
formulae of enumerations of Dyck tilings through Hermite histories. We show
that one of the formulae is equal to a certain Kazhdan--Lusztig polynomial. For
a ballot tiling, we establish formulae which are analogues of formulae for Dyck
tilings. Especially, the generating functions have factorized expressions. The
key tool is a planted plane tree and its increasing labellings. We also
introduce a generalized perfect matching which is bijective to an Hermite
history for a ballot tiling. By combining these objects, we obtain various
expressions of a generating function of ballot tilings with a fixed lower path.",1705.06434v1,math-ph,2017-05-18 06:46:09+00:00,[arxiv.Result.Author('Keiichi Shigechi')],
193,Sophisticated Attacks on Decoy Ballots: The Devil's Menu and the Market for Lemons,"Decoy ballots do not count in election outcomes, but otherwise they are
indistinguishable from real ballots. By means of a game-theoretical model, we
show that decoy ballots may not provide effective protection against a
malevolent adversary trying to buy real ballots. If the citizenry is divided
into subgroups (or districts), the adversary can construct a so-called ""Devil's
Menu"" consisting of several prices. In equilibrium, the adversary can buy the
real ballots of any strict subset of districts at a price corresponding to the
willingness to sell on the part of the citizens holding such ballots. By
contrast, decoy voters are trapped into selling their ballots at a low, or even
negligible, price. Blowing up the adversary's budget by introducing decoy
ballots may thus turn out to be futile. The Devil's Menu can also be applied to
the well-known ""Lemons Problem"".",1712.05477v1,cs.GT,2017-12-14 23:54:58+00:00,"[arxiv.Result.Author('Hans Gersbach'), arxiv.Result.Author('Akaki Mamageishvili'), arxiv.Result.Author('Oriol Tejada')]",
194,The ATHENA Class of Risk-Limiting Ballot Polling Audits,"The main risk-limiting ballot polling audit in use today, BRAVO, is designed
for use when single ballots are drawn at random and a decision regarding
whether to stop the audit or draw another ballot is taken after each ballot
draw (ballot-by-ballot (B2) audits). On the other hand, real ballot polling
audits draw many ballots in a single round before determining whether to stop
(round-by-round (R2) audits). We show that BRAVO results in significant
inefficiency when directly applied to real R2 audits. We present the ATHENA
class of R2 stopping rules, which we show are risk-limiting if the round
schedule is pre-determined (before the audit begins). We prove that each rule
is at least as efficient as the corresponding BRAVO stopping rule applied at
the end of the round. We have open-source software libraries implementing most
of our results.
  We show that ATHENA halves the number of ballots required, for all state
margins in the 2016 US Presidential election and a first round with $90\%$
stopping probability, when compared to BRAVO (stopping rule applied at the end
of the round). We present simulation results supporting the 90% stopping
probability claims and our claims for the risk accrued in the first round.
Further, ATHENA reduces the number of ballots by more than a quarter for low
margins, when compared to the BRAVO stopping rule applied on ballots in
selection order. This implies that keeping track of the order when drawing
ballots R2 is not beneficial, because ATHENA is more efficient even without
information on selection order. These results are significant because current
approaches to real ballot polling election audits use the B2 BRAVO rules,
requiring about twice as much work on the part of election officials. Applying
the rules in selection order requires fewer ballots, but keeping track of the
order, and entering it into audit software, adds to the effort.",2008.02315v5,cs.CR,2020-08-05 18:47:37+00:00,"[arxiv.Result.Author('Filip Zagórski'), arxiv.Result.Author('Grant McClearn'), arxiv.Result.Author('Sarah Morin'), arxiv.Result.Author('Neal McBurnett'), arxiv.Result.Author('Poorvi L. Vora')]",
195,$k$-Cut: A Simple Approximately-Uniform Method for Sampling Ballots in Post-Election Audits,"We present an approximate sampling framework and discuss how risk-limiting
audits can compensate for these approximations, while maintaining their
""risk-limiting"" properties. Our framework is general and can compensate for
counting mistakes made during audits.
  Moreover, we present and analyze a simple approximate sampling
method,""$k$-cut"", for picking a ballot randomly from a stack, without counting.
Our method involves doing $k$ ""cuts"", each involving moving a random portion of
ballots from the top to the bottom of the stack, and then picking the ballot on
top. Unlike conventional methods of picking a ballot at random, $k$-cut does
not require identification numbers on the ballots or counting many ballots per
draw. We analyze how close the distribution of chosen ballots is to the uniform
distribution, and design different mitigation procedures. We show that $k=6$
cuts is enough for an risk-limiting election audit, based on empirical data,
which would provide a significant increase in efficiency.",1811.08811v3,cs.DS,2018-11-21 16:26:33+00:00,"[arxiv.Result.Author('Mayuri Sridhar'), arxiv.Result.Author('Ronald L. Rivest')]",
196,Bernoulli Ballot Polling: A Manifest Improvement for Risk-Limiting Audits,"We present a method and software for ballot-polling risk-limiting audits
(RLAs) based on Bernoulli sampling: ballots are included in the sample with
probability $p$, independently. Bernoulli sampling has several advantages: (1)
it does not require a ballot manifest; (2) it can be conducted independently at
different locations, rather than requiring a central authority to select the
sample from the whole population of cast ballots or requiring stratified
sampling; (3) it can start in polling places on election night, before margins
are known. If the reported margins for the 2016 U.S. Presidential election are
correct, a Bernoulli ballot-polling audit with a risk limit of 5% and a
sampling rate of $p_0 = 1\%$ would have had at least a 99% probability of
confirming the outcome in 42 states. (The other states were more likely to have
needed to examine additional ballots.) Logistical and security advantages that
auditing in the polling place affords may outweigh the cost of examining more
ballots than some other methods might require.",1812.06361v1,stat.AP,2018-12-15 21:57:23+00:00,"[arxiv.Result.Author('Kellie Ottoboni'), arxiv.Result.Author('Matthew Bernhard'), arxiv.Result.Author('J. Alex Halderman'), arxiv.Result.Author('Ronald L. Rivest'), arxiv.Result.Author('Philip B. Stark')]",
197,"Symmetric Dyck tilings, ballot tableaux and tree-like tableaux of shifted shapes","Symmetric Dyck tilings and ballot tilings are certain tilings in the region
surrounded by two ballot paths. We study the relations of combinatorial objects
which are bijective to symmetric Dyck tilings such as labeled trees, Hermite
histories, and perfect matchings. We also introduce two operations on labeled
trees for symmetric Dyck tilings: symmetric Dyck tiling strip (symDTS) and
symmetric Dyck tiling ribbon (symDTR). We give two definitions of Hermite
histories for symmetric Dyck tilings, and show that they are equivalent by use
of the correspondence between symDTS operation and an Hermite history. Since
ballot tilings form a subset in the set of symmetric Dyck tilings, we construct
an inclusive map from labeled trees for ballot tilings to labeled trees for
symmetric Dyck tilings. By this inclusive map, the results for symmetric Dyck
tilings can be applied to those of ballot tilings. We introduce and study the
notions of ballot tableaux and tree-like tableaux of shifted shapes, which are
generalizations of Dyck tableaux and tree-like tableaux, respectively. The
correspondence between ballot tableaux and tree-like tableaux of shifted shapes
is given by using the symDTR operation and the structure of labeled trees for
symmetric Dyck tilings.",2011.07296v1,math.CO,2020-11-14 13:15:14+00:00,[arxiv.Result.Author('Keiichi Shigechi')],
198,SOBA: Secrecy-preserving Observable Ballot-level Audit,"SOBA is an approach to election verification that provides observers with
justifiably high confidence that the reported results of an election are
consistent with an audit trail (""ballots""), which can be paper or electronic.
SOBA combines three ideas: (1) publishing cast vote records (CVRs) separately
for each contest, so that anyone can verify that each reported contest outcome
is correct, if the CVRs reflect voters' intentions with sufficient accuracy;
(2) shrouding a mapping between ballots and the CVRs for those ballots to
prevent the loss of privacy that could occur otherwise; (3) assessing the
accuracy with which the CVRs reflect voters' intentions for a collection of
contests while simultaneously assessing the integrity of the shrouded mapping
between ballots and CVRs by comparing randomly selected ballots to the CVRs
that purport to represent them. Step (1) is related to work by the Humboldt
County Election Transparency Project, but publishing CVRs separately for
individual contests rather than images of entire ballots preserves privacy.
Step (2) requires a cryptographic commitment from elections officials.
Observers participate in step (3), which relies on the ""super-simple
simultaneous single-ballot risk-limiting audit."" Step (3) is designed to reveal
relatively few ballots if the shrouded mapping is proper and the CVRs
accurately reflect voter intent. But if the reported outcomes of the contests
differ from the outcomes that a full hand count would show, step (3) is
guaranteed to have a large chance of requiring all the ballots to be counted by
hand, thereby limiting the risk that an incorrect outcome will become official
and final.",1105.5803v2,stat.AP,2011-05-29 17:00:20+00:00,"[arxiv.Result.Author('Josh Benaloh'), arxiv.Result.Author('Douglas Jones'), arxiv.Result.Author('Eric Lazarus'), arxiv.Result.Author('Mark Lindeman'), arxiv.Result.Author('Philip B. Stark')]",
199,"Voter Verification of BMD Ballots Is a Two-Part Question: Can They? Mostly, They Can. Do They? Mostly, They Don't","The question of whether or not voters actually verify ballots produced by
ballot marking devices (BMDs) is presently the subject of some controversy.
Recent studies (e.g., Bernhard, et al. 2020) suggest the verification rate is
low. What is not clear from previous research is whether this is more a result
of voters being unable to do so accurately or whether this is because voters
simply choose not to attempt verification in the first place. In order to
understand this problem, we conducted an experiment in which 108 participants
participated in a mock election where the BMD displayed the voters' true
choices, but then changed a subset of those choices on the printed ballot. The
design of the printed ballot, the length of the ballot, the number of changes
that were made to the ballot, the location of those changes, and the
instructions provided to the voters were manipulated as part of the experiment.
Results indicated that of those voters who chose to examine the printed ballot,
76% detected anomalies, indicating that voters can reliably detect errors on
their ballot if they will simply review it. This suggests that administrative
remedies, rather than attempts to alter fundamental human perceptual
capabilities, could be employed to encourage voters to check their ballots,
which could prove as an effective countermeasure.",2003.04997v1,cs.HC,2020-03-10 21:06:42+00:00,"[arxiv.Result.Author('Philip Kortum'), arxiv.Result.Author('Michael D. Byrne'), arxiv.Result.Author('Julie Whitmore')]",
200,The security proof of the ping-pong protocol is wrong,The security proof of the ping-pong protocol is wrong.,quant-ph/0604035v1,quant-ph,2006-04-06 00:48:04+00:00,[arxiv.Result.Author('Zhan-jun Zhang')],
201,Generic Security Proof of Quantum Key Exchange using Squeezed States,"Recently, a Quantum Key Exchange protocol that uses squeezed states was
presented by Gottesman and Preskill. In this paper we give a generic security
proof for this protocol. The method used for this generic security proof is
based on recent work by Christiandl, Renner and Ekert.",quant-ph/0508072v1,quant-ph,2005-08-09 08:08:55+00:00,"[arxiv.Result.Author('Karin Poels'), arxiv.Result.Author('Pim Tuyls'), arxiv.Result.Author('Berry Schoenmakers')]",
202,Security proof of practical quantum key distribution schemes,"This paper provides a security proof of the Bennett-Brassard (BB84) quantum
key distribution protocol in practical implementation. To prove the security,
it is not assumed that defects in the devices are absorbed into an adversary's
attack. In fact, the only assumption in the proof is that the source is
characterized. The proof is performed by lower-bounding adversary's Renyi
entropy about the key before privacy amplification. The bound reveals the
leading factors reducing the key generation rate.",quant-ph/0506246v1,quant-ph,2005-06-29 04:43:04+00:00,[arxiv.Result.Author('Yodai Watanabe')],
203,How to Simulate It in Isabelle: Towards Formal Proof for Secure Multi-Party Computation,"In cryptography, secure Multi-Party Computation (MPC) protocols allow
participants to compute a function jointly while keeping their inputs private.
Recent breakthroughs are bringing MPC into practice, solving fundamental
challenges for secure distributed computation. Just as with classic protocols
for encryption and key exchange, precise guarantees are needed for MPC designs
and implementations; any flaw will give attackers a chance to break privacy or
correctness. In this paper we present the first (as far as we know)
formalisation of some MPC security proofs. These proofs provide probabilistic
guarantees in the computational model of security, but have a different
character to machine proofs and proof tools implemented so far --- MPC proofs
use a \emph{simulation} approach, in which security is established by showing
indistinguishability between execution traces in the actual protocol execution
and an ideal world where security is guaranteed by definition. We show that
existing machinery for reasoning about probabilistic programs adapted to this
setting, paving the way to precisely check a new class of cryptography
arguments. We implement our proofs using the CryptHOL framework inside
Isabelle/HOL.",1805.12482v1,cs.CR,2018-05-31 14:08:26+00:00,"[arxiv.Result.Author('David Butler'), arxiv.Result.Author('David Aspinall'), arxiv.Result.Author('Adria Gascon')]",
204,The Foundational Cryptography Framework,"We present the Foundational Cryptography Framework (FCF) for developing and
checking complete proofs of security for cryptographic schemes within a proof
assistant. This is a general-purpose framework that is capable of modeling and
reasoning about a wide range of cryptographic schemes, security definitions,
and assumptions. Security is proven in the computational model, and the proof
provides concrete bounds as well as asymptotic conclusions. FCF provides a
language for probabilistic programs, a theory that is used to reason about
programs, and a library of tactics and definitions that are useful in proofs
about cryptography. The framework is designed to leverage fully the existing
theory and capabilities of the Coq proof assistant in order to reduce the
effort required to develop proofs.",1410.3735v1,cs.PL,2014-10-14 15:34:39+00:00,"[arxiv.Result.Author('Adam Petcher'), arxiv.Result.Author('Greg Morrisett')]",
205,Quantum Error Correcting Codes and the Security Proof of the BB84 Protocol,"We describe the popular BB84 protocol and critically examine its security
proof as presented by Shor and Preskill. The proof requires the use of quantum
error correcting codes called the Calderbank-Shor-Steanne (CSS) quantum codes.
These quantum codes are constructed in the quantum domain from two suitable
classical linear codes, one used to correct for bit-flip errors and the other
for phase-flip errors. Consequently, as a prelude to the security proof, the
report reviews the essential properties of linear codes, especially the concept
of cosets, before building the quantum codes that are utilized in the proof.
The proof considers a security entanglement-based protocol, which is
subsequently reduced to a ""Prepare and Measure"" protocol similar in structure
to the BB84 protocol, thus establishing the security of the BB84 protocol. The
proof, however, is not without assumptions, which are also enumerated. The
treatment throughout is pedagogical, and this report, therefore, serves a
useful tutorial for researchers, practitioners, and students, new to the field
of quantum information science, in particular, quantum cryptography, as it
develops the proof in a systematic manner, starting from the properties of
linear codes, and then advancing to the quantum error correcting codes, which
are critical to the understanding of the security proof.",1409.1452v1,quant-ph,2014-08-30 23:17:35+00:00,[arxiv.Result.Author('Ramesh Bhandari')],
206,Towards Provably Secure Encrypted Control Using Homomorphic Encryption,"Encrypted control is a promising method for the secure outsourcing of
controller computation to a public cloud. However, a feasible method for
security proofs of control has not yet been developed in the field of encrypted
control systems. Additionally, cryptography does not consider certain types of
attacks on encrypted control systems; therefore, the security of such a system
cannot be guaranteed using a secure cryptosystem. This study proposes a novel
security definition for encrypted control under attack for control systems
using cryptography. It applies the concept of provable security, which is the
security of cryptosystems based on mathematical proofs, to encrypted control
systems. Furthermore, this study analyzes the relation between the proposed
security and the conventional security of cryptosystems. The results of the
analysis demonstrated that the security of an encrypted control system can be
enhanced by employing secure homomorphic encryption.",2210.08849v1,eess.SY,2022-10-17 08:45:31+00:00,"[arxiv.Result.Author('Kaoru Teranishi'), arxiv.Result.Author('Kiminao Kogiso')]",
207,Security analysis of the W-OTS$^+$ signature scheme: Updating security bounds,"In this work, we discuss in detail a flaw in the original security proof of
the W-OTS${^+}$ variant of the Winternitz one-time signature scheme, which is
an important component for various stateless and stateful many-time hash-based
digital signature schemes. We update the security proof for the W-OTS${^+}$
scheme and derive the corresponding security level. Our result is of importance
for the security analysis of hash-based digital signature schemes.",2002.07419v2,cs.CR,2020-02-18 07:59:59+00:00,"[arxiv.Result.Author('M. A. Kudinov'), arxiv.Result.Author('E. O. Kiktenko'), arxiv.Result.Author('A. K. Fedorov')]","Mat. Vopr. Kriptogr. 12, 129 (2021)"
208,Security of Quantum Key Distribution,"The security issues facing quantum key distribution (QKD) are explained,
herein focusing on those issues that are cryptographic and information
theoretic in nature and not those based on physics. The problem of security
criteria is addressed. It is demonstrated that an attacker's success
probabilities are the fundamental criteria of security that any theoretic
security criterion must relate to in order to have operational significance.
The errors committed in the prevalent interpretation of the trace distance
criterion are analyzed. The security proofs of QKD protocols are discussed and
assessed in regard to three main features: their validity, completeness, and
adequacy of the achieved numerical security level. Problems are identified in
all these features. It appears that the QKD security situation is quite
different from the common perception that a QKD-generated key is nearly
perfectly secure. Built into our discussion is a simple but complete
quantitative description of the information theoretic security of classical key
distribution that is also applicable to the quantum situation. In the
appendices, we provide a brief outline of the history of some major QKD
security proofs, a rather unfavorable comparison of current QKD proven security
with that of conventional symmetric key ciphers, and a list of objections and
answers concerning some major points of the paper.",1602.07602v1,quant-ph,2016-02-24 17:08:38+00:00,[arxiv.Result.Author('Horace Yuen')],
209,multiple layers of fuzzy logic to quantify vulnerabilies in iot,"Quantifying vulnerabilities of network systems has been a highly
controversial issue in the fields of network security and IoT. Much research
has been conducted on this purpose; however, these have many ambiguities and
uncertainties. In this paper, we investigate the quantification of
vulnerability in the Department of Transportation (DOT) as our proof of
concept. We initiate the analysis of security requirements, using Security
Quality Requirements Engineering (SQUARE) for security requirements
elicitation. Then we apply published security standards such as NIST SP-800 and
ISO 27001 to map our security factors and sub-factors. Finally, we propose our
Multi-layered Fuzzy Logic (MFL) approach based on Goal question Metrics (GQM)
to quantify network security and IoT (Mobile Devices) vulnerability in DOT.",2007.07155v1,cs.CR,2020-07-14 16:14:51+00:00,"[arxiv.Result.Author('Mohammad Shojaeshafiei'), arxiv.Result.Author('Letha Etzkorn'), arxiv.Result.Author('Michael Anderson')]",
210,How to Build Unconditionally Secure Quantum Bit Commitment Protocols,"The ``impossibility proof'' on unconditionally secure quantum bit commitment
is critically analyzed. Many possibilities for obtaining a secure bit
commitment protocol are indicated, purely on the basis of two-way quantum
communications, which are not covered by the impossibility proof formulation.
They are classified under six new types of protocols, with security proofs for
specific examples on four types. Reasons for some previously failed attempts at
obtaining secure protocols are also indicated.",quant-ph/0305144v3,quant-ph,2003-05-23 18:58:58+00:00,[arxiv.Result.Author('Horace P. Yuen')],
211,From Qualitative to Quantitative Proofs of Security Properties Using First-Order Conditional Logic,"A first-order conditional logic is considered, with semantics given by a
variant of epsilon-semantics, where p -> q means that Pr(q | p) approaches 1
super-polynomially --faster than any inverse polynomial. This type of
convergence is needed for reasoning about security protocols. A complete
axiomatization is provided for this semantics, and it is shown how a
qualitative proof of the correctness of a security protocol can be
automatically converted to a quantitative proof appropriate for reasoning about
concrete security.",0804.2155v1,cs.CR,2008-04-14 12:06:04+00:00,[arxiv.Result.Author('Joseph Y. Halpern')],
212,Towards practical security of continuous-variable quantum key distribution,"Rigorous mathematical proofs of the security of continuous-variable quantum
key distribution (CV QKD) have been obtained recently. Unfortunately, these
security proofs rely on assumptions that are hardly met in experimental
practice. Here I investigate these issues in detail, and discuss
experimentally-friendly workarounds to assess the security of CV QKD. The aim
of this paper is to show that there are hidden and unsolved issues and to
indicate possible partial solutions. To provide a complete and rigorous
mathematical security proof is out of the scope of this contribution.",1911.04799v3,quant-ph,2019-11-12 11:36:46+00:00,[arxiv.Result.Author('Cosmo Lupo')],"Phys. Rev. A 102, 022623 (2020)"
213,Prospects for device-independent quantum key distribution,"Device-independent quantum key distribution (DIQKD) aims to achieve secure
key distribution with only minimal assumptions, by basing its security on the
violation of Bell inequalities. While this offers strong security guarantees,
it comes at the cost of being challenging to implement experimentally. In this
thesis, we present security proofs for several techniques that help to improve
the keyrates and noise tolerance of DIQKD, such as noisy preprocessing, random
key measurements, and advantage distillation. We also show finite-size security
proofs for some protocols based on combining several of these techniques. These
results and proof techniques should be useful for further development of DIQKD
protocols.",2111.11769v1,quant-ph,2021-11-23 10:28:30+00:00,[arxiv.Result.Author('Ernest Y. -Z. Tan')],
214,"Relations between semantic security and indistinguishability against cpa, non-adaptive cca and adaptive cca in comparison based framework","In this paper we try to unify the frameworks of definitions of semantic
security, indistinguishability and non-malleability by defining semantic
security in comparison based framework. This facilitates the study of relations
among these goals against different attack models and makes the proof of the
equivalence of semantic security and indistinguishability easier and more
understandable. Besides, our proof of the equivalence of semantic security and
indistinguishability does not need any intermediate goals such as non
devidability to change the definition framework.",cs/0508110v1,cs.CR,2005-08-25 04:58:27+00:00,"[arxiv.Result.Author('Ali Bagherzandi'), arxiv.Result.Author('Kooshiar Azimian'), arxiv.Result.Author('Javad Mohajeri'), arxiv.Result.Author('Mahmoud Salmasizadeh')]",
215,Adversary Model: Adaptive Chosen Ciphertext Attack with Timing Attack,"We have introduced a novel adversary model in Chosen-Ciphertext Attack with
Timing Attack (CCA2-TA) and it was a practical model because the model
incorporates the timing attack. This paper is an extended paper for 'A Secure
TFTP Protocol with Security Proofs'.
  Keywords - Timing Attack, Random Oracle Model, Indistinguishabilit, Chosen
Plaintext Attack, CPA, Chosen Ciphertext Attack, IND-CCA1, Adaptive Chosen
Ciphertext Attack, IND-CCA2, Trivial File Transfer Protocol, TFTP, Security,
Trust, Privacy, Trusted Computing, UBOOT, AES, IOT, Lightweight, Asymmetric,
Symmetric, Raspberry Pi, ARM.",1409.6556v1,cs.CR,2014-09-23 14:24:35+00:00,"[arxiv.Result.Author('Mohd Anuar Mat Isa'), arxiv.Result.Author('Habibah Hashim')]",
216,Secure Vehicle Communications Using Proof-of-Nonce Blockchain,"This paper presents an autonomous driving that achieves physical layer
security. Proposed vehicle communication is implemented based on Proof-of-Nonce
(PoN) blockchain algorithm. PoN blockchain algorithm is a consensus algorithm
that can be implemented in light weight. We propose a more secure vehicle
communication scheme while achieving physical layer security by defecting PoN
algorithm and secrecy capacity. By generating a block only when secrecy
capacity is greater than or equal to the reference value, traffic information
can be provided only to vehicles with physical layer security. This vehicle
communication scheme can secure sufficient safety even from hackers based on
quantum computing.",2011.07846v1,cs.SE,2020-11-16 10:31:42+00:00,"[arxiv.Result.Author('N. Y. Ahn'), arxiv.Result.Author('D. H. Lee')]",
217,VST-Flow: Fine-grained low-level reasoning about real-world C code,"We show how support for information-flow security proofs could be added on
top of the Verified Software Toolchain (VST). We discuss several attempts to
define information flow security in a VST-compatible way, and present a
statement of information flow security in ""continuation-passing"" style.
Moreover, we present Hoare rules augmented with information flow control
assertions, and sketch how these rules could be proven sound with respect to
the definition given before. We also discuss how this can be implemented in the
Coq proof assistant, and how VST's proof automation framework (VST-Floyd) can
be adapted to support convenient information flow security proofs.",1709.05243v1,cs.LO,2017-09-15 14:54:50+00:00,"[arxiv.Result.Author('Samuel Gruetter'), arxiv.Result.Author('Toby Murray')]",
218,Why there is no impossibility theorem on Secure Quantum Bit Commitment,"The impossibility proof on unconditionally secure quantum bit commitment is
critically reviewed. Different ways of obtaining secure protocols are
indicated.",quant-ph/0210206v1,quant-ph,2002-10-30 20:45:59+00:00,[arxiv.Result.Author('Horace P. Yuen')],
219,Compositional properties of crypto-based components,"This paper presents an Isabelle/HOL+Isar set of theories which allows to
specify crypto-based components and to verify their composition properties wrt.
cryptographic aspects. We introduce a formalisation of the security property of
data secrecy, the corresponding definitions and proofs.",1405.3006v1,cs.CR,2014-05-13 01:15:14+00:00,[arxiv.Result.Author('Maria Spichkova')],
220,"Arrangements, Milnor Fibers and Polar Curves","We describe a new relation between the topology of hyperplane arrangements,
Milnor fibers and global polar curves, via the affine Lefschetz theory
developped by A. N\'emethi. In particular, we improve some results due to Orlik
and Terao (see Math. Ann. 301(1995)) and complete/clarify a proof by Randell
concerning the minimality of hyperplane arrangements (see math.AT/0011101).",math/0011073v2,math.AG,2000-11-13 08:40:33+00:00,[arxiv.Result.Author('A. Dimca')],
221,"Hypersurface complements, Milnor fibers and minimality of arrangements","We describe a new relation between the topology of hypersurface complements,
  Milnor fibers and degree of gradient mappings. The main tools are polar
curves and the affine Lefschetz theory developped by H. Hamm and A. N\'emethi.
  In the special case of the hyperplane arrangements, we strengthen some
results due to Orlik and Terao (see Math. Ann.
  301(1995)) and obtain an independant proof for the minimality of hyperplane
arrangements (see Randell math.AT/0011101 for another proof of this result).",math/0011222v2,math.AT,2000-11-27 10:13:58+00:00,[arxiv.Result.Author('A. Dimca')],
222,"Hypersurface complements, Milnor fibers and higher homotopy groups of arrangements","We describe a new relation between the topology of hypersurface complements,
Milnor fibers and degree of gradient mappings. In particular we show that any
projective hypersurface has affine parts which are bouquets of spheres. The
main tools are the polar curves and the affine Lefschetz theory developped by
H. Hamm, D.T. L\^e and A. N\'emethi. In the special case of the hyperplane
arrangements, we strengthen some results due to Orlik and Terao (see Math. Ann.
301(1995)) and obtain the minimality of hyperplane arrangements (see Randell
math.AT/0011101 for another proof of this result). This is then used to compute
some higher homotopy groups of hyperplane arrangements using the ideas from
Papadima-Suciu, see math.AT/0002251. The second version contains applications
of the above ideas to the polar Cremona transformations and gives a positive
answer to Dolgachev's Conjecture (see Michigan Math. J. 48 (2000), volume
dedicated to W. Fulton). The third version corrects some errors and provides
new applications.",math/0101246v4,math.AT,2001-01-30 10:51:00+00:00,"[arxiv.Result.Author('Alexandru Dimca'), arxiv.Result.Author('Stefan Papadima')]","Ann. of Math. (2), Vol. 158 (2003), no. 2, 473--507"
223,Counting irreducible binomials over finite fields,"We consider various counting questions for irreducible binomials over finite
fields. We use various results from analytic number theory to investigate these
questions.",1504.01172v1,math.NT,2015-04-05 23:47:39+00:00,"[arxiv.Result.Author('Randell Heyman'), arxiv.Result.Author('Igor E. Shparlinski')]","Finite fields and their applications, 38, (2016), 1-12"
224,Evaluationally coprime linear polynomials,"Two polynomials, $f,g \in \mathbb{Z}[x]$ are evaluationally coprime at x if
$\gcd(f(x),g(x))=1$. We give necessary and sufficient conditions for two such
linear polynomials to have a positive proportion of evaluated coprime values.",1603.06630v1,math.NT,2016-03-21 21:51:39+00:00,[arxiv.Result.Author('Randell Heyman')],"Integers, 16, (2016), A65"
225,Cardinality of a floor function set,"Fix a positive integer X. We quantify the cardinality of the set $\{\lfloor
X/n \rfloor\}_{n=1}^X$. We discuss restricting the set to those elements that
are prime, semiprime or similar.",1905.00533v2,math.NT,2019-05-02 00:06:02+00:00,[arxiv.Result.Author('Randell Heyman')],
226,Particle Physics Implications and Constraints on Dark Matter Interpretations of the CDMS Signal,"Recently the CDMS collaboration has reported an excess of events in the
signal region of a search for dark matter scattering with Silicon nuclei. Three
events on an expected background of 0.4 have a significance of about 2 sigma,
and it is premature to conclude that this is a signal of dark matter.
Nonetheless, it is important to examine the space of particle theories capable
of explaining this excess, to see what theories are capable of explaining it,
and how one might exclude it or find corroborating evidence in other channels.
We examine a simplified model containing a scalar mediator particle, and find
regions consistent with the CDMS observations. Bounds from colliders put
important restrictions on the theory, but viable points, including points
leading to the observed thermal relic density, survive.",1305.6609v2,hep-ph,2013-05-28 20:00:02+00:00,"[arxiv.Result.Author('Randel C. Cotta'), arxiv.Result.Author('Arvind Rajaraman'), arxiv.Result.Author('Tim M. P. Tait'), arxiv.Result.Author('Alexander M. Wijangco')]","Phys. Rev. D 90, 013020 (2014)"
227,"SEE-Few: Seed, Expand and Entail for Few-shot Named Entity Recognition","Few-shot named entity recognition (NER) aims at identifying named entities
based on only few labeled instances. Current few-shot NER methods focus on
leveraging existing datasets in the rich-resource domains which might fail in a
training-from-scratch setting where no source-domain data is used. To tackle
training-from-scratch setting, it is crucial to make full use of the annotation
information (the boundaries and entity types). Therefore, in this paper, we
propose a novel multi-task (Seed, Expand and Entail) learning framework,
SEE-Few, for Few-shot NER without using source domain data. The seeding and
expanding modules are responsible for providing as accurate candidate spans as
possible for the entailing module. The entailing module reformulates span
classification as a textual entailment task, leveraging both the contextual
clues and entity type information. All the three modules share the same text
encoder and are jointly learned. Experimental results on four benchmark
datasets under the training-from-scratch setting show that the proposed method
outperformed state-of-the-art few-shot NER methods with a large margin. Our
code is available at https://github.com/unveiled-the-red-hat/SEE-Few.",2210.05632v1,cs.CL,2022-10-11 17:20:47+00:00,"[arxiv.Result.Author('Zeng Yang'), arxiv.Result.Author('Linhai Zhang'), arxiv.Result.Author('Deyu Zhou')]",
228,Homotopy groups and twisted homology of arrangements,"Recent work of M. Yoshinaga shows that in some instances certain higher
homotopy groups of arrangements map onto non-resonant homology. This is in
contrast to the usual Hurewicz map to untwisted homology, which is always the
zero homomorphism in degree greater than one. In this work we examine this
dichotomy, generalizing both results.",0811.1531v2,math.GT,2008-11-10 18:07:45+00:00,[arxiv.Result.Author('Richard Randell')],Algebr. Geom. Topol. 9 (2009) 1299-1308
229,On the number of polynomials of bounded height that satisfy Dumas's criterion,"We study integer coefficient polynomials of fixed degree and maximum height
$H$, that are irreducible by Dumas's criterion. We call such polynomials Dumas
polynomials. We derive upper bounds on the number of Dumas polynomials, as $H$
approaches infinity. We also show that, for a fixed degree, the density of
Dumas polynomials in all irreducible integer coefficient polynomials is
strictly less than 1.",1309.4826v1,math.NT,2013-09-18 23:56:39+00:00,[arxiv.Result.Author('Randell Heyman')],"Journal of integer sequences, 17, (2014) Article 14.2.4"
230,Tuples of polynomials over finite fields with pairwise coprimality conditions,"Let $q$ be a prime power. We estimate the number of tuples of degree bounded
monic polynomials $(Q_1,\ldots,Q_v) \in (\mathbb{F}_q[z])^v$ that satisfy given
pairwise coprimality conditions. We show how this generalises from monic
polynomials in finite fields to Dedekind domains with finite norms.",1706.01181v2,math.NT,2017-06-05 03:35:00+00:00,"[arxiv.Result.Author('Juan Arias de Reyna'), arxiv.Result.Author('Randell Heyman')]",
231,A summation involving the number of divisors function and the GCD function,"Let $N$ be a positive number. We give an asymptotic formula for the sum of
$\tau(\gcd(a,b))$ for all $a$ and $b$ with $ab \le N$.",2003.13937v6,math.NT,2020-03-31 03:31:28+00:00,[arxiv.Result.Author('Randell Heyman')],
232,A summation of the number of distinct prime divisors of the lcm,"Let $x$ be a positive integer. We give an asymptotic result for
$\omega(\operatorname{lcm}(m,n))$ summed over all positive integers $m$ and $n$
with $mn \le x$. This answers an open question posed in a recent paper.",2012.11837v2,math.NT,2020-12-22 05:32:05+00:00,[arxiv.Result.Author('Randell Heyman')],
233,Primes in floor function sets,"Let $x$ be a positive integer. We give an asymptotic formula for the number
of primes in the set $\{\fl{x/n}, 1 \le n \le x\}$ and give some related
results.",2111.00408v5,math.NT,2021-10-31 05:21:37+00:00,[arxiv.Result.Author('Randell Heyman')],
234,Learning by Distilling Context,"Language models significantly benefit from context tokens, such as prompts or
scratchpads. They perform better when prompted with informative instructions,
and they acquire new reasoning capabilities by generating a scratch-pad before
predicting the final answers. However, they do not \textit{internalize} these
performance gains, which disappear when the context tokens are gone. Our work
proposes to apply context distillation so that a language model can improve
itself by internalizing these gains. Concretely, given a synthetic unlabeled
input for the target task, we condition the model on ``[instructions] +
[task-input]'' to predict ``[scratch-pad] + [final answer]''; then we fine-tune
the same model to predict its own ``[final answer]'' conditioned on the
``[task-input]'', without seeing the ``[instructions]'' or using the
``[scratch-pad]''.
  We show that context distillation is a general method to train language
models, and it can effectively internalize 3 types of training signals. First,
it can internalize abstract task instructions and explanations, so we can
iteratively update the model parameters with new instructions and overwrite old
ones. Second, it can internalize step-by-step reasoning for complex tasks
(e.g., 8-digit addition), and such a newly acquired capability proves to be
useful for other downstream tasks. Finally, it can internalize concrete
training examples, and it outperforms directly learning with gradient descent
by 9\% on the SPIDER Text-to-SQL dataset; furthermore, combining context
distillation operations can internalize more training examples than the context
window size allows.",2209.15189v1,cs.CL,2022-09-30 02:30:15+00:00,"[arxiv.Result.Author('Charlie Snell'), arxiv.Result.Author('Dan Klein'), arxiv.Result.Author('Ruiqi Zhong')]",
235,Evolving Reinforcement Learning Algorithms,"We propose a method for meta-learning reinforcement learning algorithms by
searching over the space of computational graphs which compute the loss
function for a value-based model-free RL agent to optimize. The learned
algorithms are domain-agnostic and can generalize to new environments not seen
during training. Our method can both learn from scratch and bootstrap off known
existing algorithms, like DQN, enabling interpretable modifications which
improve performance. Learning from scratch on simple classical control and
gridworld tasks, our method rediscovers the temporal-difference (TD) algorithm.
Bootstrapped from DQN, we highlight two learned algorithms which obtain good
generalization performance over other classical control tasks, gridworld type
tasks, and Atari games. The analysis of the learned algorithm behavior shows
resemblance to recently proposed RL algorithms that address overestimation in
value-based methods.",2101.03958v6,cs.LG,2021-01-08 18:55:07+00:00,"[arxiv.Result.Author('John D. Co-Reyes'), arxiv.Result.Author('Yingjie Miao'), arxiv.Result.Author('Daiyi Peng'), arxiv.Result.Author('Esteban Real'), arxiv.Result.Author('Sergey Levine'), arxiv.Result.Author('Quoc V. Le'), arxiv.Result.Author('Honglak Lee'), arxiv.Result.Author('Aleksandra Faust')]",
236,Interpretable agent communication from scratch (with a generic visual processor emerging on the side),"As deep networks begin to be deployed as autonomous agents, the issue of how
they can communicate with each other becomes important. Here, we train two deep
nets from scratch to perform realistic referent identification through
unsupervised emergent communication. We show that the largely interpretable
emergent protocol allows the nets to successfully communicate even about object
types they did not see at training time. The visual representations induced as
a by-product of our training regime, moreover, show comparable quality, when
re-used as generic visual features, to a recent self-supervised learning model.
Our results provide concrete evidence of the viability of (interpretable)
emergent deep net communication in a more realistic scenario than previously
considered, as well as establishing an intriguing link between this field and
self-supervised visual learning.",2106.04258v3,cs.CL,2021-06-08 11:32:11+00:00,"[arxiv.Result.Author('Roberto Dessì'), arxiv.Result.Author('Eugene Kharitonov'), arxiv.Result.Author('Marco Baroni')]",
237,A Tutorial on Spectral Clustering,"In recent years, spectral clustering has become one of the most popular
modern clustering algorithms. It is simple to implement, can be solved
efficiently by standard linear algebra software, and very often outperforms
traditional clustering algorithms such as the k-means algorithm. On the first
glance spectral clustering appears slightly mysterious, and it is not obvious
to see why it works at all and what it really does. The goal of this tutorial
is to give some intuition on those questions. We describe different graph
Laplacians and their basic properties, present the most common spectral
clustering algorithms, and derive those algorithms from scratch by several
different approaches. Advantages and disadvantages of the different spectral
clustering algorithms are discussed.",0711.0189v1,cs.DS,2007-11-01 19:04:43+00:00,[arxiv.Result.Author('Ulrike von Luxburg')],"Statistics and Computing 17(4), 2007"
238,Computational Thinking in Patch,"With the future likely to see even more pervasive computation, computational
thinking (problem-solving skills incorporating computing knowledge) is now
being recognized as a fundamental skill needed by all students. Computational
thinking is conceptualizing as opposed to programming, promotes natural human
thinking style than algorithmic reasoning, complements and combines
mathematical and engineering thinking, and it emphasizes ideas, not artifacts.
In this paper, we outline a new visual language, called Patch, using which
students are able to express their solutions to eScience computational problems
in abstract visual tools. Patch is closer to high level procedural languages
such as C++ or Java than Scratch or Snap! but similar to them in ease of use
and combines simplicity and expressive power in one single platform.",1706.03272v1,cs.PL,2017-06-10 19:00:51+00:00,[arxiv.Result.Author('Hasan M. Jamil')],
239,Mid-Level Visual Representations Improve Generalization and Sample Efficiency for Learning Visuomotor Policies,"How much does having visual priors about the world (e.g. the fact that the
world is 3D) assist in learning to perform downstream motor tasks (e.g.
delivering a package)? We study this question by integrating a generic
perceptual skill set (e.g. a distance estimator, an edge detector, etc.) within
a reinforcement learning framework--see Figure 1. This skill set (hereafter
mid-level perception) provides the policy with a more processed state of the
world compared to raw images.
  We find that using a mid-level perception confers significant advantages over
training end-to-end from scratch (i.e. not leveraging priors) in
navigation-oriented tasks. Agents are able to generalize to situations where
the from-scratch approach fails and training becomes significantly more sample
efficient. However, we show that realizing these gains requires careful
selection of the mid-level perceptual skills. Therefore, we refine our findings
into an efficient max-coverage feature set that can be adopted in lieu of raw
images. We perform our study in completely separate buildings for training and
testing and compare against visually blind baseline policies and
state-of-the-art feature learning methods.",1812.11971v3,cs.CV,2018-12-31 18:59:25+00:00,"[arxiv.Result.Author('Alexander Sax'), arxiv.Result.Author('Bradley Emi'), arxiv.Result.Author('Amir R. Zamir'), arxiv.Result.Author('Leonidas Guibas'), arxiv.Result.Author('Silvio Savarese'), arxiv.Result.Author('Jitendra Malik')]",
240,E-voting in Estonia,"Estonia has one of the most established e-voting systems in the world.
Internet voting - remote e-voting using the voter's own equipment - was piloted
in 2005 with the first real elections using e-voting being conducted the same
year and has been in use ever since. We detail this internet voting system and
discuss how it was developed.",1606.08654v1,cs.CR,2016-06-28 11:21:20+00:00,"[arxiv.Result.Author('Dylan Clarke'), arxiv.Result.Author('Tarvi Martens')]",
241,E-voting System Using Homomorphic Encryption and Blockchain Technology to Encrypt Voter Data,"Homomorphic encryption and blockchain technology are regarded as two
significant technologies for improving e-voting systems. In this paper, we
suggest a novel e-voting system using homomorphic encryption and blockchain
technology that is focused on encrypting voter data. By encrypting voter
information rather than cast votes, the system enables various statistical
analyses regarding the vote result while securing the credibility, privacy, and
verifiability of overall e-voting system. We checked the efficiency of the
overall system by comparing the speed of the proposed system with the speed of
other e-voting systems that use homomorphic encryption and blockchain
technology.",2111.05096v1,cs.CR,2021-11-06 01:01:13+00:00,"[arxiv.Result.Author('Hyunyeon Kim'), arxiv.Result.Author('Kyung Eun Kim'), arxiv.Result.Author('Soohan Park'), arxiv.Result.Author('Jongsoo Sohn')]",
242,A Survey on Feasibility and Suitability of Blockchain Techniques for the E-Voting Systems,"In the second decade of the 21st century, blockchain definitely became one of
the most trending computational technologies. This research aims to question
the feasibility and suitability of using blockchain technology within e-voting
systems, regarding both technical and non-technical aspects. In today's world,
although the course of this spreading is considerably slow, several countries
already use means of e-voting due to many social and economic reasons, which we
further investigated. Nevertheless, the number of countries offering various
e-government solutions, apart from e-voting, is significantly high. E-voting
systems, naturally, require much more attention and assurance regarding
potential security and anonymity issues, since voting is one of the few
extremely critical governmental processes. Nevertheless, e-voting is not purely
a governmental service, but many companies and nonprofit organizations would
benefit the cost-efficiency, scalability, remote accessibility, and ease of use
that it provides. Blockchain technology is claimed to be able to address some,
obviously not all, important security concerns, including anonymity,
confidentiality, integrity, and non-repudiation. The analysis results presented
in this article mostly confirm these claims.",2002.07175v1,cs.CR,2020-02-11 11:19:54+00:00,"[arxiv.Result.Author('Umut Can Cabuk'), arxiv.Result.Author('Eylul Adiguzel'), arxiv.Result.Author('Enis Karaarslan')]","International Journal of Advanced Research in Computer and
  Communication Engineering (IJARCCE), Vol. 7, Issue 3, March 2018"
243,Swiss Elections to the National Council: First trials with e-voting in elections at federal level,"On October 23rd 2011, around 22'000 voters will be authorized to cast their
votes electronically in occasion of the elections to the National Council.
These are the first trials ever with e-voting in elections at federal level in
Switzerland. Four cantons are going to conduct trials with this new channel.
Only Swiss voters living abroad will be authorized to participate. The Swiss
Confederation pursues the long term goal of the introduction of e-voting as a
third, complementary voting method - in addition to voting in person at the
polling station and postal voting.",1109.2489v2,cs.CY,2011-09-09 15:03:01+00:00,"[arxiv.Result.Author('Anina Weber'), arxiv.Result.Author('Geo Taglioni')]",
244,A Simple E-Voting Protocol,"We propose an e-voting protocol that seems to allow citizens to verify that
their vote has been accurately taken into account while preserving its secrecy,
without requiring the use of a complex process. The main idea is to give each
voter a receipt on which her choice is mixed with the choices of other voters.",0808.2431v1,cs.CY,2008-08-18 17:19:40+00:00,[arxiv.Result.Author('Frederic Connes')],
245,Secret Sharing Homomorphism and Secure E-voting,"Secure E-voting is a challenging protocol. Several approaches based on
homomorphic crypto systems, mix-nets blind signatures are proposed in the
literature .But most of them need complicated homomorphic encryption which
involves complicated encryption decryption process and key management which is
not efficient. In this paper we propose a secure and efficient E-voting scheme
based on secret sharing homomorphism. Here E-voting is viewed as special case
of multi party computation where several voters jointly compute the result
without revealing his vote. Secret sharing schemes are good alternative for
secure multi party computation and are computationally efficient and secure
compared with the cryptographic techniques. It is the first proposal, which
makes use of the additive homomorphic property of the Shamir secret sharing
scheme and the encoding decoding of votes to obtain the individual votes
obtained by each candidate apart from the election result. We have achieved
integrity and privacy while keeping the efficiency of the system.",1602.05372v1,cs.CR,2016-02-17 11:05:26+00:00,"[arxiv.Result.Author('V P Binu'), arxiv.Result.Author('Divya G Nair'), arxiv.Result.Author('A Sreekumar')]",
246,E-Voting with Blockchain: An E-Voting Protocol with Decentralisation and Voter Privacy,"Technology has positive impacts on many aspects of our social life. Designing
a 24hour globally connected architecture enables ease of access to a variety of
resources and services. Furthermore, technology like Internet has been a
fertile ground for innovation and creativity. One of such disruptive innovation
is blockchain -- a keystone of cryptocurrencies. The blockchain technology is
presented as a game changer for many of the existing and emerging
technologies/services. With its immutability property and decentralised
architecture, it is taking centre stage in many services as an equalisation
factor to the current parity between consumers and large
corporations/governments. One of such potential applications of the blockchain
is in e-voting schemes. The objective of such a scheme would be to provide a
decentralised architecture to run and support a voting scheme that is open,
fair and independently verifiable. In this paper, we propose potentially a new
e-voting protocol that utilises the blockchain as a transparent ballot box. The
protocol has been designed with adhering to the fundamental e-voting properties
in mind as well as offering a degree of decentralisation and allowing for the
voter to change/update their vote (within the permissible voting period). The
paper highlights the pros and cons of using blockchain for such a proposal from
practical point view in both development/deployment and usage contexts.
Concluding the paper with a potential roadmap for blockchain technology to be
able to support complex applications.",1805.10258v2,cs.CR,2018-05-25 17:18:25+00:00,"[arxiv.Result.Author('Freya Sheer Hardwick'), arxiv.Result.Author('Apostolos Gioulis'), arxiv.Result.Author('Raja Naeem Akram'), arxiv.Result.Author('Konstantinos Markantonakis')]",
247,(Universal) Unconditional Verifiability in E-Voting without Trusted Parties,"In traditional e-voting protocols, privacy is often provided by a trusted
authority that learns the votes and computes the tally. Some protocols replace
the trusted authority by a set of authorities, and privacy is guaranteed if
less than a threshold number of authorities are corrupt. For verifiability,
stronger security guarantees are demanded. Typically, corrupt authorities that
try to fake the result of the tally must always be detected.
  To provide verifiability, many e-voting protocols use Non-Interactive
Zero-Knowledge proofs (NIZKs). Thanks to their non-interactive nature, NIZKs
allow anybody, including third parties that do not participate in the protocol,
to verify the correctness of the tally. Therefore, NIZKs can be used to obtain
universal verifiability. Additionally, NIZKs also improve usability because
they allow voters to cast a vote using a non-interactive protocol.
  The disadvantage of NIZKs is that their security is based on setup
assumptions such as the common reference string (CRS) or the random oracle (RO)
model. The former requires a trusted party for the generation of a common
reference string. The latter, though a popular methodology for designing secure
protocols, has been shown to be unsound.
  In this paper, we address the design of an e-voting protocol that provides
verifiability without any trust assumptions, where verifiability here is meant
without eligibility verification. We show that Non-Interactive
Witness-Indistinguishable proofs (NIWI) can be used for this purpose. The
e-voting scheme is private under the Decision Linear assumption, while
verifiability holds unconditionally. To our knowledge, this is the first
private e-voting scheme with perfect universal verifiability, i.e. one in which
the probability of a fake tally not being detected is 0, and with {\em
non-interactive} protocols that does not rely on trust assumptions.",1610.06343v1,cs.CR,2016-10-20 09:57:12+00:00,"[arxiv.Result.Author('Gina Gallegos-Garcia'), arxiv.Result.Author('Vincenzo Iovino'), arxiv.Result.Author('Alfredo Rial'), arxiv.Result.Author('Peter B. Roenne'), arxiv.Result.Author('Peter Y. A. Ryan')]",
248,Evaluating e-voting: theory and practice,"In the Netherlands as well as many other countries, the use of electronic
voting solutions is a recurrent topic of discussion. While electronic voting
certainly has advantages over paper voting, there are also important risks
involved. This paper presents an analysis of benefits and risks of electronic
voting, and shows the relevance of these issues by means of three case studies
of real-world implementations. Additionally, techniques that may be employed to
improve upon many of the current systems are presented. We conclude that the
advantages of E-voting do not outweigh the disadvantages, as the resulting
reduced verifiability and transparency seem hard to overcome.",1602.02509v1,cs.CY,2016-02-08 09:47:04+00:00,"[arxiv.Result.Author('Wouter Bokslag'), arxiv.Result.Author('Manon de Vries')]",
249,Ques-Chain: an Ethereum Based E-Voting System,"Ethereum is an open-source, public, blockchain-based distributed computing
platform and operating system featuring smart contract functionality. In this
paper, we proposed an Ethereum based eletronic voting (e-voting) protocol,
Ques-Chain, which can ensure the authentication can be done without hurting
confidentiality and the anonymity can be protected without problems of scams at
the same time. Furthermore, the authors considered the wider usages Ques-Chain
can be applied on, pointing out that it is able to process all kinds of
messages and can be used in all fields with similar needs.",1905.05041v1,cs.CR,2019-05-13 13:58:20+00:00,"[arxiv.Result.Author('Qixuan Zhang'), arxiv.Result.Author('Bowen Xu'), arxiv.Result.Author('Haotian Jing'), arxiv.Result.Author('Zeyu Zheng')]",
250,Security Requirement Analysis of Blockchain-based E-Voting Systems,"In democratic countries such as India, voting is a fundamental right given to
citizens of their countries. Citizens need to physically present and cast their
vote in ballot-paper-based voting systems. Most of the citizens fail to fulfill
this constraint and have stayed away from their fundamental duty.
Electronic-voting systems are often considered one efficient alternative in
such situations. Blockchain Technology is an emerging technology that can
provide a real solution as it is characterized by immutable, transparent,
anonymous, and decentralized properties. This paper presents a security
requirement analysis for e-voting systems and evaluates blockchain technology
against these requirements.",2208.01277v1,cs.CR,2022-08-02 06:55:25+00:00,"[arxiv.Result.Author('Sanil S. Gandhi'), arxiv.Result.Author('Arvind W. Kiwelekar'), arxiv.Result.Author('Laxman D. Netak'), arxiv.Result.Author('Hansraj S. Wankhede')]",
251,Definitions and Analysis of Quantum E-voting Protocols,"Recent advances indicate that quantum computers will soon be reality.
Motivated by this ever more realistic threat for existing classical
cryptographic protocols, researchers have developed several schemes to resist
""quantum attacks"". In particular, for electronic voting, several e-voting
schemes relying on properties of quantum mechanics have been proposed. However,
each of these proposals comes with a different and often not well-articulated
corruption model, has different objectives, and is accompanied by security
claims which are never formalized and are at best justified only against
specific attacks. To address this, we propose the first formal security
definitions for quantum e-voting protocols. With these at hand, we systematize
and evaluate the security of previously-proposed quantum e-voting protocols; we
examine the claims of these works concerning privacy, correctness and
verifiability, and if they are correctly attributed to the proposed protocols.
In all non-trivial cases, we identify specific quantum attacks that violate
these properties. We argue that the cause of these failures lies in the absence
of formal security models and references to the existing cryptographic
literature.",1810.05083v3,quant-ph,2018-10-11 15:32:42+00:00,"[arxiv.Result.Author('Myrto Arapinis'), arxiv.Result.Author('Elham Kashefi'), arxiv.Result.Author('Nikolaos Lamprou'), arxiv.Result.Author('Anna Pappa')]","ACM Transactions on Quantum Computing 2, 1, Article 4 (2021)"
252,An Incoercible E-Voting Scheme Based on Revised Simplified Verifiable Re-encryption Mix-nets,"Simplified verifiable re-encryption mix-net (SVRM) is revised and a scheme
for e-voting systems is developed based on it. The developed scheme enables
e-voting systems to satisfy all essential requirements of elections. Namely,
they satisfy requirements about privacy, verifiability, fairness and
robustness. It also successfully protects voters from coercers except cases
where the coercers force voters to abstain from elections. In detail, voters
can conceal correspondences between them and their votes, anyone can verify the
accuracy of election results, and interim election results are concealed from
any entity. About incoercibility, provided that erasable-state voting booths
which disable voters to memorize complete information exchanged between them
and election authorities for constructing votes are available, coercer C cannot
know candidates that voters coerced by C had chosen even if the candidates are
unique to the voters. In addition, elections can be completed without
reelections even when votes were handled illegitimately.",1512.05596v1,cs.CR,2015-12-17 14:30:01+00:00,"[arxiv.Result.Author('Shinsuke Tamura'), arxiv.Result.Author('Hazim A. Haddad'), arxiv.Result.Author('Nazmul Islam'), arxiv.Result.Author('Kazi Md. Rokibul Alam')]",Information Security and Computer Fraud 3 (2015) 32-38
253,Self-sovereign identity as a tool for digital democracy,"The importance of digital identity as a foundation for digital public
services is considered. As the classical, centralised model digital identity
has proven to be subject to several limitations, self-sovereign identities are
proposed as replacement, especially in the context of e-government platforms
and direct participation to policymaking (e.g. through e-voting tools).",2106.11714v1,cs.CY,2021-06-22 12:30:56+00:00,"[arxiv.Result.Author('Roberta Centonze'), arxiv.Result.Author('Roberto Reale')]",
254,An Improved E-voting scheme using Secret Sharing based Secure Multi-party Computation,"E-voting systems (EVS)are having potential advantages over many existing
voting schemes.Security, transparency, accuracy and reliability are the major
concern in these systems.EVS continues to grow as the technology advances.It is
inexpensive and efficient as the resources become reusable.Fast and accurate
computation of results with voter privacy is the added advantage.In the
proposed system we make use of secret sharing technique and secure multi party
computation(SMC) to achieve security and reliability.Secret sharing is an
important technique used for SMC. Multi-party computation is typically
accomplished using secret sharing by making shares of the input and
manipulating the shares to compute a typical function of the input.The proposed
system make use of bitwise representation of votes and only the shares are used
for transmission and computation of result.Secure sum evaluation can be done
with shares distributed using Shamir's secret sharing scheme.The scheme is
hence secure and reliable and does not make any number theoretic assumptions
for security.We also propose a unique method which calculates the candidates
individual votes keeping the anonymity.",1502.07469v1,cs.CR,2015-02-26 08:35:35+00:00,"[arxiv.Result.Author('Divya G. Nair'), arxiv.Result.Author('V. P. Binu'), arxiv.Result.Author('G. Santhosh Kumar')]",
255,Improving Automated Symbolic Analysis for E-voting Protocols: A Method Based on Sufficient Conditions for Ballot Secrecy,"We advance the state-of-the-art in automated symbolic analysis for e-voting
protocols by introducing three conditions that together are sufficient to
guarantee ballot secrecy. There are two main advantages to using our
conditions, compared to existing automated approaches. The first is a
substantial expansion of the class of protocols and threat models that can be
automatically analysed: we can systematically deal with (a) honest authorities
present in different phases, (b) threat models in which no dishonest voters
occur, and (c) protocols whose ballot secrecy depends on fresh data coming from
other phases. The second advantage is that it can significantly improve
verification efficiency, as the individual conditions are often simpler to
verify. E.g., for the LEE protocol, we obtain a speedup of over two orders of
magnitude. We show the scope and effectiveness of our approach using ProVerif
in several case studies, including FOO, LEE, JCJ, and Belenios. In these case
studies, our approach does not yield any false attacks, suggesting that our
conditions are tight.",1709.00194v5,cs.CR,2017-09-01 08:06:18+00:00,"[arxiv.Result.Author('Cas Cremers'), arxiv.Result.Author('Lucca Hirschi')]",
256,"Electryo, In-person Voting with Transparent Voter Verifiability and Eligibility Verifiability","Selene is an e-voting protocol that allows voters to directly check their
individual vote, in cleartext, in the final tally via a tracker system, while
providing good coercion mitigation. This is in contrast to conventional,
end-to-end verifiable schemes in which the voter verifies the presence of an
encryption of her vote on the bulletin board. The Selene mechanism can be
applied to many e-voting schemes, but here we present an application to the
polling station context, resulting in a voter-verifiable electronic tally with
a paper audit trail. The system uses a smartcard-based public key system to
provide the individual verification and universal eligibility verifiability.
The paper record contains an encrypted link to the voter's identity, requiring
stronger assumptions on ballot privacy than normal paper voting, but with the
benefit of providing good auditability and dispute resolution as well as
supporting (comparison) risk limiting audits.",2105.14783v1,cs.CR,2021-05-31 08:22:29+00:00,"[arxiv.Result.Author('Peter B. Roenne'), arxiv.Result.Author('Peter Y. A Ryan'), arxiv.Result.Author('Marie-Laure Zollinger')]",
257,User Experience Design for E-Voting: How mental models align with security mechanisms,"This paper presents a mobile application for vote-casting and
vote-verification based on the Selene e-voting protocol and explains how it was
developed and implemented using the User Experience Design process. The
resulting interface was tested with 38 participants, and user experience data
was collected via questionnaires and semi-structured interviews on user
experience and perceived security. Results concerning the impact of displaying
security mechanisms on UX were presented in a complementary paper. Here we
expand on this analysis by studying the mental models revealed during the
interviews and compare them with theoretical security notions. Finally, we
propose a list of improvements for designs of future voting protocols.",2105.14901v2,cs.HC,2021-05-31 11:56:09+00:00,"[arxiv.Result.Author('Marie-Laure Zollinger'), arxiv.Result.Author('Verena Distler'), arxiv.Result.Author('Peter B. Roenne'), arxiv.Result.Author('Peter Y. A. Ryan'), arxiv.Result.Author('Carine Lallemand'), arxiv.Result.Author('Vincent Koenig')]","Fourth International Joint Conference on Electronic Voting
  E-Vote-ID 2019, p187--202"
258,Chirotonia: A Scalable and Secure e-Voting Framework based on Blockchains and Linkable Ring Signatures,"In this paper we propose a comprehensive and scalable framework to build
secure-by-design e-voting systems. Decentralization, transparency, determinism,
and untamperability of votes are granted by dedicated smart contracts on a
blockchain, while voter authenticity and anonymity are achieved through
(provable secure) linkable ring signatures. These, in combination with suitable
smart contract constraints, also grant protection from double voting. Our
design is presented in detail, focusing on its security guarantees and the
design choices that allow it to scale to a large number of voters. Finally, we
present a proof-of-concept implementation of the proposed framework, made
available as open source.",2111.02257v1,cs.CR,2021-11-03 14:47:07+00:00,"[arxiv.Result.Author('Antonio Russo'), arxiv.Result.Author('Antonio Fernández Anta'), arxiv.Result.Author('Maria Isabel González Vasco'), arxiv.Result.Author('Simon Pietro Romano')]",
259,"D-DEMOS: A distributed, end-to-end verifiable, internet voting system","E-voting systems have emerged as a powerful technology for improving
democracy by reducing election cost, increasing voter participation, and even
allowing voters to directly verify the entire election procedure. Prior
internet voting systems have single points of failure, which may result in the
compromise of availability, voter secrecy, or integrity of the election
results. In this paper, we present the design, implementation, security
analysis, and evaluation of D-DEMOS, a complete e-voting system that is
distributed, privacy-preserving and end-to-end verifiable. Our system includes
a fully asynchronous vote collection subsystem that provides immediate
assurance to the voter her vote was recorded as cast, without requiring
cryptographic operations on behalf of the voter. We also include a distributed,
replicated and fault-tolerant Bulletin Board component, that stores all
necessary election-related information, and allows any party to read and verify
the complete election process. Finally, we also incorporate trustees, i.e.,
individuals who control election result production while guaranteeing privacy
and end-to-end-verifiability as long as their strong majority is honest. Our
system is the first e-voting system whose voting operation is human verifiable,
i.e., a voter can vote over the web, even when her web client stack is
potentially unsafe, without sacrificing her privacy, and still be assured her
vote was recorded as cast. Additionally, a voter can outsource election
auditing to third parties, still without sacrificing privacy. Finally, as the
number of auditors increases, the probability of election fraud going
undetected is diminished exponentially. We provide a model and security
analysis of the system. We implement a prototype of the complete system, we
measure its performance experimentally, and we demonstrate its ability to
handle large-scale elections.",1507.06812v2,cs.CR,2015-07-24 11:29:12+00:00,"[arxiv.Result.Author('Nikos Chondros'), arxiv.Result.Author('Bingsheng Zhang'), arxiv.Result.Author('Thomas Zacharias'), arxiv.Result.Author('Panos Diamantopoulos'), arxiv.Result.Author('Stathis Maneas'), arxiv.Result.Author('Christos Patsonakis'), arxiv.Result.Author('Alex Delis'), arxiv.Result.Author('Aggelos Kiayias'), arxiv.Result.Author('Mema Roussopoulos')]",
260,E-voting in Estonia,"Estonia has one of the most established e-voting systems in the world.
Internet voting - remote e-voting using the voter's own equipment - was piloted
in 2005 with the first real elections using e-voting being conducted the same
year and has been in use ever since. We detail this internet voting system and
discuss how it was developed.",1606.08654v1,cs.CR,2016-06-28 11:21:20+00:00,"[arxiv.Result.Author('Dylan Clarke'), arxiv.Result.Author('Tarvi Martens')]",
261,E-voting System Using Homomorphic Encryption and Blockchain Technology to Encrypt Voter Data,"Homomorphic encryption and blockchain technology are regarded as two
significant technologies for improving e-voting systems. In this paper, we
suggest a novel e-voting system using homomorphic encryption and blockchain
technology that is focused on encrypting voter data. By encrypting voter
information rather than cast votes, the system enables various statistical
analyses regarding the vote result while securing the credibility, privacy, and
verifiability of overall e-voting system. We checked the efficiency of the
overall system by comparing the speed of the proposed system with the speed of
other e-voting systems that use homomorphic encryption and blockchain
technology.",2111.05096v1,cs.CR,2021-11-06 01:01:13+00:00,"[arxiv.Result.Author('Hyunyeon Kim'), arxiv.Result.Author('Kyung Eun Kim'), arxiv.Result.Author('Soohan Park'), arxiv.Result.Author('Jongsoo Sohn')]",
262,A Survey on Feasibility and Suitability of Blockchain Techniques for the E-Voting Systems,"In the second decade of the 21st century, blockchain definitely became one of
the most trending computational technologies. This research aims to question
the feasibility and suitability of using blockchain technology within e-voting
systems, regarding both technical and non-technical aspects. In today's world,
although the course of this spreading is considerably slow, several countries
already use means of e-voting due to many social and economic reasons, which we
further investigated. Nevertheless, the number of countries offering various
e-government solutions, apart from e-voting, is significantly high. E-voting
systems, naturally, require much more attention and assurance regarding
potential security and anonymity issues, since voting is one of the few
extremely critical governmental processes. Nevertheless, e-voting is not purely
a governmental service, but many companies and nonprofit organizations would
benefit the cost-efficiency, scalability, remote accessibility, and ease of use
that it provides. Blockchain technology is claimed to be able to address some,
obviously not all, important security concerns, including anonymity,
confidentiality, integrity, and non-repudiation. The analysis results presented
in this article mostly confirm these claims.",2002.07175v1,cs.CR,2020-02-11 11:19:54+00:00,"[arxiv.Result.Author('Umut Can Cabuk'), arxiv.Result.Author('Eylul Adiguzel'), arxiv.Result.Author('Enis Karaarslan')]","International Journal of Advanced Research in Computer and
  Communication Engineering (IJARCCE), Vol. 7, Issue 3, March 2018"
263,Swiss Elections to the National Council: First trials with e-voting in elections at federal level,"On October 23rd 2011, around 22'000 voters will be authorized to cast their
votes electronically in occasion of the elections to the National Council.
These are the first trials ever with e-voting in elections at federal level in
Switzerland. Four cantons are going to conduct trials with this new channel.
Only Swiss voters living abroad will be authorized to participate. The Swiss
Confederation pursues the long term goal of the introduction of e-voting as a
third, complementary voting method - in addition to voting in person at the
polling station and postal voting.",1109.2489v2,cs.CY,2011-09-09 15:03:01+00:00,"[arxiv.Result.Author('Anina Weber'), arxiv.Result.Author('Geo Taglioni')]",
264,A Simple E-Voting Protocol,"We propose an e-voting protocol that seems to allow citizens to verify that
their vote has been accurately taken into account while preserving its secrecy,
without requiring the use of a complex process. The main idea is to give each
voter a receipt on which her choice is mixed with the choices of other voters.",0808.2431v1,cs.CY,2008-08-18 17:19:40+00:00,[arxiv.Result.Author('Frederic Connes')],
265,Secret Sharing Homomorphism and Secure E-voting,"Secure E-voting is a challenging protocol. Several approaches based on
homomorphic crypto systems, mix-nets blind signatures are proposed in the
literature .But most of them need complicated homomorphic encryption which
involves complicated encryption decryption process and key management which is
not efficient. In this paper we propose a secure and efficient E-voting scheme
based on secret sharing homomorphism. Here E-voting is viewed as special case
of multi party computation where several voters jointly compute the result
without revealing his vote. Secret sharing schemes are good alternative for
secure multi party computation and are computationally efficient and secure
compared with the cryptographic techniques. It is the first proposal, which
makes use of the additive homomorphic property of the Shamir secret sharing
scheme and the encoding decoding of votes to obtain the individual votes
obtained by each candidate apart from the election result. We have achieved
integrity and privacy while keeping the efficiency of the system.",1602.05372v1,cs.CR,2016-02-17 11:05:26+00:00,"[arxiv.Result.Author('V P Binu'), arxiv.Result.Author('Divya G Nair'), arxiv.Result.Author('A Sreekumar')]",
266,E-Voting with Blockchain: An E-Voting Protocol with Decentralisation and Voter Privacy,"Technology has positive impacts on many aspects of our social life. Designing
a 24hour globally connected architecture enables ease of access to a variety of
resources and services. Furthermore, technology like Internet has been a
fertile ground for innovation and creativity. One of such disruptive innovation
is blockchain -- a keystone of cryptocurrencies. The blockchain technology is
presented as a game changer for many of the existing and emerging
technologies/services. With its immutability property and decentralised
architecture, it is taking centre stage in many services as an equalisation
factor to the current parity between consumers and large
corporations/governments. One of such potential applications of the blockchain
is in e-voting schemes. The objective of such a scheme would be to provide a
decentralised architecture to run and support a voting scheme that is open,
fair and independently verifiable. In this paper, we propose potentially a new
e-voting protocol that utilises the blockchain as a transparent ballot box. The
protocol has been designed with adhering to the fundamental e-voting properties
in mind as well as offering a degree of decentralisation and allowing for the
voter to change/update their vote (within the permissible voting period). The
paper highlights the pros and cons of using blockchain for such a proposal from
practical point view in both development/deployment and usage contexts.
Concluding the paper with a potential roadmap for blockchain technology to be
able to support complex applications.",1805.10258v2,cs.CR,2018-05-25 17:18:25+00:00,"[arxiv.Result.Author('Freya Sheer Hardwick'), arxiv.Result.Author('Apostolos Gioulis'), arxiv.Result.Author('Raja Naeem Akram'), arxiv.Result.Author('Konstantinos Markantonakis')]",
267,(Universal) Unconditional Verifiability in E-Voting without Trusted Parties,"In traditional e-voting protocols, privacy is often provided by a trusted
authority that learns the votes and computes the tally. Some protocols replace
the trusted authority by a set of authorities, and privacy is guaranteed if
less than a threshold number of authorities are corrupt. For verifiability,
stronger security guarantees are demanded. Typically, corrupt authorities that
try to fake the result of the tally must always be detected.
  To provide verifiability, many e-voting protocols use Non-Interactive
Zero-Knowledge proofs (NIZKs). Thanks to their non-interactive nature, NIZKs
allow anybody, including third parties that do not participate in the protocol,
to verify the correctness of the tally. Therefore, NIZKs can be used to obtain
universal verifiability. Additionally, NIZKs also improve usability because
they allow voters to cast a vote using a non-interactive protocol.
  The disadvantage of NIZKs is that their security is based on setup
assumptions such as the common reference string (CRS) or the random oracle (RO)
model. The former requires a trusted party for the generation of a common
reference string. The latter, though a popular methodology for designing secure
protocols, has been shown to be unsound.
  In this paper, we address the design of an e-voting protocol that provides
verifiability without any trust assumptions, where verifiability here is meant
without eligibility verification. We show that Non-Interactive
Witness-Indistinguishable proofs (NIWI) can be used for this purpose. The
e-voting scheme is private under the Decision Linear assumption, while
verifiability holds unconditionally. To our knowledge, this is the first
private e-voting scheme with perfect universal verifiability, i.e. one in which
the probability of a fake tally not being detected is 0, and with {\em
non-interactive} protocols that does not rely on trust assumptions.",1610.06343v1,cs.CR,2016-10-20 09:57:12+00:00,"[arxiv.Result.Author('Gina Gallegos-Garcia'), arxiv.Result.Author('Vincenzo Iovino'), arxiv.Result.Author('Alfredo Rial'), arxiv.Result.Author('Peter B. Roenne'), arxiv.Result.Author('Peter Y. A. Ryan')]",
268,Evaluating e-voting: theory and practice,"In the Netherlands as well as many other countries, the use of electronic
voting solutions is a recurrent topic of discussion. While electronic voting
certainly has advantages over paper voting, there are also important risks
involved. This paper presents an analysis of benefits and risks of electronic
voting, and shows the relevance of these issues by means of three case studies
of real-world implementations. Additionally, techniques that may be employed to
improve upon many of the current systems are presented. We conclude that the
advantages of E-voting do not outweigh the disadvantages, as the resulting
reduced verifiability and transparency seem hard to overcome.",1602.02509v1,cs.CY,2016-02-08 09:47:04+00:00,"[arxiv.Result.Author('Wouter Bokslag'), arxiv.Result.Author('Manon de Vries')]",
269,Ques-Chain: an Ethereum Based E-Voting System,"Ethereum is an open-source, public, blockchain-based distributed computing
platform and operating system featuring smart contract functionality. In this
paper, we proposed an Ethereum based eletronic voting (e-voting) protocol,
Ques-Chain, which can ensure the authentication can be done without hurting
confidentiality and the anonymity can be protected without problems of scams at
the same time. Furthermore, the authors considered the wider usages Ques-Chain
can be applied on, pointing out that it is able to process all kinds of
messages and can be used in all fields with similar needs.",1905.05041v1,cs.CR,2019-05-13 13:58:20+00:00,"[arxiv.Result.Author('Qixuan Zhang'), arxiv.Result.Author('Bowen Xu'), arxiv.Result.Author('Haotian Jing'), arxiv.Result.Author('Zeyu Zheng')]",
270,Security Requirement Analysis of Blockchain-based E-Voting Systems,"In democratic countries such as India, voting is a fundamental right given to
citizens of their countries. Citizens need to physically present and cast their
vote in ballot-paper-based voting systems. Most of the citizens fail to fulfill
this constraint and have stayed away from their fundamental duty.
Electronic-voting systems are often considered one efficient alternative in
such situations. Blockchain Technology is an emerging technology that can
provide a real solution as it is characterized by immutable, transparent,
anonymous, and decentralized properties. This paper presents a security
requirement analysis for e-voting systems and evaluates blockchain technology
against these requirements.",2208.01277v1,cs.CR,2022-08-02 06:55:25+00:00,"[arxiv.Result.Author('Sanil S. Gandhi'), arxiv.Result.Author('Arvind W. Kiwelekar'), arxiv.Result.Author('Laxman D. Netak'), arxiv.Result.Author('Hansraj S. Wankhede')]",
271,Definitions and Analysis of Quantum E-voting Protocols,"Recent advances indicate that quantum computers will soon be reality.
Motivated by this ever more realistic threat for existing classical
cryptographic protocols, researchers have developed several schemes to resist
""quantum attacks"". In particular, for electronic voting, several e-voting
schemes relying on properties of quantum mechanics have been proposed. However,
each of these proposals comes with a different and often not well-articulated
corruption model, has different objectives, and is accompanied by security
claims which are never formalized and are at best justified only against
specific attacks. To address this, we propose the first formal security
definitions for quantum e-voting protocols. With these at hand, we systematize
and evaluate the security of previously-proposed quantum e-voting protocols; we
examine the claims of these works concerning privacy, correctness and
verifiability, and if they are correctly attributed to the proposed protocols.
In all non-trivial cases, we identify specific quantum attacks that violate
these properties. We argue that the cause of these failures lies in the absence
of formal security models and references to the existing cryptographic
literature.",1810.05083v3,quant-ph,2018-10-11 15:32:42+00:00,"[arxiv.Result.Author('Myrto Arapinis'), arxiv.Result.Author('Elham Kashefi'), arxiv.Result.Author('Nikolaos Lamprou'), arxiv.Result.Author('Anna Pappa')]","ACM Transactions on Quantum Computing 2, 1, Article 4 (2021)"
272,An Incoercible E-Voting Scheme Based on Revised Simplified Verifiable Re-encryption Mix-nets,"Simplified verifiable re-encryption mix-net (SVRM) is revised and a scheme
for e-voting systems is developed based on it. The developed scheme enables
e-voting systems to satisfy all essential requirements of elections. Namely,
they satisfy requirements about privacy, verifiability, fairness and
robustness. It also successfully protects voters from coercers except cases
where the coercers force voters to abstain from elections. In detail, voters
can conceal correspondences between them and their votes, anyone can verify the
accuracy of election results, and interim election results are concealed from
any entity. About incoercibility, provided that erasable-state voting booths
which disable voters to memorize complete information exchanged between them
and election authorities for constructing votes are available, coercer C cannot
know candidates that voters coerced by C had chosen even if the candidates are
unique to the voters. In addition, elections can be completed without
reelections even when votes were handled illegitimately.",1512.05596v1,cs.CR,2015-12-17 14:30:01+00:00,"[arxiv.Result.Author('Shinsuke Tamura'), arxiv.Result.Author('Hazim A. Haddad'), arxiv.Result.Author('Nazmul Islam'), arxiv.Result.Author('Kazi Md. Rokibul Alam')]",Information Security and Computer Fraud 3 (2015) 32-38
273,Self-sovereign identity as a tool for digital democracy,"The importance of digital identity as a foundation for digital public
services is considered. As the classical, centralised model digital identity
has proven to be subject to several limitations, self-sovereign identities are
proposed as replacement, especially in the context of e-government platforms
and direct participation to policymaking (e.g. through e-voting tools).",2106.11714v1,cs.CY,2021-06-22 12:30:56+00:00,"[arxiv.Result.Author('Roberta Centonze'), arxiv.Result.Author('Roberto Reale')]",
274,An Improved E-voting scheme using Secret Sharing based Secure Multi-party Computation,"E-voting systems (EVS)are having potential advantages over many existing
voting schemes.Security, transparency, accuracy and reliability are the major
concern in these systems.EVS continues to grow as the technology advances.It is
inexpensive and efficient as the resources become reusable.Fast and accurate
computation of results with voter privacy is the added advantage.In the
proposed system we make use of secret sharing technique and secure multi party
computation(SMC) to achieve security and reliability.Secret sharing is an
important technique used for SMC. Multi-party computation is typically
accomplished using secret sharing by making shares of the input and
manipulating the shares to compute a typical function of the input.The proposed
system make use of bitwise representation of votes and only the shares are used
for transmission and computation of result.Secure sum evaluation can be done
with shares distributed using Shamir's secret sharing scheme.The scheme is
hence secure and reliable and does not make any number theoretic assumptions
for security.We also propose a unique method which calculates the candidates
individual votes keeping the anonymity.",1502.07469v1,cs.CR,2015-02-26 08:35:35+00:00,"[arxiv.Result.Author('Divya G. Nair'), arxiv.Result.Author('V. P. Binu'), arxiv.Result.Author('G. Santhosh Kumar')]",
275,Improving Automated Symbolic Analysis for E-voting Protocols: A Method Based on Sufficient Conditions for Ballot Secrecy,"We advance the state-of-the-art in automated symbolic analysis for e-voting
protocols by introducing three conditions that together are sufficient to
guarantee ballot secrecy. There are two main advantages to using our
conditions, compared to existing automated approaches. The first is a
substantial expansion of the class of protocols and threat models that can be
automatically analysed: we can systematically deal with (a) honest authorities
present in different phases, (b) threat models in which no dishonest voters
occur, and (c) protocols whose ballot secrecy depends on fresh data coming from
other phases. The second advantage is that it can significantly improve
verification efficiency, as the individual conditions are often simpler to
verify. E.g., for the LEE protocol, we obtain a speedup of over two orders of
magnitude. We show the scope and effectiveness of our approach using ProVerif
in several case studies, including FOO, LEE, JCJ, and Belenios. In these case
studies, our approach does not yield any false attacks, suggesting that our
conditions are tight.",1709.00194v5,cs.CR,2017-09-01 08:06:18+00:00,"[arxiv.Result.Author('Cas Cremers'), arxiv.Result.Author('Lucca Hirschi')]",
276,"Electryo, In-person Voting with Transparent Voter Verifiability and Eligibility Verifiability","Selene is an e-voting protocol that allows voters to directly check their
individual vote, in cleartext, in the final tally via a tracker system, while
providing good coercion mitigation. This is in contrast to conventional,
end-to-end verifiable schemes in which the voter verifies the presence of an
encryption of her vote on the bulletin board. The Selene mechanism can be
applied to many e-voting schemes, but here we present an application to the
polling station context, resulting in a voter-verifiable electronic tally with
a paper audit trail. The system uses a smartcard-based public key system to
provide the individual verification and universal eligibility verifiability.
The paper record contains an encrypted link to the voter's identity, requiring
stronger assumptions on ballot privacy than normal paper voting, but with the
benefit of providing good auditability and dispute resolution as well as
supporting (comparison) risk limiting audits.",2105.14783v1,cs.CR,2021-05-31 08:22:29+00:00,"[arxiv.Result.Author('Peter B. Roenne'), arxiv.Result.Author('Peter Y. A Ryan'), arxiv.Result.Author('Marie-Laure Zollinger')]",
277,User Experience Design for E-Voting: How mental models align with security mechanisms,"This paper presents a mobile application for vote-casting and
vote-verification based on the Selene e-voting protocol and explains how it was
developed and implemented using the User Experience Design process. The
resulting interface was tested with 38 participants, and user experience data
was collected via questionnaires and semi-structured interviews on user
experience and perceived security. Results concerning the impact of displaying
security mechanisms on UX were presented in a complementary paper. Here we
expand on this analysis by studying the mental models revealed during the
interviews and compare them with theoretical security notions. Finally, we
propose a list of improvements for designs of future voting protocols.",2105.14901v2,cs.HC,2021-05-31 11:56:09+00:00,"[arxiv.Result.Author('Marie-Laure Zollinger'), arxiv.Result.Author('Verena Distler'), arxiv.Result.Author('Peter B. Roenne'), arxiv.Result.Author('Peter Y. A. Ryan'), arxiv.Result.Author('Carine Lallemand'), arxiv.Result.Author('Vincent Koenig')]","Fourth International Joint Conference on Electronic Voting
  E-Vote-ID 2019, p187--202"
278,Chirotonia: A Scalable and Secure e-Voting Framework based on Blockchains and Linkable Ring Signatures,"In this paper we propose a comprehensive and scalable framework to build
secure-by-design e-voting systems. Decentralization, transparency, determinism,
and untamperability of votes are granted by dedicated smart contracts on a
blockchain, while voter authenticity and anonymity are achieved through
(provable secure) linkable ring signatures. These, in combination with suitable
smart contract constraints, also grant protection from double voting. Our
design is presented in detail, focusing on its security guarantees and the
design choices that allow it to scale to a large number of voters. Finally, we
present a proof-of-concept implementation of the proposed framework, made
available as open source.",2111.02257v1,cs.CR,2021-11-03 14:47:07+00:00,"[arxiv.Result.Author('Antonio Russo'), arxiv.Result.Author('Antonio Fernández Anta'), arxiv.Result.Author('Maria Isabel González Vasco'), arxiv.Result.Author('Simon Pietro Romano')]",
279,"D-DEMOS: A distributed, end-to-end verifiable, internet voting system","E-voting systems have emerged as a powerful technology for improving
democracy by reducing election cost, increasing voter participation, and even
allowing voters to directly verify the entire election procedure. Prior
internet voting systems have single points of failure, which may result in the
compromise of availability, voter secrecy, or integrity of the election
results. In this paper, we present the design, implementation, security
analysis, and evaluation of D-DEMOS, a complete e-voting system that is
distributed, privacy-preserving and end-to-end verifiable. Our system includes
a fully asynchronous vote collection subsystem that provides immediate
assurance to the voter her vote was recorded as cast, without requiring
cryptographic operations on behalf of the voter. We also include a distributed,
replicated and fault-tolerant Bulletin Board component, that stores all
necessary election-related information, and allows any party to read and verify
the complete election process. Finally, we also incorporate trustees, i.e.,
individuals who control election result production while guaranteeing privacy
and end-to-end-verifiability as long as their strong majority is honest. Our
system is the first e-voting system whose voting operation is human verifiable,
i.e., a voter can vote over the web, even when her web client stack is
potentially unsafe, without sacrificing her privacy, and still be assured her
vote was recorded as cast. Additionally, a voter can outsource election
auditing to third parties, still without sacrificing privacy. Finally, as the
number of auditors increases, the probability of election fraud going
undetected is diminished exponentially. We provide a model and security
analysis of the system. We implement a prototype of the complete system, we
measure its performance experimentally, and we demonstrate its ability to
handle large-scale elections.",1507.06812v2,cs.CR,2015-07-24 11:29:12+00:00,"[arxiv.Result.Author('Nikos Chondros'), arxiv.Result.Author('Bingsheng Zhang'), arxiv.Result.Author('Thomas Zacharias'), arxiv.Result.Author('Panos Diamantopoulos'), arxiv.Result.Author('Stathis Maneas'), arxiv.Result.Author('Christos Patsonakis'), arxiv.Result.Author('Alex Delis'), arxiv.Result.Author('Aggelos Kiayias'), arxiv.Result.Author('Mema Roussopoulos')]",
280,Generating Single Peaked Votes,"We discuss how to generate singled peaked votes uniformly from the Impartial
Culture model.",1503.02766v1,cs.GT,2015-03-10 04:15:23+00:00,[arxiv.Result.Author('Toby Walsh')],
281,Normalized Range Voting Broadly Resists Control,"We study the behavior of Range Voting and Normalized Range Voting with
respect to electoral control. Electoral control encompasses attempts from an
election chair to alter the structure of an election in order to change the
outcome. We show that a voting system resists a case of control by proving that
performing that case of control is computationally infeasible. Range Voting is
a natural extension of approval voting, and Normalized Range Voting is a simple
variant which alters each vote to maximize the potential impact of each voter.
We show that Normalized Range Voting has among the largest number of control
resistances among natural voting systems.",1005.5698v3,cs.GT,2010-05-31 15:34:11+00:00,[arxiv.Result.Author('Curtis Menton')],
282,Strategic Voting Under Uncertainty About the Voting Method,"Much of the theoretical work on strategic voting makes strong assumptions
about what voters know about the voting situation. A strategizing voter is
typically assumed to know how other voters will vote and to know the rules of
the voting method. A growing body of literature explores strategic voting when
there is uncertainty about how others will vote. In this paper, we study
strategic voting when there is uncertainty about the voting method. We
introduce three notions of manipulability for a set of voting methods: sure,
safe, and expected manipulability. With the help of a computer program, we
identify voting scenarios in which uncertainty about the voting method may
reduce or even eliminate a voter's incentive to misrepresent her preferences.
Thus, it may be in the interest of an election designer who wishes to reduce
strategic voting to leave voters uncertain about which of several reasonable
voting methods will be used to determine the winners of an election.",1907.09110v1,cs.MA,2019-07-22 03:17:19+00:00,"[arxiv.Result.Author('Wesley H. Holliday'), arxiv.Result.Author('Eric Pacuit')]","EPTCS 297, 2019, pp. 252-272"
283,Designing Stable Elections: A Survey,"We survey the design of elections that are resilient to attempted
interference by third parties. For example, suppose votes have been cast in an
election between two candidates, and then each vote is randomly changed with a
small probability, independently of the other votes. It is desirable to keep
the outcome of the election the same, regardless of the changes to the votes.
It is well known that the US electoral college system is about 5 times more
likely to have a changed outcome due to vote corruption, when compared to a
majority vote. In fact, Mossel, O'Donnell and Oleszkiewicz proved in 2005 that
the majority voting method is most stable to this random vote corruption, among
voting methods where each person has a small influence on the election. We
discuss some recent progress on the analogous result for elections between more
than two candidates. In this case, plurality should be most stable to
corruption in votes. We also survey results on adversarial election
manipulation (where an adversary can select particular votes to change, perhaps
in a non-random way), and we briefly discuss ranked choice voting methods
(where a vote is a ranked list of candidates).",2006.05460v2,math.PR,2020-06-09 18:59:48+00:00,[arxiv.Result.Author('Steven Heilman')],
284,Journalistic Voting System's Effects on Election Security Threats and Gerrymandering,"The Journalistic Voting System is a proxy voting system in which journalists
are delegated the task of voting on behalf of individual voters in a
western-style democracy. We introduce the Journalistic Voting System and
discuss its potential advantages and potential problems. In particular, we
discuss its advantages to individuals in the system (voters, journalists, and
politicians) and we discuss its effects relative to several widely discussed
threats to election security, namely: cybersecurity, social media, big data,
artificial intelligence (AI), and gerrymandering. The Journalistic Voting
System is modeled on a predecessor system, called the Valence Voting System,
which is reviewed.",2110.04642v1,physics.soc-ph,2021-10-09 20:57:16+00:00,[arxiv.Result.Author('Lucius Schoenbaum')],
285,Transparent Voting Platform Based on Permissioned Blockchain,"Since 2004, different research was handling the challenges in the centralized
voting systems, e-voting protocols and recently the decentralized voting. So
electronic voting puts forward some difficulties regarding the voter anonymity,
the secure casting of the votes and to prevent the voting process from
frauding. The Decentralized property of the technology called ""blockchain""
could have the solution for many of the challenges in voting research area and
brings a new secure mechanism of safe and transparent voting. In this paper, a
broad comparison between ongoing voting systems has studied by analyzing their
structure and the drawbacks that should consider in future to improve the whole
election process from keeping the privacy of the voter, casting a vote with the
possibility to check if it was counted correctly to publishing the results. The
result of the paper will give a new approach to extend the target of the
election from small scale to large scale despite the fact of Ethereum
limitation which can cast on the blockchain just five votes per minute. The
primary challenge is to find an answer for this question: ""How to balance
between voter privacy and transparency without breaking the important rule
where the voter can proof for a specific candidate that he voted for him in a
bribe situation?"".",1802.10134v1,cs.CY,2018-02-22 14:20:35+00:00,[arxiv.Result.Author('Nazim Faour')],
286,Antaeus: a retrograde group of tidal debris in the Milky Way's disk plane,"We present the discovery of a wide retrograde moving group in the disk plane
of the Milky Way using action-angle coordinates derived from the \textit{Gaia}
DR3 catalog. The structure is identified from a sample of its members that are
currently almost at the pericenter of their orbit and are passing through the
Solar neighborhood. The motions of the stars in this group are highly
correlated, indicating that the system is probably not phase mixed. With a
width of at least 1.5 kpc and with a probable intrinsic spread in metallicity,
this structure is most likely the wide remnant of a tidal stream of a disrupted
ancient dwarf galaxy (age $\sim 12$ Gyr, $\langle {\rm [Fe/H]} \rangle \sim
-1.74$). The structure presents many similarities (e.g. in energy, angular
momentum, metallicity, and eccentricity) with the Sequoia merging event.
However, it possesses extremely low vertical action $J_z$ which makes it unique
even amongst Sequoia dynamical groups. As the low $J_z$ may be attributable to
dynamical friction, we speculate that the these stars may be the remnants of
the dense core of the Sequoia progenitor.",2206.10404v1,astro-ph.GA,2022-06-21 13:56:30+00:00,"[arxiv.Result.Author('Pierre-Antoine Oria'), arxiv.Result.Author('Wassim Tenachi'), arxiv.Result.Author('Rodrigo Ibata'), arxiv.Result.Author('Benoit Famaey'), arxiv.Result.Author('Zhen Yuan'), arxiv.Result.Author('Anke Arentsen'), arxiv.Result.Author('Nicolas Martin'), arxiv.Result.Author('Akshara Viswanathan')]",
287,Heuristics in Multi-Winner Approval Voting,"In many real world situations, collective decisions are made using voting.
Moreover, scenarios such as committee or board elections require voting rules
that return multiple winners. In multi-winner approval voting (AV), an agent
may vote for as many candidates as they wish. Winners are chosen by tallying up
the votes and choosing the top-$k$ candidates receiving the most votes. An
agent may manipulate the vote to achieve a better outcome by voting in a way
that does not reflect their true preferences. In complex and uncertain
situations, agents may use heuristics to strategize, instead of incurring the
additional effort required to compute the manipulation which most favors them.
In this paper, we examine voting behavior in multi-winner approval voting
scenarios with complete information. We show that people generally manipulate
their vote to obtain a better outcome, but often do not identify the optimal
manipulation. Instead, voters tend to prioritize the candidates with the
highest utilities. Using simulations, we demonstrate the effectiveness of these
heuristics in situations where agents only have access to partial information.",1905.12104v2,cs.GT,2019-05-28 21:44:07+00:00,"[arxiv.Result.Author('Jaelle Scheuerman'), arxiv.Result.Author('Jason L. Harman'), arxiv.Result.Author('Nicholas Mattei'), arxiv.Result.Author('K. Brent Venable')]",
288,Bucklin Voting is Broadly Resistant to Control,"Electoral control models ways of changing the outcome of an election via such
actions as adding/deleting/partitioning either candidates or voters. These
actions modify an election's participation structure and aim at either making a
favorite candidate win (""constructive control"") or prevent a despised candidate
from winning (""destructive control""), which yields a total of 22 standard
control scenarios. To protect elections from such control attempts,
computational complexity has been used to show that electoral control, though
not impossible, is computationally prohibitive. Among natural voting systems
with a polynomial-time winner problem, the two systems with the highest number
of proven resistances to control types (namely 19 out of 22) are
""sincere-strategy preference-based approval voting"" (SP-AV, a modification of a
system proposed by Brams and Sanver) and fallback voting. Both are hybrid
systems; e.g., fallback voting combines approval with Bucklin voting. In this
paper, we study the control complexity of Bucklin voting itself and show that
it behaves equally well in terms of control resistance for the 20 cases
investigated so far. As Bucklin voting is a special case of fallback voting,
all resistances shown for Bucklin voting in this paper strengthen the
corresponding resistance for fallback voting.",1005.4115v1,cs.CC,2010-05-22 09:12:04+00:00,"[arxiv.Result.Author('Gábor Erdélyi'), arxiv.Result.Author('Lena Piras'), arxiv.Result.Author('Jörg Rothe')]",
289,"Square root voting system, optimal threshold and π","The problem of designing an optimal weighted voting system for the two-tier
voting, applicable in the case of the Council of Ministers of the European
Union (EU), is investigated. Various arguments in favour of the square root
voting system, where the voting weights of member states are proportional to
the square root of their population are discussed and a link between this
solution and the random walk in the one-dimensional lattice is established. It
is known that the voting power of every member state is approximately equal to
its voting weight, if the threshold q for the qualified majority in the voting
body is optimally chosen. We analyze the square root voting system for a
generic 'union' of M states and derive in this case an explicit approximate
formula for the level of the optimal threshold: q \simeq 1/2+1/\sqrt{{\pi} M}.
The prefactor 1/\sqrt{{\pi}} appears here as a result of averaging over the
ensemble of unions with random populations.",1104.5213v2,physics.soc-ph,2011-04-27 18:51:41+00:00,"[arxiv.Result.Author('Karol Zyczkowski'), arxiv.Result.Author('Wojciech Slomczynski')]",
290,Penrose voting system and optimal quota,"Systems of indirect voting based on the principle of qualified majority can
be analysed using the methods of game theory. In particular, this applies to
the voting system in the Council of the European Union, which was recently a
subject of a vivid political discussion. The a priori voting power of a voter
measures his potential influence over the decisions of the voting body under a
given decision rule. We investigate a system based on the law of Penrose, in
which each representative in the voting body receives the number of votes (the
voting weight) proportional to the square root of the population he or she
represents. Here we demonstrate that for a generic distribution of the
population there exists an optimal quota for which the voting power of any
state is proportional to its weight. The optimal quota is shown to decrease
with the number of voting countries.",physics/0610271v1,physics.soc-ph,2006-10-30 12:49:18+00:00,"[arxiv.Result.Author('Wojciech Slomczynski'), arxiv.Result.Author('Karol Zyczkowski')]","Acta Physica Polonica B37, 3133-3143 (2006)"
291,Manipulation Can Be Hard in Tractable Voting Systems Even for Constant-Sized Coalitions,"Voting theory has become increasingly integrated with computational social
choice and multiagent systems. Computational complexity has been extensively
used as a shield against manipulation of voting systems, however for several
voting schemes this complexity may cause calculating the winner to be
computationally difficult. Of the many voting systems that have been studied
with regard to election manipulation, a few have been found to have an
unweighted coalitional manipulation problem that is NP-hard for a constant
number of manipulators despite having a winner problem that is in P. We survey
this interesting class of voting systems and the work that has analyzed their
complexity.",1108.4439v1,cs.GT,2011-08-22 21:02:46+00:00,"[arxiv.Result.Author('Curtis Menton'), arxiv.Result.Author('Preetjot Singh')]",
292,A mathematical evaluation of vote transfer systems,"The paper builds a general model of vote transfer systems on the basis of the
current Hungarian electoral rules. It combines single-seat districts and list
mandates with three possible compensation rule for 'wasted' votes in
constituencies: no compensation (direct vote transfer, DVT), compensation for
votes cast for losing party candidates (positive vote transfer, PVT) and
compensation for all votes that are not necessary to win the district (negative
vote transfer, NVT).
  The model is studied in the case of two parties. When the number of votes for
the majority party follows a uniform distribution in each district, DVT results
in the greatest expected seat share, however, application of PVT, and,
especially, NVT increases the probability of winning the election. The
trade-off between vote transfer formulas and the number of list mandates
reveals that the majority party should use an appropriately calibrated NVT
system if it focuses on these two variables.",1607.02879v3,cs.GT,2016-07-11 09:58:58+00:00,[arxiv.Result.Author('László Csató')],
293,Designing Strategyproof Election Systems with Score Voting,"We focus on the strategyproofness of voting systems where voters must choose
a number of options among several possibilities. These systems include those
that are used for Participatory Budgeting, where we organize an election to
determine the allocation of a community's budget (city, region, etc.) dedicated
to the financing of projects.
  We present a model for studying voting mechanisms and the Constrained Change
Property (CCP), which will be used to design voting mechanisms that are always
strategyproof. We also define a new notion of social choice function and use it
to design a new class of utilitarian voting mechanisms that we call score
voting. We prove that the mechanisms designed with core voting with a neutral
score function are equivalent to knapsack voting on the same instance and that
any score voting designed with a total score function is strategyproof if and
only if its score function satisfies CCP.
  These results are combined to devise an algorithm that can find the closest
total score function that makes any given score voting to be strategyproof.",2210.02496v1,cs.GT,2022-10-05 18:19:52+00:00,"[arxiv.Result.Author('Johanne Cohen'), arxiv.Result.Author('Daniel Cordeiro'), arxiv.Result.Author('Valentin Dardilhac'), arxiv.Result.Author('Victor Glaser')]",
294,Manipulation and Control Complexity of Schulze Voting,"Schulze voting is a recently introduced voting system enjoying unusual
popularity and a high degree of real-world use, with users including the
Wikimedia foundation, several branches of the Pirate Party, and MTV. It is a
Condorcet voting system that determines the winners of an election using
information about paths in a graph representation of the election. We resolve
the complexity of many electoral control cases for Schulze voting. We find that
it falls short of the best known voting systems in terms of control resistance,
demonstrating vulnerabilities of concern to some prospective users of the
system.",1206.2111v4,cs.GT,2012-06-11 06:58:50+00:00,"[arxiv.Result.Author('Curtis Menton'), arxiv.Result.Author('Preetjot Singh')]",
295,Voting Framework for Distributed Real-Time Ethernet based Dependable and Safe Systems,"In many industrial sectors such as factory automation and process control
sensor redundancy is required to ensure reliable and highly-available
operation. Measured values from N-redundant sensors are typically subjected to
some voting scheme to determine a value which is used in further processing. In
this paper we present a voting framework which allows the sensors and the
voting scheme to be configured at systemconfiguration time. The voting scheme
is designed as a Real Time Ethernet profile. We describe the structure of the
voting system and the design and verification of the framework. We argue the
applicability of this sub-system based on a successful prototype
implementation.",2005.07262v1,cs.DC,2020-04-30 22:05:13+00:00,[arxiv.Result.Author('Hans Dermot Doran')],
296,"Effectiveness, Decisiveness and Success in Weighted Voting Systems","We compare the notions ""Decisiveness"" and ""Success"" for certain weighted
voting systems and various underlying voting measures. In particular, we
compute the success rate for the Shapley-Shubik meassure and, more generally,
for Common Belief Models.",1706.08382v1,math.GM,2017-06-08 10:27:31+00:00,[arxiv.Result.Author('Werner Kirsch')],
297,Information-Theoretic Secure and Private Voting System,"In this paper, we present a private voting system that consists of N
authorized voters who may vote to one of the K candidates or vote abstain. Each
voter wants to compute the final tally while staying private and robust against
malicious voters, who try to gain information about the vote of the other
voters beyond the final result, or send incorrect information to affect the
final tally. We design an information-theoretic private voting system based on
Shamir secret sharing, which is secure and robust as long as there are up to
(N-1)/3 malicious voters.",2203.07355v1,cs.IT,2022-03-14 17:53:35+00:00,"[arxiv.Result.Author('Seyed Reza Hoseini Najarkolaei'), arxiv.Result.Author('Narges Kazempour'), arxiv.Result.Author('Hasti Rostami'), arxiv.Result.Author('Mohammad Reza Aref')]",
298,Computing voting power in easy weighted voting games,"Weighted voting games are ubiquitous mathematical models which are used in
economics, political science, neuroscience, threshold logic, reliability theory
and distributed systems. They model situations where agents with variable
voting weight vote in favour of or against a decision. A coalition of agents is
winning if and only if the sum of weights of the coalition exceeds or equals a
specified quota. The Banzhaf index is a measure of voting power of an agent in
a weighted voting game. It depends on the number of coalitions in which the
agent is the difference in the coalition winning or losing. It is well known
that computing Banzhaf indices in a weighted voting game is NP-hard. We give a
comprehensive classification of weighted voting games which can be solved in
polynomial time. Among other results, we provide a polynomial
($O(k{(\frac{n}{k})}^k)$) algorithm to compute the Banzhaf indices in weighted
voting games in which the number of weight values is bounded by $k$.",0811.2497v2,cs.GT,2008-11-15 14:55:51+00:00,"[arxiv.Result.Author('Haris Aziz'), arxiv.Result.Author('Mike Paterson')]",
299,How Many Vote Operations Are Needed to Manipulate A Voting System?,"In this paper, we propose a framework to study a general class of strategic
behavior in voting, which we call vote operations. We prove the following
theorem: if we fix the number of alternatives, generate $n$ votes i.i.d.
according to a distribution $\pi$, and let $n$ go to infinity, then for any
$\epsilon >0$, with probability at least $1-\epsilon$, the minimum number of
operations that are needed for the strategic individual to achieve her goal
falls into one of the following four categories: (1) 0, (2) $\Theta(\sqrt n)$,
(3) $\Theta(n)$, and (4) $\infty$. This theorem holds for any set of vote
operations, any individual vote distribution $\pi$, and any integer generalized
scoring rule, which includes (but is not limited to) almost all commonly
studied voting rules, e.g., approval voting, all positional scoring rules
(including Borda, plurality, and veto), plurality with runoff, Bucklin,
Copeland, maximin, STV, and ranked pairs.
  We also show that many well-studied types of strategic behavior fall under
our framework, including (but not limited to) constructive/destructive
manipulation, bribery, and control by adding/deleting votes, margin of victory,
and minimum manipulation coalition size. Therefore, our main theorem naturally
applies to these problems.",1204.1231v3,cs.AI,2012-04-05 14:00:21+00:00,[arxiv.Result.Author('Lirong Xia')],
300,Preventing side-channel effects in continuous-variable quantum key distribution,"The role of the side channels in the continuous-variable quantum key
distribution is studied. It is shown how the information leakage through a side
channel from the trusted sender station increases the vulnerability of the
protocols to the eavesdropping in the main quantum communication channel.
Moreover, the untrusted noise infusion by an eavesdropper on the trusted
receiving side breaks the security even for a purely attenuating main quantum
channel. As a method to compensate for the effect of the side-channel leakage
on the sender side, we suggest several types of manipulations on the
side-channel input. It is shown that by applying the modulated coherent light
on the input of the side channel that is optimally correlated to the modulation
on the main signal and optionally, introducing additional squeezing in the case
of the squeezed-state protocol, the negative influence of the lossy side
channel on the sender side can be completely removed. For the trusted receiving
side, the method of optimal monitoring of the residual noise from the
side-channel noise infusion is suggested and shown to be able to completely
eliminate the presence of the noisy side channel. We therefore prove that the
side-channel effects can be completely removed using feasible operations if the
trusted parties access the respective parts of the side channels.",1603.03122v1,quant-ph,2016-03-10 02:02:04+00:00,"[arxiv.Result.Author('Ivan Derkach'), arxiv.Result.Author('Vladyslav C. Usenko'), arxiv.Result.Author('Radim Filip')]","Phys. Rev. A 93, 032309 (2016)"
301,Adversarial Attack Based Countermeasures against Deep Learning Side-Channel Attacks,"Numerous previous works have studied deep learning algorithms applied in the
context of side-channel attacks, which demonstrated the ability to perform
successful key recoveries. These studies show that modern cryptographic devices
are increasingly threatened by side-channel attacks with the help of deep
learning. However, the existing countermeasures are designed to resist
classical side-channel attacks, and cannot protect cryptographic devices from
deep learning based side-channel attacks. Thus, there arises a strong need for
countermeasures against deep learning based side-channel attacks. Although deep
learning has the high potential in solving complex problems, it is vulnerable
to adversarial attacks in the form of subtle perturbations to inputs that lead
a model to predict incorrectly.
  In this paper, we propose a kind of novel countermeasures based on
adversarial attacks that is specifically designed against deep learning based
side-channel attacks. We estimate several models commonly used in deep learning
based side-channel attacks to evaluate the proposed countermeasures. It shows
that our approach can effectively protect cryptographic devices from deep
learning based side-channel attacks in practice. In addition, our experiments
show that the new countermeasures can also resist classical side-channel
attacks.",2009.10568v1,cs.CR,2020-09-22 14:17:18+00:00,"[arxiv.Result.Author('Ruizhe Gu'), arxiv.Result.Author('Ping Wang'), arxiv.Result.Author('Mengce Zheng'), arxiv.Result.Author('Honggang Hu'), arxiv.Result.Author('Nenghai Yu')]",
302,Specification and Verification of Side Channel Declassification,"Side channel attacks have emerged as a serious threat to the security of both
networked and embedded systems -- in particular through the implementations of
cryptographic operations. Side channels can be difficult to model formally, but
with careful coding and program transformation techniques it may be possible to
verify security in the presence of specific side-channel attacks. But what if a
program intentionally makes a tradeoff between security and efficiency and
leaks some information through a side channel? In this paper we study such
tradeoffs using ideas from recent research on declassification. We present a
semantic model of security for programs which allow for declassification
through side channels, and show how side-channel declassification can be
verified using off-the-shelf software model checking tools. Finally, to make it
simpler for verifiers to check that a program conforms to a particular
side-channel declassification policy we introduce a further tradeoff between
efficiency and verifiability: by writing programs in a particular ""manifest
form"" security becomes considerably easier to verify.",0912.2952v1,cs.CR,2009-12-15 17:55:42+00:00,"[arxiv.Result.Author('Josef Svenningsson'), arxiv.Result.Author('David Sands')]",
303,Systematic Classification of Side-Channel Attacks: A Case Study for Mobile Devices,"Side-channel attacks on mobile devices have gained increasing attention since
their introduction in 2007. While traditional side-channel attacks, such as
power analysis attacks and electromagnetic analysis attacks, required physical
presence of the attacker as well as expensive equipment, an (unprivileged)
application is all it takes to exploit the leaking information on modern mobile
devices. Given the vast amount of sensitive information that are stored on
smartphones, the ramifications of side-channel attacks affect both the security
and privacy of users and their devices.
  In this paper, we propose a new categorization system for side-channel
attacks, which is necessary as side-channel attacks have evolved significantly
since their scientific investigations during the smart card era in the 1990s.
Our proposed classification system allows to analyze side-channel attacks
systematically, and facilitates the development of novel countermeasures.
Besides this new categorization system, the extensive survey of existing
attacks and attack strategies provides valuable insights into the evolving
field of side-channel attacks, especially when focusing on mobile devices. We
conclude by discussing open issues and challenges in this context and outline
possible future research directions.",1611.03748v3,cs.CR,2016-11-11 15:36:19+00:00,"[arxiv.Result.Author('Raphael Spreitzer'), arxiv.Result.Author('Veelasha Moonsamy'), arxiv.Result.Author('Thomas Korak'), arxiv.Result.Author('Stefan Mangard')]",
304,Osiris: Automated Discovery of Microarchitectural Side Channels,"In the last years, a series of side channels have been discovered on CPUs.
These side channels have been used in powerful attacks, e.g., on cryptographic
implementations, or as building blocks in transient-execution attacks such as
Spectre or Meltdown. However, in many cases, discovering side channels is still
a tedious manual process.
  In this paper, we present Osiris, a fuzzing-based framework to automatically
discover microarchitectural side channels. Based on a machine-readable
specification of a CPU's ISA, Osiris generates instruction-sequence triples and
automatically tests whether they form a timing-based side channel. Furthermore,
Osiris evaluates their usability as a side channel in transient-execution
attacks, i.e., as the microarchitectural encoding for attacks like Spectre. In
total, we discover four novel timing-based side channels on Intel and AMD CPUs.
Based on these side channels, we demonstrate exploitation in three case
studies. We show that our microarchitectural KASLR break using non-temporal
loads, FlushConflict, even works on the new Intel Ice Lake and Comet Lake
microarchitectures. We present a cross-core cross-VM covert channel that is not
relying on the memory subsystem and transmits up to 1 kbit/s. We demonstrate
this channel on the AWS cloud, showing that it is stealthy and noise resistant.
Finally, we demonstrate Stream+Reload, a covert channel for transient-execution
attacks that, on average, allows leaking 7.83 bytes within a transient window,
improving state-of-the-art attacks that only leak up to 3 bytes.",2106.03470v1,cs.CR,2021-06-07 09:54:20+00:00,"[arxiv.Result.Author('Daniel Weber'), arxiv.Result.Author('Ahmad Ibrahim'), arxiv.Result.Author('Hamed Nemati'), arxiv.Result.Author('Michael Schwarz'), arxiv.Result.Author('Christian Rossow')]",
305,A Study on Power Side Channels on Mobile Devices,"Power side channel is a very important category of side channels, which can
be exploited to steal confidential information from a computing system by
analyzing its power consumption. In this paper, we demonstrate the existence of
various power side channels on popular mobile devices such as smartphones.
Based on unprivileged power consumption traces, we present a list of real-world
attacks that can be initiated to identify running apps, infer sensitive UIs,
guess password lengths, and estimate geo-locations. These attack examples
demonstrate that power consumption traces can be used as a practical side
channel to gain various confidential information of mobile apps running on
smartphones. Based on these power side channels, we discuss possible
exploitations and present a general approach to exploit a power side channel on
an Android smartphone, which demonstrates that power side channels pose
imminent threats to the security and privacy of mobile users. We also discuss
possible countermeasures to mitigate the threats of power side channels.",1512.07972v1,cs.CR,2015-12-25 07:32:28+00:00,"[arxiv.Result.Author('Lin Yan'), arxiv.Result.Author('Yao Guo'), arxiv.Result.Author('Xiangqun Chen'), arxiv.Result.Author('Hong Mei')]",
306,Graphene Side Gate Engineering,"Various mesoscopic devices exploit electrostatic side gates for their
operation. In this paper, we investigate how voltage-biasing of graphene side
gates modulates the electrical transport characteristics of graphene channel.
We explore myriads of typical side gated devices such as symmetric dual side
gates and asymmetric single side gate biasing, in monolayer and bilayer
graphene. The side gates modulate the electrostatic doping in the graphene
channel whose effect is reflected in transport measurement. This modulation
efficiency is systematically characterized for all our devices and agrees well
with the modeling presented.",1410.7498v1,cond-mat.mes-hall,2014-10-28 02:44:43+00:00,"[arxiv.Result.Author('Ching-Tzu Chen'), arxiv.Result.Author('Tony Low'), arxiv.Result.Author('Hsin-Ying Chiu'), arxiv.Result.Author('Wenjuan Zhu')]","IEEE Electron Device Letters, Vol. 33, Pages 330 - 332 (2012)"
307,Virtualization Technology: Cross-VM Cache Side Channel Attacks make it Vulnerable,"Cloud computing provides an effective business model for the deployment of IT
infrastructure, platform, and software services. Often, facilities are
outsourced to cloud providers and this offers the service consumer
virtualization technologies without the added cost burden of development.
However, virtualization introduces serious threats to service delivery such as
Denial of Service (DoS) attacks, Cross-VM Cache Side Channel attacks,
Hypervisor Escape and Hyper-jacking. One of the most sophisticated forms of
attack is the cross-VM cache side channel attack that exploits shared cache
memory between VMs. A cache side channel attack results in side channel data
leakage, such as cryptographic keys. Various techniques used by the attackers
to launch cache side channel attack are presented, as is a critical analysis of
countermeasures against cache side channel attacks.",1606.01356v1,cs.CY,2016-06-04 09:31:29+00:00,"[arxiv.Result.Author('Alan Litchfield'), arxiv.Result.Author('Abid Shahzad')]",
308,ASVAAN: Semi-automatic side-channel analysis of Android NDK,"Android is the most popular operating systems for smartphones and is also
well-known for its flexibility and security. However, although it is overall
considered very secure, there are still some vulnerabilities occasionally
discovered that allow getting user sensitive information bypassing security
controls and boundaries: among these, side-channel vulnerabilities are a
significant concern these days. Although there are several types of
side-channel vulnerabilities, ones focused on APIs still represent a great area
to explore, which, until now, has often been analysed manually. Only in the
latest years, there have been published some automatic solutions which focus on
performing automatic scanning of side-channel flaws in Android, created due to
the increasing codebase of the operating system; however, they present some
limitations.
  This paper introduces a new approach to discover Android NDK side-channel
leaks, which at the best of the author knowledge have never been investigated
through the usage of automatic or semi-automatic solutions. The approach
described in the work, allowed to identify more than 8 new side-channel leaks
in several Android NDK functions,which permitted to infer with great accuracy
application and websites launches on a victim device. The findings represents
the first discovered side-channel leaks in Android NDK functions, and were
responsibly disclosed to the Android Security Team of Google.",2204.05911v1,cs.CR,2022-04-12 16:12:11+00:00,[arxiv.Result.Author('Valerio Brussani')],
309,Joint eavesdropping on the BB84 decoy state protocol with an arbitrary passive light-source side channel,"Passive light-source side channel in quantum key distribution (QKD) makes the
quantum signals more distinguishable thus provides additional information about
the quantum signal to an eavesdropper. The explicit eavesdropping strategies
aimed at the passive side channel known to date were limited to the separate
measurement of the passive side channel in addition to the operational degree
of freedom. Here we show how to account for the joint eavesdropping on both
operational degree of freedom and the passive side channel of the generic form.
In particular, we use the optimal phase-covariant cloning of the signal photon
state, which is the most effective attack on the BB84 protocol without side
channels, followed by a joint collective measurement of the side channel and
the operational degree of freedom. To estimate QKD security under this attack,
we develop an effective error method and show its applicability to the BB84
decoy-state protocol.",2211.13669v1,quant-ph,2022-11-24 15:34:57+00:00,"[arxiv.Result.Author('Danila V. Babukhin'), arxiv.Result.Author('Denis V. Sych')]",
310,Separability Criterion for One-Sided Gaussian Channels,"We show that the following nontrivial necessary precondition for an
entanglement evolution equation for pure Gaussian states under one-sided
Gaussian channels holds. Suppose a Gaussian quantum channel acts on one mode of
a pure entangled multi-mode Gaussian input state. Then, for a fixed channel,
either all output states are entangled or none of them are. In other words, if
the input state is Gaussian, pure and entangled, the separability after a
one-sided Gaussian quantum channel does not depend on the input state, but only
on the channel. Furthermore, a simple linear-algebraic separability criterion
allows to decide whether a given channel destroys the entanglement of pure
entangled input states or leaves them entangled.",1001.2225v1,quant-ph,2010-01-13 16:32:19+00:00,"[arxiv.Result.Author('Jason Hoelscher-Obermaier'), arxiv.Result.Author('Peter van Loock')]",
311,One-sided asymptotically mean stationary channels,"This paper proposes an analysis of asymptotically mean stationary (AMS)
communication channels. A hierarchy based on stability properties
(stationarity, quasi-stationarity, recurrence and asymptotically mean
stationarity) of channels is identified. Stationary channels are a subclass of
quasi-stationary channels which are a subclass of recurrent AMS channels which
are a subclass of AMS channels. These classes are proved to be stable under
Markovian composition of channels (e.g., the cascade of AMS channels is an AMS
channel). Characterizations of channels of each class are given. Some
properties of the quasi-stationary mean of a channel are established. Finally,
ergodicity conditions of AMS channels are gathered.",1403.6661v1,cs.IT,2014-03-26 13:11:23+00:00,[arxiv.Result.Author('Francois Simon')],"Advances in applied mathematics, volume 50, issue 5, May 2013,
  pages 675-701"
312,Interference Channels with Correlated Receiver Side Information,"The problem of joint source-channel coding in transmitting independent
sources over interference channels with correlated receiver side information is
studied. When each receiver has side information correlated with its own
desired source, it is shown that source-channel code separation is optimal.
When each receiver has side information correlated with the interfering source,
sufficient conditions for reliable transmission are provided based on a joint
source-channel coding scheme using the superposition encoding and partial
decoding idea of Han and Kobayashi. When the receiver side information is a
deterministic function of the interfering source, source-channel code
separation is again shown to be optimal. As a special case, for a class of
Z-interference channels, when the side information of the receiver facing
interference is a deterministic function of the interfering source, necessary
and sufficient conditions for reliable transmission are provided in the form of
single letter expressions. As a byproduct of these joint source-channel coding
results, the capacity region of a class of Z-channels with degraded message
sets is also provided.",0810.2352v1,cs.IT,2008-10-14 03:57:30+00:00,"[arxiv.Result.Author('Nan Liu'), arxiv.Result.Author('Deniz Gunduz'), arxiv.Result.Author('Andrea J. Goldsmith'), arxiv.Result.Author('H. Vincent Poor')]",
313,Capacity with Causal and Non-Causal Side Information - A Unified View,"We identify the common underlying form of the capacity expression that is
applicable to both cases where causal or non-causal side information is made
available to the transmitter. Using this common form we find that for the
single user channel, the multiple access channel, the degraded broadcast
channel, and the degraded relay channel, the sum capacity with causal and
non-causal side information are identical when all the transmitter side
information is also made available to all the receivers. A genie-aided
outerbound is developed that states that when a genie provides $n$ bits of side
information to a receiver the resulting capacity improvement can not be more
than $n$ bits. Combining these two results we are able to bound the relative
capacity advantage of non-causal side information over causal side information
for both single user as well as various multiple user communication scenarios.
Applications of these capacity bounds are demonstrated through examples of
random access channels. Interestingly, the capacity results indicate that the
excessive MAC layer overheads common in present wireless systems may be avoided
through coding across multiple access blocks. It is also shown that even one
bit of side information at the transmitter can result in unbounded capacity
improvement. As a side, we obtain the sum capacity for a multiple access
channel when the side information available to the transmitter is causal and
possibly correlated to the side information available to the receiver.",cs/0511001v2,cs.IT,2005-10-31 22:30:54+00:00,[arxiv.Result.Author('Syed A. Jafar')],
314,Practical scheme for long distance side-channel-free quantum key distribution with weak coherent states only,"We show that a side-channel-free (SCF) source does not have to be an ideal
source by introducing the idea of mapping from ideal source.
  We propose a 3-state no-touch protocol for quantum key distribution (QKD)
where Alice and Bob does not modulate any light sent out, the only thing the do
is to send (or not send, in sending-or-not protocol). The reference light are
from independent Lasers. We show that, the protocol is side-channel-free (i.e.,
both source side channel free and measurement device independent) and there is
no modulation to the weak beams for QKD coding, except for sending or not
sending. Calculation shows that one can reach a side-channel-free secure
distance over 300 km using only coherent-state source. We use worst-case
analysis which takes no limitation to the channel or detection loss for
security. Our protocol is immune to all adverse due to side channels such as
the photon frequency spectrum, emission time, propagation direction, spatial
angular moment, and so on. Numerical simulations show that our scheme can reach
a side-channel-free result for quantum key distribution over a distance longer
than 200 km given the single-photon-interference misalignment error rate of
30%, and a distance longer than 300 km given the single-photon-interference
misalignment error rate of 10%. Our no-touch idea can also apply to
phase-coding twin-field QKD protocols. The no-touch idea also applies to
twin-field QKD with phase coding.",1806.01708v1,quant-ph,2018-06-05 14:18:44+00:00,"[arxiv.Result.Author('Xiang-Bin Wang'), arxiv.Result.Author('Xiao-Long Hu'), arxiv.Result.Author('Zong-Wen Yu')]",
315,Double-Side Near-Field Channel Estimation for Extremely Large-Scale MIMO System,"Accurate channel estimation is essential to empower extremely large-scale
MIMO (XL-MIMO) in 6G networks with ultra-high spectral efficiency.
Unfortunately, most of the existing channel estimation methods designed for
XL-MIMO fail to consider a double-side near-field scenario, where both
transmitter and receiver are equipped with extremely large-scale antenna
arrays. The existing channel estimation schemes cannot be directly applied to
the double-side near-field scenario. In this paper, based on this scenario, we
first derive double-side near-field Rayleigh distance (DS-RD) and effective
double-side near-field Rayleigh distance (EDS-RD) to determine the range of the
double-side near-field region. Then, a double-side near-field channel model is
proposed to match this scenario, where the distance of the transmitter from the
receiver is smaller than EDS-RD. In the proposed channel model, the line of
sight (LoS) path component is modeled by the geometric free assumption while
non-line of sight (NLoS) path components are modeled by the near-field array
response vectors. Finally, a double-side near-field channel estimation
algorithm is proposed to solve the channel estimation problem in this scenario,
where the LoS path component and NLoS path components are estimated separately.
Numerical simulation results demonstrate that, the proposed channel estimation
algorithm is able to outperform the existing methods.",2205.03615v1,cs.IT,2022-05-07 09:44:03+00:00,"[arxiv.Result.Author('Yu Lu'), arxiv.Result.Author('Linglong Dai')]",
316,Distributed Joint Source-Channel Coding on a Multiple Access Channel with Side Information,"We consider the problem of transmission of several distributed sources over a
multiple access channel (MAC) with side information at the sources and the
decoder. Source-channel separation does not hold for this channel. Sufficient
conditions are provided for transmission of sources with a given distortion.
The source and/or the channel could have continuous alphabets (thus Gaussian
sources and Gaussian MACs are special cases). Various previous results are
obtained as special cases. We also provide several good joint source-channel
coding schemes for a discrete/continuous source and discrete/continuous
alphabet channel. Channels with feedback and fading are also considered.
  Keywords: Multiple access channel, side information, lossy joint
source-channel coding, channels with feedback, fading channels.",0803.1445v1,cs.IT,2008-03-10 17:39:19+00:00,"[arxiv.Result.Author('R. Rajesh'), arxiv.Result.Author('Vinod Sharma')]",
317,Source and Channel Coding for Correlated Sources Over Multiuser Channels,"Source and channel coding over multiuser channels in which receivers have
access to correlated source side information is considered. For several
multiuser channel models necessary and sufficient conditions for optimal
separation of the source and channel codes are obtained. In particular, the
multiple access channel, the compound multiple access channel, the interference
channel and the two-way channel with correlated sources and correlated receiver
side information are considered, and the optimality of separation is shown to
hold for certain source and side information structures. Interestingly, the
optimal separate source and channel codes identified for these models are not
necessarily the optimal codes for the underlying source coding or the channel
coding problems. In other words, while separation of the source and channel
codes is optimal, the nature of these optimal codes is impacted by the joint
design criterion.",0807.2666v2,cs.IT,2008-07-16 21:39:11+00:00,"[arxiv.Result.Author('Deniz Gunduz'), arxiv.Result.Author('Elza Erkip'), arxiv.Result.Author('Andrea Goldsmith'), arxiv.Result.Author('H. Vincent Poor')]",
318,Joint Source-Channel Coding on a Multiple Access Channel with Side Information,"We consider the problem of transmission of several distributed correlated
sources over a multiple access channel (MAC) with side information at the
sources and the decoder. Source-channel separation does not hold for this
channel. Sufficient conditions are provided for transmission of sources with a
given distortion. The source and/or the channel could have continuous alphabets
(thus Gaussian sources and Gaussian MACs are special cases). Various previous
results are obtained as special cases. We also provide several good joint
source-channel coding schemes for discrete sources and discrete/continuous
alphabet channel.",0904.4006v1,cs.IT,2009-04-26 04:43:59+00:00,"[arxiv.Result.Author('R. Rajesh'), arxiv.Result.Author('Vinod Sharma'), arxiv.Result.Author('V. K. Varshenya')]",
319,An Optimal Energy Efficient Design of Artificial Noise for Preventing Power Leakage based Side-Channel Attacks,"Side-channel attacks (SCAs), which infer secret information (for example
secret keys) by exploiting information that leaks from the implementation (such
as power consumption), have been shown to be a non-negligible threat to modern
cryptographic implementations and devices in recent years. Hence, how to
prevent side-channel attacks on cryptographic devices has become an important
problem. One of the widely used countermeasures to against power SCAs is the
injection of random noise sequences into the raw leakage traces. However, the
indiscriminate injection of random noise can lead to significant increases in
energy consumption in device, and ways must be found to reduce the amount of
energy in noise generation while keeping the side-channel invisible. In this
paper, we propose an optimal energy-efficient design for artificial noise
generation to prevent side-channel attacks. This approach exploits the sparsity
among the leakage traces. We model the side-channel as a communication channel,
which allows us to use channel capacity to measure the mutual information
between the secret and the leakage traces. For a given energy budget in the
noise generation, we obtain the optimal design of the artificial noise
injection by solving the side-channel's channel capacity minimization problem.
The experimental results also validate the effectiveness of our proposed
scheme.",2208.09140v1,cs.CR,2022-08-19 03:49:12+00:00,"[arxiv.Result.Author('Shan Jin'), arxiv.Result.Author('Minghua Xu'), arxiv.Result.Author('Riccardo Bettati'), arxiv.Result.Author('Mihai Christodorescu')]",
320,Roughly Weighted Hierarchical Simple Games,"Hierarchical simple games - both disjunctive and conjunctive - are natural
generalizations of simple majority games. They take their origin in the theory
of secret sharing. Another important generalization of simple majority games
with origin in economics and politics are weighted and roughly weighted
majority games. In this paper we characterize roughly weighted hierarchical
games identifying where the two approaches coincide.",1205.2152v1,math.CO,2012-05-10 03:34:21+00:00,"[arxiv.Result.Author('Ali Hameed'), arxiv.Result.Author('Arkadii Slinko')]",
321,A new notion of majorization for polynomials,"In this paper, we introduce a notion called strong majorization for
realrooted polynomials, and we show how it relates to standard majorization and
how it can be checked through a simple fraction decomposition.",2212.13935v1,math.CA,2022-12-28 16:28:38+00:00,[arxiv.Result.Author('Aurelien Gribinski')],
322,Majority dominator colorings of graphs,"Let $G$ be a simple graph of order $n$. A majority dominator coloring of a
graph $G$ is proper coloring in which each vertex of the graph dominates at
least half of one color class. The majority dominator chromatic number
$\chi_{md}(G)$ is the minimum number of color classes in a majority dominator
coloring of $G$. In this paper we study properties of the majority dominator
coloring of a graph. We obtain tight upper and lower bounds in terms of
chromatic number, dominator chromatic number, maximum degree, domination and
independence number. We also study majority dominator coloring number of
selected families of graphs.",2212.14082v1,math.CO,2022-12-28 20:06:25+00:00,"[arxiv.Result.Author('Marcin Anholcer'), arxiv.Result.Author('Azam Sadat Emadi'), arxiv.Result.Author('Doost Ali Mojdeh')]",
323,A Simple Proof that Major Index and Inversions are Equidistributed,"We present a short proof of MacMahon's classic result that the number of
permutations with $k$ inversions equals the number whose major index (sum of
positions at which descents occur) is $k$",2207.05210v1,math.CO,2022-07-11 22:06:57+00:00,[arxiv.Result.Author('Michael J. Collins')],
324,Simple Majority Consensus in Networks with Unreliable Communication,"In this work, we analyze the performance of a simple majority-rule protocol
solving a fundamental coordination problem in distributed systems -
\emph{binary majority consensus}, in the presence of probabilistic message
loss. Using probabilistic analysis for a large scale, fully-connected, network
of $2n$ agents, we prove that the Simple Majority Protocol (SMP) reaches
consensus in only three communication rounds with probability approaching $1$
as $n$ grows to infinity. Moreover, if the difference between the numbers of
agents that hold different opinions grows at a rate of $\sqrt{n}$, then the SMP
with only two communication rounds attains consensus on the majority opinion of
the network, and if this difference grows faster than $\sqrt{n}$, then the SMP
reaches consensus on the majority opinion of the network in a single round,
with probability converging to $1$ exponentially fast as $n \rightarrow
\infty$. We also provide some converse results, showing that these requirements
are not only sufficient, but also necessary.",2104.04996v1,cs.IT,2021-04-11 11:36:21+00:00,"[arxiv.Result.Author('Ran Tamir'), arxiv.Result.Author('Ariel Livshits'), arxiv.Result.Author('Yonatan Shadmi')]",
325,Embodied Approximation of the Density Classification Problem via Morphological Adaptation,"The Majority (or Density Classification) Problem in Cellular Automata (CA)
aims to converge a string of cells to a final homogeneous state which reflects
the majority of states present in the initial configuration. The problem is
challenging in CA as individual cells only possess information about their own
and local neighbour states. The problem is an exercise in the propagation and
processing of information within a distributed computational medium. We explore
whether the Majority Problem can be approximated in a similarly simple
distributed computing substrate - a multi-agent model of slime mould. An
initial pattern of discrete voting choices is represented by spatial
arrangement of the agent population, temporarily held in-place by an attractant
stimulus. When this stimulus is removed the model adapts its shape and size,
moving to form a minimal distance connecting line. The final position of this
line is shown, in simple examples, to successfully represent the majority vote
decision, and also accurately reflects the size of the majority. We note
properties, limitations and potential improvements to the approach before
returning full-circle by re-encoding this morphological adaptation approach in
a simple (and more space efficient) 1D CA model.",1606.06036v1,cs.ET,2016-06-20 09:42:33+00:00,[arxiv.Result.Author('Jeff Jones')],"Int. J. Unconventional Computing, 12, 2-3, p. 221-240 (2016)"
326,When is the majority-vote classifier beneficial?,"In his seminal work, Schapire (1990) proved that weak classifiers could be
improved to achieve arbitrarily high accuracy, but he never implied that a
simple majority-vote mechanism could always do the trick. By comparing the
asymptotic misclassification error of the majority-vote classifier with the
average individual error, we discover an interesting phase-transition
phenomenon. For binary classification with equal prior probabilities, our
result implies that, for the majority-vote mechanism to work, the collection of
weak classifiers must meet the minimum requirement of having an average true
positive rate of at least 50% and an average false positive rate of at most
50%.",1307.6522v1,math.ST,2013-07-24 18:33:51+00:00,[arxiv.Result.Author('Mu Zhu')],
327,A game-theoretic framework for classifier ensembles using weighted majority voting with local accuracy estimates,"In this paper, a novel approach for the optimal combination of binary
classifiers is proposed. The classifier combination problem is approached from
a Game Theory perspective. The proposed framework of adapted weighted majority
rules (WMR) is tested against common rank-based, Bayesian and simple majority
models, as well as two soft-output averaging rules. Experiments with ensembles
of Support Vector Machines (SVM), Ordinary Binary Tree Classifiers (OBTC) and
weighted k-nearest-neighbor (w/k-NN) models on benchmark datasets indicate that
this new adaptive WMR model, employing local accuracy estimators and the
analytically computed optimal weights outperform all the other simple
combination rules.",1302.0540v1,cs.LG,2013-02-03 22:12:52+00:00,"[arxiv.Result.Author('Harris V. Georgiou'), arxiv.Result.Author('Michael E. Mavroforakis')]",
328,Majorization relations and entanglement generation in a beam splitter,"We prove that a beam splitter, one of the most common optical components,
fulfills several classes of majorization relations, which govern the amount of
quantum entanglement that it can generate. First, we show that the state
resulting from k photons impinging on a beam splitter majorizes the
corresponding state with any larger photon number k'>k, implying that the
entanglement monotonically grows with k. Then, we examine parametric
infinitesimal majorization relations as a function of the beam-splitter
transmittance, and find that there exists a parameter region where majorization
is again fulfilled, implying a monotonic increase of entanglement by moving
towards a balanced beam splitter. We also identify regions with a majorization
default, where the output states become incomparable. In this latter situation,
we find examples where catalysis may nevertheless be used in order to recover
majorization. The catalyst states can be as simple as a path-entangled
single-photon state or a two-mode vacuum squeezed state.",1301.5229v1,quant-ph,2013-01-22 16:32:44+00:00,"[arxiv.Result.Author('C. N. Gagatsos'), arxiv.Result.Author('O. Oreshkov'), arxiv.Result.Author('N. J. Cerf')]","Phys. Rev. A 87, 042307 (2013)"
329,"Constructions of Majorizing Measures, Bernoulli processes and cotype","We present three methods to construct majorizing measures in various
settings. These methods are based on direct constructions of increasing
sequences of partitions through a simple exhaustion procedure rather than on
the construction of well separated ultrametric subspaces. The first scheme of
construction provides a simple unified proof of the Majorizing Measure Theorem
for Gaussian processes and of the following fact. If $A,B$ are balanced convex
sets in a vector space, and if $A$ is sufficiently convex, a control of the
covering numbers $N(A,\varepsilon B)$ for all $\varepsilon>0$ implies the (a
priori stronger) existence of a majorizing measure on $A$ provided with the
distance induced by $B$. This establishes, apparently for the first time, a
clear link between geometry and majorizing measures, and generalizes the
earlier results on majorizing measures on ellipsoids in Hilbert space, that
were obtained by specific methods. Much of the rest of the paper is concerned
with the structure of bounded Bernoulli (=Radmacher) processes. The main
conjecture on their structure is reformulated in several ways, that are shown
to be equivalent, and to be equivalent to the existence of certain majorizing
measures. Two schemes of construction of majorizing measures related to this
problem are presented. One allows to describe Bernoulli processes when the
index set, provided with the supremum norm, is sufficiently small. The other
allows to prove a weak form of the main conjecture.",math/9406216v1,math.FA,1994-06-07 18:04:42+00:00,[arxiv.Result.Author('Michel Talagrand')],
330,Remarks on cutoff phenomena for random walks on Hamming Schemes,"The sequence of the simple random walks on Hamming schemes $\{H(n,
q)\}_{n=1}^{\infty}$ has a cutoff phenomenon for each integer $q$ greater than
or equal to $3$. In this paper, for the sequence of simple random walks on
Hamming schemes $\{H(n, q)\}_{n=1}^{\infty}$ with $q\geq 3$, we give a simple
majorant and a sharp minorant function for total variance distances between
transition distributions and stationary distributions.",1601.03548v2,math.PR,2016-01-14 10:36:43+00:00,[arxiv.Result.Author('Katsuhiko Kikuchi')],
331,Computing majority with low-fan-in majority queries,"In this paper we examine the problem of computing majority function
$\mathrm{MAJ}_n$ on $n$ bits by depth-two formula, where each gate is a
majority function on at most $k$ inputs. We present such formula that gives the
first nontrivial upper bound for this problem, with $k = \frac{2}{3} n + 4$.
This answers an open question in [Kulikov, Podolskii, 2017].
  We also look at this problem in adaptive setting - when we are allowed to
query for value of $\mathrm{MAJ}_k$ on any subset, and wish to minimize the
number of such queries. We give a simple lower bound for this setting with
$\lceil n/k \rceil$ queries, and we present two algorithms for this model: the
first one makes $\approx 2\frac{n}{k} \log k$ queries in the case when we are
limited to the standard majority functions, and the second one makes
$\frac{n}{k} \log k$ queries when we are allowed to change the threshold of
majority function.",1711.10176v1,cs.CC,2017-11-28 08:38:54+00:00,[arxiv.Result.Author('Gleb Posobin')],
332,Weighted and Roughly Weighted Simple Games,"This paper contributes to the program of numerical characterisation and
classification of simple games outlined in the classical monograph of von
Neumann and Morgenstern (1944). One of the most fundamental questions of this
program is what makes a simple game a weighted majority game. The necessary and
sufficient conditions that guarantee weightedness were obtained by Elgot (1961)
and refined by Taylor and Zwicker (1992). If a simple game does not have
weights, then rough weights may serve as a reasonable substitute (see their use
in Taylor and Zwicker, 1992). A simple game is roughly weighted if there exists
a system of weights and a threshold such that all coalitions whose combined
weight is above the threshold are winning and all coalitions whose combined
weight is below the threshold are losing and a tie-breaking is needed to
classify the coalitions whose combined weight is exactly the threshold. Not all
simple games are roughly weighted, and the class of projective games is a prime
example.
  In this paper we give necessary and sufficient conditions for a simple game
to have rough weights. We define two functions f(n) and g(n) that measure the
deviation of a simple game from a weighted majority game and roughly weighted
majority game, respectively. We formulate known results in terms of lower and
upper bounds for these functions and improve those bounds. We also investigate
rough weightedness of simle games with a small number of players.",0912.5364v1,math.CO,2009-12-29 20:33:36+00:00,"[arxiv.Result.Author('T. Gvozdeva'), arxiv.Result.Author('A. Slinko')]",
333,Signed Mahonians,"A classical result of MacMahon gives a simple product formula for the
generating function of major index over the symmetric group. A similar
factorial-type product formula for the generating function of major index
together with sign was given by Gessel and Simion. Several extensions are given
in this paper, including a recurrence formula, a specialization at roots of
unity and type $B$ analogues.",math/0402208v1,math.CO,2004-02-12 17:18:18+00:00,"[arxiv.Result.Author('Ron M. Adin'), arxiv.Result.Author('Ira M. Gessel'), arxiv.Result.Author('Yuval Roichman')]",
334,Signed Mahonian polynomials for classical Weyl groups,"The generating functions of the major index and of the flag-major index, with
each of the one-dimensional characters over the symmetric and hyperoctahedral
group, respectively, have simple product formulas. In this paper, we give a
factorial-type formula for the generating function of the D-major index with
sign over the Weyl groups of type D. This completes a picture which is now
known for all the classical Weyl groups.",math/0404300v1,math.CO,2004-04-16 19:49:06+00:00,[arxiv.Result.Author('Riccardo Biagioli')],
335,Signed mahonians on some trees and parabolic quotients,"We study the distribution of the major index with sign on some parabolic
quotients of the symmetric group, extending and generalizing simultaneously
results Gessel-Simion and Adin-Gessel-Roichman, and on some special trees that
we call rakes. We further consider and compute the distribution of the
flag-major index on some parabolic quotients of wreath products and other
related groups. All these distributions turn out to have very simple
factorization formulas.",1103.4807v2,math.CO,2011-03-24 16:51:28+00:00,[arxiv.Result.Author('Fabrizio Caselli')],
336,Determinantal formulas with major indices,"We give a simple proof of a major index determinant formula in the symmetric
group discovered by Krattenthaler and first proved by Thibon using
noncommutative symmetric functions. We do so by proving a factorization of an
element in the group ring of the symmetric group. By applying similar methods
to the groups of signed permutations and colored permutations, we prove
determinant formulas in these groups as conjectured by Krattenthaler.",2102.13005v1,math.CO,2021-02-25 17:09:10+00:00,"[arxiv.Result.Author('Thomas McConville'), arxiv.Result.Author('Donald Robertson'), arxiv.Result.Author('Clifford Smyth')]",
337,On irreversible dynamic monopolies in general graphs,"Consider the following coloring process in a simple directed graph $G(V,E)$
with positive indegrees. Initially, a set $S$ of vertices are white, whereas
all the others are black. Thereafter, a black vertex is colored white whenever
more than half of its in-neighbors are white. The coloring process ends when no
additional vertices can be colored white. If all vertices end up white, we call
$S$ an irreversible dynamic monopoly (or dynamo for short) under the
strict-majority scenario. An irreversible dynamo under the simple-majority
scenario is defined similarly except that a black vertex is colored white when
at least half of its in-neighbors are white. We derive upper bounds of
$(2/3)\,|\,V\,|$ and $|\,V\,|/2$ on the minimum sizes of irreversible dynamos
under the strict and the simple-majority scenarios, respectively. For the
special case when $G$ is an undirected connected graph, we prove the existence
of an irreversible dynamo with size at most $\lceil |\,V\,|/2 \rceil$ under the
strict-majority scenario. Let $\epsilon>0$ be any constant. We also show that,
unless $\text{NP}\subseteq \text{TIME}(n^{O(\ln \ln n)}),$ no polynomial-time,
$((1/2-\epsilon)\ln |\,V\,|)$-approximation algorithms exist for finding the
minimum irreversible dynamo under either the strict or the simple-majority
scenario. The inapproximability results hold even for bipartite graphs with
diameter at most 8.",0904.2306v3,cs.DM,2009-04-15 12:56:19+00:00,"[arxiv.Result.Author('Ching-Lueh Chang'), arxiv.Result.Author('Yuh-Dauh Lyuu')]",
338,Convergence of the Gauss-Newton method for convex composite optimization under a majorant condition,"Under the hypothesis that an initial point is a quasi-regular point, we use a
majorant condition to present a new semi-local convergence analysis of an
extension of the Gauss-Newton method for solving convex composite optimization
problems. In this analysis the conditions and proof of convergence are
simplified by using a simple majorant condition to define regions where a
Gauss-Newton sequence is ""well behaved"".",1107.3796v1,math.OC,2011-07-19 17:56:43+00:00,"[arxiv.Result.Author('Orizon Perreira Ferreira'), arxiv.Result.Author('Max Leandro Nobre Gonçalves'), arxiv.Result.Author('Paulo Roberto Oliveira')]",
339,Convergence of the Gauss-Newton method for a special class of systems of equations under a majorant condition,"In this paper, we study the Gauss-Newton method for a special class of
systems of nonlinear equation. Under the hypothesis that the derivative of the
function under consideration satisfies a majorant condition, semi-local
convergence analysis is presented. In this analysis the conditions and proof of
convergence are simplified by using a simple majorant condition to define
regions where the Gauss-Newton sequence is ""well behaved"". Moreover, special
cases of the general theory are presented as applications.",1206.4103v2,math.OC,2012-06-19 01:41:23+00:00,"[arxiv.Result.Author('Max L. N. Gonçalves'), arxiv.Result.Author('Paulo R. Oliveira')]",
340,Generating Single Peaked Votes,"We discuss how to generate singled peaked votes uniformly from the Impartial
Culture model.",1503.02766v1,cs.GT,2015-03-10 04:15:23+00:00,[arxiv.Result.Author('Toby Walsh')],
341,The Computational Impact of Partial Votes on Strategic Voting,"In many real world elections, agents are not required to rank all candidates.
We study three of the most common methods used to modify voting rules to deal
with such partial votes. These methods modify scoring rules (like the Borda
count), elimination style rules (like single transferable vote) and rules based
on the tournament graph (like Copeland) respectively. We argue that with an
elimination style voting rule like single transferable vote, partial voting
does not change the situations where strategic voting is possible. However,
with scoring rules and rules based on the tournament graph, partial voting can
increase the situations where strategic voting is possible. As a consequence,
the computational complexity of computing a strategic vote can change. For
example, with Borda count, the complexity of computing a strategic vote can
decrease or stay the same depending on how we score partial votes.",1405.7714v1,cs.GT,2014-05-28 12:13:52+00:00,"[arxiv.Result.Author('Nina Narodytska'), arxiv.Result.Author('Toby Walsh')]",
342,Sub-committee Approval Voting and Generalised Justified Representation Axioms,"Social choice is replete with various settings including single-winner
voting, multi-winner voting, probabilistic voting, multiple referenda, and
public decision making. We study a general model of social choice called
Sub-Committee Voting (SCV) that simultaneously generalizes these settings. We
then focus on sub-committee voting with approvals and propose extensions of the
justified representation axioms that have been considered for proportional
representation in approval-based committee voting. We study the properties and
relations of these axioms. For each of the axioms, we analyse whether a
representative committee exists and also examine the complexity of computing
and verifying such a committee.",1711.06030v1,cs.GT,2017-11-16 11:24:39+00:00,"[arxiv.Result.Author('Haris Aziz'), arxiv.Result.Author('Barton E. Lee')]",
343,A mathematical evaluation of vote transfer systems,"The paper builds a general model of vote transfer systems on the basis of the
current Hungarian electoral rules. It combines single-seat districts and list
mandates with three possible compensation rule for 'wasted' votes in
constituencies: no compensation (direct vote transfer, DVT), compensation for
votes cast for losing party candidates (positive vote transfer, PVT) and
compensation for all votes that are not necessary to win the district (negative
vote transfer, NVT).
  The model is studied in the case of two parties. When the number of votes for
the majority party follows a uniform distribution in each district, DVT results
in the greatest expected seat share, however, application of PVT, and,
especially, NVT increases the probability of winning the election. The
trade-off between vote transfer formulas and the number of list mandates
reveals that the majority party should use an appropriately calibrated NVT
system if it focuses on these two variables.",1607.02879v3,cs.GT,2016-07-11 09:58:58+00:00,[arxiv.Result.Author('László Csató')],
344,Maximization of Relative Social Welfare on Truthful Cardinal Voting Schemes,"Consider the the problem of maximizing the relative social welfare of
truthful single-winner voting schemes with cardinal preferences compared to the
classical range voting scheme. The range voting scheme is a simple and
straightforward mechanism which deterministically maximizes the social welfare.
However, the scheme that is known to be non-truthful and we studied the
truthful mechanism that maximize the ratio of its expected social welfare to
the social welfare achieved by the range voting scheme. We provide a scheme
which achieve a ratio of $\Omega(m^{-2/3})$ in this paper. It is proved that
this bound is tight asymptotically and it is impossible to find a better voting
scheme.",1904.00538v1,cs.GT,2019-04-01 02:32:09+00:00,[arxiv.Result.Author('Sinya Lee')],
345,Multi-agent simulation of voter's behaviour,"The goal of this paper is to simulate the voters behaviour given a voting
method. Our approach uses a multi-agent simulation in order to model a voting
process through many iterations, so that the voters can vote by taking into
account the results of polls. Here we only tried basic rules and a single
voting method, but further attempts could explore new features.",2101.11538v1,cs.MA,2021-01-27 16:48:03+00:00,"[arxiv.Result.Author('Albin Soutif'), arxiv.Result.Author('Carole Adam'), arxiv.Result.Author('Sylvain Bouveret')]",
346,Distance Restricted Manipulation in Voting,"We introduce the notion of {\em Distance Restricted Manipulation}, where
colluding manipulator(s) need to compute if there exist votes which make their
preferred alternative win the election when their knowledge about the others'
votes is a little inaccurate. We use the Kendall-Tau distance to model the
manipulators' confidence in the non-manipulators' votes. To this end, we study
this problem in two settings - one where the manipulators need to compute a
manipulating vote that succeeds irrespective of perturbations in others' votes
({\em Distance Restricted Strong Manipulation}), and the second where the
manipulators need to compute a manipulating vote that succeeds for at least one
possible vote profile of the others ({\em Distance Restricted Weak
Manipulation}). We show that {\em Distance Restricted Strong Manipulation}
admits polynomial-time algorithms for every scoring rule, maximin, Bucklin, and
simplified Bucklin voting rules for a single manipulator, and for the
$k$-approval rule for any number of manipulators, but becomes intractable for
the Copeland$^\alpha$ voting rule for every $\alpha\in[0,1]$ even for a single
manipulator. In contrast, {\em Distance Restricted Weak Manipulation} is
intractable for almost all the common voting rules, with the exception of the
plurality rule. For a constant number of alternatives, we show that both the
problems are polynomial-time solvable for every anonymous and efficient voting
rule.",1909.03162v2,cs.GT,2019-09-07 01:29:32+00:00,"[arxiv.Result.Author('Aditya Anand'), arxiv.Result.Author('Palash Dey')]",
347,An Empirical Study of the Manipulability of Single Transferable Voting,"Voting is a simple mechanism to combine together the preferences of multiple
agents. Agents may try to manipulate the result of voting by mis-reporting
their preferences. One barrier that might exist to such manipulation is
computational complexity. In particular, it has been shown that it is NP-hard
to compute how to manipulate a number of different voting rules. However,
NP-hardness only bounds the worst-case complexity. Recent theoretical results
suggest that manipulation may often be easy in practice. In this paper, we
study empirically the manipulability of single transferable voting (STV) to
determine if computational complexity is really a barrier to manipulation. STV
was one of the first voting rules shown to be NP-hard. It also appears one of
the harder voting rules to manipulate. We sample a number of distributions of
votes including uniform and real world elections. In almost every election in
our experiments, it was easy to compute how a single agent could manipulate the
election or to prove that manipulation by a single agent was impossible.",1005.5268v1,cs.AI,2010-05-28 11:11:56+00:00,[arxiv.Result.Author('Toby Walsh')],
348,Measures of Partisan Bias for Legislating Fair Elections,"Several measures of partisan bias are reviewed for single member districts
with two dominant parties. These include variants of the simple bias that
considers only deviation of seats from 50% at statewide 50% vote. Also included
are equalization of losing votes and equalization of wasted votes, both of
which apply directly when the statewide vote is not 50% and which require, not
just partisan symmetry, but specific forms of the seats-votes curve. A new
measure of bias is introduced, based on the geometric area between the
seats-vote curve and the symmetrically inverted seats-votes curve. These
measures are applied to recent Pennsylvania congressional elections and to
abstract models of the seats-votes curves. The numerical values obtained from
the various measures of bias are compared and contrasted. Each bias measure has
merits for different seats-votes curves and for different elections, but all
essentially agree for most cases when applied to measure only partisan bias,
not conflated with competitiveness. This supports the inclusion of partisan
fairness as a fundamental element for election law reform, and some options are
discussed.",1505.06749v1,physics.soc-ph,2015-05-25 20:27:21+00:00,[arxiv.Result.Author('John F. Nagle')],Election Law Journal 14 (2015) 346-360
349,The probability of casting a pivotal vote in an Instant Runoff Voting election,"I derive the probability that a vote cast in an Instant Runoff Voting
election will change the election winner. I show that there can be two types of
pivotal event: direct pivotality, in which a voter causes a candidate to win by
ranking them, and indirect pivotality, in which a voter causes one candidate to
win by ranking some other candidate. This suggests a reason that voters should
be allowed to rank at most four candidates. I identify all pivotal events in
terms of the ballots that a voter expects to be cast, and then I compute those
probabilities in a common framework for voting games. I provide pseudocode, and
work through an example of calculating pivotal probabilities. I then compare
the probability of casting a pivotal vote in Instant Runoff Voting to
single-vote plurality, and show that the incentives to vote strategically are
similar in these two systems.",2210.01657v1,cs.GT,2022-10-04 15:00:43+00:00,[arxiv.Result.Author('Samuel Baltz')],
350,Heuristic Strategies in Uncertain Approval Voting Environments,"In many collective decision making situations, agents vote to choose an
alternative that best represents the preferences of the group. Agents may
manipulate the vote to achieve a better outcome by voting in a way that does
not reflect their true preferences. In real world voting scenarios, people
often do not have complete information about other voter preferences and it can
be computationally complex to identify a strategy that will maximize their
expected utility. In such situations, it is often assumed that voters will vote
truthfully rather than expending the effort to strategize. However, being
truthful is just one possible heuristic that may be used. In this paper, we
examine the effectiveness of heuristics in single winner and multi-winner
approval voting scenarios with missing votes. In particular, we look at
heuristics where a voter ignores information about other voting profiles and
makes their decisions based solely on how much they like each candidate. In a
behavioral experiment, we show that people vote truthfully in some situations
and prioritize high utility candidates in others. We examine when these
behaviors maximize expected utility and show how the structure of the voting
environment affects both how well each heuristic performs and how humans employ
these heuristics.",1912.00011v1,cs.GT,2019-11-29 13:38:34+00:00,"[arxiv.Result.Author('Jaelle Scheuerman'), arxiv.Result.Author('Jason L. Harman'), arxiv.Result.Author('Nicholas Mattei'), arxiv.Result.Author('K. Brent Venable')]",
351,Cryptographically verifiable anonymous voting using pan-european e-IDs,"In this paper we explore a method to create anonymous services on top of the
STORK framework, to be used for electronic surveys or elections.
  The STORK project aims to realize a single electronic identification and
authentication area across Europe. For verifiable and anonymous voting, users
should be authenticated with their e-id (to prevent repeated voting) but the
votes should also be anonymous. This is achieved using blind signatures and an
onion routing system similar to the one used in TOR.
  In the paper we describe the anonymous voting protocol in detail, we analyze
a reference implementation and, finally, we highlight potential weaknesses and
propose some improvements.",1611.09332v1,cs.CR,2016-11-28 20:37:08+00:00,"[arxiv.Result.Author('Alessandro Preziosi'), arxiv.Result.Author('Diana Berbecaru')]",
352,The vote Package: Single Transferable Vote and Other Electoral Systems in R,"We describe the vote package in R, which implements the plurality (or
first-past-the-post), two-round runoff, score, approval and single transferable
vote (STV) electoral systems, as well as methods for selecting the Condorcet
winner and loser. We emphasize the STV system, which we have found to work well
in practice for multi-winner elections with small electorates, such as
committee and council elections, and the selection of multiple job candidates.
For single-winner elections, the STV is also called instant runoff voting
(IRV), ranked choice voting (RCV), or the alternative vote (AV) system. The
package also implements the STV system with equal preferences, for the first
time in a software package, to our knowledge. It also implements a new variant
of STV, in which a minimum number of candidates from a specified group are
required to be elected. We illustrate the package with several real examples.",2102.05801v1,stat.CO,2021-02-11 01:50:46+00:00,"[arxiv.Result.Author('Adrian E. Raftery'), arxiv.Result.Author('Hana Ševčíková'), arxiv.Result.Author('Bernard W. Silverman')]",
353,Modeling Voters in Multi-Winner Approval Voting,"In many real world situations, collective decisions are made using voting
and, in scenarios such as committee or board elections, employing voting rules
that return multiple winners. In multi-winner approval voting (AV), an agent
submits a ballot consisting of approvals for as many candidates as they wish,
and winners are chosen by tallying up the votes and choosing the top-$k$
candidates receiving the most approvals. In many scenarios, an agent may
manipulate the ballot they submit in order to achieve a better outcome by
voting in a way that does not reflect their true preferences. In complex and
uncertain situations, agents may use heuristics instead of incurring the
additional effort required to compute the manipulation which most favors them.
In this paper, we examine voting behavior in single-winner and multi-winner
approval voting scenarios with varying degrees of uncertainty using behavioral
data obtained from Mechanical Turk. We find that people generally manipulate
their vote to obtain a better outcome, but often do not identify the optimal
manipulation. There are a number of predictive models of agent behavior in the
COMSOC and psychology literature that are based on cognitively plausible
heuristic strategies. We show that the existing approaches do not adequately
model real-world data. We propose a novel model that takes into account the
size of the winning set and human cognitive constraints, and demonstrate that
this model is more effective at capturing real-world behaviors in multi-winner
approval voting scenarios.",2012.02811v1,cs.GT,2020-12-04 19:24:28+00:00,"[arxiv.Result.Author('Jaelle Scheuerman'), arxiv.Result.Author('Jason Harman'), arxiv.Result.Author('Nicholas Mattei'), arxiv.Result.Author('K. Brent Venable')]",
354,A law of large numbers for weighted plurality,"Consider an election between k candidates in which each voter votes randomly
(but not necessarily independently) and suppose that there is a single
candidate that every voter prefers (in the sense that each voter is more likely
to vote for this special candidate than any other candidate). Suppose we have a
voting rule that takes all of the votes and produces a single outcome and
suppose that each individual voter has little effect on the outcome of the
voting rule. If the voting rule is a weighted plurality, then we show that with
high probability, the preferred candidate will win the election. Conversely, we
show that this statement fails for all other reasonable voting rules.
  This result is an extension of H\""aggstr\""om, Kalai and Mossel, who proved
the above in the case k=2.",1106.5423v2,math.PR,2011-06-27 15:53:48+00:00,[arxiv.Result.Author('Joe Neeman')],
355,Evaluating the Properties of a First Choice Weighted Approval Voting System,"Plurality and approval voting are two well-known voting systems with
different strengths and weaknesses. In this paper we consider a new voting
system we call beta(k) which allows voters to select a single first-choice
candidate and approve of any other number of candidates, where k denotes the
relative weight given to a first choice; this system is essentially a hybrid of
plurality and approval. Our primary goal is to characterize the behavior of
beta(k) for any value of k. Under certain reasonable assumptions, beta(k) can
be made to mimic plurality or approval voting in the event of a single winner
while potentially breaking ties otherwise. Under the assumption that voters are
honest, we show that it is possible to find the values of k for which a given
candidate will win the election if the respective approval and plurality votes
are known. Finally, we show how some of the commonly used voting system
criteria are satisfied by beta(k).",2006.00368v1,econ.TH,2020-05-30 21:12:52+00:00,"[arxiv.Result.Author('Peter Butler'), arxiv.Result.Author('Jerry Lin')]",
356,Resolving multi-proxy transitive vote delegation,"Solving a delegation graph for transitive votes is already a non-trivial task
for many programmers. When extending the current main paradigm, where each
voter can only appoint a single transitive delegation, to a system where each
vote can be separated over multiple delegations, solving the delegation graph
becomes even harder. This article presents a solution of an example graph, and
a non-formal proof of why this algorithm works.",1412.4039v1,cs.MA,2014-12-11 13:06:38+00:00,[arxiv.Result.Author('Jonas Degrave')],
357,"Proportional Approval Method using Squared loads, Approval removal and Coin-flip approval transformation (PAMSAC) - a new system of proportional representation using approval voting","Several multi-winner systems that use approval voting have been developed but
they each suffer from various problems. Six of these methods are discussed in
this paper. They are Satisfaction Approval Voting, Minimax Approval Voting,
Proportional Approval Voting, Monroe's Fully Proportional Representation,
Chamberlin-Courant's Rule, and Ebert's method. They all fail at least one of
Proportional Representation (PR), strong PR, monotonicity or positive support.
However, the new method described in this paper - Proportional Approval Method
using Squared loads, Approval removal and Coin-flip approval transformation
(PAMSAC) - passes them all. PAMSAC uses the squared loads of Ebert's method,
but removes non-beneficial approvals to restore monotonicity. It also uses the
Coin-Flip Approval Transformation (CFAT), where voters are ""split"" into two for
each candidate they approve, and where one half of this split voter approves
and the other half does not approve each candidate approved on the ballot. This
restores positive support, and also makes the method equivalent to the D'Hondt
party-list method for party voting. PAMSAC reduces to simple approval voting in
the single-winner case. A score voting version is described that also reduces
to simple score voting in the single-winner case.",1602.05248v2,cs.GT,2016-02-17 00:10:34+00:00,[arxiv.Result.Author('Toby Pereira')],
358,Computational Aspects of Multi-Winner Approval Voting,"We study computational aspects of three prominent voting rules that use
approval ballots to elect multiple winners. These rules are satisfaction
approval voting, proportional approval voting, and reweighted approval voting.
We first show that computing the winner for proportional approval voting is
NP-hard, closing a long standing open problem. As none of the rules are
strategyproof, even for dichotomous preferences, we study various strategic
aspects of the rules. In particular, we examine the computational complexity of
computing a best response for both a single agent and a group of agents. In
many settings, we show that it is NP-hard for an agent or agents to compute how
best to vote given a fixed set of approval ballots from the other agents.",1407.3247v1,cs.GT,2014-07-11 18:40:22+00:00,"[arxiv.Result.Author('Haris Aziz'), arxiv.Result.Author('Serge Gaspers'), arxiv.Result.Author('Joachim Gudmundsson'), arxiv.Result.Author('Simon Mackenzie'), arxiv.Result.Author('Nicholas Mattei'), arxiv.Result.Author('Toby Walsh')]",
359,Single-Peaked Opinion Updates,"We consider opinion diffusion for undirected networks with sequential updates
when the opinions of the agents are single-peaked preference rankings. Our
starting point is the study of preserving single-peakedness. We identify voting
rules that, when given a single-peaked profile, output at least one ranking
that is single peaked w.r.t. a single-peaked axis of the input. For such voting
rules we show convergence to a stable state of the diffusion process that uses
the voting rule as the agents' update rule. Further, we establish an efficient
algorithm that maximises the spread of extreme opinions.",2204.14094v1,cs.GT,2022-04-29 13:37:21+00:00,"[arxiv.Result.Author('Robert Bredereck'), arxiv.Result.Author('Anne-Marie George'), arxiv.Result.Author('Jonas Israel'), arxiv.Result.Author('Leon Kellerhals')]",
360,The Computational Impact of Partial Votes on Strategic Voting,"In many real world elections, agents are not required to rank all candidates.
We study three of the most common methods used to modify voting rules to deal
with such partial votes. These methods modify scoring rules (like the Borda
count), elimination style rules (like single transferable vote) and rules based
on the tournament graph (like Copeland) respectively. We argue that with an
elimination style voting rule like single transferable vote, partial voting
does not change the situations where strategic voting is possible. However,
with scoring rules and rules based on the tournament graph, partial voting can
increase the situations where strategic voting is possible. As a consequence,
the computational complexity of computing a strategic vote can change. For
example, with Borda count, the complexity of computing a strategic vote can
decrease or stay the same depending on how we score partial votes.",1405.7714v1,cs.GT,2014-05-28 12:13:52+00:00,"[arxiv.Result.Author('Nina Narodytska'), arxiv.Result.Author('Toby Walsh')]",
361,A mathematical evaluation of vote transfer systems,"The paper builds a general model of vote transfer systems on the basis of the
current Hungarian electoral rules. It combines single-seat districts and list
mandates with three possible compensation rule for 'wasted' votes in
constituencies: no compensation (direct vote transfer, DVT), compensation for
votes cast for losing party candidates (positive vote transfer, PVT) and
compensation for all votes that are not necessary to win the district (negative
vote transfer, NVT).
  The model is studied in the case of two parties. When the number of votes for
the majority party follows a uniform distribution in each district, DVT results
in the greatest expected seat share, however, application of PVT, and,
especially, NVT increases the probability of winning the election. The
trade-off between vote transfer formulas and the number of list mandates
reveals that the majority party should use an appropriately calibrated NVT
system if it focuses on these two variables.",1607.02879v3,cs.GT,2016-07-11 09:58:58+00:00,[arxiv.Result.Author('László Csató')],
362,An Empirical Study of the Manipulability of Single Transferable Voting,"Voting is a simple mechanism to combine together the preferences of multiple
agents. Agents may try to manipulate the result of voting by mis-reporting
their preferences. One barrier that might exist to such manipulation is
computational complexity. In particular, it has been shown that it is NP-hard
to compute how to manipulate a number of different voting rules. However,
NP-hardness only bounds the worst-case complexity. Recent theoretical results
suggest that manipulation may often be easy in practice. In this paper, we
study empirically the manipulability of single transferable voting (STV) to
determine if computational complexity is really a barrier to manipulation. STV
was one of the first voting rules shown to be NP-hard. It also appears one of
the harder voting rules to manipulate. We sample a number of distributions of
votes including uniform and real world elections. In almost every election in
our experiments, it was easy to compute how a single agent could manipulate the
election or to prove that manipulation by a single agent was impossible.",1005.5268v1,cs.AI,2010-05-28 11:11:56+00:00,[arxiv.Result.Author('Toby Walsh')],
363,The vote Package: Single Transferable Vote and Other Electoral Systems in R,"We describe the vote package in R, which implements the plurality (or
first-past-the-post), two-round runoff, score, approval and single transferable
vote (STV) electoral systems, as well as methods for selecting the Condorcet
winner and loser. We emphasize the STV system, which we have found to work well
in practice for multi-winner elections with small electorates, such as
committee and council elections, and the selection of multiple job candidates.
For single-winner elections, the STV is also called instant runoff voting
(IRV), ranked choice voting (RCV), or the alternative vote (AV) system. The
package also implements the STV system with equal preferences, for the first
time in a software package, to our knowledge. It also implements a new variant
of STV, in which a minimum number of candidates from a specified group are
required to be elected. We illustrate the package with several real examples.",2102.05801v1,stat.CO,2021-02-11 01:50:46+00:00,"[arxiv.Result.Author('Adrian E. Raftery'), arxiv.Result.Author('Hana Ševčíková'), arxiv.Result.Author('Bernard W. Silverman')]",
364,Manipulability of Single Transferable Vote,"For many voting rules, it is NP-hard to compute a successful manipulation.
However, NP-hardness only bounds the worst-case complexity. Recent theoretical
results suggest that manipulation may often be easy in practice. We study
empirically the cost of manipulating the single transferable vote (STV) rule.
This was one of the first rules shown to be NP-hard to manipulate. It also
appears to be one of the harder rules to manipulate since it involves multiple
rounds and since, unlike many other rules, it is NP-hard for a single agent to
manipulate without weights on the votes or uncertainty about how the other
agents have voted. In almost every election in our experiments, it was easy to
compute how a single agent could manipulate the election or to prove that
manipulation by a single agent was impossible. It remains an interesting open
question if manipulation by a coalition of agents is hard to compute in
practice.",0911.3708v1,cs.AI,2009-11-19 06:23:55+00:00,[arxiv.Result.Author('Toby Walsh')],
365,Generating Single Peaked Votes,"We discuss how to generate singled peaked votes uniformly from the Impartial
Culture model.",1503.02766v1,cs.GT,2015-03-10 04:15:23+00:00,[arxiv.Result.Author('Toby Walsh')],
366,A mixture of experts model for rank data with applications in election studies,"A voting bloc is defined to be a group of voters who have similar voting
preferences. The cleavage of the Irish electorate into voting blocs is of
interest. Irish elections employ a ``single transferable vote'' electoral
system; under this system voters rank some or all of the electoral candidates
in order of preference. These rank votes provide a rich source of preference
information from which inferences about the composition of the electorate may
be drawn. Additionally, the influence of social factors or covariates on the
electorate composition is of interest. A mixture of experts model is a mixture
model in which the model parameters are functions of covariates. A mixture of
experts model for rank data is developed to provide a model-based method to
cluster Irish voters into voting blocs, to examine the influence of social
factors on this clustering and to examine the characteristic preferences of the
voting blocs. The Benter model for rank data is employed as the family of
component densities within the mixture of experts model; generalized linear
model theory is employed to model the influence of covariates on the mixing
proportions. Model fitting is achieved via a hybrid of the EM and MM
algorithms. An example of the methodology is illustrated by examining an Irish
presidential election. The existence of voting blocs in the electorate is
established and it is determined that age and government satisfaction levels
are important factors in influencing voting in this election.",0901.4203v1,stat.AP,2009-01-27 09:16:05+00:00,"[arxiv.Result.Author('Isobel Claire Gormley'), arxiv.Result.Author('Thomas Brendan Murphy')]","Annals of Applied Statistics 2008, Vol. 2, No. 4, 1452-1477"
367,Unifying Ensemble Methods for Q-learning via Social Choice Theory,"Ensemble methods have been widely applied in Reinforcement Learning (RL) in
order to enhance stability, increase convergence speed, and improve
exploration. These methods typically work by employing an aggregation mechanism
over actions of different RL algorithms. We show that a variety of these
methods can be unified by drawing parallels from committee voting rules in
Social Choice Theory. We map the problem of designing an action aggregation
mechanism in an ensemble method to a voting problem which, under different
voting rules, yield popular ensemble-based RL algorithms like Majority Voting
Q-learning or Bootstrapped Q-learning. Our unification framework, in turn,
allows us to design new ensemble-RL algorithms with better performance. For
instance, we map two diversity-centered committee voting rules, namely Single
Non-Transferable Voting Rule and Chamberlin-Courant Rule, into new RL
algorithms that demonstrate excellent exploratory behavior in our experiments.",1902.10646v2,cs.AI,2019-02-27 17:27:30+00:00,"[arxiv.Result.Author('Rishav Chourasia'), arxiv.Result.Author('Adish Singla')]",
368,Random errors are not necessarily politically neutral,"Errors are inevitable in the implementation of any complex process. Here we
examine the effect of random errors on Single Transferable Vote (STV)
elections, a common approach to deciding multi-seat elections. It is usually
expected that random errors should have nearly equal effects on all candidates,
and thus be fair. We find to the contrary that random errors can introduce
systematic bias into election results. This is because, even if the errors are
random, votes for different candidates occur in different patterns that are
affected differently by random errors. In the STV context, the most important
effect of random errors is to invalidate the ballot. This removes far more
votes for those candidates whose supporters tend to list a lot of preferences,
because their ballots are much more likely to be invalidated by random error.
Different validity rules for different voting styles mean that errors are much
more likely to penalise some types of votes than others. For close elections
this systematic bias can change the result of the election.",2007.00854v3,cs.CY,2020-07-02 03:37:48+00:00,"[arxiv.Result.Author('Michelle Blom'), arxiv.Result.Author('Andrew Conway'), arxiv.Result.Author('Peter J. Stuckey'), arxiv.Result.Author('Vanessa Teague'), arxiv.Result.Author('Damjan Vukcevic')]","Electronic Voting, E-Vote-ID 2020, Lecture Notes in Computer
  Science 12455 (2020) 19-35"
369,An algorithm for a fairer and better voting system,"The major finding, of this article, is an ensemble method, but more exactly,
a novel, better ranked voting system (and other variations of it), that aims to
solve the problem of finding the best candidate to represent the voters. We
have the source code on GitHub, for making realistic simulations of elections,
based on artificial intelligence for comparing different variations of the
algorithm, and other already known algorithms.
  We have convincing evidence that our algorithm is better than Instant-Runoff
Voting, Preferential Block Voting, Single Transferable Vote, and First Past The
Post (if certain, natural conditions are met, to support the wisdom of the
crowds). By also comparing with the best voter, we demonstrated the wisdom of
the crowds, suggesting that democracy (distributed system) is a better option
than dictatorship (centralized system), if those certain, natural conditions
are met.
  Voting systems are not restricted to politics, they are ensemble methods for
artificial intelligence, but the context of this article is natural
intelligence. It is important to find a system that is fair (e.g. freedom of
expression on the ballot exists), especially when the outcome of the voting
system has social impact: some voting systems have the unfair inevitability to
trend (over time) towards the same two major candidates (Duverger's law).",2110.07066v1,cs.AI,2021-10-13 22:34:49+00:00,[arxiv.Result.Author('Gabriel-Claudiu Grama')],
370,Vote Elicitation: Complexity and Strategy-Proofness,"Preference elicitation is a central problem in AI, and has received
significant attention in single-agent settings. It is also a key problem in
multiagent systems, but has received little attention here so far. In this
setting, the agents may have different preferences that often must be
aggregated using voting. This leads to interesting issues because what, if any,
information should be elicited from an agent depends on what other agents have
revealed about their preferences so far.
  In this paper we study effective elicitation, and its impediments, for the
most common voting protocols. It turns out that in the Single Transferable Vote
protocol, even knowing when to terminate elicitation is mathcal NP-complete,
while this is easy for all the other protocols under study. Even for these
protocols, determining how to elicit effectively is NP-complete, even with
perfect suspicions about how the agents will vote. The exception is the
Plurality protocol where such effective elicitation is easy.
  We also show that elicitation introduces additional opportunities for
strategic manipulation by the voters. We demonstrate how to curtail the space
of elicitation schemes so that no such additional strategic issues arise.",cs/0205073v1,cs.GT,2002-05-29 00:10:26+00:00,"[arxiv.Result.Author('Vincent Conitzer'), arxiv.Result.Author('Tuomas Sandholm')]","Proceedings of the 18th National Conference on Artificial
  Intelligence (AAAI-02), Edmonton, Canada, 2002"
371,Sample Complexity for Winner Prediction in Elections,"Predicting the winner of an election is a favorite problem both for news
media pundits and computational social choice theorists. Since it is often
infeasible to elicit the preferences of all the voters in a typical prediction
scenario, a common algorithm used for winner prediction is to run the election
on a small sample of randomly chosen votes and output the winner as the
prediction. We analyze the performance of this algorithm for many common voting
rules.
  More formally, we introduce the $(\epsilon, \delta)$-winner determination
problem, where given an election on $n$ voters and $m$ candidates in which the
margin of victory is at least $\epsilon n$ votes, the goal is to determine the
winner with probability at least $1-\delta$. The margin of victory of an
election is the smallest number of votes that need to be modified in order to
change the election winner. We show interesting lower and upper bounds on the
number of samples needed to solve the $(\epsilon, \delta)$-winner determination
problem for many common voting rules, including scoring rules, approval,
maximin, Copeland, Bucklin, plurality with runoff, and single transferable
vote. Moreover, the lower and upper bounds match for many common voting rules
in a wide range of practically appealing scenarios.",1502.04354v3,cs.DS,2015-02-15 19:54:47+00:00,"[arxiv.Result.Author('Arnab Bhattacharyya'), arxiv.Result.Author('Palash Dey')]",
372,A First Approach to Risk-Limiting Audits for Single Transferable Vote Elections,"Risk-limiting audits (RLAs) are an increasingly important method for checking
that the reported outcome of an election is, in fact, correct. Indeed, their
use is increasingly being legislated. While effective methods for RLAs have
been developed for many forms of election -- for example: first-past-the-post,
instant-runoff voting, and D'Hondt elections -- auditing methods for single
transferable vote (STV) elections have yet to be developed. STV elections are
notoriously hard to reason about since there is a complex interaction of votes
that change their value throughout the process. In this paper we present the
first approach to risk-limiting audits for STV elections, restricted to the
case of 2-seat STV elections.",2112.09921v1,cs.CY,2021-12-18 12:36:39+00:00,"[arxiv.Result.Author('Michelle Blom'), arxiv.Result.Author('Peter J. Stuckey'), arxiv.Result.Author('Vanessa Teague'), arxiv.Result.Author('Damjan Vukcevic')]",
373,The method of Eneström and Phragmén for parliamentary elections by means of approval voting,"We study a method for proportional representation that was proposed at the
turn from the nineteenth to the twentieth century by Gustav Enestr\""om and
Edvard Phragm\'en. Like Phragm\'en's better-known iterative minimax method, it
is assumed that the voters express themselves by means of approval voting. In
contrast to the iterative minimax method, however, here one starts by fixing a
quota, i.e. the number of votes that give the right to a seat. As a matter of
fact, the method of Enestr\""om and Phragm\'en can be seen as an extension of
the method of largest remainders from closed lists to open lists, or also as an
adaptation of the single transferable vote to approval rather than preferential
voting. The properties of this method are studied and compared with those of
other methods of the same kind.",1907.10590v1,econ.TH,2019-07-23 08:59:31+00:00,"[arxiv.Result.Author('Rosa Camps'), arxiv.Result.Author('Xavier Mora'), arxiv.Result.Author('Laia Saumell')]",
374,Obvious Independence of Clones,"The Independence of Clones (IoC) criterion for social choice functions
(voting rules) measures a function's robustness to strategic nomination.
However, prior literature has established empirically that individuals cannot
always recognize whether or not a mechanism is strategy-proof and may still
submit costly, distortionary misreports even in strategy-proof settings. The
intersection of these issues motivates the search for mechanisms which are
Obviously Independent of Clones (OIoC): where strategic nomination or strategic
exiting of clones obviously have no effect on the outcome of the election. We
examine three IoC ranked-choice voting mechanisms and the pre-existing proofs
that they are independent of clones: Single Transferable Vote (STV), Ranked
Pairs, and the Schulze method. We construct a formal definition of a voting
system being Obviously Independent of Clones based on a reduction to a clocked
election by considering a bounded agent. Finally, we show that STV and Ranked
Pairs are OIoC, whereas we prove an impossibility result for the Schulze method
showing that this voting system is not OIoC.",2210.04880v1,cs.GT,2022-10-10 17:52:28+00:00,"[arxiv.Result.Author('Ratip Emin Berker'), arxiv.Result.Author('Sílvia Casacuberta'), arxiv.Result.Author('Christopher Ong'), arxiv.Result.Author('Isaac Robinson')]",
375,Eliminating the Weakest Link: Making Manipulation Intractable?,"Successive elimination of candidates is often a route to making manipulation
intractable to compute. We prove that eliminating candidates does not
necessarily increase the computational complexity of manipulation. However, for
many voting rules used in practice, the computational complexity increases. For
example, it is already known that it is NP-hard to compute how a single voter
can manipulate the result of single transferable voting (the elimination
version of plurality voting). We show here that it is NP-hard to compute how a
single voter can manipulate the result of the elimination version of veto
voting, of the closely related Coombs' rule, and of the elimination versions of
a general class of scoring rules.",1204.3918v1,cs.AI,2012-04-17 21:08:39+00:00,"[arxiv.Result.Author('Jessica Davies'), arxiv.Result.Author('Nina Narodytska'), arxiv.Result.Author('Toby Walsh')]",
376,On the Manipulability of Voting Systems: Application to Multi-Carrier Networks,"Today, Internet involves many actors who are making revenues on it
(operators, companies, service providers,...). It is therefore important to be
able to make fair decisions in this large-scale and highly competitive
economical ecosystem. One of the main issues is to prevent actors from
manipulating the natural outcome of the decision process. For that purpose,
game theory is a natural framework. In that context, voting systems represent
an interesting alternative that, to our knowledge, has not yet been considered.
They allow competing entities to decide among different options. Strong
theoretical results showed that all voting systems are susceptible to be
manipulated by one single voter, except for some ""degenerated"" and
non-acceptable cases. However, very little is known about how much a voting
system is manipulable in practical scenarios. In this paper, we investigate
empirically the use of voting systems for choosing end-to-end paths in
multi-carrier networks, analyzing their manipulability and their economical
efficiency. We show that one particular system, called \Single Transferable
Vote (STV), is largely more resistant to manipulability than the natural system
which tries to get the economical optimum. Moreover, STV manages to select
paths close to the economical optimum, whether the participants try to cheat or
not.",1204.6455v1,cs.NI,2012-04-29 05:30:06+00:00,"[arxiv.Result.Author('François Durand'), arxiv.Result.Author('Fabien Mathieu'), arxiv.Result.Author('Ludovic Noirie')]",N&deg; 2012-04-001 (2012)
377,Towards Computing Victory Margins in STV Elections,"The Single Transferable Vote (STV) is a system of preferential voting
employed in multi-seat elections. Each vote cast by a voter is a (potentially
partial) ranking over a set of candidates. No techniques currently exist for
computing the margin of victory (MOV) in STV elections. The MOV is the smallest
number of vote manipulations (changes, additions, and deletions) required to
bring about a change in the set of elected candidates. Knowledge of the MOV of
an election gives greater insight into both how much time and money should be
spent on the auditing of the election, and whether uncovered mistakes (such as
ballot box losses) throw the election result into doubt---requiring a costly
repeat election---or can be safely ignored. In this paper, we present
algorithms for computing lower and upper bounds on the MOV in STV elections. In
small instances, these algorithms are able to compute exact margins.",1703.03511v2,cs.GT,2017-03-10 01:47:23+00:00,"[arxiv.Result.Author('Michelle Blom'), arxiv.Result.Author('Peter J. Stuckey'), arxiv.Result.Author('Vanessa J. Teague')]",
378,The Expanding Approvals Rule: Improving Proportional Representation and Monotonicity,"Proportional representation (PR) is often discussed in voting settings as a
major desideratum. For the past century or so, it is common both in practice
and in the academic literature to jump to single transferable vote (STV) as the
solution for achieving PR. Some of the most prominent electoral reform
movements around the globe are pushing for the adoption of STV. It has been
termed a major open problem to design a voting rule that satisfies the same PR
properties as STV and better monotonicity properties. In this paper, we first
present a taxonomy of proportional representation axioms for general weak order
preferences, some of which generalise and strengthen previously introduced
concepts. We then present a rule called Expanding Approvals Rule (EAR) that
satisfies properties stronger than the central PR axiom satisfied by STV, can
handle indifferences in a convenient and computationally efficient manner, and
also satisfies better candidate monotonicity properties. In view of this, our
proposed rule seems to be a compelling solution for achieving proportional
representation in voting settings.",1708.07580v2,cs.GT,2017-08-25 00:10:43+00:00,"[arxiv.Result.Author('Haris Aziz'), arxiv.Result.Author('Barton Lee')]",
379,Auditing Ranked Voting Elections with Dirichlet-Tree Models: First Steps,"Ranked voting systems, such as instant-runoff voting (IRV) and single
transferable vote (STV), are used in many places around the world. They are
more complex than plurality and scoring rules, presenting a challenge for
auditing their outcomes: there is no known risk-limiting audit (RLA) method for
STV other than a full hand count.
  We present a new approach to auditing ranked systems that uses a statistical
model, a Dirichlet-tree, that can cope with high-dimensional parameters in a
computationally efficient manner. We demonstrate this approach with a
ballot-polling Bayesian audit for IRV elections. Although the technique is not
known to be risk-limiting, we suggest some strategies that might allow it to be
calibrated to limit risk.",2206.14605v2,stat.AP,2022-06-29 13:06:42+00:00,"[arxiv.Result.Author('Floyd Everest'), arxiv.Result.Author('Michelle Blom'), arxiv.Result.Author('Philip B. Stark'), arxiv.Result.Author('Peter J. Stuckey'), arxiv.Result.Author('Vanessa Teague'), arxiv.Result.Author('Damjan Vukcevic')]","E-Vote-ID 2022, Conference Proceedings, UT Press, pages 76-80"
380,Semantic properties of English nominal pluralization: Insights from word embeddings,"Semantic differentiation of nominal pluralization is grammaticalized in many
languages. For example, plural markers may only be relevant for human nouns.
English does not appear to make such distinctions. Using distributional
semantics, we show that English nominal pluralization exhibits semantic
clusters. For instance, pluralization of fruit words is more similar to one
another and less similar to pluralization of other semantic classes. Therefore,
reduction of the meaning shift in plural formation to the addition of an
abstract plural meaning is too simplistic. A semantically informed method,
called CosClassAvg, is introduced that outperforms pluralization methods in
distributional semantics which assume plural formation amounts to the addition
of a fixed plural vector. In comparison with our approach, a method from
compositional distributional semantics, called FRACSS, predicted plural vectors
that were more similar to the corpus-extracted plural vectors in terms of
direction but not vector length. A modeling study reveals that the observed
difference between the two predicted semantic spaces by CosClassAvg and FRACSS
carries over to how well a computational model of the listener can understand
previously unencountered plural forms. Mappings from word forms, represented
with triphone vectors, to predicted semantic vectors are more productive when
CosClassAvg-generated semantic vectors are employed as gold standard vectors
instead of FRACSS-generated vectors.",2203.15424v1,cs.CL,2022-03-29 10:42:47+00:00,"[arxiv.Result.Author('Elnaz Shafaei-Bajestan'), arxiv.Result.Author('Masoumeh Moradipour-Tari'), arxiv.Result.Author('Peter Uhrig'), arxiv.Result.Author('R. Harald Baayen')]",
381,We belong together? A plea for modesty in modal plural logic,A sceptical examination of the motivations for strong modal plural logics.,1612.08424v1,math.LO,2016-12-26 18:44:05+00:00,[arxiv.Result.Author('Simon Hewitt')],
382,Making sense of spoken plurals,"Distributional semantics offers new ways to study the semantics of
morphology. This study focuses on the semantics of noun singulars and their
plural inflectional variants in English. Our goal is to compare two models for
the conceptualization of plurality. One model (FRACSS) proposes that all
singular-plural pairs should be taken into account when predicting plural
semantics from singular semantics. The other model (CCA) argues that
conceptualization for plurality depends primarily on the semantic class of the
base word. We compare the two models on the basis of how well the speech signal
of plural tokens in a large corpus of spoken American English aligns with the
semantic vectors predicted by the two models. Two measures are employed: the
performance of a form-to-meaning mapping and the correlations between form
distances and meaning distances. Results converge on a superior alignment for
CCA. Our results suggest that usage-based approaches to pluralization in which
a given word's own semantic neighborhood is given priority outperform theories
according to which pluralization is conceptualized as a process building on
high-level abstraction. We see that what has often been conceived of as a
highly abstract concept, [+plural], is better captured via a family of
mid-level partial generalizations.",2207.01947v1,cs.CL,2022-07-05 10:44:26+00:00,"[arxiv.Result.Author('Elnaz Shafaei-Bajestan'), arxiv.Result.Author('Peter Uhrig'), arxiv.Result.Author('R. Harald Baayen')]",
383,Finding non-minority balls with majority and plurality queries,"Given a set of $n$ colored balls, a \textit{majority, non-minority or
plurality ball} is one whose color class has size more than $n/2$, at least
$n/2$ or larger than any other color class, respectively. We describe linear
time algorithms for finding non-minority balls using query sets of size $q$ of
the following form: the answer to a majority/plurality query $Q$ is a
majority/plurality ball in $Q$ or the statement that there is no such ball in
$Q$.",1812.08850v1,math.CO,2018-12-20 21:22:49+00:00,"[arxiv.Result.Author('Huilan Chang'), arxiv.Result.Author('Dániel Gerbner'), arxiv.Result.Author('Balázs Patkós')]",
384,Consensus Formation in Multi-state Majority and Plurality Models,"We study consensus formation in interacting systems that evolve by
multi-state majority rule and by plurality rule. In an update event, a group of
G agents (with G odd), each endowed with an s-state spin variable, is
specified. For majority rule, all group members adopt the local majority state;
for plurality rule the group adopts the local plurality state. This update is
repeated until a final consensus state is generally reached. In the mean field
limit, the consensus time for an N-spin system increases as ln N for both
majority and plurality rule, with an amplitude that depends on s and G. For
finite spatial dimensions, domains undergo diffusive coarsening in majority
rule when s or G is small. For larger s and G, opinions spread ballistically
from the few groups with an initial local majority. For plurality rule, there
is always diffusive domain coarsening toward consensus.",cond-mat/0506068v2,cond-mat.stat-mech,2005-06-02 21:57:23+00:00,"[arxiv.Result.Author('P. Chen'), arxiv.Result.Author('S. Redner')]","J. Phy. A 38, 7239-7252 (2005)."
385,Graphs of Plural Cuts,"Plural (or multiple-conclusion) cuts are inferences made by applying a
structural rule introduced by Gentzen for his sequent formulation of classical
logic. As singular (single-conclusion) cuts yield trees, which underlie
ordinary natural deduction derivations, so plural cuts yield graphs of a more
complicated kind, related to trees, which this paper defines. Besides the
inductive definition of these oriented graphs, which is based on sequent
systems, a non-inductive, graph-theoretical, combinatorial, definition is
given, and to reach that other definition is the main goal of the paper. As
trees underlie multicategories, so the graphs of plural cuts underlie
polycategories. The graphs of plural cuts are interesting in particular when
the plural cuts are appropriate for sequent systems without the structural rule
of permutation, and the main body of the paper deals with that matter. It gives
a combinatorial characterization of the planarity of the graphs involved.",1104.4064v7,math.LO,2011-04-20 16:06:36+00:00,"[arxiv.Result.Author('K. Dosen'), arxiv.Result.Author('Z. Petric')]",
386,On the Necessary Memory to Compute the Plurality in Multi-Agent Systems,"We consider the Relative-Majority Problem (also known as Plurality), in
which, given a multi-agent system where each agent is initially provided an
input value out of a set of $k$ possible ones, each agent is required to
eventually compute the input value with the highest frequency in the initial
configuration. We consider the problem in the general Population Protocols
model in which, given an underlying undirected connected graph whose nodes
represent the agents, edges are selected by a globally fair scheduler.
  The state complexity that is required for solving the Plurality Problem
(i.e., the minimum number of memory states that each agent needs to have in
order to solve the problem), has been a long-standing open problem. The best
protocol so far for the general multi-valued case requires polynomial memory:
Salehkaleybar et al. (2015) devised a protocol that solves the problem by
employing $O(k 2^k)$ states per agent, and they conjectured their upper bound
to be optimal. On the other hand, under the strong assumption that agents
initially agree on a total ordering of the initial input values, Gasieniec et
al. (2017), provided an elegant logarithmic-memory plurality protocol.
  In this work, we refute Salehkaleybar et al.'s conjecture, by providing a
plurality protocol which employs $O(k^{11})$ states per agent. Central to our
result is an ordering protocol which allows to leverage on the plurality
protocol by Gasieniec et al., of independent interest. We also provide a
$\Omega(k^2)$-state lower bound on the necessary memory to solve the problem,
proving that the Plurality Problem cannot be solved within the mere memory
necessary to encode the output.",1901.06549v1,cs.DC,2019-01-19 16:25:55+00:00,"[arxiv.Result.Author('Emanuele Natale'), arxiv.Result.Author('Iliad Ramezani')]",
387,Hybrid Pluralism,"Intuitively, a pluralist solution is one in which a single question receives
multiple answers. Such pluralist solutions have been proposed in many widely
disparate contexts. This paper restates the concept of pluralism with greater
precision; distinguishes it from, and establishes its independence of, some
other notions with which it is frequently confused; and briefly lays out some
of the benefits that this more nuanced approach to pluralism may yield for the
debates in which it may be invoked.",math/0505034v1,math.LO,2005-05-02 21:13:38+00:00,[arxiv.Result.Author('Andrew Aberdein')],
388,Poisson-Lie T-plurality revisited. Is T-duality unique?,"We investigate (non-)Abelian T-duality from the perspective of Poisson-Lie
T-plurality. We show that sigma models related by duality/plurality are given
not only by Manin triples obtained from decompositions of Drinfel'd double, but
also by their particular embeddings, i.e. maps that relate bases of these
decompositions. This allows us to get richer set of dual or plural sigma models
than previously thought. That's why we ask how T-duality is defined and what
should be the `canonical' duality or plurality transformation.",1811.12235v3,hep-th,2018-11-29 15:11:15+00:00,"[arxiv.Result.Author('Ladislav Hlavaty'), arxiv.Result.Author('Ivo Petr')]",High Energ. Phys. (2019) 2019: 157
389,T-folds as Poisson-Lie plurals,"In previous papers we have presented many purely bosonic solutions of
Generalized Supergravity Equations obtained by Poisson-Lie T-duality and
plurality of flat and Bianchi cosmologies. In this paper we focus on their
compactifications and identify solutions that can be interpreted as T-folds. To
recognize T-folds we adopt the language of Double Field Theory and discuss how
Poisson-Lie T-duality/plurality fits into this framework. As a special case we
confirm that all non-Abelian T-duals can be compactified as T-folds.",2004.08387v3,hep-th,2020-04-17 10:26:17+00:00,"[arxiv.Result.Author('Ladislav Hlavatý'), arxiv.Result.Author('Ivo Petr')]","Eur. Phys. J. C 80, 892 (2020)"
390,Who is we? Disambiguating the referents of first person plural pronouns in parliamentary debates,"This paper investigates the use of first person plural pronouns as a
rhetorical device in political speeches. We present an annotation schema for
disambiguating pronoun references and use our schema to create an annotated
corpus of debates from the German Bundestag. We then use our corpus to learn to
automatically resolve pronoun referents in parliamentary debates. We explore
the use of data augmentation with weak supervision to further expand our corpus
and report preliminary results.",2205.14182v1,cs.CL,2022-05-27 18:18:04+00:00,"[arxiv.Result.Author('Ines Rehbein'), arxiv.Result.Author('Josef Ruppenhofer'), arxiv.Result.Author('Julian Bernauer')]",
391,Analysis of the Arabic Broken Plural and Diminutive,"This paper demonstrates how the challenging problem of the Arabic broken
plural and diminutive can be handled under a multi-tape two-level model, an
extension to two-level morphology.",cmp-lg/9512001v1,cmp-lg,1995-12-09 14:15:02+00:00,[arxiv.Result.Author('George A. Kiraz')],
392,Computations of volumes in five candidates elections,"We describe several analytical results obtained in five candidates social
choice elections under the assumption of the Impartial Anonymous Culture. These
include the Condorcet and Borda paradoxes, as well as the Condorcet efficiency
of plurality, negative plurality and Borda voting, including their runoff
versions. The computations are done by Normaliz. It finds precise probabilities
as volumes of polytopes in dimension 119, using its recent implementation of
the Lawrence algorithm.",2109.00473v1,math.CO,2021-09-01 16:26:59+00:00,"[arxiv.Result.Author('Winfried Bruns'), arxiv.Result.Author('Bogdan Ichim')]",
393,Electoral Competition under Best-Worst Voting Rules,"We characterise multi-candidate pure-strategy equilibria in the
Hotelling-Downs spatial election model for the class of best-worst voting
rules, in which each voter is endowed with both a positive and a negative vote,
i.e., each voter can vote in favour of one candidate and against another one.
The weights attached to positive and negative votes in calculating a
candidate's net score may be different, so that a negative vote and a positive
vote need not cancel out exactly. These rules combine the first-place seeking
incentives of plurality with the incentives to avoid being ranked last of
anti-plurality. We show that these rules generally admit equilibria, which are
nonconvergent if and only if the importance of a positive vote exceeds that of
a negative vote. The set of equilibria in the latter case is very similar to
that of plurality, except that the platforms are less extreme due to the
moderating effect of negative votes. Moreover, any degree of dispersion between
plurality, at one extreme, and full convergence, at the other, can be attained
for the correct choice of the weights.",1610.02787v1,cs.GT,2016-10-10 07:12:59+00:00,"[arxiv.Result.Author('Dodge Cahan'), arxiv.Result.Author('Arkadii Slinko')]",
394,A plurality problem with three colors and query size three,"The Plurality problem - introduced by Aigner \cite{A2004} - has many
variants. In this article we deal with the following version: suppose we are
given $n$ balls, each of them colored by one of three colors. A
\textit{plurality ball} is one such that its color class is strictly larger
than any other color class. Questioner wants to find a plurality ball as soon
as possible or state there is no, by asking triplets (or $k$-sets, in general),
while Adversary partition the triplets into color classes as an answer for the
queries and wants to postpone the possibility of determining a plurality ball
(or stating there is no).
  We denote by $A_p(n,3)$ the largest number of queries needed to ask if both
play optimally (and Questioner asks triplets). We provide an almost precise
result in case of even $n$ by proving that for $n \ge 4$ even we have
$$\frac{3}{4}n-2 \le A_p(n,3) \le \frac{3}{4}n-\frac{1}{2},$$ and for $n \ge 3$
odd we have $$\frac{3}{4}n-O(\log n) \le A_p(n,3) \le
\frac{3}{4}n-\frac{1}{2}.$$
  We also prove some bounds on the number of queries needed to ask for larger
$k$.",1708.05864v1,math.CO,2017-08-19 15:37:34+00:00,"[arxiv.Result.Author('Dániel Gerbner'), arxiv.Result.Author('Dániel Lenger'), arxiv.Result.Author('Máté Vizer')]",
395,Range results for some social choice correspondences,"Determination of the range of a variety of social choice correspondences:
Plurality voting, the Borda rule, the Pareto rule, the Copeland correspondence,
approval voting, and the top cycle correspondence",1712.09629v1,math.CO,2017-12-27 16:58:57+00:00,[arxiv.Result.Author('Jerry S. Kelly')],
396,Poisson-Lie plurals of Bianchi cosmologies and Generalized Supergravity Equations,"Poisson-Lie T-duality and plurality are important solution generating
techniques in string theory and (generalized) supergravity. Since
duality/plurality does not preserve conformal invariance, the usual beta
function equations are replaced by Generalized Supergravity Equations
containing vector $\mathcal{J}$. In this paper we apply Poisson-Lie T-plurality
on Bianchi cosmologies. We present a formula for the vector $\mathcal{J}$ as
well as transformation rule for dilaton, and show that plural backgrounds
together with this dilaton and $\mathcal{J}$ satisfy the Generalized
Supergravity Equations. The procedure is valid also for non-local dilaton and
non-constant $\mathcal{J}$. We also show that $Div\,\Theta$ of the
non-commutative structure $\Theta$ used for non-Abelian T-duality or integrable
deformations does not give correct $\mathcal{J}$ for Poisson-Lie T-plurality.",1910.08436v3,hep-th,2019-10-18 14:29:31+00:00,"[arxiv.Result.Author('Ladislav Hlavatý'), arxiv.Result.Author('Ivo Petr')]",
397,Inflecting when there's no majority: Limitations of encoder-decoder neural networks as cognitive models for German plurals,"Can artificial neural networks learn to represent inflectional morphology and
generalize to new words as human speakers do? Kirov and Cotterell (2018) argue
that the answer is yes: modern Encoder-Decoder (ED) architectures learn
human-like behavior when inflecting English verbs, such as extending the
regular past tense form -(e)d to novel words. However, their work does not
address the criticism raised by Marcus et al. (1995): that neural models may
learn to extend not the regular, but the most frequent class -- and thus fail
on tasks like German number inflection, where infrequent suffixes like -s can
still be productively generalized.
  To investigate this question, we first collect a new dataset from German
speakers (production and ratings of plural forms for novel nouns) that is
designed to avoid sources of information unavailable to the ED model. The
speaker data show high variability, and two suffixes evince 'regular' behavior,
appearing more often with phonologically atypical inputs. Encoder-decoder
models do generalize the most frequently produced plural class, but do not show
human-like variability or 'regular' extension of these other plural markers. We
conclude that modern neural models may still struggle with minority-class
generalization.",2005.08826v1,cs.CL,2020-05-18 15:58:28+00:00,"[arxiv.Result.Author('Kate McCurdy'), arxiv.Result.Author('Sharon Goldwater'), arxiv.Result.Author('Adam Lopez')]",
398,Evaluating the Properties of a First Choice Weighted Approval Voting System,"Plurality and approval voting are two well-known voting systems with
different strengths and weaknesses. In this paper we consider a new voting
system we call beta(k) which allows voters to select a single first-choice
candidate and approve of any other number of candidates, where k denotes the
relative weight given to a first choice; this system is essentially a hybrid of
plurality and approval. Our primary goal is to characterize the behavior of
beta(k) for any value of k. Under certain reasonable assumptions, beta(k) can
be made to mimic plurality or approval voting in the event of a single winner
while potentially breaking ties otherwise. Under the assumption that voters are
honest, we show that it is possible to find the values of k for which a given
candidate will win the election if the respective approval and plurality votes
are known. Finally, we show how some of the commonly used voting system
criteria are satisfied by beta(k).",2006.00368v1,econ.TH,2020-05-30 21:12:52+00:00,"[arxiv.Result.Author('Peter Butler'), arxiv.Result.Author('Jerry Lin')]",
399,Noise Stability of Ranked Choice Voting,"We conjecture that Borda count is the ranked choice voting method that best
preserves the outcome of an election with randomly corrupted votes, among all
fair voting methods with small influences satisfying the Condorcet Loser
Criterion. This conjecture is an adaptation of the Plurality is Stablest
Conjecture to the setting of ranked choice voting. Since the plurality function
does not satisfy the Condorcet Loser Criterion, our new conjecture is not
directly related to the Plurality is Stablest Conjecture. Nevertheless, we show
that the Plurality is Stablest Conjecture implies our new Borda count is
Stablest conjecture. We therefore deduce that Borda count is stablest for
elections with three candidates when the corrupted votes are nearly
uncorrelated with the original votes. We also adapt a dimension reduction
argument to this setting, showing that the optimal ranked choice voting method
is ""low-dimensional.""
  The Condorcet Loser Criterion asserts that a candidate must lose an election
if each other candidate is preferred in head-to-head comparisons. Lastly, we
discuss a variant of our conjecture with the Condorcet Winner Criterion as a
constraint instead of the Condorcet Loser Criterion. In this case, we have no
guess for the most stable ranked choice voting method.",2209.11183v1,cs.GT,2022-09-22 17:29:58+00:00,[arxiv.Result.Author('Steven Heilman')],
400,Bifurcation of Solutions to the Allen-Cahn Equation,"We use Morse Homology to study bifurcation of the solution sets of the
Allen-Cahn Equation.",1311.2307v1,math.AP,2013-11-10 21:29:35+00:00,[arxiv.Result.Author('Graham Smith')],
401,Operads and Algebraic Homotopy II. Suspensions,"This paper extends the results of ""Operads and Algebraic Homotopy"" in giving
algebraic invariants for the stable homotopy type of a pointed simply-connected
simplicial set.",math/0102069v1,math.AT,2001-02-08 15:17:09+00:00,[arxiv.Result.Author('Justin R. Smith')],
402,Boundary Nevanlinna-Pick interpolation for generalized Nevanlinna functions,"We formulate three boundary Nevanlinna-Pick interpolation problems for
generalized Nevanlinna functions. For each problem, we parameterize the set of
all solutions in terms of a linear fractional transformation with an extended
Nevanlinna class parameter.",math/0609653v1,math.CV,2006-09-22 20:42:04+00:00,[arxiv.Result.Author('Paul Anthony Smith')],
403,A note on fragmentability and weak-G_delta sets,"In terms of fragmentability, we describe a new class of Banach spaces which
do not contain weak-G_delta open bounded subsets. In particular, none of these
spaces is isomorphic to a separable polyhedral space.",0812.4690v1,math.FA,2008-12-26 16:09:44+00:00,"[arxiv.Result.Author('V. P. Fonf'), arxiv.Result.Author('R. J. Smith'), arxiv.Result.Author('S. Troyanski')]",
404,Polytope Bounds on Multivariate Value Sets,"We improve upon the upper bounds for the cardinality of the value set of a
multivariable polynomial map over a finite field using the polytope of the
polynomial. This generalizes earlier bounds only dependent on the degree of a
polynomial.",1310.2958v2,math.NT,2013-10-10 20:29:24+00:00,[arxiv.Result.Author('Luke Smith')],Finite Fields and Their Applications 28 (2014) 132-139
405,"Topology, isomorphic smoothness and polyhedrality in Banach spaces","In recent decades, topology has come to play an increasing role in some
geometric aspects of Banach space theory. The class of so-called $w^*$-locally
relatively compact sets was introduced recently by Fonf, Pallares, Troyanski
and the author, and were found to be a useful topological tool in the theory of
isomorphic smoothness and polyhedrality in Banach spaces. We develop the
topological theory of these sets and present some Banach space applications.",1804.02899v1,math.FA,2018-04-09 10:25:07+00:00,[arxiv.Result.Author('Richard J. Smith')],
406,Fixed Point Sets and the Fundamental Group I: Semi-free Actions on G-CW-Complexes,"Smith theory says that the fixed point of a semi-free action of a group $G$
on a contractible space is ${\bb Z}_p$-acyclic for any prime factor $p$ of $G$.
Jones proved the converse of Smith theory for the case $G$ is a cyclic group
acting on finite CW-complexes. We extend the theory to semi-free group action
on finite CW-complexes of given homotopy type, in various settings. In
particular, the converse of Smith theory holds if and only if certain
$K$-theoretical obstruction vanishes. We also give some examples that show the
effects of different types of the $K$-theoretical obstruction.",2010.14987v2,math.AT,2020-10-28 13:55:21+00:00,"[arxiv.Result.Author('Sylvain Cappell'), arxiv.Result.Author('Shmuel Weinberger'), arxiv.Result.Author('Min Yan')]",
407,A Spectral Enabled GAN for Time Series Data Generation,"Time dependent data is a main source of information in today's data driven
world. Generating this type of data though has shown its challenges and made it
an interesting research area in the field of generative machine learning. One
such approach was that by Smith et al. who developed Time Series Generative
Adversarial Network (TSGAN) which showed promising performance in generating
time dependent data and the ability of few shot generation though being flawed
in certain aspects of training and learning. This paper looks to improve on the
results from TSGAN and address those flaws by unifying the training of the
independent networks in TSGAN and creating a dependency both in training and
learning. This improvement, called unified TSGAN (uTSGAN) was tested and
comapred both quantitatively and qualitatively to its predecessor on 70
benchmark time series data sets used in the community. uTSGAN showed to
outperform TSGAN in 80\% of the data sets by the same number of training epochs
and 60\% of the data sets in 3/4th the amount of training time or less while
maintaining the few shot generation ability with better FID scores across those
data sets.",2103.01904v1,cs.LG,2021-03-02 18:05:43+00:00,"[arxiv.Result.Author('Kaleb E. Smith'), arxiv.Result.Author('Anthony O. Smith')]",
408,The time of bootstrap percolation in two dimensions,"We study the distribution of the percolation time $T$ of two-neighbour
bootstrap percolation on $[n]^2$ with initial set $A\sim\mathrm{Bin}([n]^2,p)$.
We determine $T$ with high probability up to a constant factor for all $p$
above the critical probability for percolation, and to within a $1+o(1)$ factor
for a large range of $p$.",1305.5444v2,math.PR,2013-05-23 15:02:31+00:00,"[arxiv.Result.Author('Paul Balister'), arxiv.Result.Author('Béla Bollobás'), arxiv.Result.Author('Paul Smith')]",
409,An Involution on Involutions and a Generalization of Layered Permutations,"Taking transposes of Standard Young Tableaux defines a natural involution on
the set $I(n)$ of involutions of length $n$ via the the Robinson-Schensted
correspondence. In some cases, this involution can be defined without resorting
to the Robinson-Schensted correspondence. As a byproduct, we get an interesting
generalization of layered permutations.",1605.06158v2,math.CO,2016-05-19 21:55:29+00:00,"[arxiv.Result.Author('Miklos Bona'), arxiv.Result.Author('Rebecca Smith')]",
410,Searching for Dark Matter Annihilation in the Smith High-Velocity Cloud,"Recent observations suggest that some high-velocity clouds may be confined by
massive dark matter halos. In particular, the proximity and proposed dark
matter content of the Smith Cloud make it a tempting target for the indirect
detection of dark matter annihilation. We argue that the Smith Cloud may be a
better target than some Milky Way dwarf spheroidal satellite galaxies and use
gamma-ray observations from the Fermi Large Area Telescope to search for a dark
matter annihilation signal. No significant gamma-ray excess is found coincident
with the Smith Cloud, and we set strong limits on the dark matter annihilation
cross section assuming a spatially-extended dark matter profile consistent with
dynamical modeling of the Smith Cloud. Notably, these limits exclude the
canonical thermal relic cross section ($\sim 3\times10^{-26}{\rm cm}^{3}{\rm
s}^{-1}$) for dark matter masses $\lesssim 30$ GeV annihilating via the $b \bar
b$ or $\tau^{+}\tau^{-}$ channels for certain assumptions of the dark matter
density profile; however, uncertainties in the dark matter content of the Smith
Cloud may significantly weaken these constraints.",1405.1030v2,astro-ph.HE,2014-05-05 20:00:00+00:00,"[arxiv.Result.Author('Alex Drlica-Wagner'), arxiv.Result.Author('German A. Gomez-Vargas'), arxiv.Result.Author('John W. Hewitt'), arxiv.Result.Author('Tim Linden'), arxiv.Result.Author('Luigi Tibaldo')]","ApJ, 790, 24 (2014)"
411,Coarse Geometry and P. A. Smith Theory,"We define a generalization of the fixed point set, called the bounded fixed
set, for a group acting by isometries on a metric space. An analogue of the P.
A. Smith theorem is proved for metric spaces of finite asymptotic dimension,
which relates the coarse homology of the bounded fixed set to the coarse
homology of the total space.",1007.0495v2,math.GT,2010-07-03 13:42:44+00:00,"[arxiv.Result.Author('Ian Hambleton'), arxiv.Result.Author('Lucian Savin')]","Homology Homotopy Appl. 13 (2011), no. 2, 73--102"
412,Virtual resolutions of points in $\mathbb{P}^1 \times \mathbb{P}^1$,"We explore explicit virtual resolutions, as introduced by Berkesch, Erman,
and Smith, for ideals of sets of points in $\mathbb{P}^1 \times \mathbb{P}^1$.
Specifically, we describe a virtual resolution for a sufficiently general set
of points $X$ in $\mathbb{P}^1 \times \mathbb{P}^1$ that only depends on $|X|$.
We also improve an existence result of Berkesch, Erman, and Smith in the
special case of points in $\mathbb{P}^1 \times \mathbb{P}^1$; more precisely,
we give an effective bound for their construction that gives a virtual
resolution of length two for any set of points in $\mathbb{P}^1 \times
\mathbb{P}^1$.",2106.02759v2,math.AC,2021-06-05 00:22:35+00:00,"[arxiv.Result.Author('Megumi Harada'), arxiv.Result.Author('Maryam Nowroozi'), arxiv.Result.Author('Adam Van Tuyl')]",
413,Connectivity and Convexity Properties of the Momentum Map for Group Actions on Hilbert Manifolds,"In the early $1980$s a landmark result was obtained by Atiyah and
independently Guillemin and Sternberg: the image of the momentum map for a
torus action on a compact symplectic manifold is a convex polyhedron. Atiyah's
proof makes use of the fact that level sets of the momentum map are connected.
These proofs work in the setting of finite-dimensional compact symplectic
manifolds. One can ask how these results generalize. A well-known example of an
infinite-dimensional symplectic manifold with a finite-dimensional torus action
is the based loop group. Atiyah and Pressley proved convexity for this example,
but not connectedness of level sets. A proof of connectedness of level sets for
the based loop group was provided by Harada, Holm, Jeffrey and Mare in $2006$.
  In this thesis we study Hilbert manifolds equipped with a strong symplectic
structure and a finite-dimensional group action preserving the strong
symplectic structure. We prove connectedness of regular generic level sets of
the momentum map. We use this to prove convexity of the image of the momentum
map.",1407.4351v1,math.SG,2014-07-15 14:06:06+00:00,[arxiv.Result.Author('Kathleen Smith')],
414,Transition radiation on semi-infinite plate and Smith-Purcell effect,"The Smith-Purcell radiation is usually measured when an electron passes over
the grating of metallic stripes. However, for high frequencies (exceeding the
plasma frequency of the grating material) none material could be treated as a
conductor, but ought to be considered as a dielectric with plasma-like
permittivity. So for describing Smith-Purcell radiation in the range of high
frequencies new theoretical approaches are needed. In the present paper we
apply the simple variant of eikonal approximation developed earlier to the case
of radiation on the set of parallel semi-infinite dielectric plates. The
formulae obtained describe the radiation generated by the particles both
passing through the plates (traditionally referred as ""transition radiation"")
and moving in vacuum over the grating formed by the edges of the plates
(traditionally referred as ""diffraction radiation"", and, taking into account
the periodicity of the plates arrangement, as Smith-Purcell radiation).",1006.4109v1,physics.acc-ph,2010-06-21 16:17:57+00:00,"[arxiv.Result.Author(""N. F. Shul'ga""), arxiv.Result.Author('V. V. Syshchenko')]","J.Phys.Conf.Ser.236:012010,2010"
415,Universality for two-dimensional critical cellular automata,"We study the class of monotone, two-state, deterministic cellular automata,
in which sites are activated (or 'infected') by certain configurations of
nearby infected sites. These models have close connections to statistical
physics, and several specific examples have been extensively studied in recent
years by both mathematicians and physicists. This general setting was first
studied only recently, however, by Bollob\'as, Smith and Uzzell, who showed
that the family of all such 'bootstrap percolation' models on $\mathbb{Z}^2$
can be naturally partitioned into three classes, which they termed subcritical,
critical and supercritical.
  In this paper we determine the order of the threshold for percolation
(complete occupation) for every critical bootstrap percolation model in two
dimensions. This 'universality' theorem includes as special cases results of
Aizenman and Lebowitz, Gravner and Griffeath, Mountford, and van Enter and
Hulshof, significantly strengthens bounds of Bollob\'as, Smith and Uzzell, and
complements recent work of Balister, Bollob\'as, Przykucki and Smith on
subcritical models.",1406.6680v5,math.PR,2014-06-25 19:58:00+00:00,"[arxiv.Result.Author('Béla Bollobás'), arxiv.Result.Author('Hugo Duminil-Copin'), arxiv.Result.Author('Robert Morris'), arxiv.Result.Author('Paul Smith')]",
416,Fractional order [PI] Controller and Smith-like Predictor Design for A Class of High Order Systems,"To handle the control difficulties caused by high-order dynamics, a control
structure based on fractional order [proportional integral] (PI) controller and
fractional order Smith-like predictor for a class of high order systems in the
type of K/(Ts+1)n is proposed in this paper. The analysis of the tracking and
disturbance rejection is illustrated based on the terminal value theorem and
shows that the proposed control structure can ensure that the closed-loop
system converges to the set point without static error and the closed-loop
system recovers to its original state when the input disturbance occurs. Then,
simulations about the influence on the control performance and control signal
with different are carried out based on multi-objective genetic algorithm
(MO-GA). The results show that the control performance can be improved and the
energy of the control signal can be reduced simultaneously when the order is
chosen no more than one. This can verify that the fractional order Smith-like
predictor with has an advantage over that of the integral order Smith-like
predictor.",1904.07907v1,cs.SY,2019-04-16 18:15:52+00:00,"[arxiv.Result.Author('Zhenlong Wu'), arxiv.Result.Author('Jie Yuan'), arxiv.Result.Author('Yuquan Chen'), arxiv.Result.Author('Donghai Li'), arxiv.Result.Author('YangQuan Chen')]",
417,Geometric renormalization below the ground state,"The caloric gauge was introduced by Tao with studying large data energy
critical wave maps mapping from $\mathbf{R}^{2+1}$ to hyperbolic space
$\mathbf{H}^m$ in view. In \cite{BIKT} Bejenaru, Ionescu, Kenig, and Tataru
adapted the caloric gauge to the setting of Schr\""odinger maps from
$\mathbf{R}^{d + 1}$ to the standard sphere $S^2 \hookrightarrow \mathbf{R}^3$
with initial data small in the critical Sobolev norm. Here we develop the
caloric gauge in a bounded geometry setting with a construction valid up to the
ground state energy.",1009.6227v2,math.AP,2010-09-30 19:38:20+00:00,[arxiv.Result.Author('Paul Smith')],
418,Cellular coalgebras over the Barratt-Eccles operad I,"This paper considers a class of coalgebras over the Barratt-Eccles operad and
shows that they classify Z-completions of pointed, reduced simplicial sets. As
a consequence, they encapsulate the homotopy types of nilpotent simplicial
sets. This result is a direct generalization of Quillen's result characterizing
rational homotopy types via cocommutative coalgebras.",1304.6328v4,math.AT,2013-04-23 15:41:59+00:00,[arxiv.Result.Author('Justin R. Smith')],
419,Steenrod coalgebras III. The fundamental group,"In this note, we extend earlier work by showing that if $X$ and $Y$ are
delta-complexes (i.e. simplicial sets without degeneracy operators), a morphism
$g:N(X)\to N(Y)$ of Steenrod coalgebras (normalized chain-complexes equipped
with extra structure) induces one of 2-skeleta $\hat{g}:X_{2}\to Y_{2}$,
inducing a homomorphism $\pi_{1}(\hat{g}):\pi_{1}(X)\to\pi_{1}(Y)$ that is an
isomorphism if $g$ is an isomorphism. This implies a corresponding conclusion
for a morphism $g:C(X)\to C(Y)$ of Steenrod coalgebras on unnormalized
chain-complexes of simplicial sets.",1403.1973v1,math.AT,2014-03-08 14:56:14+00:00,[arxiv.Result.Author('Justin R. Smith')],
420,Some methods of estimating uncertainty in accident reconstruction,"In the paper four methods for estimating uncertainty in accident
reconstruction are discussed: total differential method, extreme values method,
Gauss statistical method, and Monte Carlo simulation method. The methods are
described and the program solutions are given.",1107.3742v2,physics.gen-ph,2011-07-19 15:25:57+00:00,[arxiv.Result.Author('Milan Batista')],
421,New simultaneous methods for finding all zeros of a polynomial,"The purpose of this paper is to present three new methods for finding all
simple zeros of polynomials simultaneously. First, we give a new method for
finding simultaneously all simple zeros of polynomials constructed by applying
the Weierstrass method to the zero in the trapezoidal Newton's method, and
prove the convergence of the method. We also present two modified Newton's
methods combined with the derivative-free method, which are constructed by
applying the derivative-free method to the zero in the trapezoidal Newton's
method and the midpoint Newton's method, respectively. Finally, we give a
numerical comparison between various simultaneous methods for finding zeros of
a polynomial.",1501.05033v1,math.NA,2015-01-21 02:10:04+00:00,[arxiv.Result.Author('Jun-Seop Song')],"Journal of Mathematical Sciences: Advances and Applications 33
  (2015) 5-18"
422,Counting methods introduced into the bibliometric research literature 1970-2018: A review,"The present review of bibliometric counting methods investigates 1) the
number of unique counting methods in the bibliometric research literature, 2)
to what extent the counting methods can be categorized according to selected
characteristics of the counting methods, 3) methods and elements to assess the
internal validity of the counting methods, and 4) to what extent and with which
characteristics the counting methods are used in research evaluations.
  The review identifies 32 counting methods introduced during the period 1981 -
2018. Two frameworks categorize these counting methods. Framework 1 describes
selected mathematical properties of counting methods, and Framework 2 describes
arguments for choosing a counting method. Twenty of the 32 counting methods are
rank-dependent, fractionalized, and introduced to measure contribution,
participation, etc. of an object of study. Next, three criteria for internal
validity are used to identify five methods that test the adequacy of counting
methods, two elements that test sensitivity, and three elements that test
homogeneity of the counting methods. These methods and elements may be used to
assess the internal validity of counting methods. Finally, a literature search
finds research evaluations that use the counting methods. Only three of the 32
counting methods are used by four research evaluations or more. Of these three
counting methods, two are used with the same characteristics as defined in the
studies that introduced the counting methods.
  The review provides practitioners in research evaluation and researchers in
bibliometrics with a detailed foundation for working with counting methods. At
the same time, many of the findings in the review provide bases for future
investigations of counting methods.",2012.04986v1,cs.DL,2020-12-09 11:29:35+00:00,[arxiv.Result.Author('Marianne Gauffriau')],
423,Numerical Methods for the Stray-Field Calculation: A Comparison of recently developed Algorithms,"Different numerical approaches for the stray-field calculation in the context
of micromagnetic simulations are investigated. We compare finite difference
based fast Fourier transform methods, tensor grid methods and the
finite-element method with shell transformation in terms of computational
complexity, storage requirements and accuracy tested on several benchmark
problems. These methods can be subdivided into integral methods (fast Fourier
transform methods, tensor-grid method) which solve the stray field directly and
in differential equation methods (finite-element method), which compute the
stray field as the solution of a partial differential equation. It turns out
that for cuboid structures the integral methods, which work on cuboid grids
(fast Fourier transform methods and tensor grid methods) outperform the
finite-element method in terms of the ratio of computational effort to
accuracy. Among these three methods the tensor grid method is the fastest.
However, the use of the tensor grid method in the context of full micromagnetic
codes is not well investigated yet. The finite-element method performs best for
computations on curved structures.",1204.4302v1,physics.comp-ph,2012-04-19 10:06:28+00:00,"[arxiv.Result.Author('Claas Abert'), arxiv.Result.Author('Lukas Exl'), arxiv.Result.Author('Gunnar Selke'), arxiv.Result.Author('André Drews'), arxiv.Result.Author('Thomas Schrefl')]",
424,The standard forms of the Kaczmarz-Tanabe type methods and their convergence theory,"In this paper, we consider the standard form of two kinds of Kaczmarz-Tanabe
type methods, one derived from the Kaczmarz method and the other derived from
the symmetric Kaczmarz method. As a famous image reconstruction method in
computed tomography, the Kaczmarz method has both advantage and disadvantage.
The advantage are simple and easy to implement, while the disadvantages are
slow convergence speed, and the symmetric Kaczmarz method is the same. For the
standard form of this method, once the iterative matrix is generated, it can be
used continuously in the subsequent iterations. Moreover, the iterative matrix
can be stored in the image reconstructive devices, which makes the Kaczmarz
method and the symmetric Kaczmarz method can be used like the simultaneous
iterative reconstructive techniques (SIRT). Meanwhile, theoretical analysis
shows that the convergence rate of symmetric Kaczmarz method is better than the
Kaczmarz method but is slightly worse than that of two iterations Kaczmarz
method, which is verified numerically. Numerical experiments also show that the
convergence rates of the Kaczmarz method and the symmetric Kaczmarz method are
better than the SIRT methods and slightly worse than CGMN method in some cases.
However, the Kaczmarz Tanabe type methods have better problem adaptability.",2211.00328v1,math.NA,2022-11-01 08:31:08+00:00,[arxiv.Result.Author('Chuan-gang Kang')],
425,Methods of Matrix Multiplication: An Overview of Several Methods and their Implementation,"In this overview article we present several methods for multiplying matrices
and the implementation of these methods in C. Also a little test program is
given to compare their running time and the numerical stability.
  The methods are: naive method, naive method working on arrays, naive method
with the \textsc{Kahan} trick, three methods with loop unrolling, winograd
method and the scaled variant, original \textsc{Strassen} method and the
\textsc{Strassen}-\textsc{Winograd} variant.
  Please note, that this is the FIRST version. The algorithms are not well
tested and the implementation is not optimized. If you like to join the
project, please contact me.",1106.1347v1,cs.MS,2011-06-03 09:17:11+00:00,[arxiv.Result.Author('Ivo Hedtke')],
426,Strong Convergence Theorems by Generalized CQ Method in Hilbert Spaces,"Recently, CQ method has been investigated extensively. However, it is mainly
applied to modify Mann, Ishikawa and Halpern iterations to get strong
convergence. In this paper, we study the properties of CQ method and proposed a
framework. Based on that, we obtain a series of strong convergence theorems.
Some of them are the extensions of previous results. On the other hand, CQ
method, monotone Q method, monotone C method and monotone CQ method, used to be
given separately, have the following relations: CQ method TRUE $\Rightarrow$
monotone Q method TRUE $\Rightarrow$ monotone C method TRUE $\Leftrightarrow$
monotone CQ method TRUE.",2001.02194v2,math.FA,2020-01-07 17:44:45+00:00,"[arxiv.Result.Author('Songnian He'), arxiv.Result.Author('Tian Shi')]","Fixed Point Theory, 12(2011), No. 2, 355-382"
427,Preconditioning Kaczmarz method by sketching,"We propose a new method for preconditioning Kaczmarz method by sketching.
Kaczmarz method is a stochastic method for solving overdetermined linear
systems based on a sampling of matrix rows. The standard approach to speed up
convergence of iterative methods is using preconditioner. As we show the best
possible preconditioner for this method can be constructed from QR
decomposition of the system matrix, but the complexity of this procedure is too
high. Therefore, to reduce this complexity, we use random sketching and compare
it with the Kaczmarz method without preconditioning. The developed method is
applicable for different modifications of classical Kaczmarz method that were
proposed recently. We provide numerical experiments to show the performance of
the developed methods on solving both random and real overdetermined linear
systems.",1903.01806v1,cs.NA,2019-03-05 13:11:08+00:00,"[arxiv.Result.Author('Alexandr Katrutsa'), arxiv.Result.Author('Ivan Oseledets')]",
428,A Two-Point Newton Method suitable for non-convergent Cases and with Super-Quadratic Convergence,"An iterative formula based on Newton Method alone is presented for the
iterative solutions of equations that ensures convergence in cases where the
traditional Newton Method may fail to converge to the desired root. In
addition, the method has super quadratic convergence of order 2.414. Newton
method is said to fail in certain cases leading to oscillation, divergence to
increasingly large number or off-shooting away to another root further from the
desired domain or off shooting to an invalid domain where the function may not
be defined. In addition when the derivative at the iteration point is zero,
Newton method stalls. In most of these cases, hybrids of several methods such
as Newton, bisection and secant methods are suggested as substitute methods and
Newton method is essentially blended with other methods or altogether
abandoned. This paper argues that a solution is still possible in most of these
cases by the application of Newton Method alone without resorting to other
methods and with the same computational effort, two functional evaluations per
iteration, like the traditional Newton method. In addition, the proposed
modified formula based on Newton method has better convergence characteristics
than the traditional Newton method.",1210.5766v2,math.NA,2012-10-21 22:10:36+00:00,[arxiv.Result.Author('Ababu Teklemariam Tiruneh')],
429,DPG* Method,"We introduce a cousin of the DPG method - the DPG* method - discuss their
relationship and compare the two methods through numerical experiments.",1710.05223v1,math.NA,2017-10-14 19:18:08+00:00,"[arxiv.Result.Author('Brendan Keith'), arxiv.Result.Author('Leszek Demkowicz'), arxiv.Result.Author('Jay Gopalakrishnan')]",
430,The Weak Galerkin methods are rewritings of the Hybridizable Discontinuous Galerkin methods,"We establish that the Weak Galerkin methods are rewritings of the
hybridizable discontinuous Galerkin methods.",1812.08146v1,math.NA,2018-12-19 18:40:59+00:00,[arxiv.Result.Author('Bernardo Cockburn')],
431,Hybrid LBM-FVM and LBM-MCM Methods for Fluid Flow and Heat Transfer Simulation,"The fluid flow and heat transfer problems encountered in industry
applications span into different scales and there are different numerical
methods for different scales problems. It is not possible to use single scale
method to solve problems involving multiple scales. Multiscale methods are
needed to solve problems involving multiple scales. In this chapter,
meso-macro-multiscale methods are developed by combining various single scale
numerical methods, including lattice Boltzmann method (LBM), finite volume
method (FVM) and Monte Carlo method (MCM). Macroscale methods include FVM,
while LBM and MCM belongs to mesoscale methods. Two strategies exist in combing
these numerical methods. For the first one, the whole domain is divided into
multiple subdomains and different domains use various numerical methods.
Message passing among subdomains decides the accuracy of this type of
multiscale numerical method. For the second one, various parameters are solved
with different numerical methods. These two types of multiscale methods are
both discussed in this chapter.",1908.08386v1,cs.CE,2019-08-18 14:51:45+00:00,"[arxiv.Result.Author('Zheng Li'), arxiv.Result.Author('Mo Yang'), arxiv.Result.Author('Yuwen Zhang')]","Multiscale Thermal Transport in Energy Systems, Nova Science
  Publishers, Inc., Chapter 9, pp. 281-336, 2016"
432,Yet another fast multipole method without multipoles --- Pseudo-particle multipole method,"In this paper we describe a new approach to implement the O(N) fast multipole
method and $O(N\log N)$ tree method, which uses pseudoparticles to express the
potential field. The new method is similar to Anderson's method, which uses the
values of potential at discrete points to represent the potential field.
However, for the same expansion order the new method is more accurate and
computationally efficient.",astro-ph/9806213v1,astro-ph,1998-06-16 07:36:36+00:00,[arxiv.Result.Author('Junichiro Makino')],
433,An efficient method for calculation of cooling in Lagrange computational gas dynamics,"A new method for computation of gas cooling for Lagrange approach is
suggested. The method is based on precalculation of cooling law for known
cooling function. Unlike implicit methods, this method is very efficient, it is
an one-step method which is even more accurate than implicit methods of the
same order.",0705.2129v1,astro-ph,2007-05-15 12:10:39+00:00,[arxiv.Result.Author('E. P. Kurbatov')],
434,An asymptotic preserving method for linear systems of balance laws based on Galerkin's method,"We apply the concept of Asymptotic Preserving (AP) schemes to the linearized
p-system and discretize the resulting elliptic equation using standard
continuous Finite Elements instead of Finite Differences. The fully discrete
method is analyzed with respect to consistency, and we compare it numerically
with more traditional methods such as Implicit Euler's method. Numerical
results indicate that the AP method is indeed superior to more traditional
methods.",1406.3940v1,math.NA,2014-06-16 08:50:56+00:00,[arxiv.Result.Author('Jochen Schütz')],
435,Equivalence of Weak Galerkin Methods and Virtual Element Methods for Elliptic Equations,"We propose a modification of the weak Galerkin methods and show its
equivalence to a new version of virtual element methods. We also show the
original weak Galerkin method is equivalent to the non-conforming virtual
element method. As a consequence, ideas and techniques used for one method can
be transferred to another. The key of the connection is the degree of freedoms.",1503.04700v2,math.NA,2015-03-16 16:00:33+00:00,[arxiv.Result.Author('Long Chen')],
436,$α$-Parameterized Differential Transform Method,"In this paper we propose a new version of differential transform method (we
shall call this method as $\alpha$-parameterized differential transform
method), which differs from the traditional differential transform method in
calculating coefficients of Taylor polynomials. Numerical examples are
presented to illustrate the efficiency and reliability of own method. The
result reveal that $\alpha$-Parameterized differential transform method is a
simple and effective numerical algorithm.",1507.03803v1,math.CA,2015-07-14 11:13:43+00:00,"[arxiv.Result.Author('K. Aydemir'), arxiv.Result.Author('O. Sh. Mukhtarov')]",
437,A fitted L-Multi-point Flux Approximation method for pricing options,"In this paper, we introduce a special kind of finite volume method called
Multi-Point Flux Approximation method (MPFA) to price European and American
options in two dimensional domain. We focus on the L-MPFA method for space
discretization of the diffusion term of Black-Scholes operator. The degeneracy
of the Black Scholes operator is tackled using the fitted finite volume method.
This combination of fitted finite volume method and L-MPFA method coupled to
upwind methods gives us a novel scheme called the fitted L-MPFA method.
Numerical experiments show the accuracy of the novel fitted L-MPFA method
comparing to well known schemes for pricing options.",1912.12743v1,math.NA,2019-12-29 21:49:15+00:00,"[arxiv.Result.Author('Rock Stephane Koffi'), arxiv.Result.Author('Antoine Tambue')]",
438,A conforming discontinuous Galerkin finite element method,"A new finite element method with discontinuous approximation is introduced
for solving second order elliptic problem. Since this method combines the
features of both conforming finite element method and discontinuous Galerkin
(DG) method, we call it conforming DG method. While using DG finite element
space, this conforming DG method maintains the features of the conforming
finite element method such as simple formulation and strong enforcement of
boundary condition. Therefore, this finite element method has the flexibility
of using discontinuous approximation and simplicity in formulation of the
conforming finite element method. Error estimates of optimal order are
established for the corresponding discontinuous finite element approximation in
both a discrete $H^1$ norm and the $L^2$ norm. Numerical results are presented
to confirm the theory.",1904.03331v1,math.NA,2019-04-06 01:29:37+00:00,"[arxiv.Result.Author('Xiu Ye'), arxiv.Result.Author('Shangyou Zhang')]",
439,A New family of methods for solving delay differential equations,"In the present paper, we introduce a new family of $
  \theta-$methods for solving delay differential equations. New methods are
developed using a combination of decomposition technique viz. new iterative
method proposed by Daftardar Gejji and Jafari and existing implicit numerical
methods. Using Butcher tableau, we observed that new methods are non
Runge-Kutta methods. Further, convergence of new methods is investigated along
with its stability analysis. Applications to variety of problems indicates that
the proposed family of methods is more efficient than existing methods.",2102.06925v1,math.NA,2021-02-13 12:59:37+00:00,"[arxiv.Result.Author('Yogita Mahatekar'), arxiv.Result.Author('Pallavi S. Scindia')]",
440,Making sense of spoken plurals,"Distributional semantics offers new ways to study the semantics of
morphology. This study focuses on the semantics of noun singulars and their
plural inflectional variants in English. Our goal is to compare two models for
the conceptualization of plurality. One model (FRACSS) proposes that all
singular-plural pairs should be taken into account when predicting plural
semantics from singular semantics. The other model (CCA) argues that
conceptualization for plurality depends primarily on the semantic class of the
base word. We compare the two models on the basis of how well the speech signal
of plural tokens in a large corpus of spoken American English aligns with the
semantic vectors predicted by the two models. Two measures are employed: the
performance of a form-to-meaning mapping and the correlations between form
distances and meaning distances. Results converge on a superior alignment for
CCA. Our results suggest that usage-based approaches to pluralization in which
a given word's own semantic neighborhood is given priority outperform theories
according to which pluralization is conceptualized as a process building on
high-level abstraction. We see that what has often been conceived of as a
highly abstract concept, [+plural], is better captured via a family of
mid-level partial generalizations.",2207.01947v1,cs.CL,2022-07-05 10:44:26+00:00,"[arxiv.Result.Author('Elnaz Shafaei-Bajestan'), arxiv.Result.Author('Peter Uhrig'), arxiv.Result.Author('R. Harald Baayen')]",
441,An SMP-Based Algorithm for Solving the Constrained Utility Maximization Problem via Deep Learning,"We consider the utility maximization problem under convex constraints with
regard to theoretical results which allow the formulation of algorithmic
solvers which make use of deep learning techniques. In particular for the case
of random coefficients, we prove a stochastic maximum principle (SMP), which
also holds for utility functions $U$ with $\mathrm{id}_{\mathbb{R}^{+}} \cdot
U'$ being not necessarily nonincreasing, like the power utility functions,
thereby generalizing the SMP proved by Li and Zheng (2018). We use this SMP
together with the strong duality property for defining a new algorithm, which
we call deep primal SMP algorithm. Numerical examples illustrate the
effectiveness of the proposed algorithm - in particular for higher-dimensional
problems and problems with random coefficients, which are either path dependent
or satisfy their own SDEs. Moreover, our numerical experiments for constrained
problems show that the novel deep primal SMP algorithm overcomes the deep SMP
algorithm's (see Davey and Zheng (2021)) weakness of erroneously producing the
value of the corresponding unconstrained problem. Furthermore, in contrast to
the deep controlled 2BSDE algorithm from Davey and Zheng (2021), this algorithm
is also applicable to problems with path dependent coefficients. As the deep
primal SMP algorithm even yields the most accurate results in many of our
studied problems, we can highly recommend its usage. Moreover, we propose a
learning procedure based on epochs which improved the results of our algorithm
even further. Implementing a semi-recurrent network architecture for the
control process turned out to be also a valuable advancement.",2202.07771v1,q-fin.CP,2022-02-15 22:50:07+00:00,[arxiv.Result.Author('Kristof Wiedermann')],
442,Plurals: individuals and sets in a richly typed semantics,"We developed a type-theoretical framework for natural lan- guage semantics
that, in addition to the usual Montagovian treatment of compositional
semantics, includes a treatment of some phenomena of lex- ical semantic:
coercions, meaning, transfers, (in)felicitous co-predication. In this setting
we see how the various readings of plurals (collective, dis- tributive,
coverings,...) can be modelled.",1401.0660v1,cs.CL,2014-01-03 15:37:19+00:00,"[arxiv.Result.Author('Bruno Mery'), arxiv.Result.Author('Richard Moot'), arxiv.Result.Author('Christian Retoré')]","LENSL'10 - 10th Workshop on Logic and Engineering of Natural
  Semantics of Language, Japanese Symposium for Artifitial Intelligence,
  International Society for AI - 2013 (2013)"
443,"Universal Communication, Universal Graphs, and Graph Labeling","We introduce a communication model called universal SMP, in which Alice and
Bob receive a function $f$ belonging to a family $\mathcal{F}$, and inputs $x$
and $y$. Alice and Bob use shared randomness to send a message to a third party
who cannot see $f, x, y$, or the shared randomness, and must decide $f(x,y)$.
Our main application of universal SMP is to relate communication complexity to
graph labeling, where the goal is to give a short label to each vertex in a
graph, so that adjacency or other functions of two vertices $x$ and $y$ can be
determined from the labels $\ell(x),\ell(y)$. We give a universal SMP protocol
using $O(k^2)$ bits of communication for deciding whether two vertices have
distance at most $k$ on distributive lattices (generalizing the $k$-Hamming
Distance problem in communication complexity), and explain how this implies an
$O(k^2\log n)$ labeling scheme for determining $\mathrm{dist}(x,y) \leq k$ on
distributive lattices with size $n$; in contrast, we show that a universal SMP
protocol for determining $\mathrm{dist}(x,y) \leq 2$ in modular lattices (a
superset of distributive lattices) has super-constant $\Omega(n^{1/4})$
communication cost. On the other hand, we demonstrate that many graph families
known to have efficient adjacency labeling schemes, such as trees,
low-arboricity graphs, and planar graphs, admit constant-cost communication
protocols for adjacency. Trees also have an $O(k)$ protocol for deciding
$\mathrm{dist}(x,y) \leq k$ and planar graphs have an $O(1)$ protocol for
$\mathrm{dist}(x,y) \leq 2$, which implies a new $O(\log n)$ labeling scheme
for the same problem on planar graphs.",1911.03757v1,cs.CC,2019-11-09 19:11:08+00:00,[arxiv.Result.Author('Nathaniel Harms')],
444,Semantic properties of English nominal pluralization: Insights from word embeddings,"Semantic differentiation of nominal pluralization is grammaticalized in many
languages. For example, plural markers may only be relevant for human nouns.
English does not appear to make such distinctions. Using distributional
semantics, we show that English nominal pluralization exhibits semantic
clusters. For instance, pluralization of fruit words is more similar to one
another and less similar to pluralization of other semantic classes. Therefore,
reduction of the meaning shift in plural formation to the addition of an
abstract plural meaning is too simplistic. A semantically informed method,
called CosClassAvg, is introduced that outperforms pluralization methods in
distributional semantics which assume plural formation amounts to the addition
of a fixed plural vector. In comparison with our approach, a method from
compositional distributional semantics, called FRACSS, predicted plural vectors
that were more similar to the corpus-extracted plural vectors in terms of
direction but not vector length. A modeling study reveals that the observed
difference between the two predicted semantic spaces by CosClassAvg and FRACSS
carries over to how well a computational model of the listener can understand
previously unencountered plural forms. Mappings from word forms, represented
with triphone vectors, to predicted semantic vectors are more productive when
CosClassAvg-generated semantic vectors are employed as gold standard vectors
instead of FRACSS-generated vectors.",2203.15424v1,cs.CL,2022-03-29 10:42:47+00:00,"[arxiv.Result.Author('Elnaz Shafaei-Bajestan'), arxiv.Result.Author('Masoumeh Moradipour-Tari'), arxiv.Result.Author('Peter Uhrig'), arxiv.Result.Author('R. Harald Baayen')]",
445,Quantum Entanglement and Topological Order in Hole-Doped Valence Bond Solid States,"We present a detailed analysis of topological properties of the valence bond
solid (VBS) states doped with fermionic holes. As concrete examples, we
consider the supersymmetric extension of the SU(2)- and the SO(5) VBS states,
dubbed UOSp(1|2) and UOSp(1|4) supersymmetric VBS states, respectively.
Specifically, we investigate the string-order parameters and the entanglement
spectra of these states to find that, even when the parent states (bosonic VBS
states) do not support the string order, they recover it when holes are doped
and the fermionic sector appears in the entanglement spectrum. These peculiar
properties are discussed in light of the symmetry-protected topological order.
To this end, we characterize a few typical classes of symmetry-protected
topological orders in terms of supermatrix-product states (SMPS). From this, we
see that the topological order in the bulk manifests itself in the
transformation properties of the SMPS in question and thereby affects the
structure of the entanglement spectrum. Then, we explicitly relate the
existence of the string order and the structure of the entanglement spectrum to
explain the recovery and the stabilization of the string order in the
supersymmetric systems.",1210.0299v2,cond-mat.str-el,2012-10-01 07:18:18+00:00,"[arxiv.Result.Author('Kazuki Hasebe'), arxiv.Result.Author('Keisuke Totsuka')]","Phys.Rev.B 87, 045115 (2013)"
446,Radio Planetary Nebulae in the Small Magellanic Cloud,"We present ten new radio continuum (RC) detections at catalogued planetary
nebula (PN) positions in the Small Magellanic Cloud (SMC): SMPS6, LIN 41, LIN
142, SMP S13, SMP S14, SMP S16, J18, SMP S18, SMP S19 and SMP S22.
Additionally, six SMC radio PNe previously detected, LIN 45, SMP S11, SMPS17,
LIN321, LIN339 and SMPS24 are also investigated (re-observed) here making up a
population of 16 radio detections of catalogued PNe in the SMC. These 16 radio
detections represent ~15 % of the total catalogued PN population in the SMC. We
show that six of these objects have characteristics that suggest that they are
PN mimics: LIN 41, LIN 45, SMP S11, LIN 142, LIN 321 and LIN 339. We also
present our results for the surface brightness - PN radius relation
({\Sigma}-D) of the SMC radio PN population. These are consistent with previous
SMC and LMC PN measurements of the ({\Sigma}-D) relation.",1602.03911v1,astro-ph.SR,2016-02-11 22:04:00+00:00,"[arxiv.Result.Author('Howard Leverenz'), arxiv.Result.Author('Miroslav D. Filipović'), arxiv.Result.Author('Ivan S. Bojičić'), arxiv.Result.Author('Evan J. Crawford'), arxiv.Result.Author('Jordan D. Collier'), arxiv.Result.Author('Kevin Grieve'), arxiv.Result.Author('Danica Drašković'), arxiv.Result.Author('Warren A. Reid')]",
447,Second Moment Polytopic Systems: Generalization of Uncertain Stochastic Linear Dynamics,"This paper presents a new paradigm to stabilize uncertain stochastic linear
systems. Herein, second moment polytopic (SMP) systems are proposed that
generalize systems with both uncertainty and randomness. The SMP systems are
characterized by second moments of the stochastic system matrices and the
uncertain parameters. Further, a fundamental theory for guaranteeing stability
of the SMP systems is established. It is challenging to analyze the SMP systems
owing to both the uncertainty and randomness. An idea to overcome this
difficulty is to expand the SMP systems and exclude the randomness. Because the
expanded systems contain only the uncertainty, their stability can be analyzed
via robust stability theory. The stability of the expanded systems is
equivalent to statistical stability of the SMP systems. These facts provide
sufficient conditions for the stability of the SMP systems as linear matrix
inequalities (MIs). In controller design for the SMP systems, the linear MIs
reduce to cubic MIs whose solutions correspond to feedback gains. The cubic MIs
are transformed into simpler quadratic MIs that can be solved using
optimization techniques. Moreover, solving such non-convex MIs is relaxed into
the iteration of a convex optimization. Solutions to the iterative optimization
provide feedback gains that stabilize the SMP systems. As demonstrated here,
the SMP systems represent linear dynamics with uncertain mean and covariance
and other existing systems such as independently identically distributed
dynamics and random polytopes. Finally, a numerical simulation shows the
effectiveness of the proposed method.",2207.05922v1,math.OC,2022-07-13 02:02:18+00:00,"[arxiv.Result.Author('Yuji Ito'), arxiv.Result.Author('Kenji Fujimoto')]",
448,We belong together? A plea for modesty in modal plural logic,A sceptical examination of the motivations for strong modal plural logics.,1612.08424v1,math.LO,2016-12-26 18:44:05+00:00,[arxiv.Result.Author('Simon Hewitt')],
449,Non-collider searches for stable massive particles,"The theoretical motivation for exotic stable massive particles (SMPs) and the
results of SMP searches at non-collider facilities are reviewed. SMPs are
defined such that they would be sufficiently long-lived so as to still exist in
the cosmos either as Big Bang relics or secondary collision products, and
sufficiently massive to be beyond the reach of any conceivable
accelerator-based experiment. The discovery of SMPs would address a number of
important questions in modern physics, such as the origin and composition of
dark matter in the Universe and the unification of the fundamental forces. This
review outlines the scenarios predicting SMPs and the techniques used at
non-collider experiments to look for SMPs, eg in cosmic rays and bound in
matter. The limits so far obtained on the fluxes and matter densities of SMPs
which possess various detection-relevant properties such as electric and
magnetic charge are given.",1410.1374v1,hep-ph,2014-10-06 13:59:54+00:00,"[arxiv.Result.Author('Sergey Burdin'), arxiv.Result.Author('Malcolm Fairbairn'), arxiv.Result.Author('Philippe Mermod'), arxiv.Result.Author('David Milstead'), arxiv.Result.Author('James Pinfold'), arxiv.Result.Author('Terry Sloan'), arxiv.Result.Author('Wendy Taylor')]",
450,A Functional Model for SMP Matrices and the Jacobi Flow,"This is the second part of the paper arXiv:1309.0959v2 on the theory of SMP
(Strong Moment Problem) matrices and their relation to the Killip-Simon problem
on two disjoint intervals. In this part we define and study the Jacobi flow on
SMP matrices.",1401.1320v1,math.SP,2014-01-07 09:33:23+00:00,"[arxiv.Result.Author('Benjamin Eichinger'), arxiv.Result.Author('Florian Puchhammer'), arxiv.Result.Author('Peter Yuditskii')]",
451,The subpower membership problem for bands,"Fix a finite semigroup $S$ and let $a_1,\ldots,a_k, b$ be tuples in a direct
power $S^n$. The subpower membership problem (SMP) for $S$ asks whether $b$ can
be generated by $a_1,\ldots,a_k$. For bands (idempotent semigroups), we provide
a dichotomy result: if a band $S$ belongs to a certain quasivariety, then
$SMP(S)$ is in P; otherwise it is NP-complete.
  Furthermore we determine the greatest variety of bands all of whose finite
members induce a tractable SMP. Finally we present the first example of two
finite algebras that generate the same variety and have tractable and
NP-complete SMPs, respectively.",1604.01014v1,math.GR,2016-04-02 20:19:47+00:00,[arxiv.Result.Author('Markus Steindl')],
452,Stochastic Maximum Principle for Optimal Liquidation with Control-dependent Terminal Time,"In this paper we study a general optimal liquidation problem with a
control-dependent stopping time which is the first time the stock holding
becomes zero or a fixed terminal time, whichever comes first. We prove a
stochastic maximum principle (SMP) which is markedly different in its
Hamiltonian condition from that of the standard SMP with fixed terminal time.
We present a simple example in which the optimal solution satisfies the SMP in
this paper but fails the standard SMP in the literature.",2107.08489v2,math.OC,2021-07-18 16:48:55+00:00,"[arxiv.Result.Author('Riccardo Cesari'), arxiv.Result.Author('Harry Zheng')]",
453,Control in the Presence of Manipulators: Cooperative and Competitive Cases,"Control and manipulation are two of the most studied types of attacks on
elections. In this paper, we study the complexity of control attacks on
elections in which there are manipulators. We study both the case where the
""chair"" who is seeking to control the election is allied with the manipulators,
and the case where the manipulators seek to thwart the chair. In the latter
case, we see that the order of play substantially influences the complexity. We
prove upper bounds, holding over every election system with a polynomial-time
winner problem, for all standard control cases, and some of these bounds are at
the second or third level of the polynomial hierarchy, and we provide matching
lower bounds to prove these tight. Nonetheless, for important natural systems
the complexity can be much lower. We prove that for approval and plurality
elections, the complexity of even competitive clashes between a controller and
manipulators falls far below those high bounds, even as low as polynomial time.
Yet for a Borda-voting case we show that such clashes raise the complexity
unless NP = coNP.",1308.0544v3,cs.GT,2013-08-02 15:51:30+00:00,"[arxiv.Result.Author('Zack Fitzsimmons'), arxiv.Result.Author('Edith Hemaspaandra'), arxiv.Result.Author('Lane A. Hemaspaandra')]",
454,On Fourier Coefficients of GL(n)-Automorphic Functions over Number Fields,"We study Fourier coefficients of $GL_n(\A)$-automorphic functions $\phi$, for
$\A$ being the adele group of a number field $\kkk$. Let FC be an abbreviation
for such a Fourier coefficient (and FCs for plural). Roughly speaking, in the
present paper we process FCs by iteratively using the operations: Fourier
expansions, certain exchanges of Fourier expansions, and conjugations. In
Theorem 3.1 we express any FC in terms of---degenerate in many
cases---Whittaker FCs. For FCs obtained from the trivial FC by choosing a
certain ""generic"" term in each Fourier expansion involved, we establish a
shortcut (Main corollary 6.17) for studying their expressions of the form in
Theorem 3.1. The shortcut gives considerably less information, but it remains
useful on finding automorphic representations so that for appropriate choices
of $\phi$ in them, the FC is factorizable and nonzero. Then in Theorems 8.3.11,
8.3.12, and 8.3.18, we study examples of FCs on which this shortcut applies,
with many of them turning out to ""correspond"" to more than one unipotent orbit
in $GL_n.$
  For most of the paper, no knowledge on automorphic forms is necessary.",1711.11545v2,math.NT,2017-11-30 18:07:43+00:00,[arxiv.Result.Author('Eleftherios Tsiokos')],
455,Geometric crystals and Cluster ensembles in Kac-Moody setting,"For a Kac-Moody group $G$, double Bruhat cells $G^{u,e}$ ($u$ is a Weyl group
element) have positive geometric crystal structures. In arXiv:1210.2533, it is
shown that there exist birational maps between `cluster tori'
$\mathcal{X}_{\Sigma}$ (resp. $\mathcal{A}_{\Sigma}$) and $G_{\rm Ad}^{u,e}$
(resp. $G^{u,e}$), and they are extended to regular maps from cluster
$\mathcal{X}$ (resp. $\mathcal{A}$) -varieties to $G_{\rm Ad}^{u,e}$ (resp.
$G^{u,e}$). The aim of this article is to construct certain positive geometric
crystal structures on the cluster tori $\mathcal{X}_{\Sigma}$ and
$\mathcal{A}_{\Sigma}$ by presenting their explicit formulae. In particular,
the geometric crystal structures on the tori $\mathcal{A}_{\Sigma}$ are
obtained by applying the twist map. As a corollary, we see the sets of
$\mathbb{Z}^T$-valued points of the cluster varieties have plural structures of
crystals.",1807.11684v1,math.QA,2018-07-31 07:06:48+00:00,"[arxiv.Result.Author('Yuki Kanakubo'), arxiv.Result.Author('Toshiki Nakashima')]",
456,Approval-Based Elections and Distortion of Voting Rules,"We consider elections where both voters and candidates can be associated with
points in a metric space and voters prefer candidates that are closer to those
that are farther away. It is often assumed that the optimal candidate is the
one that minimizes the total distance to the voters. Yet, the voting rules
often do not have access to the metric space $M$ and only see preference
rankings induced by $M$.Consequently, they often are incapable of selecting the
optimal candidate. The distortion of a voting rule measures the worst-case loss
of the quality being the result of having access only to preference rankings.
We extend the idea of distortion to approval-based preferences. First, we
compute the distortion of Approval Voting. Second, we introduce the concept of
acceptability-based distortion---the main idea behind is that the optimal
candidate is the one that is acceptable to most voters. We determine
acceptability-distortion for a number of rules, including Plurality, Borda,
$k$-Approval, Veto, the Copeland's rule, Ranked Pairs, the Schulze's method,
and STV.",1901.06709v1,cs.GT,2019-01-20 18:22:58+00:00,"[arxiv.Result.Author('Grzegorz Pierczyński'), arxiv.Result.Author('Piotr Skowron')]",
457,Two $^9$Li clusters connected with two valence neutrons in $^{20}$C,"Many preceding works have shown in $^{11}$Li the presence of the halo
structure comprised of the weakly bound two neutrons around $^9$Li, and it is
intriguing to see how this halo structure changes when another $^9$Li
approaches. In this study, we introduce a four-body model for $^{20}$C with two
$^9$Li clusters and two valence neutrons. The recent development of the
antisymmetrized quasi cluster model (AQCM) makes it possible to generate
$jj$-coupling shell-model wave functions from $\alpha$ cluster models. Here,
$jj$-coupling shell model wave function of $^9$Li is regarded as a cluster,
which corresponds to the subclosure configuration of $p_{3/2}$ for the
neutrons, and we discuss how the two neutrons connect two $^9$Li clusters.
Until now, most of the clusters in the conventional models have been limited to
the closures of the three-dimensional harmonic oscillators, such as $^4$He,
$^{16}$O, and $^{40}$Ca; however, owing to AQCM, it is feasible to utilize the
$jj$-coupling shell model wave functions as plural subsystems quite easily. The
appearance of a rotational band structure with a cluster structure around the
four-body threshold energy is discussed.",2102.04589v1,nucl-th,2021-02-09 00:47:04+00:00,"[arxiv.Result.Author('Naoyuki Itagaki'), arxiv.Result.Author('Tokuro Fukui'), arxiv.Result.Author('Junki Tanaka'), arxiv.Result.Author('Yuma Kikuchi')]",
458,Do LSTMs See Gender? Probing the Ability of LSTMs to Learn Abstract Syntactic Rules,"LSTMs trained on next-word prediction can accurately perform linguistic tasks
that require tracking long-distance syntactic dependencies. Notably, model
accuracy approaches human performance on number agreement tasks (Gulordava et
al., 2018). However, we do not have a mechanistic understanding of how LSTMs
perform such linguistic tasks. Do LSTMs learn abstract grammatical rules, or do
they rely on simple heuristics? Here, we test gender agreement in French which
requires tracking both hierarchical syntactic structures and the inherent
gender of lexical units. Our model is able to reliably predict long-distance
gender agreement in two subject-predicate contexts: noun-adjective and
noun-passive-verb agreement. The model showed more inaccuracies on plural noun
phrases with gender attractors compared to singular cases, suggesting a
reliance on clues from gendered articles for agreement. Overall, our study
highlights key ways in which LSTMs deviate from human behaviour and questions
whether LSTMs genuinely learn abstract syntactic rules and categories. We
propose using gender agreement as a useful probe to investigate the underlying
mechanisms, internal representations, and linguistic capabilities of LSTM
language models.",2211.00153v1,cs.CL,2022-10-31 21:37:12+00:00,"[arxiv.Result.Author('Priyanka Sukumaran'), arxiv.Result.Author('Conor Houghton'), arxiv.Result.Author('Nina Kazanina')]",
459,Performance Evaluation of Parallel Message Passing and Thread Programming Model on Multicore Architectures,"The current trend of multicore architectures on shared memory systems
underscores the need of parallelism. While there are some programming model to
express parallelism, thread programming model has become a standard to support
these system such as OpenMP, and POSIX threads. MPI (Message Passing Interface)
which remains the dominant model used in high-performance computing today faces
this challenge.
  Previous version of MPI which is MPI-1 has no shared memory concept, and
Current MPI version 2 which is MPI-2 has a limited support for shared memory
systems. In this research, MPI-2 version of MPI will be compared with OpenMP to
see how well does MPI perform on multicore / SMP (Symmetric Multiprocessor)
machines.
  Comparison between OpenMP for thread programming model and MPI for message
passing programming model will be conducted on multicore shared memory machine
architectures to see who has a better performance in terms of speed and
throughput. Application used to assess the scalability of the evaluated
parallel programming solutions is matrix multiplication with customizable
matrix dimension.
  Many research done on a large scale parallel computing which using high scale
benchmark such as NSA Parallel Benchmark (NPB) for their testing standarization
[1]. This research will be conducted on a small scale parallel computing that
emphasize more on the performance evaluation between MPI and OpenMPI parallel
programming model using self created benchmark.",1012.2273v1,cs.DC,2010-12-10 14:17:19+00:00,"[arxiv.Result.Author('D. T. Hasta'), arxiv.Result.Author('A. B. Mutiara')]",
460,Social cohesion V.S. task cohesion: An evolutionary game theory study,"Using methods from evolutionary game theory, this paper investigates the
difference between social cohesion and task cohesion in promoting the evolution
of cooperation in group interactions. Players engage in public goods games and
are allowed to leave their groups if too many defections occur. Both social
cohesion and task cohesion may prevent players from leaving. While a higher
level of social cohesion increases a player's tolerance towards defections,
task cohesion is associated with her group performance in the past. With a
higher level of task cohesion, it is more likely that a dissatisfied player
will refer to the history and remains in her group if she was satisfied in the
past. Our results reveal that social cohesion is detrimental to the evolution
of cooperation while task cohesion facilitates it. This is because social
cohesion hinders the conditional dissociation mechanism but task cohesion
improves the robustness of cooperative groups which are usually vulnerable to
mistakes. We also discuss other potential aspects of cohesion and how they can
be investigated through our modelling. Overall, our analysis provides novel
insights into the relationship between group cohesion and group performance
through studying the group dynamics and suggests further application of
evolutionary game theory in this area.",2101.06961v1,physics.soc-ph,2021-01-18 09:52:16+00:00,"[arxiv.Result.Author('Xinglong Qu'), arxiv.Result.Author('Shun Kurokawa'), arxiv.Result.Author('The Anh Han')]",
461,"Network, Popularity and Social Cohesion: A Game-Theoretic Approach","In studies of social dynamics, cohesion refers to a group's tendency to stay
in unity, which -- as argued in sociometry -- arises from the network topology
of interpersonal ties between members of the group. We follow this idea and
propose a game-based model of cohesion that not only relies on the social
network, but also reflects individuals' social needs. In particular, our model
is a type of cooperative games where players may gain popularity by
strategically forming groups. A group is socially cohesive if the grand
coalition is core stable. We study social cohesion in some special types of
graphs and draw a link between social cohesion and the classical notion of
structural cohesion. We then focus on the problem of deciding whether a given
social network is socially cohesive and show that this problem is
CoNP-complete. Nevertheless, we give two efficient heuristics for coalition
structures where players enjoy high popularity and experimentally evaluate
their performances.",1612.08351v1,cs.SI,2016-12-26 09:41:56+00:00,"[arxiv.Result.Author('Jiamou Liu'), arxiv.Result.Author('Ziheng Wei')]",
462,Novel Edge and Density Metrics for Link Cohesion,"We present a new metric of link cohesion for measuring the strength of edges
in complex, highly connected graphs. Link cohesion accounts for local small hop
connections and associated node degrees and can be used to support edge scoring
and graph simplification. We also present a novel graph density measure to
estimate the average cohesion across nodes. Link cohesion and the density
measure are employed to demonstrate community detection through graph
sparsification by maximizing graph density. Link cohesion is also shown to be
loosely correlated with edge betweenness centrality.",2003.02999v1,cs.SI,2020-03-06 02:09:49+00:00,"[arxiv.Result.Author('Cetin Savkli'), arxiv.Result.Author('Catherine Schwartz'), arxiv.Result.Author('Amanda Galante'), arxiv.Result.Author('Jonathan Cohen')]",
463,Structural Cohesion: Visualization and Heuristics for Fast Computation,"The structural cohesion model is a powerful theoretical conception of
cohesion in social groups, but its diffusion in empirical literature has been
hampered by operationalization and computational problems. In this paper we
start from the classic definition of structural cohesion as the minimum number
of actors who need to be removed in a network in order to disconnect it, and
extend it by using average node connectivity as a finer grained measure of
cohesion. We present useful heuristics for computing structural cohesion that
allow a speed-up of one order of magnitude over the algorithms currently
available. We analyze three large collaboration networks (co-maintenance of
Debian packages, co-authorship in Nuclear Theory and High-Energy Theory) and
show how our approach can help researchers measure structural cohesion in
relatively large networks. We also introduce a novel graphical representation
of the structural cohesion analysis to quickly spot differences across
networks.",1503.04476v1,cs.SI,2015-03-15 21:25:50+00:00,"[arxiv.Result.Author('Jordi Torrents'), arxiv.Result.Author('Fabrizio Ferraro')]",
464,How unitizing affects annotation of cohesion,"This paper investigates how unitizing affects external observers' annotation
of group cohesion. We compared unitizing techniques belonging to these
categories: interval coding, continuous coding, and a technique inspired by a
cognitive theory on event perception. We applied such techniques for sampling
coding units from a set of recordings of social interactions rich in behaviors
related to cohesion. Then, we compared the cohesion scores the observers
assigned to each coding unit. Results show that the three techniques can lead
to suitable ratings and that the technique inspired to cognitive theories leads
to scores reflecting variability in cohesion better than the other ones.",2209.14186v1,cs.HC,2022-09-28 16:00:19+00:00,"[arxiv.Result.Author('Eleonora Ceccaldi'), arxiv.Result.Author('Nale Lehmann-Willenbrock'), arxiv.Result.Author('Erica Volta'), arxiv.Result.Author('Mohamed Chetouani'), arxiv.Result.Author('Gualtiero Volpe'), arxiv.Result.Author('Giovanna Varni')]",
465,CoMet: Modeling Group Cohesion for Socially Compliant Robot Navigation in Crowded Scenes,"We present CoMet, a novel approach for computing a group's cohesion and using
that to improve a robot's navigation in crowded scenes. Our approach uses a
novel cohesion-metric that builds on prior work in social psychology. We
compute this metric by utilizing various visual features of pedestrians from an
RGB-D camera on-board a robot. Specifically, we detect characteristics
corresponding to proximity between people, their relative walking speeds, the
group size, and interactions between group members. We use our cohesion-metric
to design and improve a navigation scheme that accounts for different levels of
group cohesion while a robot moves through a crowd. We evaluate the precision
and recall of our cohesion-metric based on perceptual evaluations. We highlight
the performance of our social navigation algorithm on a Turtlebot robot and
demonstrate its benefits in terms of multiple metrics: freezing rate (57%
decrease), deviation (35.7% decrease), and path length of the trajectory(23.2%
decrease).",2108.09848v2,cs.RO,2021-08-22 21:17:22+00:00,"[arxiv.Result.Author('Adarsh Jagan Sathyamoorthy'), arxiv.Result.Author('Utsav Patel'), arxiv.Result.Author('Moumita Paul'), arxiv.Result.Author('Nithish K Sanjeev Kumar'), arxiv.Result.Author('Yash Savle'), arxiv.Result.Author('Dinesh Manocha')]",
466,Phase transitions in growing groups: How cohesion can persist,"The cohesion of a social group is the group's tendency to remain united. It
has important implications for the stability and survival of social
organizations, such as political parties, research teams, or online groups.
Empirical studies suggest that cohesion is affected by both the admission
process of new members and the group size. Yet, a theoretical understanding of
their interplay is still lacking. To this end, we propose a model where a group
grows by a noisy admission process of new members who can be of two different
types. Cohesion is defined in this framework as the fraction of members of the
same type and the noise in the admission process represents the level of
randomness in the evaluation of new candidates. The model can reproduce the
empirically reported decrease of cohesion with the group size. When the
admission of new candidates involves the decision of only one group member, the
group growth causes a loss of cohesion even for infinitesimal levels of noise.
However, when admissions require a consensus of several group members, there is
a critical noise level below which the growing group remains cohesive. The
nature of the transition between the cohesive and non-cohesive phases depends
on the model parameters and forms a rich structure reminiscent of critical
phenomena in ferromagnetic materials.",2107.07324v4,physics.soc-ph,2021-07-15 13:48:58+00:00,"[arxiv.Result.Author('Enrico Maria Fenoaltea'), arxiv.Result.Author('Fanyuan Meng'), arxiv.Result.Author('Run-Ran Liu'), arxiv.Result.Author('Matus Medo')]",
467,CommuNety: A Deep Learning System for the Prediction of Cohesive Social Communities,"Effective mining of social media, which consists of a large number of users
is a challenging task. Traditional approaches rely on the analysis of text data
related to users to accomplish this task. However, text data lacks significant
information about the social users and their associated groups. In this paper,
we propose CommuNety, a deep learning system for the prediction of cohesive
social networks using images. The proposed deep learning model consists of
hierarchical CNN architecture to learn descriptive features related to each
cohesive network. The paper also proposes a novel Face Co-occurrence Frequency
algorithm to quantify existence of people in images, and a novel photo ranking
method to analyze the strength of relationship between different individuals in
a predicted social network. We extensively evaluate the proposed technique on
PIPA dataset and compare with state-of-the-art methods. Our experimental
results demonstrate the superior performance of the proposed technique for the
prediction of relationship between different individuals and the cohesiveness
of communities.",2007.14741v1,cs.SI,2020-07-29 11:03:22+00:00,"[arxiv.Result.Author('Syed Afaq Ali Shah'), arxiv.Result.Author('Weifeng Deng'), arxiv.Result.Author('Jianxin Li'), arxiv.Result.Author('Muhammad Aamir Cheema'), arxiv.Result.Author('Abdul Bais')]",
468,Social Cohesion in Autonomous Driving,"Autonomous cars can perform poorly for many reasons. They may have perception
issues, incorrect dynamics models, be unaware of obscure rules of human traffic
systems, or follow certain rules too conservatively. Regardless of the exact
failure mode of the car, often human drivers around the car are behaving
correctly. For example, even if the car does not know that it should pull over
when an ambulance races by, other humans on the road will know and will pull
over. We propose to make socially cohesive cars that leverage the behavior of
nearby human drivers to act in ways that are safer and more socially
acceptable. The simple intuition behind our algorithm is that if all the humans
are consistently behaving in a particular way, then the autonomous car probably
should too. We analyze the performance of our algorithm in a variety of
scenarios and conduct a user study to assess people's attitudes towards
socially cohesive cars. We find that people are surprisingly tolerant of
mistakes that cohesive cars might make in order to get the benefits of driving
in a car with a safer, or even just more socially acceptable behavior.",1808.03845v2,cs.RO,2018-08-11 18:12:56+00:00,"[arxiv.Result.Author('Nicholas C. Landolfi'), arxiv.Result.Author('Anca D. Dragan')]",
469,On the Role of Social Identity and Cohesion in Characterizing Online Social Communities,"Two prevailing theories for explaining social group or community structure
are cohesion and identity. The social cohesion approach posits that social
groups arise out of an aggregation of individuals that have mutual
interpersonal attraction as they share common characteristics. These
characteristics can range from common interests to kinship ties and from social
values to ethnic backgrounds. In contrast, the social identity approach posits
that an individual is likely to join a group based on an intrinsic
self-evaluation at a cognitive or perceptual level. In other words group
members typically share an awareness of a common category membership.
  In this work we seek to understand the role of these two contrasting theories
in explaining the behavior and stability of social communities in Twitter. A
specific focal point of our work is to understand the role of these theories in
disparate contexts ranging from disaster response to socio-political activism.
We extract social identity and social cohesion features-of-interest for large
scale datasets of five real-world events and examine the effectiveness of such
features in capturing behavioral characteristics and the stability of groups.
We also propose a novel measure of social group sustainability based on the
divergence in group discussion. Our main findings are: 1) Sharing of social
identities (especially physical location) among group members has a positive
impact on group sustainability, 2) Structural cohesion (represented by high
group density and low average shortest path length) is a strong indicator of
group sustainability, and 3) Event characteristics play a role in shaping group
sustainability, as social groups in transient events behave differently from
groups in events that last longer.",1212.0141v1,cs.SI,2012-12-01 18:03:33+00:00,"[arxiv.Result.Author('Hemant Purohit'), arxiv.Result.Author('Yiye Ruan'), arxiv.Result.Author('David Fuhry'), arxiv.Result.Author('Srinivasan Parthasarathy'), arxiv.Result.Author('Amit Sheth')]",
470,Triangles to Capture Social Cohesion,"Although community detection has drawn tremendous amount of attention across
the sciences in the past decades, no formal consensus has been reached on the
very nature of what qualifies a community as such. In this article we take an
orthogonal approach by introducing a novel point of view to the problem of
overlapping communities. Instead of quantifying the quality of a set of
communities, we choose to focus on the intrinsic community-ness of one given
set of nodes. To do so, we propose a general metric on graphs, the cohesion,
based on counting triangles and inspired by well established sociological
considerations. The model has been validated through a large-scale online
experiment called Fellows in which users were able to compute their social
groups on Face- book and rate the quality of the obtained groups. By observing
those ratings in relation to the cohesion we assess that the cohesion is a
strong indicator of users subjective perception of the community-ness of a set
of people.",1107.3231v1,cs.SI,2011-07-16 13:00:12+00:00,"[arxiv.Result.Author('Adrien Friggeri'), arxiv.Result.Author('Guillaume Chelius'), arxiv.Result.Author('Eric Fleury')]",N&deg; RR-7686 (2011)
471,The role of neighbours selection on cohesion and order of swarms,"We introduce a multi-agent model for exploring how selection of neighbours
determines some aspects of order and cohesion in swarms. The model algorithm
states that every agents' motion seeks for an optimal distance from the nearest
topological neighbour encompassed in a limited attention field. Despite the
great simplicity of the implementation, varying the amplitude of the attention
landscape, swarms pass from cohesive and regular structures towards fragmented
and irregular configurations. Interestingly, this movement rule is an ideal
candidate for implementing the selfish herd hypothesis which explains
aggregation of alarmed group of social animals.",1309.5362v2,q-bio.QM,2013-09-20 19:13:25+00:00,"[arxiv.Result.Author('A. M. Calvão'), arxiv.Result.Author('E. Brigatti')]",
472,Cohesion and Coalition Formation in the European Parliament: Roll-Call Votes and Twitter Activities,"We study the cohesion within and the coalitions between political groups in
the Eighth European Parliament (2014--2019) by analyzing two entirely different
aspects of the behavior of the Members of the European Parliament (MEPs) in the
policy-making processes. On one hand, we analyze their co-voting patterns and,
on the other, their retweeting behavior. We make use of two diverse datasets in
the analysis. The first one is the roll-call vote dataset, where cohesion is
regarded as the tendency to co-vote within a group, and a coalition is formed
when the members of several groups exhibit a high degree of co-voting agreement
on a subject. The second dataset comes from Twitter; it captures the retweeting
(i.e., endorsing) behavior of the MEPs and implies cohesion (retweets within
the same group) and coalitions (retweets between groups) from a completely
different perspective.
  We employ two different methodologies to analyze the cohesion and coalitions.
The first one is based on Krippendorff's Alpha reliability, used to measure the
agreement between raters in data-analysis scenarios, and the second one is
based on Exponential Random Graph Models, often used in social-network
analysis. We give general insights into the cohesion of political groups in the
European Parliament, explore whether coalitions are formed in the same way for
different policy areas, and examine to what degree the retweeting behavior of
MEPs corresponds to their co-voting patterns. A novel and interesting aspect of
our work is the relationship between the co-voting and retweeting patterns.",1608.04917v2,cs.CL,2016-08-17 10:10:14+00:00,"[arxiv.Result.Author('Darko Cherepnalkoski'), arxiv.Result.Author('Andreas Karpf'), arxiv.Result.Author('Igor Mozetic'), arxiv.Result.Author('Miha Grcar')]","PLoS ONE 11(11): e0166586, 2016"
473,News Cohesiveness: an Indicator of Systemic Risk in Financial Markets,"Motivated by recent financial crises significant research efforts have been
put into studying contagion effects and herding behaviour in financial markets.
Much less has been said about influence of financial news on financial markets.
We propose a novel measure of collective behaviour in financial news on the
Web, News Cohesiveness Index (NCI), and show that it can be used as a systemic
risk indicator. We evaluate the NCI on financial documents from large Web news
sources on a daily basis from October 2011 to July 2013 and analyse the
interplay between financial markets and financially related news. We
hypothesized that strong cohesion in financial news reflects movements in the
financial markets. Cohesiveness is more general and robust measure of systemic
risk expressed in news, than measures based on simple occurrences of specific
terms. Our results indicate that cohesiveness in the financial news is highly
correlated with and driven by volatility on the financial markets.",1402.3483v1,cs.SI,2014-02-14 14:54:48+00:00,"[arxiv.Result.Author('Matija Piškorec'), arxiv.Result.Author('Nino Antulov-Fantulin'), arxiv.Result.Author('Petra Kralj Novak'), arxiv.Result.Author('Igor Mozetič'), arxiv.Result.Author('Miha Grčar'), arxiv.Result.Author('Irena Vodenska'), arxiv.Result.Author('Tomislav Šmuc')]",Scientific Reports 4: 5038 (2014)
474,"Egomunities, Exploring Socially Cohesive Person-based Communities","In the last few years, there has been a great interest in detecting
overlapping communities in complex networks, which is understood as dense
groups of nodes featuring a low outbound density. To date, most methods used to
compute such communities stem from the field of disjoint community detection by
either extending the concept of modularity to an overlapping context or by
attempting to decompose the whole set of nodes into several possibly
overlapping subsets. In this report we take an orthogonal approach by
introducing a metric, the cohesion, rooted in sociological considerations. The
cohesion quantifies the community-ness of one given set of nodes, based on the
notions of triangles - triplets of connected nodes - and weak ties, instead of
the classical view using only edge density. A set of nodes has a high cohesion
if it features a high density of triangles and intersects few triangles with
the rest of the network. As such, we introduce a numerical characterization of
communities: sets of nodes featuring a high cohesion. We then present a new
approach to the problem of overlapping communities by introducing the concept
of ego-munities, which are subjective communities centered around a given node,
specifically inside its neighborhood. We build upon the cohesion to construct a
heuristic algorithm which outputs a node's ego-munities by attempting to
maximize their cohesion. We illustrate the pertinence of our method with a
detailed description of one person's ego-munities among Facebook friends. We
finally conclude by describing promising applications of ego-munities such as
information inference and interest recommendations, and present a possible
extension to cohesion in the case of weighted networks.",1102.2623v2,cs.SI,2011-02-13 19:08:20+00:00,"[arxiv.Result.Author('Adrien Friggeri'), arxiv.Result.Author('Guillaume Chelius'), arxiv.Result.Author('Eric Fleury')]",
475,Beyond Nadel's Paradox. A computational approach to structural and cultural dimensions of social cohesion,"Nadel's Paradox states that it is not possible to take into account
simultaneously cultural and relational dimensions of social structure. By means
of a simple computational model, the authors explore a dynamic perspective of
the concept of social cohesion that enables the integration of both structural
and cultural dimensions in the same analysis. The design of the model
reproduces a causal path from the level of conflict suffered by a population to
variations on its social cohesiveness, observed both from a structural and
cognitive viewpoint. Submitted to sudden variations on its environmental
conflict level, the model is able to reproduce certain characteristics
previously observed in real populations under situations of emergency or
crisis.",0807.2880v1,physics.soc-ph,2008-07-17 21:03:30+00:00,"[arxiv.Result.Author('Sergi Lozano'), arxiv.Result.Author('Javier Borge'), arxiv.Result.Author('Alex Arenas'), arxiv.Result.Author('Jose Luis Molina')]",
476,"On the emergence of an ""intention field"" for socially cohesive agents","We argue that when a social convergence mechanism exists and is strong
enough, one should expect the emergence of a well defined ""field"", i.e. a
slowly evolving, local quantity around which individual attributes fluctuate in
a finite range. This condensation phenomenon is well illustrated by the
Deffuant-Weisbuch opinion model for which we provide a natural extension to
allow for spatial heterogeneities. We show analytically and numerically that
the resulting dynamics of the emergent field is a noisy diffusion equation that
has a slow dynamics. This random diffusion equation reproduces the long-ranged,
logarithmic decrease of the correlation of spatial voting patterns empirically
found in [1, 2]. Interestingly enough, we find that when the social cohesion
mechanism becomes too weak, cultural cohesion breaks down completely, in the
sense that the distribution of intentions/opinions becomes infinitely broad. No
emerging field exists in this case. All these analytical findings are confirmed
by numerical simulations of an agent-based model.",1311.0810v2,physics.soc-ph,2013-11-04 18:42:52+00:00,"[arxiv.Result.Author('Jean-Philippe Bouchaud'), arxiv.Result.Author('Christian Borghesi'), arxiv.Result.Author('Pablo Jensen')]",
477,Spatio-Temporal Small Worlds for Decentralized Information Retrieval in Social Networking,"We discuss foundations and options for alternative, agent-based information
retrieval (IR) approaches in Social Networking, especially Decentralized and
Mobile Social Networking scenarios. In addition to usual semantic contexts,
these approaches make use of long-term social and spatio-temporal contexts in
order to satisfy conscious as well as unconscious information needs according
to Human IR heuristics. Using a large Twitter dataset, we investigate these
approaches and especially investigate the question in how far spatio-temporal
contexts can act as a conceptual bracket implicating social and semantic
cohesion, giving rise to the concept of Spatio-Temporal Small Worlds.",1209.2868v1,cs.SI,2012-09-13 12:11:10+00:00,"[arxiv.Result.Author('Georg Groh'), arxiv.Result.Author('Florian Straub'), arxiv.Result.Author('Benjamin Koster')]",
478,"Social cohesion, structural holes, and a tale of two measures","In the social sciences, the debate over the structural foundations of social
capital has long vacillated between two positions on the relative benefits
associated with two types of social structures: closed structures, rich in
third-party relationships, and open structures, rich in structural holes and
brokerage opportunities. In this paper, we engage with this debate by focusing
on the measures typically used for formalising the two conceptions of social
capital: clustering and effective size. We show that these two measures are
simply two sides of the same coin, as they can be expressed one in terms of the
other through a simple functional relation. Building on this relation, we then
attempt to reconcile closed and open structures by proposing a new measure,
Simmelian brokerage, that captures opportunities of brokerage between otherwise
disconnected cohesive groups of contacts. Implications of our findings for
research on social capital and complex networks are discussed.",1211.0719v2,physics.soc-ph,2012-11-04 20:46:57+00:00,"[arxiv.Result.Author('Vito Latora'), arxiv.Result.Author('Vincenzo Nicosia'), arxiv.Result.Author('Pietro Panzarasa')]","J. Stat. Phys. 151 (3-4), 745 (2013)"
479,"Cohesion, consensus and extreme information in opinion dynamics","Opinion formation is an important element of social dynamics. It has been
widely studied in the last years with tools from physics, mathematics and
computer science. Here, a continuous model of opinion dynamics for multiple
possible choices is analysed. Its main features are the inclusion of
disagreement and possibility of modulating information, both from one and
multiple sources. The interest is in identifying the effect of the initial
cohesion of the population, the interplay between cohesion and information
extremism, and the effect of using multiple sources of information that can
influence the system. Final consensus, especially with external information,
depends highly on these factors, as numerical simulations show. When no
information is present, consensus or segregation is determined by the initial
cohesion of the population. Interestingly, when only one source of information
is present, consensus can be obtained, in general, only when this is extremely
mild, i.e. there is not a single opinion strongly promoted, or in the special
case of a large initial cohesion and low information exposure. On the contrary,
when multiple information sources are allowed, consensus can emerge with an
information source even when this is not extremely mild, i.e. it carries a
strong message, for a large range of initial conditions.",1302.4872v1,physics.soc-ph,2013-02-20 11:02:43+00:00,"[arxiv.Result.Author('Alina Sîrbu'), arxiv.Result.Author('Vittorio Loreto'), arxiv.Result.Author('Vito D. P. Servedio'), arxiv.Result.Author('Francesca Tria')]","ADVANCES IN COMPLEX SYSTEMS online, 1350035 (2013)"
480,How do Software Ecosystems Co-Evolve? A view from OpenStack and beyond,"Much research that analyzes the evolution of a software ecosystem is confined
to its own boundaries. Evidence shows, however, that software ecosystems
co-evolve independently with other software ecosystems. In other words,
understanding the evolution of a software ecosystem requires an especially
astute awareness of its competitive landscape and much consideration for other
software ecosystems in related markets. A software ecosystem does not evolve in
insulation but with other software ecosystems. In this research, we analyzed
the OpenStack software ecosystem with a focal perspective that attempted to
understand its evolution as a function of other software ecosystems. We
attempted to understand and explain the evolution of OpenStack in relation to
other software ecosystems in the cloud computing market. Our findings add to
theoretical knowledge in software ecosystems by identifying and discussing
seven different mechanisms by which software ecosystems mutually influence each
other: sedimentation and embeddedness of business relationships, strategic
management of the portfolio of business relationships, firms values and
reputation as a partner, core technological architecture, design of the APIs,
competitive replication of functionality and multi-homing. Research addressing
the evolution of software ecosystem should, therefore, acknowledge that
software ecosystems entangle with other software ecosystems in multiple ways,
even with competing ones. A rigorous analysis of the evolution of a software
ecosystem should not be solely confined to its inner boundaries.",1808.06663v1,cs.SE,2018-08-20 19:28:16+00:00,"[arxiv.Result.Author('José Apolinário Teixeira'), arxiv.Result.Author('Sami Hyrynsalmi')]",
481,Distributed Software Evolution: a Survey,"Distribution can be a feature of the software evolution process. In other
words, temporally and spatially distributed teams and organizations can develop
and work on a software application. The simplest case is to outsource
production and employ workforce at distributed sites so that multiple
distributed teams can work on a project within a parallel framework. If this
distribution is global, it will be called the global software evolution or
development. A higher level of distribution is defined as decentralization and
decentralized software evolution, which means that software development can be
independent of the initial provider. It also means that software execution is
independent of the initial provider and the initial system so that the software
application can easily be reused in different and new projects. However, the
high level architecture is managed within a practically centralized framework
in the decentralized software evolution. Most of the large scale open-source
projects are exemplars of this level. In terms of distribution, there is a
higher level of decentralized software evolution called ""distributed cognition
and leadership"". At this level of distribution, all system levels evolve within
a distributed framework, and there are no centralized points in the project
network and its evolution process. Some open-source software applications are
the exemplars of this last level. Not only is the distributed software
evolution faced with certain challenges and opportunities to reach its goals,
but it has also caused some challenges and opportunities in other fields. This
paper conducts a general review of the distributed software evolution. For this
purpose, the paper first addresses the importance of the distributed software
evolution, and then introduces its noteworthy paradigms.",2204.14036v1,cs.SE,2022-04-28 06:37:33+00:00,[arxiv.Result.Author('Mohammad Reza Besharati')],
482,Problems in Systematic Application of Software Metrics and Possible Solution,"Systematic application of software metric techniques can lead to significant
improvements of the quality of a final software product. However, there is
still the evident lack of wider utilization of software metrics techniques and
tools due to many reasons. In this paper we investigate some limitations of
contemporary software metrics tools and then propose construction of a new tool
that would solve some of the problems. We describe the promising prototype, its
internal structure, and then focus on its independency of the input language.",1311.3852v1,cs.SE,2013-11-15 13:54:57+00:00,"[arxiv.Result.Author('Gordana Rakic'), arxiv.Result.Author('Zoran Budimac')]",
483,Transforming Platform-Independent to Platform-Specific Component and Connector Software Architecture Models,"Combining component & connector architecture
descriptionlanguageswithcomponentbehaviormodelinglanguages enables modeling
great parts of software architectures platformindependently. Nontrivial systems
typically contain components with programming language behavior descriptions to
interface with APIs. These components tie the complete software architecture to
a specific platform and thus hamper reuse. Previous work on software
architecture reuse with multiple platforms either requires platform-specific
handcrafting or the effort of explicit platform models. We present an automated
approach to transform platform-independent, logical software architectures into
architectures with platform-specific components. This approach introduces
abstract components to the platform-independent architecture and refines the se
with components specific to the target platform prior to code generation.
Consequently, a single logical software architecture model can be reused with
multiple target platforms, which increases architecture maturity and reduces
the maintenance effort of multiple similar software architectures.",1511.05365v1,cs.SE,2015-11-17 12:02:50+00:00,"[arxiv.Result.Author('Jan O. Ringert'), arxiv.Result.Author('Bernhard Rumpe'), arxiv.Result.Author('Andreas Wortmann')]",
484,The Software Garden,"This paper describes a practical method of developing custom HPC software
products using a store of libraries and tools independent from the OS called a
""garden"". All dependencies from the product to libraries of the underlying OS
distribution are carefully severed, isolating the package from instability due
to system upgrades and ensuring repeatable deterministic builds on different
flavors of Linux. The method also guarantees multiple versions of a software
product may exist together and function correctly, greatly facilitating upgrade
and rollback. The method is the first known system to expose all past software
versions to the designer, and support deterministic single-package rollback
without affecting other installed software. An application of this method for
building a high performance trading system in C++ is presented.",1305.0152v1,cs.SE,2013-05-01 12:14:14+00:00,[arxiv.Result.Author('Federico D. Sacerdoti')],
485,Deriving a Usage-Independent Software Quality Metric,"Context:The extent of post-release use of software affects the number of
faults, thus biasing quality metrics and adversely affecting associated
decisions. The proprietary nature of usage data limited deeper exploration of
this subject in the past. Objective: To determine how software faults and
software use are related and how an accurate quality measure can be designed.
Method: New users, usage intensity, usage frequency, exceptions, and release
date and duration measured for complex proprietary mobile applications for
Android and iOS. Utilized Bayesian Network and Random Forest models to explain
the interrelationships and to derive the usage independent release quality
measure. Investigated the interrelationship among various code complexity
measures, usage (downloads), and number of issues for 520 NPM packages and
derived a usage-independent quality measure from these analyses, applied it on
4430 popular NPM packages to construct timelines for comparing the perceived
quality (issues) and our derived measure of quality for these packages.Results:
We found the number of new users to be the primary factor determining the
number of exceptions, and found no direct link between the intensity and
frequency of software usage and software faults. Release quality expressed as
crashes per user was independent of other usage-related predictors, thus
serving as a usage independent measure of software quality. Usage also affected
quality in NPM, where downloads were strongly associated with numbers of
issues, even after taking the other code complexity measures into
consideration. Conclusions: We expect our result and our proposed quality
measure will help gauge release quality of a software more accurately and
inspire further research in this area.",2002.09989v1,cs.SE,2020-02-23 21:19:36+00:00,"[arxiv.Result.Author('Tapajit Dey'), arxiv.Result.Author('Audris Mockus')]",
486,Continuous API Evolution in Heterogenous Enterprise Software Systems,"The ability to independently deploy parts of a software system is one of the
cornerstones of modern software development, and allows for these parts to
evolve independently and at different speeds.
  A major challenge of such independent deployment, however, is to ensure that
despite their individual evolution, the interfaces between interacting parts
remain compatible. This is especially important for enterprise software
systems, which are often highly integrated and based on heterogenous IT
infrastructures.
  Although several approaches for interface evolution have been proposed, many
of these rely on the developer to adhere to certain rules, but provide little
guidance for doing so. In this paper, we present an approach for interface
evolution that is easy to use for developers, and also addresses typical
challenges of heterogenous enterprise software, especially legacy system
integration.",2103.11397v1,cs.SE,2021-03-21 13:46:43+00:00,"[arxiv.Result.Author('Holger Knoche'), arxiv.Result.Author('Wilhelm Hasselbring')]",
487,Software is a directed multigraph (and so is software process),"For a software system, its architecture is typically defined as the
fundamental organization of the system incorporated by its components, their
relationships to one another and their environment, and the principles
governing their design. If contributed to by the artifacts coresponding to
engineering processes that govern the system's evolution, the definition gets
natually extended into the architecture of software and software process.
Obviously, as long as there were no software systems, managing their
architecture was no problem at all; when there were only small systems,
managing their architecture became a mild problem; and now we have gigantic
software systems, and managing their architecture has become an equally
gigantic problem (to paraphrase Edsger Dijkstra). In this paper we propose a
simple, yet we believe effective, model for organizing architecture of software
systems. First of all we postulate that only a hollistic approach that supports
continuous integration and verification for all software and software process
architectural artifacts is the one worth taking. Next we indicate a graph-based
model that not only allows collecting and maintaining the architectural
knowledge in respect to both software and software process, but allows to
conveniently create various quantitive metric to asses their respective quality
or maturity. Such model is actually independent of the development
methodologies that are currently in-use, that is it could well be applied for
projects managed in an adaptive, as well as in a formal approach. Eventually we
argue that the model could actually be implemented by already existing tools,
in particular graph databases are a convenient implementation of architectural
repository.",1103.4056v1,cs.SE,2011-03-21 15:37:38+00:00,"[arxiv.Result.Author('Robert Dabrowski'), arxiv.Result.Author('Krzysztof Stencel'), arxiv.Result.Author('Grzegorz Timoszuk')]",
488,Context Oriented Software Middleware,"Our middleware approach, Context-Oriented Software Middleware (COSM),
supports context-dependent software with self-adaptability and dependability in
a mobile computing environment. The COSM-middleware is a generic and
platform-independent adaptation engine, which performs a runtime composition of
the software's context-dependent behaviours based on the execution contexts.
Our middleware distinguishes between the context-dependent and
context-independent functionality of software systems. This enables the
COSM-middleware to adapt the application behaviour by composing a set of
context-oriented components, that implement the context-dependent functionality
of the software. Accordingly, the software dependability is achieved by
considering the functionality of the COSM-middleware and the adaptation
impact/costs. The COSM-middleware uses a dynamic policy-based engine to
evaluate the adaptation outputs and verify the fitness of the adaptation output
with the application's objectives, goals and the architecture quality
attributes. These capabilities are demonstrated through an empirical evaluation
of a case study implementation.",1901.04016v1,cs.SE,2019-01-13 16:57:38+00:00,[arxiv.Result.Author('Basel Magableh')],
489,The Unnecessity of Assuming Statistically Independent Tests in Bayesian Software Reliability Assessments,"When assessing a software-based system, the results of Bayesian statistical
inference on operational testing data can provide strong support for software
reliability claims. For inference, this data (i.e. software successes and
failures) is often assumed to arise in an independent, identically distributed
(i.i.d.) manner. In this paper we show how conservative Bayesian approaches
make this assumption unnecessary, by incorporating one's doubts about the
assumption into the assessment. We derive conservative confidence bounds on a
system's probability of failure on demand (pfd), when operational testing
reveals no failures. The generality and utility of the confidence bounds are
illustrated in the assessment of a nuclear power-plant safety-protection
system, under varying levels of skepticism about the i.i.d. assumption. The
analysis suggests that the i.i.d. assumption can make Bayesian reliability
assessments extremely optimistic - such assessments do not explicitly account
for how software can be very likely to exhibit no failures during extensive
operational testing despite the software's pfd being undesirably large.",2208.00462v2,cs.SE,2022-07-31 16:23:03+00:00,"[arxiv.Result.Author('Kizito Salako'), arxiv.Result.Author('Xingyu Zhao')]",
490,Delta-oriented Architectural Variability Using MontiCore,"Modeling of software architectures is a fundamental part of software
development processes. Reuse of software components and early analysis of
software topologies allow the reduction of development costs and increases
software quality. Integrating variability modeling concepts into architecture
description languages (ADLs) is essential for the development of diverse
software systems with high demands on software quality. In this paper, we
present the integration of delta modeling into the existing ADL MontiArc. Delta
modeling is a language-independent variability modeling approach supporting
proactive, reactive and extractive product line development. We show how
?-MontiArc, a language for explicit modeling of architectural variability based
on delta modeling, is implemented as domain-specific language (DSL) using the
DSL development framework MontiCore. We also demonstrate how MontiCore's
language reuse mechanisms provide efficient means to derive an implementation
of ?-MontiArc tool implementation. We evaluate ?-Monti-Arc by comparing it with
annotative variability modeling.",1409.2317v1,cs.SE,2014-09-08 12:13:16+00:00,"[arxiv.Result.Author('Arne Haber'), arxiv.Result.Author('Thomas Kutz'), arxiv.Result.Author('Holger Rendel'), arxiv.Result.Author('Bernhard Rumpe'), arxiv.Result.Author('Ina Schaefer')]",
491,"Research Software Development & Management in Universities: Case Studies from Manchester's RSDS Group, Illinois' NCSA, and Notre Dame's CRC","Modern research in the sciences, engineering, humanities, and other fields
depends on software, and specifically, research software. Much of this research
software is developed in universities, by faculty, postdocs, students, and
staff. In this paper, we focus on the role of university staff. We examine
three different, independently-developed models under which these staff are
organized and perform their work, and comparatively analyze these models and
their consequences on the staff and on the software, considering how the
different models support software engineering practices and processes. This
information can be used by software engineering researchers to understand the
practices of such organizations and by universities who want to set up similar
organizations and to better produce and maintain research software.",1903.00732v1,cs.SE,2019-03-02 16:40:54+00:00,"[arxiv.Result.Author('Daniel S. Katz'), arxiv.Result.Author('Kenton McHenry'), arxiv.Result.Author('Caleb Reinking'), arxiv.Result.Author('Robert Haines')]",
492,Software Supply Chain Map: How Reuse Networks Expand,"Clone-and-own is a typical code reuse approach because of its simplicity and
efficiency. Cloned software components are maintained independently by a new
owner. These clone-and-own operations can be occurred sequentially, that is,
cloned components can be cloned again and owned by other new owners on the
supply chain. In general, code reuse is not documented well, consequently,
appropriate changes like security patches cannot be propagated to descendant
software projects. However, the OpenChain Project defined identifying and
tracking source code reuses as responsibilities of FLOSS software staffs. Hence
supporting source code reuse awareness is in a real need. This paper studies
software reuse relations in FLOSS ecosystem. Technically, clone-and-own reuses
of source code can be identified by file-level clone set detection. Since
change histories are associated with files, we can determine origins and
destinations in reusing across multiple software by considering times. By
building software supply chain maps, we find that clone-and-own is prevalent in
FLOSS development, and set of files are reused widely and repeatedly. These
observations open up future challenges of maintaining and tracking global
software genealogies.",2204.06531v1,cs.SE,2022-04-13 17:22:41+00:00,"[arxiv.Result.Author('Hideaki Hata'), arxiv.Result.Author('Takashi Ishio')]",
493,An Integrated Software-based Solution for Modular and Self-independent Networked Robot,"An integrated software-based solution for a modular and self-independent
networked robot is introduced. The wirelessly operatable robot has been
developed mainly for autonomous monitoring works with full control over web.
The integrated software solution covers three components : a) the digital
signal processing unit for data retrieval and monitoring system; b) the
externally executable codes for control system; and c) the web programming for
interfacing the end-users with the robot. It is argued that this integrated
software-based approach is crucial to realize a flexible, modular and low
development cost mobile monitoring apparatus.",0812.0070v1,cs.RO,2008-11-29 12:52:54+00:00,"[arxiv.Result.Author('I. Firmansyah'), arxiv.Result.Author('Z. Akbar'), arxiv.Result.Author('B. Hermanto'), arxiv.Result.Author('L. T. Handoko')]",
494,Towards Modal Software Engineering,"In this paper we introduce the notion of Modal Software Engineering:
automatically turning sequential, deterministic programs into semantically
equivalent programs efficiently operating on inputs coming from multiple
overlapping worlds. We are drawing an analogy between modal logics, and
software application domains where multiple sets of inputs (multiple worlds)
need to be processed efficiently. Typically those sets highly overlap, so
processing them independently would involve a lot of redundancy, resulting in
lower performance, and in many cases intractability. Three application domains
are presented: reasoning about feature-based variability of Software Product
Lines (SPLs), probabilistic programming, and approximate programming.",2102.02966v2,cs.SE,2021-02-05 02:45:29+00:00,[arxiv.Result.Author('Ramy Shahin')],
495,An Agile Method for E-Service Composition,"Nowadays, application of Service Oriented Architecture is increasing rapidly;
especially since introduction of distributed electronic services on the web.
SOA software has a modular manner and works as a collaboration of independent
software components. As a result, e-service approach is sufficient for software
with independent components, each of which may be developed by a different
company. Such software components and their cooperation form a composite
service. Agile methodologies are the best candidate for developing small
software components. Composite services and its building blocks are small
pieces of software, making agile methodology a perfect fit for their
development. In this paper, we introduce an agile method for service
composition, inspired by agile patterns and practices. Therefore, across the
agile manifesto, we can develop low cost, high quality composite services
quickly using this method.",1203.3085v1,cs.SE,2012-03-14 13:52:42+00:00,"[arxiv.Result.Author('Pouya Fatehi'), arxiv.Result.Author('Seyyed Mohsen Hashemi')]",
496,Hierarchical Small Worlds in Software Architecture,"In this paper, we present a complex network approach to the study of software
engineering. We have found universal network patterns in a large collection of
object-oriented (OO) software systems written in C++ and Java. All the systems
analyzed here display the small-world behavior, that is, the average distance
between any pair of classes is very small even when coupling is low and
cohesion is high. In addition, the structure of OO software is a very
heterogeneous network characterized by a degree distribution following a
power-law with similar exponents. We have investigated the origin of these
universal patterns. Our study suggests that some features of OO programing
languages, like encapsulation, seem to be largely responsible for the
small-world behavior. On the other hand, software heterogeneity is largely
independent of the purpose and objectives of the particular system under study
and appears to be related to a pattern of constrained growth. A number of
software engineering topics may benefit from the present approach, including
empirical software measurement and program comprehension.",cond-mat/0307278v2,cond-mat.dis-nn,2003-07-11 11:33:36+00:00,"[arxiv.Result.Author('Sergi Valverde'), arxiv.Result.Author('Ricard V. Sole')]",
497,The Sensemaking-Coevolution-Implementation Theory of Software Design,"Understanding software design practice is critical to understanding modern
information systems development. New developments in empirical software
engineering, information systems design science and the interdisciplinary
design literature combined with recent advances in process theory and
testability have created a situation ripe for innovation. Consequently, this
paper utilizes these breakthroughs to formulate a process theory of software
design practice: Sensemaking-Coevolution-Implementation Theory explains how
complex software systems are created by collocated software development teams
in organizations. It posits that an independent agent (design team) creates a
software system by alternating between three activities: organizing their
perceptions about the context, mutually refining their understandings of the
context and design space, and manifesting their understanding of the design
space in a technological artifact. This theory development paper defines and
illustrates Sensemaking-Coevolution-Implementation Theory, grounds its concepts
and relationships in existing literature, conceptually evaluates the theory and
situates it in the broader context of information systems development.",1302.4061v1,cs.SE,2013-02-17 12:09:46+00:00,[arxiv.Result.Author('Paul Ralph')],"Science of Computer Programming Volume 101, 1 April 2015, Pages
  21-41"
498,Empowered and Embedded: Ethics and Agile Processes,"In this article we focus on the structural aspects of the development of
ethical software, and argue that ethical considerations need to be embedded
into the (agile) software development process. In fact, we claim that agile
processes of software development lend themselves specifically well for this
endeavour. First, we contend that ethical evaluations need to go beyond the use
of software products and include an evaluation of the software itself. This
implies that software engineers influence peoples' lives through the features
of their designed products. Embedded values are thus approached best by
software engineers themselves. Therefore, we put emphasis on the possibility to
implement ethical deliberations in already existing and well established agile
software development processes. Our approach relies on software engineers
making their own judgments throughout the entire development process to ensure
that technical features and ethical evaluation can be addressed adequately to
transport and foster desirable values and norms. We argue that agile software
development processes may help the implementation of ethical deliberation for
five reasons: 1) agile methods are widely spread, 2) their emphasis on flat
hierarchies promotes independent thinking, 3) their reliance on existing team
structures serve as an incubator for deliberation, 4) agile development
enhances object-focused techno-ethical realism, and, finally, 5) agile
structures provide a salient endpoint to deliberation.",2107.07249v1,cs.SE,2021-07-15 11:14:03+00:00,"[arxiv.Result.Author('Niina Zuber'), arxiv.Result.Author('Severin Kacianka'), arxiv.Result.Author('Jan Gogoll'), arxiv.Result.Author('Alexander Pretschner'), arxiv.Result.Author('Julian Nida-Rümelin')]",
499,xSDK Foundations: Toward an Extreme-scale Scientific Software Development Kit,"Extreme-scale computational science increasingly demands multiscale and
multiphysics formulations. Combining software developed by independent groups
is imperative: no single team has resources for all predictive science and
decision support capabilities. Scientific libraries provide high-quality,
reusable software components for constructing applications with improved
robustness and portability. However, without coordination, many libraries
cannot be easily composed. Namespace collisions, inconsistent arguments, lack
of third-party software versioning, and additional difficulties make
composition costly.
  The Extreme-scale Scientific Software Development Kit (xSDK) defines
community policies to improve code quality and compatibility across
independently developed packages (hypre, PETSc, SuperLU, Trilinos, and
Alquimia) and provides a foundation for addressing broader issues in software
interoperability, performance portability, and sustainability. The xSDK
provides turnkey installation of member software and seamless combination of
aggregate capabilities, and it marks first steps toward extreme-scale
scientific software ecosystems from which future applications can be composed
rapidly with assured quality and scalability.",1702.08425v1,cs.MS,2017-02-27 18:37:36+00:00,"[arxiv.Result.Author('Roscoe Bartlett'), arxiv.Result.Author('Irina Demeshko'), arxiv.Result.Author('Todd Gamblin'), arxiv.Result.Author('Glenn Hammond'), arxiv.Result.Author('Michael Heroux'), arxiv.Result.Author('Jeffrey Johnson'), arxiv.Result.Author('Alicia Klinvex'), arxiv.Result.Author('Xiaoye Li'), arxiv.Result.Author('Lois Curfman McInnes'), arxiv.Result.Author('J. David Moulton'), arxiv.Result.Author('Daniel Osei-Kuffuor'), arxiv.Result.Author('Jason Sarich'), arxiv.Result.Author('Barry Smith'), arxiv.Result.Author('Jim Willenbring'), arxiv.Result.Author('Ulrike Meier Yang')]",
500,"STAR-Vote: A Secure, Transparent, Auditable, and Reliable Voting System","In her 2011 EVT/WOTE keynote, Travis County, Texas County Clerk Dana
DeBeauvoir described the qualities she wanted in her ideal election system to
replace their existing DREs. In response, in April of 2012, the authors,
working with DeBeauvoir and her staff, jointly architected STAR-Vote, a voting
system with a DRE-style human interface and a ""belt and suspenders"" approach to
verifiability. It provides both a paper trail and end-to-end cryptography using
COTS hardware. It is designed to support both ballot-level risk-limiting
audits, and auditing by individual voters and observers. The human interface
and process flow is based on modern usability research. This paper describes
the STAR-Vote architecture, which could well be the next-generation voting
system for Travis County and perhaps elsewhere.",1211.1904v1,cs.CR,2012-11-08 17:06:33+00:00,"[arxiv.Result.Author('Josh Benaloh'), arxiv.Result.Author('Mike Byrne'), arxiv.Result.Author('Philip Kortum'), arxiv.Result.Author('Neal McBurnett'), arxiv.Result.Author('Olivier Pereira'), arxiv.Result.Author('Philip B. Stark'), arxiv.Result.Author('Dan S. Wallach')]",
501,"STAR-Vote: A Secure, Transparent, Auditable, and Reliable Voting System","In her 2011 EVT/WOTE keynote, Travis County, Texas County Clerk Dana
DeBeauvoir described the qualities she wanted in her ideal election system to
replace their existing DREs. In response, in April of 2012, the authors,
working with DeBeauvoir and her staff, jointly architected STAR-Vote, a voting
system with a DRE-style human interface and a ""belt and suspenders"" approach to
verifiability. It provides both a paper trail and end-to-end cryptography using
COTS hardware. It is designed to support both ballot-level risk-limiting
audits, and auditing by individual voters and observers. The human interface
and process flow is based on modern usability research. This paper describes
the STAR-Vote architecture, which could well be the next-generation voting
system for Travis County and perhaps elsewhere.",1211.1904v1,cs.CR,2012-11-08 17:06:33+00:00,"[arxiv.Result.Author('Josh Benaloh'), arxiv.Result.Author('Mike Byrne'), arxiv.Result.Author('Philip Kortum'), arxiv.Result.Author('Neal McBurnett'), arxiv.Result.Author('Olivier Pereira'), arxiv.Result.Author('Philip B. Stark'), arxiv.Result.Author('Dan S. Wallach')]",
502,Risk Automatic Prediction for Social Economy Companies using Camels,"Governments have to supervise and inspect social economy enterprises (SEEs).
However, inspecting all SEEs is not possible due to the large number of SEEs
and the low number of inspectors in general. We proposed a prediction model
based on a machine learning approach. The method was trained with the random
forest algorithm with historical data provided by each SEE. Three consecutive
periods of data were concatenated. The proposed method uses these periods as
input data and predicts the risk of each SEE in the fourth period. The model
achieved 76\% overall accuracy. In addition, it obtained good accuracy in
predicting the high risk of a SEE. We found that the legal nature and the
variation of the past-due portfolio are good predictors of the future risk of a
SEE. Thus, the risk of a SEE in a future period can be predicted by a
supervised machine learning method. Predicting the high risk of a SEE improves
the daily work of each inspector by focusing only on high-risk SEEs.",2210.05052v1,cs.LG,2022-10-10 23:50:02+00:00,"[arxiv.Result.Author('Joseph Gallego-Mejia'), arxiv.Result.Author('Daniela Martin-Vega'), arxiv.Result.Author('Fabio Gonzalez')]",
503,Triviality and the (Supersymmetric) See-Saw,"For the D=5 Majorana neutrino mass operator to have a see-saw ultraviolet
completion that is viable up to the Planck scale, the see-saw scale is bounded
above due to triviality limits on the see-saw couplings. For supersymmetric
see-saw models, with realistic neutrino mass textures, we compare constraints
on the see-saw scale from triviality bounds, with those arising from
experimental limits on induced charged-lepton flavour violation, for both the
CMSSM and for models with split supersymmetry.",hep-ph/0603053v2,hep-ph,2006-03-07 16:47:09+00:00,"[arxiv.Result.Author('Bruce A. Campbell'), arxiv.Result.Author('David W. Maybury')]","JHEP 0704:077,2007"
504,Astronomical Seeing at Maidanak Observatory during the year 2018,"Astronomical seeing measurements were carried out at Maidanak observatory
during the period from August to November 2018 using DIMM (Differential Image
Motion Monitor). The median value of seeing for the entire period was
determined as 0.54 arcseconds. This value was compared to the seeing data of
the period 1996-2002.",2012.08110v1,astro-ph.IM,2020-12-15 06:19:17+00:00,"[arxiv.Result.Author('Y. A. Tillayev'), arxiv.Result.Author('A. M. Azimov'), arxiv.Result.Author('A. R. Hafizov')]",
505,"The see-saw mechanism: neutrino mixing, leptogenesis and lepton flavor violation","The see-saw mechanism to generate small neutrino masses is reviewed. After
summarizing our current knowledge about the low energy neutrino mass matrix we
consider reconstructing the see-saw mechanism. Low energy neutrino physics is
not sufficient to reconstruct see-saw, a feature which we refer to as ``see-saw
degeneracy''. Indirect tests of see-saw are leptogenesis and lepton flavor
violation in supersymmetric scenarios, which together with neutrino mass and
mixing define the framework of see-saw phenomenology. Several examples are
given, both phenomenological and GUT-related. Variants of the see-saw mechanism
like the type II or triplet see-saw are also discussed. In particular, we
compare many general aspects regarding the dependence of LFV on low energy
neutrino parameters in the extreme cases of a dominating conventional see-saw
term or a dominating triplet term. For instance, the absence of mu -> e gamma
or tau -> e gamma in the pure triplet case means that CP is conserved in
neutrino oscillations. Scanning models, we also find that among the decays mu
-> e gamma, tau -> e gamma and tau -> mu gamma the latter one has the largest
branching ratio in (i) SO(10) type I see-saw models and in (ii) scenarios in
which the triplet term dominates in the neutrino mass matrix.",0804.3925v3,hep-ph,2008-04-24 13:44:29+00:00,[arxiv.Result.Author('Werner Rodejohann')],"Pramana 72:217-227,2009"
506,Statistics of turbulence profile at Cerro Tololo,"Results of 3-month continuous monitoring of turbulence profile and seeing at
Cerro Tololo (Chile) in May-July 2002 are presented. Some 28000 low-resolution
profiles were measured by a new MASS single-star turbulence monitor,
accompanied by seeing data from DIMM. The median seeing was 0.95 arcseconds.
The first 500 m contribute 60% to the total seeing, the free-atmosphere median
seeing was 0.55 arcseconds. Free-atmosphere seeing is almost never better than
0.15 arcseconds because there is always some turbulence above 12 km. A 4-day
period of calm upper atmosphere with a stable free-atmosphere seeing of 0.2-0.3
arcseconds was noted. A gain in resolution from adaptive compensation of ground
layer will be 1.7 times typically and 2-3 times during such calm periods.
Correlations of the free-atmosphere turbulence with the wind speed at
tropopause and of the ground-layer turbulence with ground wind are studied.
Temporal evolution of turbulence is characterized by recurrent bursts, their
typical duration increases from 15 minutes in low layers to 1-2 hours in high
layers. The large data base of turbulence profiles can be used to test
meso-scale modeling of astronomical seeing.",astro-ph/0209432v1,astro-ph,2002-09-20 16:32:20+00:00,"[arxiv.Result.Author('A. Tokovinin'), arxiv.Result.Author('S. Baumont'), arxiv.Result.Author('J. Vasquez')]",Mon.Not.Roy.Astron.Soc. 340 (2003) 52
507,The Spectrum of HD 3651B: An Extrasolar Nemesis?,This article has been withdrawn; see astro-ph/0611542,astro-ph/0609556v2,astro-ph,2006-09-20 00:36:50+00:00,[arxiv.Result.Author('Adam J. Burgasser')],
508,Criticality versus q in the 2+1-dimensional $Z_q$ clock model,"Paper has been withdrawn, see comment.",cond-mat/0212255v2,cond-mat.supr-con,2002-12-11 17:32:31+00:00,"[arxiv.Result.Author('J. Hove'), arxiv.Result.Author('A. Sudbo')]",
509,Closedness of the Space of AHE Metrics on 4-Manifolds,See comment above.,math/0012167v2,math.DG,2000-12-18 19:05:21+00:00,[arxiv.Result.Author('Michael T. Anderson')],
510,A Machine Learning Approach to Correcting Atmospheric Seeing in Solar Flare Observations,"Current post-processing techniques for the correction of atmospheric seeing
in solar observations -- such as Speckle interferometry and Phase Diversity
methods -- have limitations when it comes to their reconstructive capabilities
of solar flare observations. This, combined with the sporadic nature of flares
meaning observers cannot wait until seeing conditions are optimal before taking
measurements, means that many ground-based solar flare observations are marred
with bad seeing. To combat this, we propose a method for dedicated flare seeing
correction based on training a deep neural network to learn to correct
artificial seeing from flare observations taken during good seeing conditions.
This model uses transfer learning, a novel technique in solar physics, to help
learn these corrections. Transfer learning is when another network already
trained on similar data is used to influence the learning of the new network.
Once trained, the model has been applied to two flare datasets: one from
AR12157 on 2014/09/06 and one from AR12673 on 2017/09/06. The results show good
corrections to images with bad seeing with a relative error assigned to the
estimate based on the performance of the model. Further discussion takes place
of improvements to the robustness of the error on these estimates.",2011.12814v1,astro-ph.SR,2020-11-25 15:17:26+00:00,"[arxiv.Result.Author('John A. Armstrong'), arxiv.Result.Author('Lyndsay Fletcher')]",
511,Daytime Seeing and Solar Limb Positions,"A method to measure the seeing from video made during drift-scan solar
transits is proposed. The limb of the Sun is projected over a regular grid
evenly spaced. The temporal dispersion of the time intervals among the contacts
between solar limb and grid's rows is proportional to the atmospheric seeing.
Seeing effects on the position of the inflexion point of the limb's luminosity
profile are calculated numerically with Fast Fourier Transform. Observational
examples from Locarno and Paris Observatories are presented to show the
asymmetric contributions of the seeing at the beginning and the end of each
drift-scan transit.",1106.2539v1,astro-ph.IM,2011-06-13 19:58:47+00:00,[arxiv.Result.Author('Costantino Sigismondi')],
512,The effect of aperture and seeing on the visibility of sunspots when using early modern and modern telescopes of modest size,"Using the convolution of seeing and diffraction, the relation between seeing
and aperture in the visibility of sunspots is explored. It is shown that even
telescopes with apertures smaller than 5 centimetres are significantly affected
by seeing. Although larger aperture instruments suffer more from seeing than
smaller ones, their level of detail always remains better under the same
atmospheric conditions.",2208.07244v3,astro-ph.SR,2022-08-15 15:00:51+00:00,"[arxiv.Result.Author('Nicolàs de Hilster'), arxiv.Result.Author('Siebren van der Werf')]",
513,Typical duration of good seeing sequences at Concordia,"Context: The winter seeing at Concordia is essentially bimodal, excellent or
quite poor, with relative proportions that depend on altitude above the snow
surface. This paper studies the temporal behavior of the good seeing sequences.
Aims: An efficient exploitation of extremely good seeing with an adaptive
optics system needs long integrations. It is then important to explore the
temporal distribution of the fraction of time providing excellent seeing.
Methods: Temporal windows of good seeing are created by a simple binary
process. Good or bad. Their autocorrelations are corrected for those of the
existing data sets, since these are not continuous, being often interrupted by
technical problems in addition to the adverse weather gaps. At the end these
corrected autocorrelations provide the typical duration of good seeing
sequences. This study has to be a little detailed as its results depend on the
season, summer or winter. Results: Using a threshold of 0.5 arcsec to define
the ""good seeing"", three characteristic numbers are found to describe the
temporal evolution of the good seeing windows. The first number is the mean
duration of an uninterrupted good seeing sequence: it is $\tau_0=7.5$ hours at
8 m above the ground (15 hours at 20 m). These sequences are randomly
distributed in time, with a negative exponential law of damping time
$\tau_1=29$ hours (at elevation 8 m and 20 m). The third number is the mean
time between two 29 hours episodes. It is T=10 days at 8 m high (5 days at 20
m).",1003.3583v1,astro-ph.IM,2010-03-18 14:09:06+00:00,"[arxiv.Result.Author('Eric Fossat'), arxiv.Result.Author('Eric Aristidi'), arxiv.Result.Author('Karim Agabi'), arxiv.Result.Author('Erick Bondoux'), arxiv.Result.Author('Zalpha Challita'), arxiv.Result.Author('Francois Jeanneaux'), arxiv.Result.Author('Djamel Mekarnia')]",
514,Excellent daytime seeing at Dome Fuji on the Antarctic plateau,"Context. Dome Fuji, the second highest region on the Antarctic plateau, is
expected to have some of the best astronomical seeing on Earth. However, site
testing at Dome Fuji is still in its very early stages.
  Aims. To investigate the astronomical seeing in the free atmosphere above
Dome Fuji, and to determine the height of the surface boundary layer.
  Methods. A Differential Image Motion Monitor was used to measure the seeing
in the visible (472 nm) at a height of 11 m above the snow surface at Dome Fuji
during the austral summer of 2012/2013.
  Results. Seeing below 0.2'' has been observed. The seeing often has a local
minimum of ~0.3'' near 18 h local time. Some periods of excellent seeing, 0.3''
or smaller, were also observed, sometimes extending for several hours at local
midnight. The median seeing is higher, at 0.52''---this large value is believed
to be caused by periods when the telescope was within the turbulent boundary
layer.
  Conclusions. The diurnal variation of the daytime seeing at Dome Fuji is
similar to that reported for Dome C, and the height of the surface boundary
layer is consistent with previous simulations for Dome Fuji. The free
atmosphere seeing is ~0.2'', and the height of the surface boundary layer can
be as low as ~11 m.",1305.5109v1,astro-ph.IM,2013-05-22 12:38:07+00:00,"[arxiv.Result.Author('H. Okita'), arxiv.Result.Author('T. Ichikawa'), arxiv.Result.Author('M. C. B. Ashley'), arxiv.Result.Author('N. Takato')]",
515,Night-time measurements of astronomical seeing at Dome A in Antarctica,"Seeing, the angular size of stellar images blurred by atmospheric turbulence,
is a critical parameter used to assess the quality of astronomical sites.
Median values at the best mid-latitude sites are generally in the range of
0.6--0.8\,arcsec. Sites on the Antarctic plateau are characterized by
comparatively-weak turbulence in the free-atmosphere above a strong but thin
boundary layer. The median seeing at Dome C is estimated to be 0.23--0.36
arcsec above a boundary layer that has a typical height of 30\,m. At Dome A and
F, the only previous seeing measurements were made during daytime. Here we
report the first direct measurements of night-time seeing at Dome A, using a
Differential Image Motion Monitor. Located at a height of just 8\,m, it
recorded seeing as low as 0.13\,arcsec, and provided seeing statistics that are
comparable to those for a 20\,m height at Dome C. It indicates that the
boundary layer was below 8\,m 31\% of the time. At such times the median seeing
was 0.31\,arcsec, consistent with free-atmosphere seeing. The seeing and
boundary layer thickness are found to be strongly correlated with the
near-surface temperature gradient. The correlation confirms a median thickness
of approximately 14\,m for the boundary layer at Dome A, as found from a sonic
radar. The thinner boundary layer makes it less challenging to locate a
telescope above it, thereby giving greater access to the free-atmosphere.",2007.15365v1,astro-ph.IM,2020-07-30 10:36:24+00:00,"[arxiv.Result.Author('Bin Ma'), arxiv.Result.Author('Zhaohui Shang'), arxiv.Result.Author('Yi Hu'), arxiv.Result.Author('Keliang Hu'), arxiv.Result.Author('Yongjiang Wang'), arxiv.Result.Author('Xu Yang'), arxiv.Result.Author('Michael C. B. Ashley'), arxiv.Result.Author('Paul Hickson'), arxiv.Result.Author('Peng Jiang')]","Nature 583, 771-774 (2020)"
516,Gaze-Vergence-Controlled See-Through Vision in Augmented Reality,"Augmented Reality (AR) see-through vision is an interesting research topic
since it enables users to see through a wall and see the occluded objects. Most
existing research focuses on the visual effects of see-through vision, while
the interaction method is less studied. However, we argue that using common
interaction modalities, e.g., midair click and speech, may not be the optimal
way to control see-through vision. This is because when we want to see through
something, it is physically related to our gaze depth/vergence and thus should
be naturally controlled by the eyes. Following this idea, this paper proposes a
novel gaze-vergence-controlled (GVC) see-through vision technique in AR. Since
gaze depth is needed, we build a gaze tracking module with two infrared cameras
and the corresponding algorithm and assemble it into the Microsoft HoloLens 2
to achieve gaze depth estimation. We then propose two different GVC modes for
see-through vision to fit different scenarios. Extensive experimental results
demonstrate that our gaze depth estimation is efficient and accurate. By
comparing with conventional interaction modalities, our GVC techniques are also
shown to be superior in terms of efficiency and more preferred by users.
Finally, we present four example applications of gaze-vergence-controlled
see-through vision.",2207.02645v1,cs.CV,2022-07-06 13:11:34+00:00,"[arxiv.Result.Author('Zhimin Wang'), arxiv.Result.Author('Yuxin Zhao'), arxiv.Result.Author('Feng Lu')]",
517,Vlasov Simulation of Emissive Plasma Sheath with Energy-Dependent Secondary Emission Coefficient and Improved Modeling for Dielectric Charging Effects,"A one dimensional Vlasov Poisson simulation code is employed to investigate
the plasma sheath considering electron induced secondary electron emission
(SEE) and backscattering. The SEE coefficient is commonly treated as constant
in a range of plasma simulations, here improved SEE model of a charged
dielectric wall is constructed which includes the wall charging effect on SEE
coefficient and the energy dependency of SEE coefficient. Pertinent algorithms
to implement above SEE model in plasma simulation are studied in detail. It is
found that the SEE coefficient increases with the amount of negative wall
charges, which in turn reduces the emissive sheath potential. With energy
dependent SEE coefficient, the sheath potential is a nonlinear function of the
plasma electron temperature, as opposed to the linear relation predicted by
classic emissive sheath theory. Simulation combining both wall charging effect
and SEE coefficient energy dependency suggests that the space charged limited
sheath is formed at high plasma electron temperature levels, where both sheath
potential and surface charging saturate. Additionally, different algorithms to
implement the backscattering in kinetic simulation are tested and compared.
Converting backscattered electron to secondary electron via an effective SEE
coefficient barely affects the sheath properties. The simulation results are
shown to be commensurate with the upgraded sheath theory predictions.",2209.09567v1,physics.plasm-ph,2022-09-20 09:13:56+00:00,"[arxiv.Result.Author('Guang-Yu Sun'), arxiv.Result.Author('Shu Zhang'), arxiv.Result.Author('Bao-Hong Guo'), arxiv.Result.Author('An-Bang Sun'), arxiv.Result.Author('Guan-Jun Zhang')]",
518,Leptogenesis and LHC Physics with Type III See-Saw,"The See-Saw mechanism provides a nice way to explain why neutrino masses are
so much lighter than their charged lepton partners. It also provides a nice way
to explain baryon asymmetry in our universe via the leptogenesis mechanism. In
this talk we review leptogenesis and LHC physics in a See-Saw model proposed in
1989, now termed the Type III See-Saw model. In this model, $SU(2)_L$ triplet
leptons are introduced with the neutral particles of the triplets playing the
role of See-Saw. The triplet leptons have charged partners with standard model
gauge interactions resulting in many new features. The gauge interactions of
these particles make it easier for leptognesis with low masses, as low as a TeV
is possible. The gauge interactions also make the production and detection of
triplet leptons at LHC possible. The See-Saw mechanism and leptogenesis due to
Type III See-Saw may be tested at LHC.",0901.1264v2,hep-ph,2009-01-09 16:14:07+00:00,"[arxiv.Result.Author('Shao-Long Chen'), arxiv.Result.Author('Xiao-Gang He')]",
519,Avoiding the gauge heirarchy problem with see-sawed neutrino masses,"We show that the see-saw neutrino mass mechanism can coexist naturally with
an extended gauge symmetry (i.e. without any gauge heirarchy problem) provided
that the gauge symmetry contains gauged lepton number differences. The simplest
such `natural' see-saw models are constructed and their implications for
neutrino anomalies discussed.",hep-ph/0505154v1,hep-ph,2005-05-18 00:16:53+00:00,[arxiv.Result.Author('R. Foot')],Mod.Phys.Lett. A20 (2005) 3035-3044
520,On the F-expanding of Homoclinic class,"We establish a closing property for thin trapped homoclinic classes. Taking
advantage of this property, we proved that if the homoclinic class $H(p)$
admits a dominated splitting $T_{H(p)}M=E\oplus_{<}F$, where $E$ is thin
trapped (see Definition \ref{Def:TP}) and all periodic points homoclinically
related to $p$ are uniformly $F$-expanding at the period (see Definition
\ref{Def:expanding}), then $F$ is expanded (see Definition \ref{Def:TP}).",1710.08487v1,math.DS,2017-10-23 20:06:47+00:00,"[arxiv.Result.Author('Wanlou Wu'), arxiv.Result.Author('Bo Li')]",
521,Catfish Effect Between Internal and External Attackers:Being Semi-honest is Helpful,"The consensus protocol named proof of work (PoW) is widely applied by
cryptocurrencies like Bitcoin. Although security of a PoW cryptocurrency is
always the top priority, it is threatened by mining attacks like selfish
mining. Researchers have proposed many mining attack models with one attacker,
and optimized the attacker's strategy. During these mining attacks, an attacker
pursues a higher relative revenue (RR) by wasting a large amount of
computational power of the honest miners at the cost of a small amount of
computational power of himself. In this paper, we propose a mining attack model
with two phases: the original system and the multi-attacker system. It is the
first model to provide both theoretical and quantitative analysis of mining
attacks with two attackers. We explain how the original system turns into the
multi-attacker system by introducing two attackers: the internal attacker and
the external attacker. If both attackers take the attacking strategy selfish
mining, the RR of the internal attacker in multi-attacker system will drop by
up to 31.9% compared with his RR in original system. The external attacker will
overestimate his RR by up to 44.6% in multiattacker system. Unexpected
competitions, auctions between attackers and overestimation of attackers'
influence factor are three main causes of both attackers' dropping RR. We
propose a mining strategy named Partial Initiative Release (PIR) which is a
semi-honest mining strategy in multi-attacker system. In some specific
situations, PIR allows the attacker to get more block reward by launching an
attack in multi-attacker system.",1907.03720v1,cs.CR,2019-06-19 11:25:22+00:00,"[arxiv.Result.Author('Hanqing Liu'), arxiv.Result.Author('Na Ruan'), arxiv.Result.Author('Joseph K. Liu')]",
522,Data Attacks on Power System State Estimation: Limited Adversarial Knowledge vs. Limited Attack Resources,"A class of data integrity attack, known as false data injection (FDI) attack,
has been studied with a considerable amount of work. It has shown that with
perfect knowledge of the system model and the capability to manipulate a
certain number of measurements, the FDI attacks can coordinate measurements
corruption to keep stealth against the bad data detection. However, a more
realistic attack is essentially an attack with limited adversarial knowledge of
the system model and limited attack resources due to various reasons. In this
paper, we generalize the data attacks that they can be pure FDI attacks or
combined with availability attacks (e.g., DoS attacks) and analyze the attacks
with limited adversarial knowledge or limited attack resources. The attack
impact is evaluated by the proposed metrics and the detection probability of
attacks is calculated using the distribution property of data with or without
attacks. The analysis is supported with results from a power system use case.
The results show how important the knowledge is to the attacker and which
measurements are more vulnerable to attacks with limited resources.",1708.08355v1,cs.CR,2017-08-28 14:54:04+00:00,"[arxiv.Result.Author('Kaikai Pan'), arxiv.Result.Author('André Teixeira'), arxiv.Result.Author('Milos Cvetkovic'), arxiv.Result.Author('Peter Palensky')]",
523,Bidirectional RNN-based Few-shot Training for Detecting Multi-stage Attack,"""Feint Attack"", as a new type of APT attack, has become the focus of
attention. It adopts a multi-stage attacks mode which can be concluded as a
combination of virtual attacks and real attacks. Under the cover of virtual
attacks, real attacks can achieve the real purpose of the attacker, as a
result, it often caused huge losses inadvertently. However, to our knowledge,
all previous works use common methods such as Causal-Correlation or Cased-based
to detect outdated multi-stage attacks. Few attentions have been paid to detect
the ""Feint Attack"", because the difficulty of detection lies in the
diversification of the concept of ""Feint Attack"" and the lack of professional
datasets, many detection methods ignore the semantic relationship in the
attack. Aiming at the existing challenge, this paper explores a new method to
solve the problem. In the attack scenario, the fuzzy clustering method based on
attribute similarity is used to mine multi-stage attack chains. Then we use a
few-shot deep learning algorithm (SMOTE&CNN-SVM) and bidirectional Recurrent
Neural Network model (Bi-RNN) to obtain the ""Feint Attack"" chains. ""Feint
Attack"" is simulated by the real attack inserted in the normal causal attack
chain, and the addition of the real attack destroys the causal relationship of
the original attack chain. So we used Bi-RNN coding to obtain the hidden
feature of ""Feint Attack"" chain. In the end, our method achieved the goal to
detect the ""Feint Attack"" accurately by using the LLDoS1.0 and LLDoS2.0 of
DARPA2000 and CICIDS2017 of Canadian Institute for Cybersecurity.",1905.03454v1,cs.CR,2019-05-09 06:38:12+00:00,"[arxiv.Result.Author('Di Zhao'), arxiv.Result.Author('Jiqiang Liu'), arxiv.Result.Author('Jialin Wang'), arxiv.Result.Author('Wenjia Niu'), arxiv.Result.Author('Endong Tong'), arxiv.Result.Author('Tong Chen'), arxiv.Result.Author('Gang Li')]",
524,Towards Secrecy-Aware Attacks Against Trust Prediction in Signed Graphs,"Signed graphs are widely used to model the trust relationships among users in
security-sensitive systems such as cryptocurrency trading platforms, where
trust prediction plays a critical role. In this paper, we investigate how
attackers could mislead trust prediction via manipulating signed graphs while
remaining secret. To this end, we first design effective poisoning attacks
against representative trust prediction tools. The attacks are formulated as
hard bi-level optimization problems, for which we propose several efficient
approximation solutions. The resulting basic attacks would severely change the
structural semantics (in particular, both local and global balance properties)
of a signed graph, which makes the attacks prone to be detected by the powerful
attack detectors we designed. To address this issue, we further refine the
basic attacks by integrating some conflicting metrics as penalty terms into the
objective function. The refined attacks become secrecy-aware: they can
successfully evade attack detectors with high probability while sacrificing
little attack performance. We conduct comprehensive experiments to demonstrate
that the basic attacks can severely disrupt trust prediction, the basic attacks
could be easily detected, and the refined attacks can preserve attack
performance while evading detection. Overall, our results significantly advance
the knowledge in designing more practical attacks, reflecting more realistic
threats to current trust prediction systems.",2206.13104v1,cs.CR,2022-06-27 08:19:29+00:00,"[arxiv.Result.Author('Yulin Zhu'), arxiv.Result.Author('Tomasz Michalak'), arxiv.Result.Author('Xiapu Luo'), arxiv.Result.Author('Kai Zhou')]",
525,Visualization and Attack Prevention for a Sensor-Based Agricultural Monitoring System,"This project proposes a sensor-based visual agricultural monitoring system.
Distinguished from traditional agricultural monitoring systems, this system
further analyzes basic agricultural data and prevents and monitors common
wireless network attacks such as Selective Forwarding, Black Hole Attacks,
Sinkhole Attacks, Flooding Attacks and Misdirection Attacks. Experimental
verification and evaluation of the attack prevention and monitoring are also
conducted.",2111.14032v1,cs.CR,2021-11-28 03:08:13+00:00,"[arxiv.Result.Author('Yifan Zhou'), arxiv.Result.Author('Zhendong Shi'), arxiv.Result.Author('Ruoxi Sun')]",
526,ATTENTION: ATTackEr traceback using MAC layer abNormality detecTION,"Denial-of-Service (DoS) and Distributed DoS (DDoS) attacks can cause serious
problems in wireless networks due to limited network and host resources.
Attacker traceback is a promising solution to take a proper countermeasure near
the attack origins, to discourage attackers from launching attacks, and for
forensics. However, attacker traceback in Mobile Ad-hoc Networks (MANETs) is a
challenging problem due to the dynamic topology, and limited network resources.
It is especially difficult to trace back attacker(s) when they are moving to
avoid traceback. In this paper, we introduce the ATTENTION protocol framework,
which pays special attention to MAC layer abnormal activity under attack.
ATTENTION consists of three classes, namely, coarse-grained traceback,
fine-grained traceback and spatio-temporal fusion architecture. For
energy-efficient attacker searching in MANETs, we also utilize small-world
model. Our simulation analysis shows 79% of success rate in DoS attacker
traceback with coarse-grained attack signature. In addition, with fine-grained
attack signature, it shows 97% of success rate in DoS attacker traceback and
83% of success rate in DDoS attacker traceback. We also show that ATTENTION has
robustness against node collusion and mobility.",cs/0508010v1,cs.NI,2005-08-02 04:04:24+00:00,"[arxiv.Result.Author('Yongjin Kim'), arxiv.Result.Author('Ahmed Helmy')]",
527,REACT to Cyber Attacks on Power Grids,"Motivated by the recent cyber attack on the Ukrainian power grid, we study
cyber attacks on power grids that affect both the physical infrastructure and
the data at the control center. In particular, we assume that an adversary
attacks an area by: (i) remotely disconnecting some lines within the attacked
area, and (ii) modifying the information received from the attacked area to
mask the line failures and hide the attacked area from the control center. For
the latter, we consider two types of attacks: (i) data distortion: which
distorts the data by adding powerful noise to the actual data, and (ii) data
replay: which replays a locally consistent old data instead of the actual data.
We use the DC power flow model and prove that the problem of finding the set of
line failures given the phase angles of the nodes outside of the attacked area
is strongly NP-hard, even when the attacked area is known. However, we
introduce the polynomial time REcurrent Attack Containment and deTection
(REACT) Algorithm to approximately detect the attacked area and line failures
after a cyber attack. We numerically show that it performs very well in
detecting the attacked area, and detecting single, double, and triple line
failures in small and large attacked areas.",1709.06934v1,cs.SY,2017-09-20 15:40:14+00:00,"[arxiv.Result.Author('Saleh Soltan'), arxiv.Result.Author('Mihalis Yannakakis'), arxiv.Result.Author('Gil Zussman')]",
528,MAAC: Novel Alert Correlation Method To Detect Multi-step Attack,"With the continuous improvement of attack methods, there are more and more
distributed, complex, targeted attacks in which the attackers use combined
attack methods to achieve the purpose. Advanced cyber attacks include multiple
stages to achieve the ultimate goal. Traditional intrusion detection systems
such as endpoint security management tools, firewalls, and other monitoring
tools generate a large number of alerts during the attack. These alerts include
attack clues, as well as many false positives unrelated to attacks. Security
analysts need to analyze a large number of alerts and find useful clues from
them and reconstruct attack scenarios. However, most traditional security
monitoring tools cannot correlate alerts from different sources, so many
multi-step attacks are still completely unnoticed, requiring manual analysis by
security analysts like finding a needle in a haystack. We propose MAAC, a
multi-step attack alert correlation system, which reduces repeated alerts and
combines multi-step attack paths based on alert semantics and attack stages.
The evaluation results of the real-world datasets show that MAAC can
effectively reduce the alerts by 90\% and find attack paths from a large number
of alerts.",2011.07793v2,cs.CR,2020-11-16 08:51:03+00:00,"[arxiv.Result.Author('Xiaoyu Wang'), arxiv.Result.Author('Xiaorui Gong'), arxiv.Result.Author('Lei Yu'), arxiv.Result.Author('Jian Liu')]",
529,Generative Dynamic Patch Attack,"Adversarial patch attack is a family of attack algorithms that perturb a part
of image to fool a deep neural network model. Existing patch attacks mostly
consider injecting adversarial patches at input-agnostic locations: either a
predefined location or a random location. This attack setup may be sufficient
for attack but has considerable limitations when using it for adversarial
training. Thus, robust models trained with existing patch attacks cannot
effectively defend other adversarial attacks. In this paper, we first propose
an end-to-end patch attack algorithm, Generative Dynamic Patch Attack (GDPA),
which generates both patch pattern and patch location adversarially for each
input image. We show that GDPA is a generic attack framework that can produce
dynamic/static and visible/invisible patches with a few configuration changes.
Secondly, GDPA can be readily integrated for adversarial training to improve
model robustness to various adversarial attacks. Extensive experiments on
VGGFace, Traffic Sign and ImageNet show that GDPA achieves higher attack
success rates than state-of-the-art patch attacks, while adversarially trained
model with GDPA demonstrates superior robustness to adversarial patch attacks
than competing methods. Our source code can be found at
https://github.com/lxuniverse/gdpa.",2111.04266v2,cs.CV,2021-11-08 04:15:34+00:00,"[arxiv.Result.Author('Xiang Li'), arxiv.Result.Author('Shihao Ji')]",
530,TCAB: A Large-Scale Text Classification Attack Benchmark,"We introduce the Text Classification Attack Benchmark (TCAB), a dataset for
analyzing, understanding, detecting, and labeling adversarial attacks against
text classifiers. TCAB includes 1.5 million attack instances, generated by
twelve adversarial attacks targeting three classifiers trained on six source
datasets for sentiment analysis and abuse detection in English. Unlike standard
text classification, text attacks must be understood in the context of the
target classifier that is being attacked, and thus features of the target
classifier are important as well. TCAB includes all attack instances that are
successful in flipping the predicted label; a subset of the attacks are also
labeled by human annotators to determine how frequently the primary semantics
are preserved. The process of generating attacks is automated, so that TCAB can
easily be extended to incorporate new text attacks and better classifiers as
they are developed. In addition to the primary tasks of detecting and labeling
attacks, TCAB can also be used for attack localization, attack target labeling,
and attack characterization. TCAB code and dataset are available at
https://react-nlp.github.io/tcab/.",2210.12233v1,cs.LG,2022-10-21 20:22:45+00:00,"[arxiv.Result.Author('Kalyani Asthana'), arxiv.Result.Author('Zhouhang Xie'), arxiv.Result.Author('Wencong You'), arxiv.Result.Author('Adam Noack'), arxiv.Result.Author('Jonathan Brophy'), arxiv.Result.Author('Sameer Singh'), arxiv.Result.Author('Daniel Lowd')]",
531,A New Ensemble Method for Concessively Targeted Multi-model Attack,"It is well known that deep learning models are vulnerable to adversarial
examples crafted by maliciously adding perturbations to original inputs. There
are two types of attacks: targeted attack and non-targeted attack, and most
researchers often pay more attention to the targeted adversarial examples.
However, targeted attack has a low success rate, especially when aiming at a
robust model or under a black-box attack protocol. In this case, non-targeted
attack is the last chance to disable AI systems. Thus, in this paper, we
propose a new attack mechanism which performs the non-targeted attack when the
targeted attack fails. Besides, we aim to generate a single adversarial sample
for different deployed models of the same task, e.g. image classification
models. Hence, for this practical application, we focus on attacking ensemble
models by dividing them into two groups: easy-to-attack and robust models. We
alternately attack these two groups of models in the non-targeted or targeted
manner. We name it a bagging and stacking ensemble (BAST) attack. The BAST
attack can generate an adversarial sample that fails multiple models
simultaneously. Some of the models classify the adversarial sample as a target
label, and other models which are not attacked successfully may give wrong
labels at least. The experimental results show that the proposed BAST attack
outperforms the state-of-the-art attack methods on the new defined criterion
that considers both targeted and non-targeted attack performance.",1912.10833v1,cs.CR,2019-12-19 10:56:36+00:00,"[arxiv.Result.Author('Ziwen He'), arxiv.Result.Author('Wei Wang'), arxiv.Result.Author('Xinsheng Xuan'), arxiv.Result.Author('Jing Dong'), arxiv.Result.Author('Tieniu Tan')]",
532,Cross-Origin State Inference (COSI) Attacks: Leaking Web Site States through XS-Leaks,"In a Cross-Origin State Inference (COSI) attack, an attacker convinces a
victim into visiting an attack web page, which leverages the cross-origin
interaction features of the victim's web browser to infer the victim's state at
a target web site. Multiple instances of COSI attacks have been found in the
past under different names such as login detection or access detection attacks.
But, those attacks only consider two states (e.g., logged in or not) and focus
on a specific browser leak method (or XS-Leak). This work shows that mounting
more complex COSI attacks such as deanonymizing the owner of an account,
determining if the victim owns sensitive content, and determining the victim's
account type often requires considering more than two states. Furthermore,
robust attacks require supporting a variety of browsers since the victim's
browser cannot be predicted apriori. To address these issues, we present a
novel approach to identify and build complex COSI attacks that differentiate
more than two states and support multiple browsers by combining multiple attack
vectors, possibly using different XS-Leaks. To enable our approach, we
introduce the concept of a COSI attack class. We propose two novel techniques
to generalize existing COSI attack instances into COSI attack classes and to
discover new COSI attack classes. We systematically apply our techniques to
existing attacks, identifying 40 COSI attack classes. As part of this process,
we discover a novel XS-Leak based on window.postMessage. We implement our
approach into Basta-COSI, a tool to find COSI attacks in a target web site. We
apply Basta-COSI to test four stand-alone web applications and 58 popular web
sites, finding COSI attacks against each of them.",1908.02204v2,cs.CR,2019-08-06 15:11:59+00:00,"[arxiv.Result.Author('Avinash Sudhodanan'), arxiv.Result.Author('Soheil Khodayari'), arxiv.Result.Author('Juan Caballero')]",
533,Adversarial Imitation Attack,"Deep learning models are known to be vulnerable to adversarial examples. A
practical adversarial attack should require as little as possible knowledge of
attacked models. Current substitute attacks need pre-trained models to generate
adversarial examples and their attack success rates heavily rely on the
transferability of adversarial examples. Current score-based and decision-based
attacks require lots of queries for the attacked models. In this study, we
propose a novel adversarial imitation attack. First, it produces a replica of
the attacked model by a two-player game like the generative adversarial
networks (GANs). The objective of the generative model is to generate examples
that lead the imitation model returning different outputs with the attacked
model. The objective of the imitation model is to output the same labels with
the attacked model under the same inputs. Then, the adversarial examples
generated by the imitation model are utilized to fool the attacked model.
Compared with the current substitute attacks, imitation attacks can use less
training data to produce a replica of the attacked model and improve the
transferability of adversarial examples. Experiments demonstrate that our
imitation attack requires less training data than the black-box substitute
attacks, but achieves an attack success rate close to the white-box attack on
unseen data with no query.",2003.12760v2,cs.CR,2020-03-28 10:02:49+00:00,"[arxiv.Result.Author('Mingyi Zhou'), arxiv.Result.Author('Jing Wu'), arxiv.Result.Author('Yipeng Liu'), arxiv.Result.Author('Xiaolin Huang'), arxiv.Result.Author('Shuaicheng Liu'), arxiv.Result.Author('Xiang Zhang'), arxiv.Result.Author('Ce Zhu')]",
534,Parallel Rectangle Flip Attack: A Query-based Black-box Attack against Object Detection,"Object detection has been widely used in many safety-critical tasks, such as
autonomous driving. However, its vulnerability to adversarial examples has not
been sufficiently studied, especially under the practical scenario of black-box
attacks, where the attacker can only access the query feedback of predicted
bounding-boxes and top-1 scores returned by the attacked model. Compared with
black-box attack to image classification, there are two main challenges in
black-box attack to detection. Firstly, even if one bounding-box is
successfully attacked, another sub-optimal bounding-box may be detected near
the attacked bounding-box. Secondly, there are multiple bounding-boxes, leading
to very high attack cost. To address these challenges, we propose a Parallel
Rectangle Flip Attack (PRFA) via random search. We explain the difference
between our method with other attacks in Fig.~\ref{fig1}. Specifically, we
generate perturbations in each rectangle patch to avoid sub-optimal detection
near the attacked region. Besides, utilizing the observation that adversarial
perturbations mainly locate around objects' contours and critical points under
white-box attacks, the search space of attacked rectangles is reduced to
improve the attack efficiency. Moreover, we develop a parallel mechanism of
attacking multiple rectangles simultaneously to further accelerate the attack
process. Extensive experiments demonstrate that our method can effectively and
efficiently attack various popular object detectors, including anchor-based and
anchor-free, and generate transferable adversarial examples.",2201.08970v1,cs.CV,2022-01-22 06:00:17+00:00,"[arxiv.Result.Author('Siyuan Liang'), arxiv.Result.Author('Baoyuan Wu'), arxiv.Result.Author('Yanbo Fan'), arxiv.Result.Author('Xingxing Wei'), arxiv.Result.Author('Xiaochun Cao')]",
535,Cooperating Attackers in Neural Cryptography,"A new and successful attack strategy in neural cryptography is presented. The
neural cryptosystem, based on synchronization of neural networks by mutual
learning, has been recently shown to be secure under different attack
strategies. The advanced attacker presented here, named the ``Majority-Flipping
Attacker'', is the first whose success does not decay with the parameters of
the model. This new attacker's outstanding success is due to its using a group
of attackers which cooperate throughout the synchronization process, unlike any
other attack strategy known. An analytical description of this attack is also
presented, and fits the results of simulations.",cond-mat/0312068v1,cond-mat.dis-nn,2003-12-02 13:36:06+00:00,"[arxiv.Result.Author('L. N. Shacham'), arxiv.Result.Author('E. Klein'), arxiv.Result.Author('R. Mislovaty'), arxiv.Result.Author('I. Kanter'), arxiv.Result.Author('W. Kinzel')]",
536,Adversary Model: Adaptive Chosen Ciphertext Attack with Timing Attack,"We have introduced a novel adversary model in Chosen-Ciphertext Attack with
Timing Attack (CCA2-TA) and it was a practical model because the model
incorporates the timing attack. This paper is an extended paper for 'A Secure
TFTP Protocol with Security Proofs'.
  Keywords - Timing Attack, Random Oracle Model, Indistinguishabilit, Chosen
Plaintext Attack, CPA, Chosen Ciphertext Attack, IND-CCA1, Adaptive Chosen
Ciphertext Attack, IND-CCA2, Trivial File Transfer Protocol, TFTP, Security,
Trust, Privacy, Trusted Computing, UBOOT, AES, IOT, Lightweight, Asymmetric,
Symmetric, Raspberry Pi, ARM.",1409.6556v1,cs.CR,2014-09-23 14:24:35+00:00,"[arxiv.Result.Author('Mohd Anuar Mat Isa'), arxiv.Result.Author('Habibah Hashim')]",
537,The Attack as Intuitionistic Negation,"We translate the argumentation networks ${\cal A}=(S, R)$ into a theory $D$
of intuitionistic logic, retaining $S$ as the domain and using intuitionistic
negation to model the attack $R$ in ${\cal A}$: the attack $xRy$ is translated
to $x\to\neg y$. The intuitionistic models of $D$ characterise the complete
extensions of ${\cal A}$.
  The reduction of argumentation networks to intuitionistic logic yields, in
addition to a representation theorem, some additional benefits: it allows us to
give semantics to higher level attacks, where an attack ""$xRy$"" can itself
attack another attack ""$uRv$""; one can make higher level meta-statements $W$ on
$(S, R)$ and such meta-statements can attack and be attacked in the domain.",1510.00077v1,cs.LO,2015-09-30 23:38:55+00:00,"[arxiv.Result.Author('Dov Gabbay'), arxiv.Result.Author('Michael Gabbay')]",
538,A Statistical Explanation of the Timing Attack on QC-MDPC Code Crypto-system,"The McEliece cryptosystem based on quasi-cyclic moderate-density parity-check
(QC-MDPC) codes is first purposed in 2013\cite{QCMDPC} and is considered a
promising contender in the post-quantum era. Understanding its security is
hence essential. Till now, the most effective attacks are the reaction
attack\cite{Reaction} and the timing attack\cite{Timing}. Both of these attacks
rely on the decoding performance to recover the private key. The reaction
attack relies on the decoding failure rate and the timing attack relies on the
iterations during decoding. However, the mechanics behind these attacks remain
elusive. In this paper, a mathematical model is proposed to explain both
attacks by connecting the spectrum of private key and first-layer performance
of the decoder.",1912.07005v1,cs.CR,2019-12-15 08:49:10+00:00,[arxiv.Result.Author('Han Li')],
539,"Towards Realistic Threat Modeling: Attack Commodification, Irrelevant Vulnerabilities, and Unrealistic Assumptions","Current threat models typically consider all possible ways an attacker can
penetrate a system and assign probabilities to each path according to some
metric (e.g. time-to-compromise). In this paper we discuss how this view
hinders the realness of both technical (e.g. attack graphs) and strategic (e.g.
game theory) approaches of current threat modeling, and propose to steer away
by looking more carefully at attack characteristics and attacker environment.
We use a toy threat model for ICS attacks to show how a realistic view of
attack instances can emerge from a simple analysis of attack phases and
attacker limitations.",1801.04569v1,cs.CR,2018-01-14 15:05:34+00:00,"[arxiv.Result.Author('Luca Allodi'), arxiv.Result.Author('Sandro Etalle')]",
540,ML Attack Models: Adversarial Attacks and Data Poisoning Attacks,"Many state-of-the-art ML models have outperformed humans in various tasks
such as image classification. With such outstanding performance, ML models are
widely used today. However, the existence of adversarial attacks and data
poisoning attacks really questions the robustness of ML models. For instance,
Engstrom et al. demonstrated that state-of-the-art image classifiers could be
easily fooled by a small rotation on an arbitrary image. As ML systems are
being increasingly integrated into safety and security-sensitive applications,
adversarial attacks and data poisoning attacks pose a considerable threat. This
chapter focuses on the two broad and important areas of ML security:
adversarial attacks and data poisoning attacks.",2112.02797v1,cs.LG,2021-12-06 05:59:30+00:00,"[arxiv.Result.Author('Jing Lin'), arxiv.Result.Author('Long Dang'), arxiv.Result.Author('Mohamed Rahouti'), arxiv.Result.Author('Kaiqi Xiong')]",
541,Is it ever safe to vote strategically?,"There are many situations in which mis-coordinated strategic voting can leave
strategic voters worse off than they would have been had they not tried to
strategize. We analyse the simplest of such scenarios, in which the set of
strategic voters all have the same sincere preferences and all cast the same
strategic vote, while all other voters vote sincerely. Most mis-coordinations
in this framework can be classified as instances of either strategic
overshooting (too many voted strategically) or strategic undershooting (too
few). If mis-coordination can result in strategic voters ending up worse off
than they would have been had they all just voted sincerely, we call the
relevant strategic vote unsafe. We show that under every onto and
non-dictatorial social choice rule there exist circumstances where a voter has
an incentive to cast a safe strategic vote. We extend the Gibbard-Satterthwaite
Theorem by proving that every onto and non-dictatorial social choice rule can
be individually manipulated by a voter casting a safe strategic vote.",1301.1420v1,cs.GT,2013-01-08 06:05:29+00:00,"[arxiv.Result.Author('Arkadii Slinko'), arxiv.Result.Author('Shaun White')]",
542,Strategic Voting Under Uncertainty About the Voting Method,"Much of the theoretical work on strategic voting makes strong assumptions
about what voters know about the voting situation. A strategizing voter is
typically assumed to know how other voters will vote and to know the rules of
the voting method. A growing body of literature explores strategic voting when
there is uncertainty about how others will vote. In this paper, we study
strategic voting when there is uncertainty about the voting method. We
introduce three notions of manipulability for a set of voting methods: sure,
safe, and expected manipulability. With the help of a computer program, we
identify voting scenarios in which uncertainty about the voting method may
reduce or even eliminate a voter's incentive to misrepresent her preferences.
Thus, it may be in the interest of an election designer who wishes to reduce
strategic voting to leave voters uncertain about which of several reasonable
voting methods will be used to determine the winners of an election.",1907.09110v1,cs.MA,2019-07-22 03:17:19+00:00,"[arxiv.Result.Author('Wesley H. Holliday'), arxiv.Result.Author('Eric Pacuit')]","EPTCS 297, 2019, pp. 252-272"
543,The Computational Impact of Partial Votes on Strategic Voting,"In many real world elections, agents are not required to rank all candidates.
We study three of the most common methods used to modify voting rules to deal
with such partial votes. These methods modify scoring rules (like the Borda
count), elimination style rules (like single transferable vote) and rules based
on the tournament graph (like Copeland) respectively. We argue that with an
elimination style voting rule like single transferable vote, partial voting
does not change the situations where strategic voting is possible. However,
with scoring rules and rules based on the tournament graph, partial voting can
increase the situations where strategic voting is possible. As a consequence,
the computational complexity of computing a strategic vote can change. For
example, with Borda count, the complexity of computing a strategic vote can
decrease or stay the same depending on how we score partial votes.",1405.7714v1,cs.GT,2014-05-28 12:13:52+00:00,"[arxiv.Result.Author('Nina Narodytska'), arxiv.Result.Author('Toby Walsh')]",
544,Representing the Insincere: Strategically Robust Proportional Representation,"Proportional representation (PR) is a fundamental principle of many
democracies world-wide which employ PR-based voting rules to elect their
representatives. The normative properties of these voting rules however, are
often only understood in the context of sincere voting.
  In this paper we consider PR in the presence of strategic voters. We
construct a voting rule such that for every preference profile there exists at
least one costly voting equilibrium satisfying PR with respect to voters'
private and unrevealed preferences - such a voting rule is said to be
strategically robust. In contrast, a commonly applied voting rule is shown not
be strategically robust. Furthermore, we prove a limit on `how strategically
robust' a PR-based voting rule can be; we show that there is no PR-based voting
rule which ensures that every equilibrium satisfies PR. Collectively, our
results highlight the possibility and limit of achieving PR in the presence of
strategic voters and a positive role for mechanisms, such as pre-election
polls, which coordinate voter behaviour towards equilibria which satisfy PR.",1801.09346v1,cs.GT,2018-01-29 02:35:21+00:00,[arxiv.Result.Author('Barton E. Lee')],
545,Exploring Weak Strategy-Proofness in Voting Theory,"Voting is the aggregation of individual preferences in order to select a
winning alternative. Selection of a winner is accomplished via a voting rule,
e.g., rank-order voting, majority rule, plurality rule, approval voting. Which
voting rule should be used? In social choice theory, desirable properties of
voting rules are expressed as axioms to be satisfied. This thesis focuses on
axioms concerning strategic manipulation by voters. Sometimes, voters may
intentionally misstate their true preferences in order to alter the outcome for
their own advantage. For example, in plurality rule, if a voter knows that
their top-choice candidate will lose, then they might instead vote for their
second-choice candidate just to avoid an even less desirable result. When no
coalition of voters can strategically manipulate, then the voting rule is said
to satisfy the axiom of Strategy-Proofness. A less restrictive axiom is Weak
Strategy-Proofness (as defined by Dasgupta and Maskin (2019)), which allows for
strategic manipulation by all but the smallest coalitions. Under certain
intuitive conditions, Dasgupta and Maskin (2019) proved that the only voting
rules satisfying Strategy-Proofness are rank-order voting and majority rule. In
my thesis, I generalize their result, by proving that rank-order voting and
majority rule are surprisingly still the only voting rules satisfying Weak
Strategy-Proofness.",2005.07521v1,econ.TH,2020-05-13 19:53:08+00:00,[arxiv.Result.Author('Anne Carlstein')],
546,Paradoxes in Sequential Voting,"We analyse strategic, complete information, sequential voting with ordinal
preferences over the alternatives. We consider several voting mechanisms:
plurality voting and approval voting with deterministic or uniform tie-breaking
rules. We show that strategic voting in these voting procedures may lead to a
very undesirable outcome: Condorcet winning alternative might be rejected,
Condorcet losing alternative might be elected, and Pareto dominated alternative
might be elected. These undesirable phenomena occur already with four
alternatives and a small number of voters. For the case of three alternatives
we present positive and negative results.",1807.03979v2,cs.GT,2018-07-11 07:50:42+00:00,"[arxiv.Result.Author('Oren Dean'), arxiv.Result.Author('Yakov Babichenko'), arxiv.Result.Author('Moshe Tennenholtz')]",
547,Strategically Simple Mechanisms,"We define and investigate a property of mechanisms that we call ""strategic
simplicity,"" and that is meant to capture the idea that, in strategically
simple mechanisms, strategic choices require limited strategic sophistication.
We define a mechanism to be strategically simple if choices can be based on
first-order beliefs about the other agents' preferences and first-order
certainty about the other agents' rationality alone, and there is no need for
agents to form higher-order beliefs, because such beliefs are irrelevant to the
optimal strategies. All dominant strategy mechanisms are strategically simple.
But many more mechanisms are strategically simple. In particular, strategically
simple mechanisms may be more flexible than dominant strategy mechanisms in the
bilateral trade problem and the voting problem.",1812.00849v1,econ.TH,2018-12-03 15:47:19+00:00,"[arxiv.Result.Author('Tilman Borgers'), arxiv.Result.Author('Jiangtao Li')]",
548,How Many Vote Operations Are Needed to Manipulate A Voting System?,"In this paper, we propose a framework to study a general class of strategic
behavior in voting, which we call vote operations. We prove the following
theorem: if we fix the number of alternatives, generate $n$ votes i.i.d.
according to a distribution $\pi$, and let $n$ go to infinity, then for any
$\epsilon >0$, with probability at least $1-\epsilon$, the minimum number of
operations that are needed for the strategic individual to achieve her goal
falls into one of the following four categories: (1) 0, (2) $\Theta(\sqrt n)$,
(3) $\Theta(n)$, and (4) $\infty$. This theorem holds for any set of vote
operations, any individual vote distribution $\pi$, and any integer generalized
scoring rule, which includes (but is not limited to) almost all commonly
studied voting rules, e.g., approval voting, all positional scoring rules
(including Borda, plurality, and veto), plurality with runoff, Bucklin,
Copeland, maximin, STV, and ranked pairs.
  We also show that many well-studied types of strategic behavior fall under
our framework, including (but not limited to) constructive/destructive
manipulation, bribery, and control by adding/deleting votes, margin of victory,
and minimum manipulation coalition size. Therefore, our main theorem naturally
applies to these problems.",1204.1231v3,cs.AI,2012-04-05 14:00:21+00:00,[arxiv.Result.Author('Lirong Xia')],
549,Modeling Peoples Voting Behavior with Poll Information,"Despite the prevalence of voting systems in the real world there is no
consensus among researchers of how people vote strategically, even in simple
voting settings. This paper addresses this gap by comparing different
approaches that have been used to model strategic voting, including expected
utility maximization, heuristic decisionmaking, and bounded rationality models.
The models are applied to data collected from hundreds of people in controlled
voting experiments, where people vote after observing non-binding poll
information. We introduce a new voting model, the Attainability- Utility (AU)
heuristic, which weighs the popularity of a candidate according to the poll,
with the utility of the candidate to the voter. We argue that the AU model is
cognitively plausible, and show that it is able to predict peoples voting
behavior significantly better than other models from the literature. It was
almost at par with (and sometimes better than) a machine learning algorithm
that uses substantially more information. Our results provide new insights into
the strategic considerations of voters, that undermine the prevalent
assumptions of much theoretical work in social choice.",1909.10492v1,cs.GT,2019-09-23 17:20:16+00:00,"[arxiv.Result.Author('Roy Fairstein'), arxiv.Result.Author('Adam Lauz'), arxiv.Result.Author('Kobi Gal'), arxiv.Result.Author('Reshef Meir')]",
550,Heuristics in Multi-Winner Approval Voting,"In many real world situations, collective decisions are made using voting.
Moreover, scenarios such as committee or board elections require voting rules
that return multiple winners. In multi-winner approval voting (AV), an agent
may vote for as many candidates as they wish. Winners are chosen by tallying up
the votes and choosing the top-$k$ candidates receiving the most votes. An
agent may manipulate the vote to achieve a better outcome by voting in a way
that does not reflect their true preferences. In complex and uncertain
situations, agents may use heuristics to strategize, instead of incurring the
additional effort required to compute the manipulation which most favors them.
In this paper, we examine voting behavior in multi-winner approval voting
scenarios with complete information. We show that people generally manipulate
their vote to obtain a better outcome, but often do not identify the optimal
manipulation. Instead, voters tend to prioritize the candidates with the
highest utilities. Using simulations, we demonstrate the effectiveness of these
heuristics in situations where agents only have access to partial information.",1905.12104v2,cs.GT,2019-05-28 21:44:07+00:00,"[arxiv.Result.Author('Jaelle Scheuerman'), arxiv.Result.Author('Jason L. Harman'), arxiv.Result.Author('Nicholas Mattei'), arxiv.Result.Author('K. Brent Venable')]",
551,Predicting Strategic Voting Behavior with Poll Information,"The question of how people vote strategically under uncertainty has attracted
much attention in several disciplines. Theoretical decision models have been
proposed which vary in their assumptions on the sophistication of the voters
and on the information made available to them about others' preferences and
their voting behavior. This work focuses on modeling strategic voting behavior
under poll information. It proposes a new heuristic for voting behavior that
weighs the success of each candidate according to the poll score with the
utility of the candidate given the voters' preferences. The model weights can
be tuned individually for each voter. We compared this model with other
relevant voting models from the literature on data obtained from a recently
released large scale study. We show that the new heuristic outperforms all
other tested models. The prediction errors of the model can be partly explained
due to inconsistent voters that vote for (weakly) dominated candidates.",1805.07606v1,cs.GT,2018-05-19 15:17:25+00:00,"[arxiv.Result.Author('Roy Fairstein'), arxiv.Result.Author('Adam Lauz'), arxiv.Result.Author('Kobi Gal'), arxiv.Result.Author('Reshef Meir')]",
552,"Complexity of Manipulation, Bribery, and Campaign Management in Bucklin and Fallback Voting","A central theme in computational social choice is to study the extent to
which voting systems computationally resist manipulative attacks seeking to
influence the outcome of elections, such as manipulation (i.e., strategic
voting), control, and bribery. Bucklin and fallback voting are among the voting
systems with the broadest resistance (i.e., NP-hardness) to control attacks.
However, only little is known about their behavior regarding manipulation and
bribery attacks. We comprehensively investigate the computational resistance of
Bucklin and fallback voting for many of the common manipulation and bribery
scenarios; we also complement our discussion by considering several campaign
management problems for Bucklin and fallback.",1307.7322v1,cs.GT,2013-07-28 00:24:35+00:00,"[arxiv.Result.Author('Piotr Faliszewski'), arxiv.Result.Author('Yannick Reisch'), arxiv.Result.Author('Jörg Rothe'), arxiv.Result.Author('Lena Schend')]",
553,A Local-Dominance Theory of Voting Equilibria,"It is well known that no reasonable voting rule is strategyproof. Moreover,
the common Plurality rule is particularly prone to strategic behavior of the
voters and empirical studies show that people often vote strategically in
practice. Multiple game-theoretic models have been proposed to better
understand and predict such behavior and the outcomes it induces. However,
these models often make unrealistic assumptions regarding voters' behavior and
the information on which they base their vote.
  We suggest a new model for strategic voting that takes into account voters'
bounded rationality, as well as their limited access to reliable information.
We introduce a simple behavioral heuristic based on \emph{local dominance},
where each voter considers a set of possible world states without assigning
probabilities to them. This set is constructed based on prospective candidates'
scores (e.g., available from an inaccurate poll). In a \emph{voting
equilibrium}, all voters vote for candidates not dominated within the set of
possible states.
  We prove that these voting equilibria exist in the Plurality rule for a broad
class of local dominance relations (that is, different ways to decide which
states are possible). Furthermore, we show that in an iterative setting where
voters may repeatedly change their vote, local dominance-based dynamics quickly
converge to an equilibrium if voters start from the truthful state. Weaker
convergence guarantees in more general settings are also provided.
  Using extensive simulations of strategic voting on generated and real
preference profiles, we show that convergence is fast and robust, that emerging
equilibria are consistent across various starting conditions, and that they
replicate widely known patterns of human voting behavior such as Duverger's
law. Further, strategic voting generally improves the quality of the winner
compared to truthful voting.",1404.4688v2,cs.GT,2014-04-18 04:40:28+00:00,"[arxiv.Result.Author('Reshef Meir'), arxiv.Result.Author('Omer Lev'), arxiv.Result.Author('Jeffrey S. Rosenschein')]",
554,Strategic Voting and the Logic of Knowledge,"We propose a general framework for strategic voting when a voter may lack
knowledge about other votes or about other voters' knowledge about her own
vote. In this setting we define notions of manipulation and equilibrium. We
also model action changing knowledge about votes, such as a voter revealing its
preference or as a central authority performing a voting poll. Some forms of
manipulation are preserved under such updates and others not. Another form of
knowledge dynamics is the effect of a voter declaring its vote. We envisage
Stackelberg games for uncertain profiles. The purpose of this investigation is
to provide the epistemic background for the analysis and design of voting rules
that incorporate uncertainty.",1310.6436v1,cs.GT,2013-10-23 23:45:28+00:00,"[arxiv.Result.Author('Hans van Ditmarsch'), arxiv.Result.Author('Jerome Lang'), arxiv.Result.Author('Abdallah Saffidine')]",
555,Proxy Voting for Better Outcomes,"We consider a social choice problem where only a small number of people out
of a large population are sufficiently available or motivated to vote. A common
solution to increase participation is to allow voters use a proxy, that is,
transfer their voting rights to another voter. Considering social choice
problems on metric spaces, we compare voting with and without the use of
proxies to see which mechanism better approximates the optimal outcome, and
characterize the regimes in which proxy voting is beneficial. When voters'
opinions are located on an interval, both the median mechanism and the mean
mechanism are substantially improved by proxy voting. When voters vote on many
binary issues, proxy voting is better when the sample of active voters is too
small to provide a good outcome. Our theoretical results extend to situations
where available voters choose strategically whether to participate. We support
our theoretical findings with empirical results showing substantial benefits of
proxy voting on simulated and real preference data.",1611.08308v1,cs.GT,2016-11-24 21:05:50+00:00,"[arxiv.Result.Author('Gal Cohensius'), arxiv.Result.Author('Shie Manor'), arxiv.Result.Author('Reshef Meir'), arxiv.Result.Author('Eli Meirom'), arxiv.Result.Author('Ariel Orda')]",
556,The probability of casting a pivotal vote in an Instant Runoff Voting election,"I derive the probability that a vote cast in an Instant Runoff Voting
election will change the election winner. I show that there can be two types of
pivotal event: direct pivotality, in which a voter causes a candidate to win by
ranking them, and indirect pivotality, in which a voter causes one candidate to
win by ranking some other candidate. This suggests a reason that voters should
be allowed to rank at most four candidates. I identify all pivotal events in
terms of the ballots that a voter expects to be cast, and then I compute those
probabilities in a common framework for voting games. I provide pseudocode, and
work through an example of calculating pivotal probabilities. I then compare
the probability of casting a pivotal vote in Instant Runoff Voting to
single-vote plurality, and show that the incentives to vote strategically are
similar in these two systems.",2210.01657v1,cs.GT,2022-10-04 15:00:43+00:00,[arxiv.Result.Author('Samuel Baltz')],
557,Obvious Independence of Clones,"The Independence of Clones (IoC) criterion for social choice functions
(voting rules) measures a function's robustness to strategic nomination.
However, prior literature has established empirically that individuals cannot
always recognize whether or not a mechanism is strategy-proof and may still
submit costly, distortionary misreports even in strategy-proof settings. The
intersection of these issues motivates the search for mechanisms which are
Obviously Independent of Clones (OIoC): where strategic nomination or strategic
exiting of clones obviously have no effect on the outcome of the election. We
examine three IoC ranked-choice voting mechanisms and the pre-existing proofs
that they are independent of clones: Single Transferable Vote (STV), Ranked
Pairs, and the Schulze method. We construct a formal definition of a voting
system being Obviously Independent of Clones based on a reduction to a clocked
election by considering a bounded agent. Finally, we show that STV and Ranked
Pairs are OIoC, whereas we prove an impossibility result for the Schulze method
showing that this voting system is not OIoC.",2210.04880v1,cs.GT,2022-10-10 17:52:28+00:00,"[arxiv.Result.Author('Ratip Emin Berker'), arxiv.Result.Author('Sílvia Casacuberta'), arxiv.Result.Author('Christopher Ong'), arxiv.Result.Author('Isaac Robinson')]",
558,Gibbard-Satterthwaite Games for k-Approval Voting Rules,"The Gibbard-Satterthwaite theorem implies the existence of voters, called
manipulators, who can change the election outcome in their favour by voting
strategically. When a given preference profile admits several such
manipulators, voting becomes a game played by these voters, who have to reason
strategically about each others' actions. To complicate the game even further,
counter-manipulators may then try to counteract the actions of manipulators.
Our voters are boundedly rational and do not think beyond manipulating or
countermanipulating. We call these games Gibbard--Satterthwaite Games. In this
paper we look for conditions that guarantee the existence of a Nash equilibria
in pure strategies.",1707.05619v1,cs.GT,2017-07-18 14:02:16+00:00,"[arxiv.Result.Author('Umberto Grandi'), arxiv.Result.Author('Daniel Hughes'), arxiv.Result.Author('Francesca Rossi'), arxiv.Result.Author('Arkadii Slinko')]",
559,Equilibria of Plurality Voting with Abstentions,"In the traditional voting manipulation literature, it is assumed that a group
of manipulators jointly misrepresent their preferences to get a certain
candidate elected, while the remaining voters are truthful. In this paper, we
depart from this assumption, and consider the setting where all voters are
strategic. In this case, the election can be viewed as a game, and the election
outcomes correspond to Nash equilibria of this game. We use this framework to
analyze two variants of Plurality voting, namely, simultaneous voting, where
all voters submit their ballots at the same time, and sequential voting, where
the voters express their preferences one by one. For simultaneous voting, we
characterize the preference profiles that admit a pure Nash equilibrium, but
show that it is computationally hard to check if a given profile fits our
criterion. For sequential voting, we provide a complete analysis of the setting
with two candidates, and show that for three or more candidates the equilibria
of sequential voting may behave in a counterintuitive manner.",1001.4939v1,cs.GT,2010-01-27 13:31:06+00:00,"[arxiv.Result.Author('Yvo Desmedt'), arxiv.Result.Author('Edith Elkind')]",
560,Lie on the Fly: Strategic Voting in an Iterative Preference Elicitation Process,"A voting center is in charge of collecting and aggregating voter preferences.
In an iterative process, the center sends comparison queries to voters,
requesting them to submit their preference between two items. Voters might
discuss the candidates among themselves, figuring out during the elicitation
process which candidates stand a chance of winning and which do not.
Consequently, strategic voters might attempt to manipulate by deviating from
their true preferences and instead submit a different response in order to
attempt to maximize their profit. We provide a practical algorithm for
strategic voters which computes the best manipulative vote and maximizes the
voter's selfish outcome when such a vote exists. We also provide a careful
voting center which is aware of the possible manipulations and avoids
manipulative queries when possible. In an empirical study on four real-world
domains, we show that in practice manipulation occurs in a low percentage of
settings and has a low impact on the final outcome. The careful voting center
reduces manipulation even further, thus allowing for a non-distorted group
decision process to take place. We thus provide a core technology study of a
voting process that can be adopted in opinion or information aggregation
systems and in crowdsourcing applications, e.g., peer grading in Massive Open
Online Courses (MOOCs).",1905.04933v1,cs.CY,2019-05-13 09:32:17+00:00,"[arxiv.Result.Author('Lihi Dery'), arxiv.Result.Author('Svetlana Obraztsova'), arxiv.Result.Author('Zinovi Rabinovich'), arxiv.Result.Author('Meir Kalech')]",
561,Capacity Region of $K$-User Discrete Memoryless Interference Channels with a Mixed Strong-Very Strong Interference,"The capacity region of the 3-user Gaussian Interference Channel (GIC) with
mixed strong-very strong interference was established in \cite{ChS}. The mixed
strong-very strong interference conditions considered in \cite{ChS} correspond
to the case where, at each receiver, one of the interfering signals is strong
and the other is very strong. In this paper, we derive the capacity region of
$K$-user $(K\geq 3)$ Discrete Memoryless Interference Channels (DMICs) with a
mixed strong-very strong interference. This corresponds to the case where, at
each receiver one of the interfering signals is strong and the other $(K-2)$
interfering signals are very strong. This includes, as a special case, the
3-user DMIC with mixed strong-very strong interference. The proof is
specialized to the 3-user GIC case and hence an alternative simpler derivation
for the capacity region of the 3-user GIC with mixed strong-very strong
interference is provided.",1102.3140v1,cs.IT,2011-02-15 17:50:48+00:00,"[arxiv.Result.Author('G. Abhinav'), arxiv.Result.Author('B. Sundar Rajan')]",
562,Strong 2.t and Strong 3.t Transformations for Strong M-equivalence,"Parikh matrices have been extensively investigated due to their usefulness in
studying subword occurrences in words. Due to the dependency of Parikh matrices
on the ordering of the alphabet, strong M-equivalence was proposed as an
order-independent alternative to M-equivalence in studying words possessing the
same Parikh matrix. This paper introduces and studies the notions of strong 2.t
and strong 3.t transformations in determining when two ternary words are
strongly M-equivalent. The irreducibility of strong 2.t transformations are
then scrutinized, exemplified by a structural characterization of irreducible
strong 2.2 transformations. The common limitation of these transformations in
characterizing strong M-equivalence is then addressed.",1702.03647v1,math.CO,2017-02-13 06:23:11+00:00,"[arxiv.Result.Author('Ghajendran Poovanandran'), arxiv.Result.Author('Wen Chean Teh')]",
563,Packing Strong Subgraph in Digraphs,"In this paper, we study two types of strong subgraph packing problems in
digraphs, including internally disjoint strong subgraph packing problem and
arc-disjoint strong subgraph packing problem. These problems can be viewed as
generalizations of the famous Steiner tree packing problem and are closely
related to the strong arc decomposition problem. We first prove the
NP-completeness for the internally disjoint strong subgraph packing problem
restricted to symmetric digraphs and Eulerian digraphs. Then we get
inapproximability results for the arc-disjoint strong subgraph packing problem
and the internally disjoint strong subgraph packing problem. Finally we study
the arc-disjoint strong subgraph packing problem restricted to digraph
compositions and obtain some algorithmic results by utilizing the structural
properties.",2110.12783v1,math.CO,2021-10-25 10:27:46+00:00,"[arxiv.Result.Author('Yuefang Sun'), arxiv.Result.Author('Gregory Gutin'), arxiv.Result.Author('Xiaoyan Zhang')]",
564,Blow-ups and resolutions of strong Kähler with torsion metrics,"On a compact complex manifold we study the behaviour of strong K\""ahler with
torsion (strong KT) structures under small deformations of the complex
structure and the problem of extension of a strong KT metric. In this context
we obtain the analogous result of Miyaoka extension theorem. Studying the
blow-up of a strong KT manifold at a point or along a complex submanifold, we
prove that a complex orbifold endowed with a strong KT metric admits a strong
KT resolution. In this way we obtain new examples of compact simply-connected
strong KT manifolds.",0804.0397v2,math.DG,2008-04-02 16:56:09+00:00,"[arxiv.Result.Author('Anna Fino'), arxiv.Result.Author('Adriano Tomassini')]",
565,The Capacity Region of the 3-User Gaussian Interference Channel with Mixed Strong-Very Strong Interference,"We consider the 3-user Gaussian interference channel and provide an outer
bound on its capacity region. Under some conditions, which we call the mixed
strong-very strong interference conditions, this outer bound is achievable.
These conditions correspond to the case where at each receiver, one transmitter
is causing strong interference and the other is causing very strong
interference. Therefore, we characterize the capacity region of the 3-user
interference channel with mixed strong-very strong interference.",1010.4911v1,cs.IT,2010-10-23 20:51:53+00:00,"[arxiv.Result.Author('Anas Chaaban'), arxiv.Result.Author('Aydin Sezgin')]",
566,Small forcing creates neither strong nor Woodin cardinals,"After small forcing, almost every strongness embedding is the lift of a
strongness embedding in the ground model. Consequently, small forcing creates
neither strong nor Woodin cardinals.",math/9808124v1,math.LO,1998-08-29 06:03:25+00:00,"[arxiv.Result.Author('Joel David Hamkins'), arxiv.Result.Author('W. Hugh Woodin')]",
567,The strong Lefschetz property and simple extensions,"Stanley showed that monomial complete intersections have the strong Lefschetz
property. Extending this result we show that a simple extension of an Artinian
Gorenstein algebra with the strong Lefschetz property has again the strong
Lefschetz property.",math/0506537v1,math.AC,2005-06-27 11:35:22+00:00,"[arxiv.Result.Author('Juergen Herzog'), arxiv.Result.Author('Dorin Popescu')]",
568,"Strong dependence, weight, and measure","I give an account of Shelah's notion of strong dependence, or strong NIP, in
terms of suitable generically stable measures, forking, and weight.",1005.0076v1,math.LO,2010-05-01 14:27:48+00:00,[arxiv.Result.Author('Anand Pillay')],
569,Strong cliques in diamond-free graphs,"A strong clique in a graph is a clique intersecting all inclusion-maximal
stable sets. Strong cliques play an important role in the study of perfect
graphs. We study strong cliques in the class of diamond-free graphs, from both
structural and algorithmic points of view. We show that the following five
NP-hard or co-NP-hard problems remain intractable when restricted to the class
of diamond-free graphs: Is a given clique strong? Does the graph have a strong
clique? Is every vertex contained in a strong clique? Given a partition of the
vertex set into cliques, is every clique in the partition strong? Can the
vertex set be partitioned into strong cliques? On the positive side, we show
that the following two problems whose computational complexity is open in
general can be solved in linear time in the class of diamond-free graphs: Is
every maximal clique strong? Is every edge contained in a strong clique? These
results are derived from a characterization of diamond-free graphs in which
every maximal clique is strong, which also implies an improved Erd\H{o}s-Hajnal
property for such graphs.",2006.13822v1,math.CO,2020-06-24 15:50:16+00:00,"[arxiv.Result.Author('Nina Chiarelli'), arxiv.Result.Author('Berenice Martínez Barona'), arxiv.Result.Author('Martin Milanič'), arxiv.Result.Author('Jérôme Monnot'), arxiv.Result.Author('Peter Muršič')]",
570,Strong measure zero sets without Cohen reals,"If ZFC is consistent, then each of the following are consistent with ZFC +
2^{{aleph_0}}= aleph_2 :
  1.) X subseteq R is of strong measure zero iff |X| <= aleph_1 + there is a
generalized Sierpinski set.
  2.) The union of aleph_1 many strong measure zero sets is a strong measure
zero set + there is a strong measure zero set of size aleph_2.",math/9306214v1,math.LO,1993-06-15 00:00:00+00:00,"[arxiv.Result.Author('Martin Goldstern'), arxiv.Result.Author('Haim Judah'), arxiv.Result.Author('Saharon Shelah')]","J. Symbolic Logic 58 (1993), 1323--1341"
571,The generalized strong recurrence for non-zero rational parameters,"The strong recurrence is equivalent to the Riemann hypothesis. On the other
hand, the generalized strong recurrence holds for any irrational number. In
this paper, we show the generalized strong recurrence for all non-zero rational
numbers. Moreover, we prove that the generalized strong recurrence in the
region of absolute convergence holds for any real number.",1006.1778v1,math.NT,2010-06-09 12:07:13+00:00,[arxiv.Result.Author('Takashi Nakamura')],
572,Strong Subgraph Connectivity of Digraphs: A Survey,"In this survey we overview known results on the strong subgraph
$k$-connectivity and strong subgraph $k$-arc-connectivity of digraphs. After an
introductory section, the paper is divided into four sections: basic results,
algorithms and complexity, sharp bounds for strong subgraph
$k$-(arc-)connectivity, minimally strong subgraph $(k, \ell)$-(arc-) connected
digraphs. This survey contains several conjectures and open problems for
further study.",1808.02740v1,cs.DM,2018-08-08 12:56:00+00:00,"[arxiv.Result.Author('Yuefang Sun'), arxiv.Result.Author('Gregory Gutin')]",
573,On strong λ-statistical convergence of sequences in probabilistic metric (pm) spaces,"In this paper we study some basic properties of strong {\lambda}- statistical
convergence of sequences in probabilistic metric (PM) spaces. We also introduce
and study the notion of strong {\lambda}-statistically Cauchyness. Further
introducing the notions of strong {\lambda}-statistical limit point and strong
{\lambda}-statistical cluster point of a sequence in a probabilistic metric
(PM) space we examine their interrelationship.",2007.09173v1,math.FA,2020-07-17 18:16:35+00:00,"[arxiv.Result.Author('Prasanta Malik'), arxiv.Result.Author('Samiran Das')]",
574,Construction of Strong-Uniform Fuzzy Partitions of Arbitrary Dimensions,"Strong-uniform fuzzy partition is necessary for the accuracy of fuzzy
partition-based histograms. Most previous research focused on constructing
one-dimensional strong-uniform fuzzy partitions. While to the best of our
knowledge, few have been reported for high-dimensional cases. In order to fill
this theoretical vacancy, this paper proves the existence of high-dimensional
strong-uniform fuzzy partitions via proposing an analytic formula to construct
strong-uniform fuzzy partitions of arbitrary dimensions.",2201.05441v1,math.GM,2022-01-13 13:54:51+00:00,"[arxiv.Result.Author('Zhi Zeng'), arxiv.Result.Author('Ting Wang')]",
575,Minimal strong digraphs,"We introduce adequate concepts of expansion of a digraph to obtain a
sequential construction of minimal strong digraphs. We characterize the class
of minimal strong digraphs whose expansion preserves the property of
minimality. We prove that every minimal strong digraph of order $n\geq 2$ is
the expansion of a minimal strong digraph of order $n-1$ and we give
sequentially generative procedures for the constructive characterization of the
classes of minimal strong digraphs. Finally we describe algorithms to compute
unlabeled minimal strong digraphs and their isospectral classes.",1004.4827v1,math.CO,2010-04-27 14:58:54+00:00,"[arxiv.Result.Author('Jesús García-López'), arxiv.Result.Author('Carlos Marijuán')]",
576,On determinacy/indeterminacy of Moment Problems,"This paper treat determinacy of strong moment problems in part I and
indeterminacy of strong moment problems in part II. This paper is a summary of
the following papers:
  [1] Ald\'en. E., Determinacy of Strong Moment Problems. [2] On Indeterminacy
of Strong Moment Problems. [3] Indeterminacy of Strong Moment Problems.
  This paper will treat determinacy/indeterminacy of the strong Stieltjes and
Hamburger moment problems, part I. Indeterminacy, part II, for certain class of
distribution functions. We conclude by proving a theorem for indeterminacy of
the strong problems above for general distribution functions.",1604.06263v1,math.CA,2016-04-21 11:32:29+00:00,[arxiv.Result.Author('Erik Aldén')],
577,On Strong A-statistical Convergence in Probabilistic Metric Spaces,"In this paper we study some basic properties of strong A-statistical
convergence and strong A-statistical Cauchyness of sequences in probabilistic
metric spaces not done earlier. We also study some basic properties of strong
A-statistical limit points and strong A-statistical cluster points of a
sequence in a probabilistic metric space. Further we also introduce the notion
of strong statistically A-summable sequence in a probabilistic metric space and
study its relationship with strong A-statistical convergence.",2204.02727v1,math.FA,2022-04-06 11:07:17+00:00,"[arxiv.Result.Author('Prasanta Malik'), arxiv.Result.Author('Samiran Das')]",
578,On strong $\mathcal{A}^{\mathcal{I}}$-statistical convergence of sequences in probabilistic metric spaces,"In this paper using a non-negative regular summability matrix $\mathcal{A}$
and a non-trivial admissible ideal $\mathcal{I}$ in $\mathbb{N}$ we study some
basic properties of strong $\mathcal{A}^{\mathcal{I}}$-statistical convergence
and strong $\mathcal{A}^{\mathcal{I}}$-statistical Cauchyness of sequences in
probabilistic metric spaces not done earlier. We also introduce strong
$\mathcal{A}^{\mathcal{I^*}}$-statistical Cauchyness in probabilistic metric
space and study its relationship with strong
A$\mathcal{A}^{\mathcal{I}}$-statistical Cauchyness there. Further, we study
some basic properties of strong $\mathcal{A}^{\mathcal{I}}$-statistical limit
points and strong $\mathcal{A}^{\mathcal{I}}$-statistical cluster points of a
sequence in probabilistic metric spaces.",2208.03010v1,math.FA,2022-08-05 06:55:56+00:00,"[arxiv.Result.Author('Prasanta Malik'), arxiv.Result.Author('Samiran Das')]",
579,Strong cliques in vertex-transitive graphs,"A clique (resp., independent set) in a graph is strong if it intersects every
maximal independent sets (resp., every maximal cliques). A graph is CIS if all
of its maximal cliques are strong and localizable if it admits a partition of
its vertex set into strong cliques. In this paper we prove that a clique $C$ in
a vertex-transitive graph $\Gamma$ is strong if and only if
$|C||I|=|V(\Gamma)|$ for every maximal independent set $I$ of $\Gamma$. Based
on this result we prove that a vertex-transitive graph is CIS if and only if it
admits a strong clique and a strong independent set. We classify all
vertex-transitive graphs of valency at most 4 admitting a strong clique, and
give a partial characterization of $5$-valent vertex-transitive graphs
admitting a strong clique. Our results imply that every vertex-transitive graph
of valency at most $5$ that admits a strong clique is localizable. We answer an
open question by providing an example of a vertex-transitive CIS graph which is
not localizable.",1808.09534v1,math.CO,2018-08-28 20:34:05+00:00,[arxiv.Result.Author('Ademir Hujdurovic')],
580,Strong Partially Greedy Bases with Respect to an Arbitrary Sequence,"For Schauder bases, Dilworth et al. introduced and characterized the
partially greedy property, which is strictly weaker than the (almost) greedy
property. Later, Berasategui et al. defined and studied the strong partially
greedy property for general bases. Let $\mathbf n$ be any strictly increasing
sequence of positive integers. In this paper, we define the strong partially
greedy property with respect to $\mathbf n$, called the ($\mathbf n$, strong
partially greedy) property. We give characterizations of this new property,
study relations among ($\mathbf n$, strong partially greedy) properties for
different sequences $\mathbf n$, establish Lebesgue-type inequalities for the
($\mathbf n$, strong partially greedy) parameter, investigate ($\mathbf n$,
strong partially greedy) bases with gaps, and weighted ($\mathbf n$, strong
partially greedy) bases, to name a few. Furthermore, we introduce the ($\mathbf
n$, almost greedy) property and equate the property to a strengthening of the
($\mathbf n$, strong partially greedy) property. This paper can be viewed both
as a survey of recent results regarding strong partially greedy bases and as a
natural and nontrivial extension of these results to an arbitrary sequence
instead of $\mathbb{N}$.",2208.07300v1,math.FA,2022-08-10 16:30:34+00:00,[arxiv.Result.Author('Hung Viet Chu')],
581,Practical Algorithms for STV and Ranked Pairs with Parallel Universes Tiebreaking,"STV and ranked pairs (RP) are two well-studied voting rules for group
decision-making. They proceed in multiple rounds, and are affected by how ties
are broken in each round. However, the literature is surprisingly vague about
how ties should be broken. We propose the first algorithms for computing the
set of alternatives that are winners under some tiebreaking mechanism under STV
and RP, which is also known as parallel-universes tiebreaking (PUT).
Unfortunately, PUT-winners are NP-complete to compute under STV and RP, and
standard search algorithms from AI do not apply. We propose multiple DFS-based
algorithms along with pruning strategies and heuristics to prioritize search
direction to significantly improve the performance using machine learning. We
also propose novel ILP formulations for PUT-winners under STV and RP,
respectively. Experiments on synthetic and real-world data show that our
algorithms are overall significantly faster than ILP, while there are a few
cases where ILP is significantly faster for RP.",1805.06992v1,cs.AI,2018-05-17 23:20:57+00:00,"[arxiv.Result.Author('Jun Wang'), arxiv.Result.Author('Sujoy Sikdar'), arxiv.Result.Author('Tyler Shepherd'), arxiv.Result.Author('Zhibing Zhao'), arxiv.Result.Author('Chunheng Jiang'), arxiv.Result.Author('Lirong Xia')]",
582,The vote Package: Single Transferable Vote and Other Electoral Systems in R,"We describe the vote package in R, which implements the plurality (or
first-past-the-post), two-round runoff, score, approval and single transferable
vote (STV) electoral systems, as well as methods for selecting the Condorcet
winner and loser. We emphasize the STV system, which we have found to work well
in practice for multi-winner elections with small electorates, such as
committee and council elections, and the selection of multiple job candidates.
For single-winner elections, the STV is also called instant runoff voting
(IRV), ranked choice voting (RCV), or the alternative vote (AV) system. The
package also implements the STV system with equal preferences, for the first
time in a software package, to our knowledge. It also implements a new variant
of STV, in which a minimum number of candidates from a specified group are
required to be elected. We illustrate the package with several real examples.",2102.05801v1,stat.CO,2021-02-11 01:50:46+00:00,"[arxiv.Result.Author('Adrian E. Raftery'), arxiv.Result.Author('Hana Ševčíková'), arxiv.Result.Author('Bernard W. Silverman')]",
583,Towards Computing Victory Margins in STV Elections,"The Single Transferable Vote (STV) is a system of preferential voting
employed in multi-seat elections. Each vote cast by a voter is a (potentially
partial) ranking over a set of candidates. No techniques currently exist for
computing the margin of victory (MOV) in STV elections. The MOV is the smallest
number of vote manipulations (changes, additions, and deletions) required to
bring about a change in the set of elected candidates. Knowledge of the MOV of
an election gives greater insight into both how much time and money should be
spent on the auditing of the election, and whether uncovered mistakes (such as
ballot box losses) throw the election result into doubt---requiring a costly
repeat election---or can be safely ignored. In this paper, we present
algorithms for computing lower and upper bounds on the MOV in STV elections. In
small instances, these algorithms are able to compute exact margins.",1703.03511v2,cs.GT,2017-03-10 01:47:23+00:00,"[arxiv.Result.Author('Michelle Blom'), arxiv.Result.Author('Peter J. Stuckey'), arxiv.Result.Author('Vanessa J. Teague')]",
584,The Expanding Approvals Rule: Improving Proportional Representation and Monotonicity,"Proportional representation (PR) is often discussed in voting settings as a
major desideratum. For the past century or so, it is common both in practice
and in the academic literature to jump to single transferable vote (STV) as the
solution for achieving PR. Some of the most prominent electoral reform
movements around the globe are pushing for the adoption of STV. It has been
termed a major open problem to design a voting rule that satisfies the same PR
properties as STV and better monotonicity properties. In this paper, we first
present a taxonomy of proportional representation axioms for general weak order
preferences, some of which generalise and strengthen previously introduced
concepts. We then present a rule called Expanding Approvals Rule (EAR) that
satisfies properties stronger than the central PR axiom satisfied by STV, can
handle indifferences in a convenient and computationally efficient manner, and
also satisfies better candidate monotonicity properties. In view of this, our
proposed rule seems to be a compelling solution for achieving proportional
representation in voting settings.",1708.07580v2,cs.GT,2017-08-25 00:10:43+00:00,"[arxiv.Result.Author('Haris Aziz'), arxiv.Result.Author('Barton Lee')]",
585,Practical Algorithms for Multi-Stage Voting Rules with Parallel Universes Tiebreaking,"STV and ranked pairs (RP) are two well-studied voting rules for group
decision-making. They proceed in multiple rounds, and are affected by how ties
are broken in each round. However, the literature is surprisingly vague about
how ties should be broken. We propose the first algorithms for computing the
set of alternatives that are winners under some tiebreaking mechanism under STV
and RP, which is also known as parallel-universes tiebreaking (PUT).
Unfortunately, PUT-winners are NP-complete to compute under STV and RP, and
standard search algorithms from AI do not apply. We propose multiple DFS-based
algorithms along with pruning strategies, heuristics, sampling and machine
learning to prioritize search direction to significantly improve the
performance. We also propose novel ILP formulations for PUT-winners under STV
and RP, respectively. Experiments on synthetic and real-world data show that
our algorithms are overall faster than ILP.",1901.09791v1,cs.AI,2019-01-16 21:41:39+00:00,"[arxiv.Result.Author('Jun Wang'), arxiv.Result.Author('Sujoy Sikdar'), arxiv.Result.Author('Tyler Shepherd'), arxiv.Result.Author('Zhibing Zhao'), arxiv.Result.Author('Chunheng Jiang'), arxiv.Result.Author('Lirong Xia')]",
586,A First Approach to Risk-Limiting Audits for Single Transferable Vote Elections,"Risk-limiting audits (RLAs) are an increasingly important method for checking
that the reported outcome of an election is, in fact, correct. Indeed, their
use is increasingly being legislated. While effective methods for RLAs have
been developed for many forms of election -- for example: first-past-the-post,
instant-runoff voting, and D'Hondt elections -- auditing methods for single
transferable vote (STV) elections have yet to be developed. STV elections are
notoriously hard to reason about since there is a complex interaction of votes
that change their value throughout the process. In this paper we present the
first approach to risk-limiting audits for STV elections, restricted to the
case of 2-seat STV elections.",2112.09921v1,cs.CY,2021-12-18 12:36:39+00:00,"[arxiv.Result.Author('Michelle Blom'), arxiv.Result.Author('Peter J. Stuckey'), arxiv.Result.Author('Vanessa Teague'), arxiv.Result.Author('Damjan Vukcevic')]",
587,Classification of Hyperspectral Images Using SVM with Shape-adaptive Reconstruction and Smoothed Total Variation,"In this work, a novel algorithm called SVM with Shape-adaptive Reconstruction
and Smoothed Total Variation (SaR-SVM-STV) is introduced to classify
hyperspectral images, which makes full use of spatial and spectral information.
The Shape-adaptive Reconstruction (SaR) is introduced to preprocess each pixel
based on the Pearson Correlation between pixels in its shape-adaptive (SA)
region. Support Vector Machines (SVMs) are trained to estimate the pixel-wise
probability maps of each class. Then the Smoothed Total Variation (STV) model
is applied to denoise and generate the final classification map. Experiments
show that SaR-SVM-STV outperforms the SVM-STV method with a few training
labels, demonstrating the significance of reconstructing hyperspectral images
before classification.",2203.15619v3,cs.CV,2022-03-29 14:39:21+00:00,"[arxiv.Result.Author('Ruoning Li'), arxiv.Result.Author('Kangning Cui'), arxiv.Result.Author('Raymond H. Chan'), arxiv.Result.Author('Robert J. Plemmons')]",
588,Simultaneous Control of the Spatial and Temporal Spectra of Light with Space-Time Varying Metasurfaces,"This paper presents space-time varying (STV) metasurfaces for simultaneously
controlling the spatial and temporal spectra of electromagnetic waves. These
metasurfaces transform incident electromagnetic waves into specified reflected
and transmitted waves, with arbitrary temporal and spatial frequencies. They
are synthesized in terms of time-domain generalized sheet transition conditions
(GSTCs). Moreover, they are characterized using an analytical method and the
unstaggered finite-difference time-domain (FDTD) technique adapted to
space-time metasurfaces. STV metasurfaces performing pulse shaping, time
reversal and differentiation are demonstrated as examples.",1808.03385v2,physics.optics,2018-08-10 01:40:51+00:00,"[arxiv.Result.Author('Nima Chamanara'), arxiv.Result.Author('Yousef Vahabzadeh'), arxiv.Result.Author('Christophe Caloz')]",
589,STV+AGR: Towards Practical Verification of Strategic Ability Using Assume-Guarantee Reasoning,"We present a substantially expanded version of our tool STV for strategy
synthesis and verification of strategic abilities. The new version provides a
web interface and support for assume-guarantee verification of multi-agent
systems.",2203.01033v1,cs.MA,2022-03-02 11:19:09+00:00,"[arxiv.Result.Author('Damian Kurpiewski'), arxiv.Result.Author('Łukasz Mikulski'), arxiv.Result.Author('Wojciech Jamroga')]",
590,Adaptive Direction-Guided Structure Tensor Total Variation,"Direction-guided structure tensor total variation (DSTV) is a recently
proposed regularization term that aims at increasing the sensitivity of the
structure tensor total variation (STV) to the changes towards a predetermined
direction. Despite of the plausible results obtained on the uni-directional
images, the DSTV model is not applicable to the multi-directional images of
real-world. In this study, we build a two-stage framework that brings
adaptivity to DSTV. We design an alternative to STV, which encodes the
first-order information within a local neighborhood under the guidance of
spatially varying directional descriptors (i.e., orientation and the dose of
anisotropy). In order to estimate those descriptors, we propose an efficient
preprocessor that captures the local geometry based on the structure tensor.
Through the extensive experiments, we demonstrate how beneficial the
involvement of the directional information in STV is, by comparing the proposed
method with the state-of-the-art analysis-based denoising models, both in terms
of restoration quality and computational efficiency.",2001.05717v1,eess.IV,2020-01-16 09:49:29+00:00,"[arxiv.Result.Author('Ezgi Demircan-Tureyen'), arxiv.Result.Author('Mustafa E. Kamasak')]",
591,Quasi-simultaneous two band optical variability of the blazars 1ES 1959+650 and 1ES 2344+514,"We report the results of quasi-simultaneous two filter optical monitoring of
two high-energy peaked blazars, 1ES 1959+650 and 1ES 2344+514, to search for
microvariability and short-term variability (STV). We carried out optical
photometric monitoring of these sources in an alternating sequence of B and R
pass-bands, and have 24 and 19 nights of new data for these two sources,
respectively. No genuine microvariability (intra-night variability) was
detected in either of these sources. This non-detection of intra-night
variations is in agreement with the conclusions of previous studies that
high-energy peaked BL Lacs are intrinsically less variable than low-energy
peaked BL Lacs in the optical bands. We also report the results of STV studies
for these two sources between July 2009 and August 2010. Genuine STV is found
for the source 1ES 1959+650 but not for 1ES 2344+514. We briefly discuss
possible reasons for the difference between the intra-night variability
behaviour of high- and low-energy peaked blazars.",1112.3125v1,astro-ph.CO,2011-12-14 05:44:23+00:00,"[arxiv.Result.Author('Haritma Gaur'), arxiv.Result.Author('Alok C. Gupta'), arxiv.Result.Author('A. Strigachev'), arxiv.Result.Author('R. Bachev'), arxiv.Result.Author('E. Semkov'), arxiv.Result.Author('Paul J. Wiita'), arxiv.Result.Author('S. Peneva'), arxiv.Result.Author('S. Boeva'), arxiv.Result.Author('N. Kacharov'), arxiv.Result.Author('B. Mihov'), arxiv.Result.Author('E. Ovcharov')]",
592,"Dimensionality, Coordination, and Robustness in Voting","We study the performance of voting mechanisms from a utilitarian standpoint,
under the recently introduced framework of metric-distortion, offering new
insights along three main lines. First, if $d$ represents the doubling
dimension of the metric space, we show that the distortion of STV is $O(d \log
\log m)$, where $m$ represents the number of candidates. For doubling metrics
this implies an exponential improvement over the lower bound for general
metrics, and as a special case it effectively answers a question left open by
Skowron and Elkind (AAAI '17) regarding the distortion of STV under
low-dimensional Euclidean spaces. More broadly, this constitutes the first
nexus between the performance of any voting rule and the ""intrinsic
dimensionality"" of the underlying metric space. We also establish a
nearly-matching lower bound, refining the construction of Skowron and Elkind.
Moreover, motivated by the efficiency of STV, we investigate whether natural
learning rules can lead to low-distortion outcomes. Specifically, we introduce
simple, deterministic and decentralized exploration/exploitation dynamics, and
we show that they converge to a candidate with $O(1)$ distortion. Finally,
driven by applications in facility location games, we consider several
refinements and extensions of the standard metric-setting. Namely, we prove
that the deterministic mechanism recently introduced by Gkatzelis, Halpern, and
Shah (FOCS '20) attains the optimal distortion bound of $2$ under
ultra-metrics, while it also comes close to our lower bound under distances
satisfying approximate triangle inequalities.",2109.02184v2,cs.GT,2021-09-05 23:24:20+00:00,"[arxiv.Result.Author('Ioannis Anagnostides'), arxiv.Result.Author('Dimitris Fotakis'), arxiv.Result.Author('Panagiotis Patsilinakos')]",
593,Ballot-Polling Audits of Instant-Runoff Voting Elections with a Dirichlet-Tree Model,"Instant-runoff voting (IRV) is used in several countries around the world. It
requires voters to rank candidates in order of preference, and uses a counting
algorithm that is more complex than systems such as first-past-the-post or
scoring rules. An even more complex system, the single transferable vote (STV),
is used when multiple candidates need to be elected. The complexity of these
systems has made it difficult to audit the election outcomes. There is
currently no known risk-limiting audit (RLA) method for STV, other than a full
manual count of the ballots.
  A new approach to auditing these systems was recently proposed, based on a
Dirichlet-tree model. We present a detailed analysis of this approach for
ballot-polling Bayesian audits of IRV elections. We compared several choices
for the prior distribution, including some approaches using a Bayesian
bootstrap (equivalent to an improper prior). Our findings include that the
bootstrap-based approaches can be adapted to perform similarly to a full
Bayesian model in practice, and that an overly informative prior can give
counter-intuitive results. Via carefully chosen examples, we show why creating
an RLA with this model is challenging, but we also suggest ways to overcome
this.
  As well as providing a practical and computationally feasible implementation
of a Bayesian IRV audit, our work is important in laying the foundation for an
RLA for STV elections.",2209.03881v1,stat.AP,2022-09-08 15:35:50+00:00,"[arxiv.Result.Author('Floyd Everest'), arxiv.Result.Author('Michelle Blom'), arxiv.Result.Author('Philip B. Stark'), arxiv.Result.Author('Peter J. Stuckey'), arxiv.Result.Author('Vanessa Teague'), arxiv.Result.Author('Damjan Vukcevic')]",
594,Where are the hard manipulation problems?,"One possible escape from the Gibbard-Satterthwaite theorem is computational
complexity. For example, it is NP-hard to compute if the STV rule can be
manipulated. However, there is increasing concern that such results may not re
ect the difficulty of manipulation in practice. In this tutorial, I survey
recent results in this area.",1007.5114v1,cs.AI,2010-07-29 05:52:53+00:00,[arxiv.Result.Author('Toby Walsh')],
595,A Practical Grid-Partitioning Method Considering the Dynamic VAR Response of Power Grid under Contingency Set,"Due to the increasing load demand, the operating state of modern power
systems are become closing to their critical levels. Moreover, the modern power
systems are integrated with a large amount of fast-response dynamic elements,
so the short-term voltage stability (STVS) issues should be taken seriously. In
order to improve the STVS of power systems, we can optimize the dynamic VAR
reserve under contingency set. However, the scale of actual power grids is
usually large, so it is hard to solve the overall optimization problem
directly. To reduce the difficulty of solving the problem, a practical
grid-partitioning method considering the dynamic VAR response of power grid
under contingency set is proposed in this paper, to decompose the overall
problem into several sub-problems. The buses in each region are similar in
terms of voltage response to dynamic VARs and contingencies. The effectiveness
of the proposed method is verified based on a region power grid model of China.",1808.09203v1,cs.SY,2018-08-28 09:59:08+00:00,[arxiv.Result.Author('Wenlu Zhao')],
596,An Empirical Study of the Manipulability of Single Transferable Voting,"Voting is a simple mechanism to combine together the preferences of multiple
agents. Agents may try to manipulate the result of voting by mis-reporting
their preferences. One barrier that might exist to such manipulation is
computational complexity. In particular, it has been shown that it is NP-hard
to compute how to manipulate a number of different voting rules. However,
NP-hardness only bounds the worst-case complexity. Recent theoretical results
suggest that manipulation may often be easy in practice. In this paper, we
study empirically the manipulability of single transferable voting (STV) to
determine if computational complexity is really a barrier to manipulation. STV
was one of the first voting rules shown to be NP-hard. It also appears one of
the harder voting rules to manipulate. We sample a number of distributions of
votes including uniform and real world elections. In almost every election in
our experiments, it was easy to compute how a single agent could manipulate the
election or to prove that manipulation by a single agent was impossible.",1005.5268v1,cs.AI,2010-05-28 11:11:56+00:00,[arxiv.Result.Author('Toby Walsh')],
597,On Modules Over Motivic Ring Spectra,"In this note, we provide an axiomatic framework that characterizes the stable
$\infty$-categories that are module categories over a motivic spectrum. This is
done by invoking Lurie's $\infty$-categorical version of the Barr--Beck
theorem. As an application, this gives an alternative approach to R\""ondigs and
\O stv\ae r's theorem relating Voevodsky's motives with modules over motivic
cohomology, and to Garkusha's extension of R\""ondigs and \O stv\ae r's result
to general correspondence categories, including the category of Milnor-Witt
correspondences in the sense of Calm\`es and Fasel. We also extend these
comparison results to regular Noetherian schemes over a field (after inverting
the residue characteristic), following the methods of Cisinski and D\'eglise.",1708.05651v4,math.AG,2017-08-18 15:36:38+00:00,"[arxiv.Result.Author('Elden Elmanto'), arxiv.Result.Author('Håkon Kolderup')]",Ann. K-Th. 5 (2020) 327-355
598,What Do Multiwinner Voting Rules Do? An Experiment Over the Two-Dimensional Euclidean Domain,"We visualize aggregate outputs of popular multiwinner voting rules--SNTV,
STV, Bloc, k-Borda, Monroe, Chamberlin--Courant, and HarmonicBorda--for
elections generated according to the two-dimensional Euclidean model. We
consider three applications of multiwinner voting, namely, parliamentary
elections, portfolio/movie selection, and shortlisting, and use our results to
understand which of our rules seem to be best suited for each application. In
particular, we show that STV (one of the few nontrivial rules used in real
high-stake elections) exhibits excellent performance, whereas the Bloc rule
(also often used in practice) performs poorly.",1901.09217v1,cs.GT,2019-01-26 14:03:04+00:00,"[arxiv.Result.Author('Edith Elkind'), arxiv.Result.Author('Piotr Faliszewski'), arxiv.Result.Author('Jean-Francois Laslier'), arxiv.Result.Author('Piotr Skowron'), arxiv.Result.Author('Arkadii Slinko'), arxiv.Result.Author('Nimrod Talmon')]",
599,Random errors are not necessarily politically neutral,"Errors are inevitable in the implementation of any complex process. Here we
examine the effect of random errors on Single Transferable Vote (STV)
elections, a common approach to deciding multi-seat elections. It is usually
expected that random errors should have nearly equal effects on all candidates,
and thus be fair. We find to the contrary that random errors can introduce
systematic bias into election results. This is because, even if the errors are
random, votes for different candidates occur in different patterns that are
affected differently by random errors. In the STV context, the most important
effect of random errors is to invalidate the ballot. This removes far more
votes for those candidates whose supporters tend to list a lot of preferences,
because their ballots are much more likely to be invalidated by random error.
Different validity rules for different voting styles mean that errors are much
more likely to penalise some types of votes than others. For close elections
this systematic bias can change the result of the election.",2007.00854v3,cs.CY,2020-07-02 03:37:48+00:00,"[arxiv.Result.Author('Michelle Blom'), arxiv.Result.Author('Andrew Conway'), arxiv.Result.Author('Peter J. Stuckey'), arxiv.Result.Author('Vanessa Teague'), arxiv.Result.Author('Damjan Vukcevic')]","Electronic Voting, E-Vote-ID 2020, Lecture Notes in Computer
  Science 12455 (2020) 19-35"
600,Deep Learning for Short-Term Voltage Stability Assessment of Power Systems,"To fully learn the latent temporal dependencies from post-disturbance system
dynamic trajectories, deep learning is utilized for short-term voltage
stability (STVS) assessment of power systems in this paper. First of all, a
semi-supervised cluster algorithm is performed to obtain class labels of STVS
instances due to the unavailability of reliable quantitative criteria.
Secondly, a long short-term memory (LSTM) based assessment model is built
through learning the time dependencies from the post-disturbance system
dynamics. Finally, the trained assessment model is employed to determine the
systems stability status in real time. The test results on the IEEE 39-bus
system suggest that the proposed approach manages to assess the stability
status of the system accurately and timely. Furthermore, the superiority of the
proposed method over traditional shallow learning-based assessment methods has
also been proved.",2102.02526v1,eess.SP,2021-02-04 10:33:33+00:00,"[arxiv.Result.Author('Meng Zhang'), arxiv.Result.Author('Jiazheng Li'), arxiv.Result.Author('Yang Li'), arxiv.Result.Author('Runnan Xu')]",IEEE Access 9 (2021) 29711-29718
601,The vote Package: Single Transferable Vote and Other Electoral Systems in R,"We describe the vote package in R, which implements the plurality (or
first-past-the-post), two-round runoff, score, approval and single transferable
vote (STV) electoral systems, as well as methods for selecting the Condorcet
winner and loser. We emphasize the STV system, which we have found to work well
in practice for multi-winner elections with small electorates, such as
committee and council elections, and the selection of multiple job candidates.
For single-winner elections, the STV is also called instant runoff voting
(IRV), ranked choice voting (RCV), or the alternative vote (AV) system. The
package also implements the STV system with equal preferences, for the first
time in a software package, to our knowledge. It also implements a new variant
of STV, in which a minimum number of candidates from a specified group are
required to be elected. We illustrate the package with several real examples.",2102.05801v1,stat.CO,2021-02-11 01:50:46+00:00,"[arxiv.Result.Author('Adrian E. Raftery'), arxiv.Result.Author('Hana Ševčíková'), arxiv.Result.Author('Bernard W. Silverman')]",
602,A First Approach to Risk-Limiting Audits for Single Transferable Vote Elections,"Risk-limiting audits (RLAs) are an increasingly important method for checking
that the reported outcome of an election is, in fact, correct. Indeed, their
use is increasingly being legislated. While effective methods for RLAs have
been developed for many forms of election -- for example: first-past-the-post,
instant-runoff voting, and D'Hondt elections -- auditing methods for single
transferable vote (STV) elections have yet to be developed. STV elections are
notoriously hard to reason about since there is a complex interaction of votes
that change their value throughout the process. In this paper we present the
first approach to risk-limiting audits for STV elections, restricted to the
case of 2-seat STV elections.",2112.09921v1,cs.CY,2021-12-18 12:36:39+00:00,"[arxiv.Result.Author('Michelle Blom'), arxiv.Result.Author('Peter J. Stuckey'), arxiv.Result.Author('Vanessa Teague'), arxiv.Result.Author('Damjan Vukcevic')]",
603,Towards Computing Victory Margins in STV Elections,"The Single Transferable Vote (STV) is a system of preferential voting
employed in multi-seat elections. Each vote cast by a voter is a (potentially
partial) ranking over a set of candidates. No techniques currently exist for
computing the margin of victory (MOV) in STV elections. The MOV is the smallest
number of vote manipulations (changes, additions, and deletions) required to
bring about a change in the set of elected candidates. Knowledge of the MOV of
an election gives greater insight into both how much time and money should be
spent on the auditing of the election, and whether uncovered mistakes (such as
ballot box losses) throw the election result into doubt---requiring a costly
repeat election---or can be safely ignored. In this paper, we present
algorithms for computing lower and upper bounds on the MOV in STV elections. In
small instances, these algorithms are able to compute exact margins.",1703.03511v2,cs.GT,2017-03-10 01:47:23+00:00,"[arxiv.Result.Author('Michelle Blom'), arxiv.Result.Author('Peter J. Stuckey'), arxiv.Result.Author('Vanessa J. Teague')]",
604,The Expanding Approvals Rule: Improving Proportional Representation and Monotonicity,"Proportional representation (PR) is often discussed in voting settings as a
major desideratum. For the past century or so, it is common both in practice
and in the academic literature to jump to single transferable vote (STV) as the
solution for achieving PR. Some of the most prominent electoral reform
movements around the globe are pushing for the adoption of STV. It has been
termed a major open problem to design a voting rule that satisfies the same PR
properties as STV and better monotonicity properties. In this paper, we first
present a taxonomy of proportional representation axioms for general weak order
preferences, some of which generalise and strengthen previously introduced
concepts. We then present a rule called Expanding Approvals Rule (EAR) that
satisfies properties stronger than the central PR axiom satisfied by STV, can
handle indifferences in a convenient and computationally efficient manner, and
also satisfies better candidate monotonicity properties. In view of this, our
proposed rule seems to be a compelling solution for achieving proportional
representation in voting settings.",1708.07580v2,cs.GT,2017-08-25 00:10:43+00:00,"[arxiv.Result.Author('Haris Aziz'), arxiv.Result.Author('Barton Lee')]",
605,An Empirical Study of the Manipulability of Single Transferable Voting,"Voting is a simple mechanism to combine together the preferences of multiple
agents. Agents may try to manipulate the result of voting by mis-reporting
their preferences. One barrier that might exist to such manipulation is
computational complexity. In particular, it has been shown that it is NP-hard
to compute how to manipulate a number of different voting rules. However,
NP-hardness only bounds the worst-case complexity. Recent theoretical results
suggest that manipulation may often be easy in practice. In this paper, we
study empirically the manipulability of single transferable voting (STV) to
determine if computational complexity is really a barrier to manipulation. STV
was one of the first voting rules shown to be NP-hard. It also appears one of
the harder voting rules to manipulate. We sample a number of distributions of
votes including uniform and real world elections. In almost every election in
our experiments, it was easy to compute how a single agent could manipulate the
election or to prove that manipulation by a single agent was impossible.",1005.5268v1,cs.AI,2010-05-28 11:11:56+00:00,[arxiv.Result.Author('Toby Walsh')],
606,Random errors are not necessarily politically neutral,"Errors are inevitable in the implementation of any complex process. Here we
examine the effect of random errors on Single Transferable Vote (STV)
elections, a common approach to deciding multi-seat elections. It is usually
expected that random errors should have nearly equal effects on all candidates,
and thus be fair. We find to the contrary that random errors can introduce
systematic bias into election results. This is because, even if the errors are
random, votes for different candidates occur in different patterns that are
affected differently by random errors. In the STV context, the most important
effect of random errors is to invalidate the ballot. This removes far more
votes for those candidates whose supporters tend to list a lot of preferences,
because their ballots are much more likely to be invalidated by random error.
Different validity rules for different voting styles mean that errors are much
more likely to penalise some types of votes than others. For close elections
this systematic bias can change the result of the election.",2007.00854v3,cs.CY,2020-07-02 03:37:48+00:00,"[arxiv.Result.Author('Michelle Blom'), arxiv.Result.Author('Andrew Conway'), arxiv.Result.Author('Peter J. Stuckey'), arxiv.Result.Author('Vanessa Teague'), arxiv.Result.Author('Damjan Vukcevic')]","Electronic Voting, E-Vote-ID 2020, Lecture Notes in Computer
  Science 12455 (2020) 19-35"
607,Obvious Independence of Clones,"The Independence of Clones (IoC) criterion for social choice functions
(voting rules) measures a function's robustness to strategic nomination.
However, prior literature has established empirically that individuals cannot
always recognize whether or not a mechanism is strategy-proof and may still
submit costly, distortionary misreports even in strategy-proof settings. The
intersection of these issues motivates the search for mechanisms which are
Obviously Independent of Clones (OIoC): where strategic nomination or strategic
exiting of clones obviously have no effect on the outcome of the election. We
examine three IoC ranked-choice voting mechanisms and the pre-existing proofs
that they are independent of clones: Single Transferable Vote (STV), Ranked
Pairs, and the Schulze method. We construct a formal definition of a voting
system being Obviously Independent of Clones based on a reduction to a clocked
election by considering a bounded agent. Finally, we show that STV and Ranked
Pairs are OIoC, whereas we prove an impossibility result for the Schulze method
showing that this voting system is not OIoC.",2210.04880v1,cs.GT,2022-10-10 17:52:28+00:00,"[arxiv.Result.Author('Ratip Emin Berker'), arxiv.Result.Author('Sílvia Casacuberta'), arxiv.Result.Author('Christopher Ong'), arxiv.Result.Author('Isaac Robinson')]",
608,Auditing Ranked Voting Elections with Dirichlet-Tree Models: First Steps,"Ranked voting systems, such as instant-runoff voting (IRV) and single
transferable vote (STV), are used in many places around the world. They are
more complex than plurality and scoring rules, presenting a challenge for
auditing their outcomes: there is no known risk-limiting audit (RLA) method for
STV other than a full hand count.
  We present a new approach to auditing ranked systems that uses a statistical
model, a Dirichlet-tree, that can cope with high-dimensional parameters in a
computationally efficient manner. We demonstrate this approach with a
ballot-polling Bayesian audit for IRV elections. Although the technique is not
known to be risk-limiting, we suggest some strategies that might allow it to be
calibrated to limit risk.",2206.14605v2,stat.AP,2022-06-29 13:06:42+00:00,"[arxiv.Result.Author('Floyd Everest'), arxiv.Result.Author('Michelle Blom'), arxiv.Result.Author('Philip B. Stark'), arxiv.Result.Author('Peter J. Stuckey'), arxiv.Result.Author('Vanessa Teague'), arxiv.Result.Author('Damjan Vukcevic')]","E-Vote-ID 2022, Conference Proceedings, UT Press, pages 76-80"
609,On the Manipulability of Voting Systems: Application to Multi-Carrier Networks,"Today, Internet involves many actors who are making revenues on it
(operators, companies, service providers,...). It is therefore important to be
able to make fair decisions in this large-scale and highly competitive
economical ecosystem. One of the main issues is to prevent actors from
manipulating the natural outcome of the decision process. For that purpose,
game theory is a natural framework. In that context, voting systems represent
an interesting alternative that, to our knowledge, has not yet been considered.
They allow competing entities to decide among different options. Strong
theoretical results showed that all voting systems are susceptible to be
manipulated by one single voter, except for some ""degenerated"" and
non-acceptable cases. However, very little is known about how much a voting
system is manipulable in practical scenarios. In this paper, we investigate
empirically the use of voting systems for choosing end-to-end paths in
multi-carrier networks, analyzing their manipulability and their economical
efficiency. We show that one particular system, called \Single Transferable
Vote (STV), is largely more resistant to manipulability than the natural system
which tries to get the economical optimum. Moreover, STV manages to select
paths close to the economical optimum, whether the participants try to cheat or
not.",1204.6455v1,cs.NI,2012-04-29 05:30:06+00:00,"[arxiv.Result.Author('François Durand'), arxiv.Result.Author('Fabien Mathieu'), arxiv.Result.Author('Ludovic Noirie')]",N&deg; 2012-04-001 (2012)
610,Ballot-Polling Audits of Instant-Runoff Voting Elections with a Dirichlet-Tree Model,"Instant-runoff voting (IRV) is used in several countries around the world. It
requires voters to rank candidates in order of preference, and uses a counting
algorithm that is more complex than systems such as first-past-the-post or
scoring rules. An even more complex system, the single transferable vote (STV),
is used when multiple candidates need to be elected. The complexity of these
systems has made it difficult to audit the election outcomes. There is
currently no known risk-limiting audit (RLA) method for STV, other than a full
manual count of the ballots.
  A new approach to auditing these systems was recently proposed, based on a
Dirichlet-tree model. We present a detailed analysis of this approach for
ballot-polling Bayesian audits of IRV elections. We compared several choices
for the prior distribution, including some approaches using a Bayesian
bootstrap (equivalent to an improper prior). Our findings include that the
bootstrap-based approaches can be adapted to perform similarly to a full
Bayesian model in practice, and that an overly informative prior can give
counter-intuitive results. Via carefully chosen examples, we show why creating
an RLA with this model is challenging, but we also suggest ways to overcome
this.
  As well as providing a practical and computationally feasible implementation
of a Bayesian IRV audit, our work is important in laying the foundation for an
RLA for STV elections.",2209.03881v1,stat.AP,2022-09-08 15:35:50+00:00,"[arxiv.Result.Author('Floyd Everest'), arxiv.Result.Author('Michelle Blom'), arxiv.Result.Author('Philip B. Stark'), arxiv.Result.Author('Peter J. Stuckey'), arxiv.Result.Author('Vanessa Teague'), arxiv.Result.Author('Damjan Vukcevic')]",
611,Manipulability of Single Transferable Vote,"For many voting rules, it is NP-hard to compute a successful manipulation.
However, NP-hardness only bounds the worst-case complexity. Recent theoretical
results suggest that manipulation may often be easy in practice. We study
empirically the cost of manipulating the single transferable vote (STV) rule.
This was one of the first rules shown to be NP-hard to manipulate. It also
appears to be one of the harder rules to manipulate since it involves multiple
rounds and since, unlike many other rules, it is NP-hard for a single agent to
manipulate without weights on the votes or uncertainty about how the other
agents have voted. In almost every election in our experiments, it was easy to
compute how a single agent could manipulate the election or to prove that
manipulation by a single agent was impossible. It remains an interesting open
question if manipulation by a coalition of agents is hard to compute in
practice.",0911.3708v1,cs.AI,2009-11-19 06:23:55+00:00,[arxiv.Result.Author('Toby Walsh')],
612,Relating Metric Distortion and Fairness of Social Choice Rules,"One way of evaluating social choice (voting) rules is through a utilitarian
distortion framework. In this model, we assume that agents submit full rankings
over the alternatives, and these rankings are generated from underlying, but
unknown, quantitative costs. The \emph{distortion} of a social choice rule is
then the ratio of the total social cost of the chosen alternative to the
optimal social cost of any alternative; since the true costs are unknown, we
consider the worst-case distortion over all possible underlying costs.
Analogously, we can consider the worst-case \emph{fairness ratio} of a social
choice rule by comparing a useful notion of fairness (based on approximate
majorization) for the chosen alternative to that of the optimal alternative.
With an additional metric assumption -- that the costs equal the
agent-alternative distances in some metric space -- it is known that the
Copeland rule achieves both a distortion and fairness ratio of at most 5. For
other rules, only bounds on the distortion are known, e.g., the popular Single
Transferable Vote (STV) rule has distortion $O(\log m)$, where $m$ is the
number of alternatives. We prove that the distinct notions of distortion and
fairness ratio are in fact closely linked -- within an additive factor of 2 for
any voting rule -- and thus STV also achieves an $O(\log m)$ fairness ratio. We
further extend the notions of distortion and fairness ratio to social choice
rules choosing a \emph{set} of alternatives. By relating the distortion of
single-winner rules to multiple-winner rules, we establish that Recursive
Copeland achieves a distortion of 5 and a fairness ratio of at most 7 for
choosing a set of alternatives.",1810.01092v1,cs.GT,2018-10-02 07:03:08+00:00,"[arxiv.Result.Author('Ashish Goel'), arxiv.Result.Author('Reyna Hulett'), arxiv.Result.Author('Anilesh K. Krishnaswamy')]",
613,Equality of Voice: Towards Fair Representation in Crowdsourced Top-K Recommendations,"To help their users to discover important items at a particular time, major
websites like Twitter, Yelp, TripAdvisor or NYTimes provide Top-K
recommendations (e.g., 10 Trending Topics, Top 5 Hotels in Paris or 10 Most
Viewed News Stories), which rely on crowdsourced popularity signals to select
the items. However, different sections of a crowd may have different
preferences, and there is a large silent majority who do not explicitly express
their opinion. Also, the crowd often consists of actors like bots, spammers, or
people running orchestrated campaigns. Recommendation algorithms today largely
do not consider such nuances, hence are vulnerable to strategic manipulation by
small but hyper-active user groups.
  To fairly aggregate the preferences of all users while recommending top-K
items, we borrow ideas from prior research on social choice theory, and
identify a voting mechanism called Single Transferable Vote (STV) as having
many of the fairness properties we desire in top-K item (s)elections. We
develop an innovative mechanism to attribute preferences of silent majority
which also make STV completely operational. We show the generalizability of our
approach by implementing it on two different real-world datasets. Through
extensive experimentation and comparison with state-of-the-art techniques, we
show that our proposed approach provides maximum user satisfaction, and cuts
down drastically on items disliked by most but hyper-actively promoted by a few
users.",1811.08690v1,cs.SI,2018-11-21 11:25:01+00:00,"[arxiv.Result.Author('Abhijnan Chakraborty'), arxiv.Result.Author('Gourab K Patro'), arxiv.Result.Author('Niloy Ganguly'), arxiv.Result.Author('Krishna P. Gummadi'), arxiv.Result.Author('Patrick Loiseau')]",
614,Rank Aggregation Using Scoring Rules,"To aggregate rankings into a social ranking, one can use scoring systems such
as Plurality, Veto, and Borda. We distinguish three types of methods: ranking
by score, ranking by repeatedly choosing a winner that we delete and rank at
the top, and ranking by repeatedly choosing a loser that we delete and rank at
the bottom. The latter method captures the frequently studied voting rules
Single Transferable Vote (aka Instant Runoff Voting), Coombs, and Baldwin. In
an experimental analysis, we show that the three types of methods produce
different rankings in practice. We also provide evidence that sequentially
selecting winners is most suitable to detect the ""true"" ranking of candidates.
For different rules in our classes, we then study the (parameterized)
computational complexity of deciding in which positions a given candidate can
appear in the chosen ranking. As part of our analysis, we also consider the
Winner Determination problem for STV, Coombs, and Baldwin and determine their
complexity when there are few voters or candidates.",2209.08856v1,cs.GT,2022-09-19 08:57:02+00:00,"[arxiv.Result.Author('Niclas Boehmer'), arxiv.Result.Author('Robert Bredereck'), arxiv.Result.Author('Dominik Peters')]",
615,The Schulze Method of Voting,"We propose a new single-winner election method (""Schulze method"") and prove
that it satisfies many academic criteria (e.g. monotonicity, reversal symmetry,
resolvability, independence of clones, Condorcet criterion, k-consistency,
polynomial runtime). We then generalize this method to proportional
representation by the single transferable vote (""Schulze STV"") and to methods
to calculate a proportional ranking (""Schulze proportional ranking"").
Furthermore, we propose a generalization of the Condorcet criterion to
multi-winner elections. This paper contains a large number of examples to
illustrate the proposed methods.",1804.02973v11,cs.GT,2018-03-15 20:12:08+00:00,[arxiv.Result.Author('Markus Schulze')],
616,An analysis of New South Wales electronic vote counting,"We re-examine the 2012 local government elections in New South Wales,
Australia. The count was conducted electronically using a randomised form of
the Single Transferable Vote (STV). It was already well known that randomness
does make a difference to outcomes in some seats. We describe how the process
could be amended to include a demonstration that the randomness was chosen
fairly.
  Second, and more significantly, we found an error in the official counting
software, which caused a mistake in the count in the council of Griffith, where
candidate Rina Mercuri narrowly missed out on a seat. We believe the software
error incorrectly decreased Mercuri's winning probability to about
10%---according to our count she should have won with 91% probability.
  The NSW Electoral Commission (NSWEC) corrected their code when we pointed out
the error, and made their own announcement.
  We have since investigated the 2016 local government election (held after
correcting the error above) and found two new errors. We notified the NSWEC
about these errors a few days after they posted the results.",1611.02015v1,cs.CR,2016-11-07 12:20:04+00:00,"[arxiv.Result.Author('Andrew Conway'), arxiv.Result.Author('Michelle Blom'), arxiv.Result.Author('Lee Naish'), arxiv.Result.Author('Vanessa Teague')]",
617,Properties of Multiwinner Voting Rules,"The goal of this paper is to propose and study properties of multiwinner
voting rules which can be consider as generalisations of single-winner scoring
voting rules. We consider SNTV, Bloc, k-Borda, STV, and several variants of
Chamberlin--Courant's and Monroe's rules and their approximations. We identify
two broad natural classes of multiwinner score-based rules, and show that many
of the existing rules can be captured by one or both of these approaches. We
then formulate a number of desirable properties of multiwinner rules, and
evaluate the rules we consider with respect to these properties.",1506.02891v1,cs.GT,2015-06-09 13:09:01+00:00,"[arxiv.Result.Author('Edith Elkind'), arxiv.Result.Author('Piotr Faliszewski'), arxiv.Result.Author('Piotr Skowron'), arxiv.Result.Author('Arkadii Slinko')]",
618,Approval-Based Elections and Distortion of Voting Rules,"We consider elections where both voters and candidates can be associated with
points in a metric space and voters prefer candidates that are closer to those
that are farther away. It is often assumed that the optimal candidate is the
one that minimizes the total distance to the voters. Yet, the voting rules
often do not have access to the metric space $M$ and only see preference
rankings induced by $M$.Consequently, they often are incapable of selecting the
optimal candidate. The distortion of a voting rule measures the worst-case loss
of the quality being the result of having access only to preference rankings.
We extend the idea of distortion to approval-based preferences. First, we
compute the distortion of Approval Voting. Second, we introduce the concept of
acceptability-based distortion---the main idea behind is that the optimal
candidate is the one that is acceptable to most voters. We determine
acceptability-distortion for a number of rules, including Plurality, Borda,
$k$-Approval, Veto, the Copeland's rule, Ranked Pairs, the Schulze's method,
and STV.",1901.06709v1,cs.GT,2019-01-20 18:22:58+00:00,"[arxiv.Result.Author('Grzegorz Pierczyński'), arxiv.Result.Author('Piotr Skowron')]",
619,The Computational Impact of Partial Votes on Strategic Voting,"In many real world elections, agents are not required to rank all candidates.
We study three of the most common methods used to modify voting rules to deal
with such partial votes. These methods modify scoring rules (like the Borda
count), elimination style rules (like single transferable vote) and rules based
on the tournament graph (like Copeland) respectively. We argue that with an
elimination style voting rule like single transferable vote, partial voting
does not change the situations where strategic voting is possible. However,
with scoring rules and rules based on the tournament graph, partial voting can
increase the situations where strategic voting is possible. As a consequence,
the computational complexity of computing a strategic vote can change. For
example, with Borda count, the complexity of computing a strategic vote can
decrease or stay the same depending on how we score partial votes.",1405.7714v1,cs.GT,2014-05-28 12:13:52+00:00,"[arxiv.Result.Author('Nina Narodytska'), arxiv.Result.Author('Toby Walsh')]",
620,A mathematical evaluation of vote transfer systems,"The paper builds a general model of vote transfer systems on the basis of the
current Hungarian electoral rules. It combines single-seat districts and list
mandates with three possible compensation rule for 'wasted' votes in
constituencies: no compensation (direct vote transfer, DVT), compensation for
votes cast for losing party candidates (positive vote transfer, PVT) and
compensation for all votes that are not necessary to win the district (negative
vote transfer, NVT).
  The model is studied in the case of two parties. When the number of votes for
the majority party follows a uniform distribution in each district, DVT results
in the greatest expected seat share, however, application of PVT, and,
especially, NVT increases the probability of winning the election. The
trade-off between vote transfer formulas and the number of list mandates
reveals that the majority party should use an appropriately calibrated NVT
system if it focuses on these two variables.",1607.02879v3,cs.GT,2016-07-11 09:58:58+00:00,[arxiv.Result.Author('László Csató')],
621,Design of Transport Layer Based Hybrid Covert Channel Detection Engine,"Computer network is unpredictable due to information warfare and is prone to
various attacks. Such attacks on network compromise the most important
attribute, the privacy. Most of such attacks are devised using special
communication channel called ""Covert Channel"". The word ""Covert"" stands for
hidden or non-transparent. Network Covert Channel is a concealed communication
path within legitimate network communication that clearly violates security
policies laid down. The non-transparency in covert channel is also referred to
as trapdoor. A trapdoor is unintended design within legitimate communication
whose motto is to leak information. Subliminal channel, a variant of covert
channel works similarly except that the trapdoor is set in a cryptographic
algorithm. A composition of covert channel with subliminal channel is the
""Hybrid Covert Channel"". Hybrid covert channel is homogenous or heterogeneous
mixture of two or more variants of covert channels either active at same
instance or at different instances of time. Detecting such malicious channel
activity plays a vital role in removing threat to the legitimate network. In
this paper, we present a study of multi-trapdoor covert channels and introduce
design of a new detection engine for hybrid covert channel in transport layer
visualized in TCP and SSL.",1101.0104v1,cs.CR,2010-12-30 16:19:17+00:00,"[arxiv.Result.Author('Anjan K'), arxiv.Result.Author('Jibi Abraham'), arxiv.Result.Author('Mamatha Jadhav V')]",
622,DSA Security Enhancement through Efficient Nonce Generation,"The Digital Signature Algorithm (DSA) has become the de facto standard for
authentication of transacting entities since its inception as a standard by
NIST. An integral part of the signing process in DSA is the generation of a
random number called a nonce or an ephemeral key. If sufficient caution is not
taken while generating the nonce, it can lead to the discovery of the
private-key paving the way for critical security violations further on. The
standard algorithms for generation of the nonce as specified by NIST, as well
as the widely implemented random number generators, fail to serve as true
random sources, thus leaving the DSA algorithm open to attack, resulting in
possible signature forgery in electronic transactions, by potential attackers.
Furthermore, the user can select the nonce arbitrarily, which leads to a
subliminal channel being present to exchange messages through each signature,
which may be intolerable for security reasons. In this paper, we have improved
the security of the DSA algorithm by proposing an efficient nonce-generation
process, which ensures that the generated nonce is sufficiently random as well
as unique for each generated signature, thereby securing the signing process.
Furthermore, our algorithm also ensures that there are no subliminal channels
present in DSA.",1508.06370v1,cs.CR,2015-08-26 05:36:14+00:00,"[arxiv.Result.Author('Akash Nag'), arxiv.Result.Author('Sunil Karforma')]","Journal of Global Research in Computer Science (JGRCS). Vol.5(10).
  pp:14-19. 2014"
623,How the Brain Transitions from Conscious to Subliminal Perception,"We study the transition in the functional networks that characterize the
human brains' conscious-state to an unconscious subliminal state of perception
by using k-core percolation. We find that the most inner core (i.e., the most
connected kernel) of the conscious-state functional network corresponds to
areas which remain functionally active when the brain transitions from the
conscious-state to the subliminal-state. That is, the inner core of the
conscious network coincides with the subliminal-state. Mathematical modeling
allows to interpret the conscious to subliminal transition as driven by k-core
percolation, through which the conscious state is lost by the inactivation of
the peripheral k-shells of the conscious functional network. Thus, the inner
core and most robust component of the conscious brain corresponds to the
unconscious subliminal state. This finding imposes constraints to theoretical
models of consciousness, in that the location of the core of the functional
brain network is in the unconscious part of the brain rather than in the
conscious state as previously thought.",1903.09630v3,q-bio.NC,2019-03-21 01:09:05+00:00,"[arxiv.Result.Author('Francesca Arese Lucini'), arxiv.Result.Author('Gino Del Ferraro'), arxiv.Result.Author('Mariano Sigman'), arxiv.Result.Author('Hernan A. Makse')]",Neuroscience 2019
624,Blindspot: Indistinguishable Anonymous Communications,"Communication anonymity is a key requirement for individuals under targeted
surveillance. Practical anonymous communications also require
indistinguishability - an adversary should be unable to distinguish between
anonymised and non-anonymised traffic for a given user. We propose Blindspot, a
design for high-latency anonymous communications that offers
indistinguishability and unobservability under a (qualified) global active
adversary. Blindspot creates anonymous routes between sender-receiver pairs by
subliminally encoding messages within the pre-existing communication behaviour
of users within a social network. Specifically, the organic image sharing
behaviour of users. Thus channel bandwidth depends on the intensity of image
sharing behaviour of users along a route. A major challenge we successfully
overcome is that routing must be accomplished in the face of significant
restrictions - channel bandwidth is stochastic. We show that conventional
social network routing strategies do not work. To solve this problem, we
propose a novel routing algorithm. We evaluate Blindspot using a real-world
dataset. We find that it delivers reasonable results for applications requiring
low-volume unobservable communication.",1408.0784v2,cs.CR,2014-08-04 19:35:15+00:00,"[arxiv.Result.Author('Joseph Gardiner'), arxiv.Result.Author('Shishir Nagaraja')]",
625,"Cognitive Architecture for Direction of Attention Founded on Subliminal Memory Searches, Pseudorandom and Nonstop","By way of explaining how a brain works logically, human associative memory is
modeled with logical and memory neurons, corresponding to standard digital
circuits. The resulting cognitive architecture incorporates basic psychological
elements such as short term and long term memory. Novel to the architecture are
memory searches using cues chosen pseudorandomly from short term memory.
Recalls alternated with sensory images, many tens per second, are analyzed
subliminally as an ongoing process, to determine a direction of attention in
short term memory.",0805.3126v1,cs.AI,2008-05-20 17:37:31+00:00,[arxiv.Result.Author('J. R. Burger')],
626,The meta-problem and the transfer of knowledge between theories of consciousness: a software engineer's take,"This contribution examines two radically different explanations of our
phenomenal intuitions, one reductive and one strongly non-reductive, and
identifies two germane ideas that could benefit many other theories of
consciousness. Firstly, the ability of sophisticated agent architectures with a
purely physical implementation to support certain functional forms of qualia or
proto-qualia appears to entail the possibility of machine consciousness with
qualia, not only for reductive theories but also for the nonreductive ones that
regard consciousness as ubiquitous in Nature. Secondly, analysis of
introspective psychological material seems to hint that, under the threshold of
our ordinary waking awareness, there exist further 'submerged' or 'subliminal'
layers of consciousness which constitute a hidden foundation and support and
another source of our phenomenal intuitions. These 'submerged' layers might
help explain certain puzzling phenomena concerning subliminal perception, such
as the apparently 'unconscious' multisensory integration and learning of
subliminal stimuli.",1903.03418v1,q-bio.NC,2019-02-18 19:17:44+00:00,[arxiv.Result.Author('Marcel Kvassay')],
627,Subliminal Probing for Private Information via EEG-Based BCI Devices,"Martinovic et al. proposed a Brain-Computer-Interface (BCI) -based attack in
which an adversary is able to infer private information about a user, such as
their bank or area-of-living, by analyzing the user's brain activities.
However, a key limitation of the above attack is that it is intrusive,
requiring user cooperation, and is thus easily detectable and can be reported
to other users. In this paper, we identify and analyze a more serious threat
for users of BCI devices. We propose a it subliminal attack in which the victim
is attacked at the levels below his cognitive perception. Our attack involves
exposing the victim to visual stimuli for a duration of 13.3 milliseconds -- a
duration usually not sufficient for conscious perception. The attacker analyzes
subliminal brain activity in response to these short visual stimuli to infer
private information about the user. If carried out carefully, for example by
hiding the visual stimuli within screen content that the user expects to see,
the attack may remain undetected. As a consequence, the attacker can scale it
to many victims and expose them to the attack for a long time. We
experimentally demonstrate the feasibility of our subliminal attack via a
proof-of-concept study carried out with 27 subjects. We conducted experiments
on users wearing Electroencephalography-based BCI devices, and used portrait
pictures of people as visual stimuli which were embedded within the background
of an innocuous video for a time duration not exceeding 13.3 milliseconds. Our
experimental results show that it is feasible for an attacker to learn relevant
private information about the user, such as whether the user knows the identity
of the person for which the attacker is probing.",1312.6052v2,cs.CR,2013-12-20 17:31:42+00:00,"[arxiv.Result.Author('Mario Frank'), arxiv.Result.Author('Tiffany Hwu'), arxiv.Result.Author('Sakshi Jain'), arxiv.Result.Author('Robert Knight'), arxiv.Result.Author('Ivan Martinovic'), arxiv.Result.Author('Prateek Mittal'), arxiv.Result.Author('Daniele Perito'), arxiv.Result.Author('Dawn Song')]",
628,MELENCOLIA I: The physics of Albrecht Duerer,"Duerer's engraving ``MELENCOLIA I'' was circulated in two versions not
previously distinguished. Besides their conspicuous early Renaissance
scientific instruments and tools, they contain numerous apparently unreported
concealments whose detection reveals heresies expressed in the work. The main
one is encoded in the motto {\em MELENCOLIA I} itself: Natural Philosophy, not
Mathematical Philosophy or Theological Philosophy, is the way to knowledge.
Unusual optical illusions and subliminal images, differing between the two
versions, declare the relativity and ambiguity of perception, and indicate that
the work was a Humanist document intended for a Humanist viewership.",physics/0602185v2,physics.hist-ph,2006-02-27 03:50:22+00:00,[arxiv.Result.Author('David Ritz Finkelstein')],
629,Charged compact star model in Einstein-Maxwell-Gauss-Bonnet gravity,"Present paper provides a model of static charged anisotropic fluid sphere in
the EinsteinMaxwell- GaussBonnet (EMGB) theory of gravitation. We select KB
anstz as the metric co-efficient along with electric field intensity. To
develop our model we assume a linear EoS between the radial pressure and the
matter density. The model obtained here is found to satisfy the elementary
physical requirements like non-negativity nature of pressure and density, the
energy conditions, continuity of the metric co-efficients, subliminal velocity
of sound and also pressure free hypersurface etc. It may also noted that the
solution is free from any kind of singularities.",1709.03977v1,physics.gen-ph,2017-09-05 08:10:25+00:00,"[arxiv.Result.Author('Piyali Bhar'), arxiv.Result.Author('Megan Govender')]","Astrophys Space Sci 364, 186 (2019)"
630,Exotic light transition between superluminal and subliminal group velocity in a $\mathcal{PT}$ coupled slab waveguide,"We propose a rigorous full-wave modal analysis based on the eigenmodes
approach (""supermodes""), that allows the calculation of the transverse electric
($TE$) and transverse magnetic ($TM$) stationary propagation eigenmodes in a
coupled $\mathcal{PT}$-symmetric slab waveguide. Our findings show that the
group velocity for the fundamental $TE_{0}$ supermode passes from superluminal
to subluminal speed over both sides of a critical point (CP), located near to
the exceptional point (EP). We also demonstrate that the first higher-order
supermode, $TE_{1}$, exhibits a slow light phenomenon around the EP.",2212.01195v1,physics.optics,2022-12-02 14:23:16+00:00,"[arxiv.Result.Author('B. M. Villegas-Martínez'), arxiv.Result.Author('H. M. Moya-Cessa'), arxiv.Result.Author('F. Soto-Eguibar')]",
631,How to Subvert Backdoored Encryption: Security Against Adversaries that Decrypt All Ciphertexts,"We study secure and undetectable communication in a world where governments
can read all encrypted communications of citizens. We consider a world where
the only permitted communication method is via a government-mandated encryption
scheme, using government-mandated keys. Citizens caught trying to communicate
otherwise (e.g., by encrypting strings which do not appear to be natural
language plaintexts) will be arrested. The one guarantee we suppose is that the
government-mandated encryption scheme is semantically secure against outsiders:
a perhaps advantageous feature to secure communication against foreign
entities. But what good is semantic security against an adversary that has the
power to decrypt?
  Even in this pessimistic scenario, we show citizens can communicate securely
and undetectably. Informally, there is a protocol between Alice and Bob where
they exchange ciphertexts that look innocuous even to someone who knows the
secret keys and thus sees the corresponding plaintexts. And yet, in the end,
Alice will have transmitted her secret message to Bob. Our security definition
requires indistinguishability between unmodified use of the mandated encryption
scheme, and conversations using the mandated encryption scheme in a modified
way for subliminal communication.
  Our topics may be thought to fall broadly within the realm of steganography:
the science of hiding secret communication in innocent-looking messages, or
cover objects. However, we deal with the non-standard setting of adversarial
cover object distributions (i.e., a stronger-than-usual adversary). We leverage
that our cover objects are ciphertexts of a secure encryption scheme to bypass
impossibility results which we show for broader classes of steganographic
schemes. We give several constructions of subliminal communication schemes
based on any key exchange protocol with random messages (e.g., Diffie-Hellman).",1802.07381v1,cs.CR,2018-02-21 00:16:49+00:00,"[arxiv.Result.Author('Thibaut Horel'), arxiv.Result.Author('Sunoo Park'), arxiv.Result.Author('Silas Richelson'), arxiv.Result.Author('Vinod Vaikuntanathan')]","10th Innovations in Theoretical Computer Science Conference (ITCS
  2019)"
632,The disappearing $Q$ operator,"In the Schroedinger formulation of non-Hermitian quantum theories a
positive-definite metric operator $\eta\equiv e^{-Q}$ must be introduced in
order to ensure their probabilistic interpretation. This operator also gives an
equivalent Hermitian theory, by means of a similarity transformation. If,
however, quantum mechanics is formulated in terms of functional integrals, we
show that the $Q$ operator makes only a subliminal appearance and is not needed
for the calculation of expectation values. Instead, the relation to the
Hermitian theory is encoded via the external source $j(t)$. These points are
illustrated and amplified for two non-Hermitian quantum theories: the Swanson
model, a non-Hermitian transform of the simple harmonic oscillator, and the
wrong-sign quartic oscillator, which has been shown to be equivalent to a
conventional asymmetric quartic oscillator.",hep-th/0612093v1,hep-th,2006-12-11 15:12:31+00:00,"[arxiv.Result.Author('H. F. Jones'), arxiv.Result.Author('R. J. Rivers')]","Phys.Rev.D75:025023,2007"
633,"Invisible stimuli, implicit thresholds: Why invisibility judgments cannot be interpreted in isolation","Some studies of unconscious cognition rely on judgments of participants
stating that they have ""not seen"" the critical stimulus (e.g., in a
masked-priming experiment). Trials in which participants gave ""not-seen""
judgments are then treated as those where the critical stimulus was
""subliminal"" or ""unconscious"", as opposed to trials with higher visibility
ratings. Sometimes, only these trials are further analyzed, for instance, for
unconscious priming effects. Here I argue that this practice requires implicit
assumptions about subjective measures of awareness incompatible with basic
models of categorization under uncertainty (e.g., modern signal-detection and
threshold theories). Most importantly, it ignores the potential effects of
response bias. Instead of taking ""not-seen"" judgments literally, they would
better be employed in parametric experiments where stimulus visibility is
manipulated systematically, not accidentally. This would allow studying
qualitative and double dissociations between measures of awareness and of
stimulus processing per se.",1306.0756v4,q-bio.NC,2013-06-04 12:49:45+00:00,[arxiv.Result.Author('Thomas Schmidt')],
634,Compact star in Tolman Kuchowicz spacetime in background of Einstein Gauss Bonnet gravity,"The present work is devoted to the study of anisotropic compact matter
distributions within the framework of 5-dimensional Einstein-Gauss-Bonnet
gravity. To solve the field equations, we have considered that the inner
geometry is described by Tolman-Kuchowicz spacetime. The Gauss-Bonnet
Lagrangian is coupled to Einstein-Hilbert action through a coupling constant.
When this coupling tends to zero general relativity results are recovered. We
analyze the effect of this parameter on the principal salient features of the
model, such as energy density, radial and tangential pressure and anisotropy
factor.Additionally, the behaviour of the subliminal sound speed of the
pressure waves in the principal direction of the configuration and the conduct
of the energy-momentum tensor throughout the star are analyzed employing
causality condition and energy conditions, respectively. All these subjects are
supported by mean of physical, mathematical and graphical survey",1905.07231v1,physics.gen-ph,2019-05-13 07:24:38+00:00,"[arxiv.Result.Author('Piyali Bhar'), arxiv.Result.Author('Ksh. Newton Singh'), arxiv.Result.Author('Francisco Tello-Ortiz')]",
635,Subliminal aspects concerning the Lounesto's classification,"In the present communication we employ a split programme applied to spinors
belonging to the regular and singular sectors of the Lounesto's classification,
looking towards to unveil how it can be built or defined upon two spinors
arrangement. We separate the spinors into two distinct parts and investigate to
which class within the Lounesto's classification each part belong. The
machinery here developed open up the possibility to better understand how
spinors behave under such classification. As we shall see, the resulting spinor
from the arrangement of other spinors (belonging to a distinct class or not)
does not necessarily inherit the characteristics of the spinors that compose
them, as example, such characteristics stands for the class, dynamic or the
encoded physical information.",1911.08506v2,math-ph,2019-11-19 19:04:43+00:00,[arxiv.Result.Author('R. J. Bueno Rogerio')],"Eur. Phys. J. C 80, 299 (2020)"
636,Brain representation of perceptual stimuli at different levels of awareness,"This article questions the widespread assumption that there are brain
representations that will always remain unconscious in the sense of being
inaccessible to individual awareness under any circumstances. This implies that
some part of the knowledge generated by the brain is once and for always
excluded from consciousness and, therefore, from being communicated to the
outside world. This standpoint neglects the possibility that the human brain
might have a capacity for generating metarepresentations of nonconscious
knowledge contents at a given moment in time through context sensitive adaptive
learning, and is somewhat difficult to reconcile with experimental findings
showing that initially subliminal targets can be made available to awareness,
or break through to supraliminal levels of processing, when they are embedded
in an appropriate perceptual object context (relevance condition). Specific
properties of neural network architectures, inspired by the functional
organization of the primate cortex, are able to explain how a human brain could
generate this kind of perceptual learning. Signals or knowledge processed
outside awareness could be made available to awareness through adaptive
resonance of bottom-up and top-down signal exchanges in massively parallel
neural network architectures; in other words, on the basis of statistically
significant signal matches in the domain of time and in the domain of memory
content.",2202.10849v1,q-bio.NC,2022-02-22 12:23:28+00:00,[arxiv.Result.Author('Birgitta Dresp-Langley')],
637,Particle Creation and Entanglement in Dispersive Model with Step Velocity Profile,"We investigate particle creation and entanglement structure in a dispersive
model with subliminal dispersion relation. Assuming the step function spatial
velocity profile of the background flow, mode functions for a massless scalar
field is exactly obtained by the matching method. Power spectrums of created
particles are calculated for the subsonic and the transsonic flow cases. For
the transsonic case, the sonic horizon exists and created particles show the
Planckian distribution for low frequency region but the thermal property
disappears for high frequency region near the cutoff frequency introduced by
the non-linear dispersion. For the subsonic case, although the sonic horizon
does not exist, the effective group velocity horizon appears due to the
non-linear dispersion for high frequency region and approximate thermal
property of the power spectrum arises. Relation between particle creation and
entanglement between each mode is also discussed.",2204.08684v1,gr-qc,2022-04-19 06:04:10+00:00,"[arxiv.Result.Author('Yuki Osawa'), arxiv.Result.Author('Yasusada Nambu')]",
638,MFCC based Enlargement of the Training Set for Emotion Recognition in Speech,"Emotional state recognition through speech is being a very interesting
research topic nowadays. Using subliminal information of speech, denominated as
prosody, it is possible to recognize the emotional state of the person. One of
the main problems in the design of automatic emotion recognition systems is the
small number of available patterns. This fact makes the learning process more
difficult, due to the generalization problems that arise under these
conditions. In this work we propose a solution to this problem consisting in
enlarging the training set through the creation the new virtual patterns. In
the case of emotional speech, most of the emotional information is included in
speed and pitch variations. So, a change in the average pitch that does not
modify neither the speed nor the pitch variations does not affect the expressed
emotion. Thus, we use this prior information in order to create new patterns
applying a gender dependent pitch shift modification in the feature extraction
process of the classification system. For this purpose, we propose a frequency
scaling modification of the Mel Frequency Cepstral Coefficients, used to
classify the emotion. For this purpose, we propose a gender dependent frequency
scaling modification. This proposed process allows us to synthetically increase
the number of available patterns in the training set, thus increasing the
generalization capability of the system and reducing the test error. Results
carried out with two different classifiers with different degree of
generalization capability demonstrate the suitability of the proposal.",1403.4777v1,cs.CV,2014-03-19 12:03:09+00:00,"[arxiv.Result.Author('Inma Mohino-Herranz'), arxiv.Result.Author('Roberto Gil-Pita'), arxiv.Result.Author('Sagrario Alonso-Diaz'), arxiv.Result.Author('Manuel Rosa-Zurera')]","Signal & Image Processing : An International Journal (SIPIJ),
  Vol.5, No,1. 2014"
639,Constraints on modified gravity from Planck 2015: when the health of your theory makes the difference,"We use the effective field theory of dark energy (EFT of DE) formalism to
constrain dark energy models belonging to the Horndeski class with the recent
Planck 2015 CMB data. The space of theories is spanned by a certain number of
parameters determining the linear cosmological perturbations, while the
expansion history is set to that of a standard $\Lambda$CDM model. We always
demand that the theories be free of fatal instabilities. Additionally, we
consider two optional conditions, namely that scalar and tensor perturbations
propagate with subliminal speed. Such criteria severely restrict the allowed
parameter space and are thus very effective in shaping the posteriors. As a
result, we confirm that no theory performs better than $\Lambda$CDM when CMB
data alone are analysed. Indeed, the healthy dark energy models considered here
are not able to reproduce those phenomenological behaviours of the effective
Newton constant and gravitational slip parameters that, according to previous
studies, best fit the data.",1602.08283v3,astro-ph.CO,2016-02-26 11:36:19+00:00,"[arxiv.Result.Author('Valentina Salvatelli'), arxiv.Result.Author('Federico Piazza'), arxiv.Result.Author('Christian Marinoni')]",JCAP09(2016)027
640,"Anisotropic fluid spheres in the framework of $f(R,\mathcal{T})$ gravity theory","The main aim of this paper is to obtain analytic relativistic anisotropic
spherical solutions in f(R,$\mathcal{T}$) scenario. To do so we use modified
Durgapal-Fuloria metric potential and the isotropic condition is imposed in
order to obtain the effective anisotropic factor $\tilde{\Delta}$. Besides, a
notable and viable election on f(R,$\mathcal{T}$) gravity formulation is taken.
Specifically $f(R,\mathcal{T})=R+2\chi\mathcal{T}$, where $R$ is the Ricci
scalar, $\mathcal{T}$ the trace of the energy-momentum tensor and $\chi$ a
dimensionless parameter. This choice of $f(R,\mathcal{T})$ function modifies
the matter sector only, including new ingredients to the physical parameters
that characterize the model such as density, radial, and tangential pressure.
Moreover, other important quantities are affected such as subliminal speeds of
the pressure waves in both radial and transverse direction, observational
parameters, for example, the surface redshift which is related with the total
mass $M$ and the radius $r_{s}$ of the compact object. Also, a transcendent
mechanism like equilibrium through generalized Tolman-Oppenheimer-Volkoff
equation and stability of the system are upset. We analyze all the physical and
mathematical general requirements of the configuration taking $M=1.04
M_{\odot}$ and varying $\chi$ from $-0.1$ to $0.1$. It is shown by the
graphical procedure that $\chi<0$ yields to a more compact object in comparison
when $\chi\geq0$ (where $\chi=0.0$ corresponds to general relativity theory)
and increases the value of the surface redshift. However, negative values of
$\chi$ introduce in the system an attractive anisotropic force (inward) and the
configuration is completely unstable (corroborated employing Abreu's
criterion). Furthermore, the model in Einstein gravity theory presents cracking
while for $\chi>0$ the system is fully stable.",1906.11756v1,gr-qc,2019-06-27 16:00:37+00:00,"[arxiv.Result.Author('S. K. Maurya'), arxiv.Result.Author('Francisco Tello-Ortiz')]",
641,Barely-Supervised Learning: Semi-Supervised Learning with very few labeled images,"This paper tackles the problem of semi-supervised learning when the set of
labeled samples is limited to a small number of images per class, typically
less than 10, problem that we refer to as barely-supervised learning. We
analyze in depth the behavior of a state-of-the-art semi-supervised method,
FixMatch, which relies on a weakly-augmented version of an image to obtain
supervision signal for a more strongly-augmented version. We show that it
frequently fails in barely-supervised scenarios, due to a lack of training
signal when no pseudo-label can be predicted with high confidence. We propose a
method to leverage self-supervised methods that provides training signal in the
absence of confident pseudo-labels. We then propose two methods to refine the
pseudo-label selection process which lead to further improvements. The first
one relies on a per-sample history of the model predictions, akin to a voting
scheme. The second iteratively updates class-dependent confidence thresholds to
better explore classes that are under-represented in the pseudo-labels. Our
experiments show that our approach performs significantly better on STL-10 in
the barely-supervised regime, e.g. with 4 or 8 labeled images per class.",2112.12004v1,cs.CV,2021-12-22 16:29:10+00:00,"[arxiv.Result.Author('Thomas Lucas'), arxiv.Result.Author('Philippe Weinzaepfel'), arxiv.Result.Author('Gregory Rogez')]",
642,Vulnerability analysis of three remote voting methods,"This article analyses three methods of remote voting in an uncontrolled
environment: postal voting, internet voting and hybrid voting. It breaks down
the voting process into different stages and compares their vulnerabilities
considering criteria that must be respected in any democratic vote:
confidentiality, anonymity, transparency, vote unicity and authenticity.
Whether for safety or reliability, each vulnerability is quantified by three
parameters: size, visibility and difficulty to achieve. The study concludes
that the automatisation of treatments combined with the dematerialisation of
the objects used during an election tends to substitute visible vulnerabilities
of a lesser magnitude by invisible and widespread vulnerabilities.",0908.1059v1,cs.CY,2009-08-07 14:02:40+00:00,"[arxiv.Result.Author('Chantal Enguehard'), arxiv.Result.Author('Rémi Lehn')]","XXI IPSA World Congress of Political Science, RC10 Electronic
  Democracy - Dilemmas of Change?, Santiago : Chile (2009)"
643,Weakly supervised segment annotation via expectation kernel density estimation,"Since the labelling for the positive images/videos is ambiguous in weakly
supervised segment annotation, negative mining based methods that only use the
intra-class information emerge. In these methods, negative instances are
utilized to penalize unknown instances to rank their likelihood of being an
object, which can be considered as a voting in terms of similarity. However,
these methods 1) ignore the information contained in positive bags, 2) only
rank the likelihood but cannot generate an explicit decision function. In this
paper, we propose a voting scheme involving not only the definite negative
instances but also the ambiguous positive instances to make use of the extra
useful information in the weakly labelled positive bags. In the scheme, each
instance votes for its label with a magnitude arising from the similarity, and
the ambiguous positive instances are assigned soft labels that are iteratively
updated during the voting. It overcomes the limitations of voting using only
the negative bags. We also propose an expectation kernel density estimation
(eKDE) algorithm to gain further insight into the voting mechanism.
Experimental results demonstrate the superiority of our scheme beyond the
baselines.",1812.06228v1,cs.CV,2018-12-15 03:31:32+00:00,"[arxiv.Result.Author('Liantao Wang'), arxiv.Result.Author('Qingwu Li'), arxiv.Result.Author('Jianfeng Lu')]",
644,Understanding Programmatic Weak Supervision via Source-aware Influence Function,"Programmatic Weak Supervision (PWS) aggregates the source votes of multiple
weak supervision sources into probabilistic training labels, which are in turn
used to train an end model. With its increasing popularity, it is critical to
have some tool for users to understand the influence of each component (e.g.,
the source vote or training data) in the pipeline and interpret the end model
behavior. To achieve this, we build on Influence Function (IF) and propose
source-aware IF, which leverages the generation process of the probabilistic
labels to decompose the end model's training objective and then calculate the
influence associated with each (data, source, class) tuple. These primitive
influence score can then be used to estimate the influence of individual
component of PWS, such as source vote, supervision source, and training data.
On datasets of diverse domains, we demonstrate multiple use cases: (1)
interpreting incorrect predictions from multiple angles that reveals insights
for debugging the PWS pipeline, (2) identifying mislabeling of sources with a
gain of 9%-37% over baselines, and (3) improving the end model's generalization
performance by removing harmful components in the training objective (13%-24%
better than ordinary IF).",2205.12879v1,cs.LG,2022-05-25 15:57:24+00:00,"[arxiv.Result.Author('Jieyu Zhang'), arxiv.Result.Author('Haonan Wang'), arxiv.Result.Author('Cheng-Yu Hsieh'), arxiv.Result.Author('Alexander Ratner')]",
645,Symmetric reduced form voting,"We study a model of voting with two alternatives in a symmetric environment.
We characterize the interim allocation probabilities that can be implemented by
a symmetric voting rule. We show that every such interim allocation
probabilities can be implemented as a convex combination of two families of
deterministic voting rules: qualified majority and qualified anti-majority. We
also provide analogous results by requiring implementation by a unanimous
voting rule. A consequence of our results is that if the prior is independent,
every symmetric and ordinally Bayesian incentive compatible voting rule is
reduced (interim) form equivalent to a symmetric and strategy-proof voting
rule.",2207.09253v2,econ.TH,2022-07-19 13:09:40+00:00,"[arxiv.Result.Author('Xu Lang'), arxiv.Result.Author('Debasis Mishra')]",
646,Box2Mask: Weakly Supervised 3D Semantic Instance Segmentation Using Bounding Boxes,"Current 3D segmentation methods heavily rely on large-scale point-cloud
datasets, which are notoriously laborious to annotate. Few attempts have been
made to circumvent the need for dense per-point annotations. In this work, we
look at weakly-supervised 3D semantic instance segmentation. The key idea is to
leverage 3D bounding box labels which are easier and faster to annotate.
Indeed, we show that it is possible to train dense segmentation models using
only bounding box labels. At the core of our method, \name{}, lies a deep
model, inspired by classical Hough voting, that directly votes for bounding box
parameters, and a clustering method specifically tailored to bounding box
votes. This goes beyond commonly used center votes, which would not fully
exploit the bounding box annotations. On ScanNet test, our weakly supervised
model attains leading performance among other weakly supervised approaches (+18
mAP@50). Remarkably, it also achieves 97% of the mAP@50 score of current fully
supervised models. To further illustrate the practicality of our work, we train
Box2Mask on the recently released ARKitScenes dataset which is annotated with
3D bounding boxes only, and show, for the first time, compelling 3D instance
segmentation masks.",2206.01203v2,cs.CV,2022-06-02 17:59:57+00:00,"[arxiv.Result.Author('Julian Chibane'), arxiv.Result.Author('Francis Engelmann'), arxiv.Result.Author('Tuan Anh Tran'), arxiv.Result.Author('Gerard Pons-Moll')]","European Conference on Computer Vision (ECCV), 2022, Oral
  Presentation"
647,Improving Distantly Supervised Relation Extraction using Word and Entity Based Attention,"Relation extraction is the problem of classifying the relationship between
two entities in a given sentence. Distant Supervision (DS) is a popular
technique for developing relation extractors starting with limited supervision.
We note that most of the sentences in the distant supervision relation
extraction setting are very long and may benefit from word attention for better
sentence representation. Our contributions in this paper are threefold.
Firstly, we propose two novel word attention models for distantly- supervised
relation extraction: (1) a Bi-directional Gated Recurrent Unit (Bi-GRU) based
word attention model (BGWA), (2) an entity-centric attention model (EA), and
(3) a combination model which combines multiple complementary models using
weighted voting method for improved relation extraction. Secondly, we introduce
GDS, a new distant supervision dataset for relation extraction. GDS removes
test data noise present in all previous distant- supervision benchmark
datasets, making credible automatic evaluation possible. Thirdly, through
extensive experiments on multiple real-world datasets, we demonstrate the
effectiveness of the proposed methods.",1804.06987v1,cs.CL,2018-04-19 03:38:43+00:00,"[arxiv.Result.Author('Sharmistha Jat'), arxiv.Result.Author('Siddhesh Khandelwal'), arxiv.Result.Author('Partha Talukdar')]",
648,PVStereo: Pyramid Voting Module for End-to-End Self-Supervised Stereo Matching,"Supervised learning with deep convolutional neural networks (DCNNs) has seen
huge adoption in stereo matching. However, the acquisition of large-scale
datasets with well-labeled ground truth is cumbersome and labor-intensive,
making supervised learning-based approaches often hard to implement in
practice. To overcome this drawback, we propose a robust and effective
self-supervised stereo matching approach, consisting of a pyramid voting module
(PVM) and a novel DCNN architecture, referred to as OptStereo. Specifically,
our OptStereo first builds multi-scale cost volumes, and then adopts a
recurrent unit to iteratively update disparity estimations at high resolution;
while our PVM can generate reliable semi-dense disparity images, which can be
employed to supervise OptStereo training. Furthermore, we publish the
HKUST-Drive dataset, a large-scale synthetic stereo dataset, collected under
different illumination and weather conditions for research purposes. Extensive
experimental results demonstrate the effectiveness and efficiency of our
self-supervised stereo matching approach on the KITTI Stereo benchmarks and our
HKUST-Drive dataset. PVStereo, our best-performing implementation, greatly
outperforms all other state-of-the-art self-supervised stereo matching
approaches. Our project page is available at sites.google.com/view/pvstereo.",2103.07094v1,cs.CV,2021-03-12 05:27:14+00:00,"[arxiv.Result.Author('Hengli Wang'), arxiv.Result.Author('Rui Fan'), arxiv.Result.Author('Peide Cai'), arxiv.Result.Author('Ming Liu')]",
649,Self-supervised Pretraining of Visual Features in the Wild,"Recently, self-supervised learning methods like MoCo, SimCLR, BYOL and SwAV
have reduced the gap with supervised methods. These results have been achieved
in a control environment, that is the highly curated ImageNet dataset. However,
the premise of self-supervised learning is that it can learn from any random
image and from any unbounded dataset. In this work, we explore if
self-supervision lives to its expectation by training large models on random,
uncurated images with no supervision. Our final SElf-supERvised (SEER) model, a
RegNetY with 1.3B parameters trained on 1B random images with 512 GPUs achieves
84.2% top-1 accuracy, surpassing the best self-supervised pretrained model by
1% and confirming that self-supervised learning works in a real world setting.
Interestingly, we also observe that self-supervised models are good few-shot
learners achieving 77.9% top-1 with access to only 10% of ImageNet. Code:
https://github.com/facebookresearch/vissl",2103.01988v2,cs.CV,2021-03-02 19:12:29+00:00,"[arxiv.Result.Author('Priya Goyal'), arxiv.Result.Author('Mathilde Caron'), arxiv.Result.Author('Benjamin Lefaudeux'), arxiv.Result.Author('Min Xu'), arxiv.Result.Author('Pengchao Wang'), arxiv.Result.Author('Vivek Pai'), arxiv.Result.Author('Mannat Singh'), arxiv.Result.Author('Vitaliy Liptchinsky'), arxiv.Result.Author('Ishan Misra'), arxiv.Result.Author('Armand Joulin'), arxiv.Result.Author('Piotr Bojanowski')]",
650,SLV: Spatial Likelihood Voting for Weakly Supervised Object Detection,"Based on the framework of multiple instance learning (MIL), tremendous works
have promoted the advances of weakly supervised object detection (WSOD).
However, most MIL-based methods tend to localize instances to their
discriminative parts instead of the whole content. In this paper, we propose a
spatial likelihood voting (SLV) module to converge the proposal localizing
process without any bounding box annotations. Specifically, all region
proposals in a given image play the role of voters every iteration during
training, voting for the likelihood of each category in spatial dimensions.
After dilating alignment on the area with large likelihood values, the voting
results are regularized as bounding boxes, being used for the final
classification and localization. Based on SLV, we further propose an end-to-end
training framework for multi-task learning. The classification and localization
tasks promote each other, which further improves the detection performance.
Extensive experiments on the PASCAL VOC 2007 and 2012 datasets demonstrate the
superior performance of SLV.",2006.12884v1,cs.CV,2020-06-23 10:24:13+00:00,"[arxiv.Result.Author('Ze Chen'), arxiv.Result.Author('Zhihang Fu'), arxiv.Result.Author('Rongxin Jiang'), arxiv.Result.Author('Yaowu Chen'), arxiv.Result.Author('Xian-sheng Hua')]",
651,Training Complex Models with Multi-Task Weak Supervision,"As machine learning models continue to increase in complexity, collecting
large hand-labeled training sets has become one of the biggest roadblocks in
practice. Instead, weaker forms of supervision that provide noisier but cheaper
labels are often used. However, these weak supervision sources have diverse and
unknown accuracies, may output correlated labels, and may label different tasks
or apply at different levels of granularity. We propose a framework for
integrating and modeling such weak supervision sources by viewing them as
labeling different related sub-tasks of a problem, which we refer to as the
multi-task weak supervision setting. We show that by solving a matrix
completion-style problem, we can recover the accuracies of these multi-task
sources given their dependency structure, but without any labeled data, leading
to higher-quality supervision for training an end model. Theoretically, we show
that the generalization error of models trained with this approach improves
with the number of unlabeled data points, and characterize the scaling with
respect to the task and dependency structures. On three fine-grained
classification problems, we show that our approach leads to average gains of
20.2 points in accuracy over a traditional supervised approach, 6.8 points over
a majority vote baseline, and 4.1 points over a previously proposed weak
supervision method that models tasks separately.",1810.02840v2,stat.ML,2018-10-05 18:30:11+00:00,"[arxiv.Result.Author('Alexander Ratner'), arxiv.Result.Author('Braden Hancock'), arxiv.Result.Author('Jared Dunnmon'), arxiv.Result.Author('Frederic Sala'), arxiv.Result.Author('Shreyash Pandey'), arxiv.Result.Author('Christopher Ré')]",
652,Vehicle Trajectory Prediction by Transfer Learning of Semi-Supervised Models,"In this work we show that semi-supervised models for vehicle trajectory
prediction significantly improve performance over supervised models on
state-of-the-art real-world benchmarks. Moving from supervised to
semi-supervised models allows scaling-up by using unlabeled data, increasing
the number of images in pre-training from Millions to a Billion. We perform
ablation studies comparing transfer learning of semi-supervised and supervised
models while keeping all other factors equal. Within semi-supervised models we
compare contrastive learning with teacher-student methods as well as networks
predicting a small number of trajectories with networks predicting
probabilities over a large trajectory set. Our results using both low-level and
mid-level representations of the driving environment demonstrate the
applicability of semi-supervised methods for real-world vehicle trajectory
prediction.",2007.06781v2,cs.CV,2020-07-14 02:42:48+00:00,"[arxiv.Result.Author('Nick Lamm'), arxiv.Result.Author('Shashank Jaiprakash'), arxiv.Result.Author('Malavika Srikanth'), arxiv.Result.Author('Iddo Drori')]",
653,Supervise Thyself: Examining Self-Supervised Representations in Interactive Environments,"Self-supervised methods, wherein an agent learns representations solely by
observing the results of its actions, become crucial in environments which do
not provide a dense reward signal or have labels. In most cases, such methods
are used for pretraining or auxiliary tasks for ""downstream"" tasks, such as
control, exploration, or imitation learning. However, it is not clear which
method's representations best capture meaningful features of the environment,
and which are best suited for which types of environments. We present a
small-scale study of self-supervised methods on two visual environments: Flappy
Bird and Sonic The Hedgehog. In particular, we quantitatively evaluate the
representations learned from these tasks in two contexts: a) the extent to
which the representations capture true state information of the agent and b)
how generalizable these representations are to novel situations, like new
levels and textures. Lastly, we evaluate these self-supervised features by
visualizing which parts of the environment they focus on. Our results show that
the utility of the representations is highly dependent on the visuals and
dynamics of the environment.",1906.11951v1,cs.LG,2019-06-27 20:38:47+00:00,"[arxiv.Result.Author('Evan Racah'), arxiv.Result.Author('Christopher Pal')]",
654,Sequential Voting with Relational Box Fields for Active Object Detection,"A key component of understanding hand-object interactions is the ability to
identify the active object -- the object that is being manipulated by the human
hand. In order to accurately localize the active object, any method must reason
using information encoded by each image pixel, such as whether it belongs to
the hand, the object, or the background. To leverage each pixel as evidence to
determine the bounding box of the active object, we propose a pixel-wise voting
function. Our pixel-wise voting function takes an initial bounding box as input
and produces an improved bounding box of the active object as output. The
voting function is designed so that each pixel inside of the input bounding box
votes for an improved bounding box, and the box with the majority vote is
selected as the output. We call the collection of bounding boxes generated
inside of the voting function, the Relational Box Field, as it characterizes a
field of bounding boxes defined in relationship to the current bounding box.
While our voting function is able to improve the bounding box of the active
object, one round of voting is typically not enough to accurately localize the
active object. Therefore, we repeatedly apply the voting function to
sequentially improve the location of the bounding box. However, since it is
known that repeatedly applying a one-step predictor (i.e., auto-regressive
processing with our voting function) can cause a data distribution shift, we
mitigate this issue using reinforcement learning (RL). We adopt standard RL to
learn the voting function parameters and show that it provides a meaningful
improvement over a standard supervised learning approach. We perform
experiments on two large-scale datasets: 100DOH and MECCANO, improving AP50
performance by 8% and 30%, respectively, over the state of the art.",2110.11524v4,cs.CV,2021-10-21 23:40:45+00:00,"[arxiv.Result.Author('Qichen Fu'), arxiv.Result.Author('Xingyu Liu'), arxiv.Result.Author('Kris M. Kitani')]",
655,Merging Weak and Active Supervision for Semantic Parsing,"A semantic parser maps natural language commands (NLs) from the users to
executable meaning representations (MRs), which are later executed in certain
environment to obtain user-desired results. The fully-supervised training of
such parser requires NL/MR pairs, annotated by domain experts, which makes them
expensive to collect. However, weakly-supervised semantic parsers are learnt
only from pairs of NL and expected execution results, leaving the MRs latent.
While weak supervision is cheaper to acquire, learning from this input poses
difficulties. It demands that parsers search a large space with a very weak
learning signal and it is hard to avoid spurious MRs that achieve the correct
answer in the wrong way. These factors lead to a performance gap between
parsers trained in weakly- and fully-supervised setting. To bridge this gap, we
examine the intersection between weak supervision and active learning, which
allows the learner to actively select examples and query for manual annotations
as extra supervision to improve the model trained under weak supervision. We
study different active learning heuristics for selecting examples to query, and
various forms of extra supervision for such queries. We evaluate the
effectiveness of our method on two different datasets. Experiments on the
WikiSQL show that by annotating only 1.8% of examples, we improve over a
state-of-the-art weakly-supervised baseline by 6.4%, achieving an accuracy of
79.0%, which is only 1.3% away from the model trained with full supervision.
Experiments on WikiTableQuestions with human annotators show that our method
can improve the performance with only 100 active queries, especially for
weakly-supervised parsers learnt from a cold start.",1911.12986v1,cs.CL,2019-11-29 07:48:19+00:00,"[arxiv.Result.Author('Ansong Ni'), arxiv.Result.Author('Pengcheng Yin'), arxiv.Result.Author('Graham Neubig')]",
656,Heuristic Strategies in Uncertain Approval Voting Environments,"In many collective decision making situations, agents vote to choose an
alternative that best represents the preferences of the group. Agents may
manipulate the vote to achieve a better outcome by voting in a way that does
not reflect their true preferences. In real world voting scenarios, people
often do not have complete information about other voter preferences and it can
be computationally complex to identify a strategy that will maximize their
expected utility. In such situations, it is often assumed that voters will vote
truthfully rather than expending the effort to strategize. However, being
truthful is just one possible heuristic that may be used. In this paper, we
examine the effectiveness of heuristics in single winner and multi-winner
approval voting scenarios with missing votes. In particular, we look at
heuristics where a voter ignores information about other voting profiles and
makes their decisions based solely on how much they like each candidate. In a
behavioral experiment, we show that people vote truthfully in some situations
and prioritize high utility candidates in others. We examine when these
behaviors maximize expected utility and show how the structure of the voting
environment affects both how well each heuristic performs and how humans employ
these heuristics.",1912.00011v1,cs.GT,2019-11-29 13:38:34+00:00,"[arxiv.Result.Author('Jaelle Scheuerman'), arxiv.Result.Author('Jason L. Harman'), arxiv.Result.Author('Nicholas Mattei'), arxiv.Result.Author('K. Brent Venable')]",
657,Semi-Supervised Radio Signal Identification,"Radio emitter recognition in dense multi-user environments is an important
tool for optimizing spectrum utilization, identifying and minimizing
interference, and enforcing spectrum policy. Radio data is readily available
and easy to obtain from an antenna, but labeled and curated data is often
scarce making supervised learning strategies difficult and time consuming in
practice. We demonstrate that semi-supervised learning techniques can be used
to scale learning beyond supervised datasets, allowing for discerning and
recalling new radio signals by using sparse signal representations based on
both unsupervised and supervised methods for nonlinear feature learning and
clustering methods.",1611.00303v2,cs.LG,2016-11-01 17:21:50+00:00,"[arxiv.Result.Author(""Timothy J. O'Shea""), arxiv.Result.Author('Nathan West'), arxiv.Result.Author('Matthew Vondal'), arxiv.Result.Author('T. Charles Clancy')]",
658,Semi-supervised Clustering Ensemble by Voting,"Clustering ensemble is one of the most recent advances in unsupervised
learning. It aims to combine the clustering results obtained using different
algorithms or from different runs of the same clustering algorithm for the same
data set, this is accomplished using on a consensus function, the efficiency
and accuracy of this method has been proven in many works in literature. In the
first part of this paper we make a comparison among current approaches to
clustering ensemble in literature. All of these approaches consist of two main
steps: the ensemble generation and consensus function. In the second part of
the paper, we suggest engaging supervision in the clustering ensemble procedure
to get more enhancements on the clustering results. Supervision can be applied
in two places: either by using semi-supervised algorithms in the clustering
ensemble generation step or in the form of a feedback used by the consensus
function stage. Also, we introduce a flexible two parameter weighting
mechanism, the first parameter describes the compatibility between the datasets
under study and the semi-supervised clustering algorithms used to generate the
base partitions, the second parameter is used to provide the user feedback on
the these partitions. The two parameters are engaged in a ""relabeling and
voting"" based consensus function to produce the final clustering.",1208.4138v1,cs.LG,2012-08-20 23:21:10+00:00,"[arxiv.Result.Author('Ashraf Mohammed Iqbal'), arxiv.Result.Author(""Abidalrahman Moh'd""), arxiv.Result.Author('Zahoor Khan')]",
659,Semi-supervised 3D Object Detection with Proficient Teachers,"Dominated point cloud-based 3D object detectors in autonomous driving
scenarios rely heavily on the huge amount of accurately labeled samples,
however, 3D annotation in the point cloud is extremely tedious, expensive and
time-consuming. To reduce the dependence on large supervision, semi-supervised
learning (SSL) based approaches have been proposed. The Pseudo-Labeling
methodology is commonly used for SSL frameworks, however, the low-quality
predictions from the teacher model have seriously limited its performance. In
this work, we propose a new Pseudo-Labeling framework for semi-supervised 3D
object detection, by enhancing the teacher model to a proficient one with
several necessary designs. First, to improve the recall of pseudo labels, a
Spatialtemporal Ensemble (STE) module is proposed to generate sufficient seed
boxes. Second, to improve the precision of recalled boxes, a Clusteringbased
Box Voting (CBV) module is designed to get aggregated votes from the clustered
seed boxes. This also eliminates the necessity of sophisticated thresholds to
select pseudo labels. Furthermore, to reduce the negative influence of wrongly
pseudo-labeled samples during the training, a soft supervision signal is
proposed by considering Box-wise Contrastive Learning (BCL). The effectiveness
of our model is verified on both ONCE and Waymo datasets. For example, on ONCE,
our approach significantly improves the baseline by 9.51 mAP. Moreover, with
half annotations, our model outperforms the oracle model with full annotations
on Waymo.",2207.12655v1,cs.CV,2022-07-26 04:54:03+00:00,"[arxiv.Result.Author('Junbo Yin'), arxiv.Result.Author('Jin Fang'), arxiv.Result.Author('Dingfu Zhou'), arxiv.Result.Author('Liangjun Zhang'), arxiv.Result.Author('Cheng-Zhong Xu'), arxiv.Result.Author('Jianbing Shen'), arxiv.Result.Author('Wenguan Wang')]",
660,Self-Supervised GANs with Label Augmentation,"Recently, transformation-based self-supervised learning has been applied to
generative adversarial networks (GANs) to mitigate catastrophic forgetting in
the discriminator by introducing a stationary learning environment. However,
the separate self-supervised tasks in existing self-supervised GANs cause a
goal inconsistent with generative modeling due to the fact that their
self-supervised classifiers are agnostic to the generator distribution. To
address this problem, we propose a novel self-supervised GAN that unifies the
GAN task with the self-supervised task by augmenting the GAN labels (real or
fake) via self-supervision of data transformation. Specifically, the original
discriminator and self-supervised classifier are unified into a label-augmented
discriminator that predicts the augmented labels to be aware of both the
generator distribution and the data distribution under every transformation,
and then provide the discrepancy between them to optimize the generator.
Theoretically, we prove that the optimal generator could converge to replicate
the real data distribution. Empirically, we show that the proposed method
significantly outperforms previous self-supervised and data augmentation GANs
on both generative modeling and representation learning across benchmark
datasets.",2106.08601v5,cs.LG,2021-06-16 07:58:00+00:00,"[arxiv.Result.Author('Liang Hou'), arxiv.Result.Author('Huawei Shen'), arxiv.Result.Author('Qi Cao'), arxiv.Result.Author('Xueqi Cheng')]",
661,Compact integral manifolds of differential systems,"The boundedness tests for the number of compact integral manifolds of
autonomous ordinary differential systems, of autonomous total differential
systems, of linear systems of partial differential equations, of Pfaff systems
of equations, and of systems of exterior differential equations are proved.",1009.2998v1,math.DS,2010-09-15 19:06:37+00:00,[arxiv.Result.Author('V. N. Gorbuzov')],
662,Morphisms of Networks of Hybrid Open Systems,"This thesis (defended 10/07/2019) develops a theory of networks of hybrid
open systems and morphisms. It builds upon a framework of networks of
continuous-time open systems as product and interconnection. We work out
categorical notions for hybrid systems, deterministic hybrid systems, hybrid
open systems, networks of hybrid open systems, and morphisms of networks of
hybrid open systems.
  We also develop categorical notions for abstract systems, abstract open
systems, networks of abstract open systems, and morphisms of networks of
abstract open systems. We show that a collection of relations holding among
pairs of systems induces a relation between interconnected systems. We use this
result for abstract systems to prove a corresponding result for networks of
hybrid systems.
  This result translates as saying that our procedure for building networks
preserves morphisms of open systems: a collection of morphisms of (sub)systems
is sent to a morphism of networked systems. We thus both justify our formalism
and concretize the intuition that a network is a collection of systems pieced
together in a certain way.",1911.09048v2,math.DS,2019-11-20 17:20:41+00:00,[arxiv.Result.Author('James Schmidt')],
663,First integrals of ordinary linear differential systems,"The spectral method for building first integrals of ordinary linear
differential systems is elaborated. Using this method, we obtain bases of first
integrals for linear differential systems with constant coefficients, for
linear nonautonomous differential systems integrable in closed form (algebraic
reducible systems, triangular systems, the Lappo-Danilevskii systems), and for
reducible ordinary differential systems with respect to various transformation
groups.",1201.4141v1,math.DS,2012-01-19 18:45:08+00:00,"[arxiv.Result.Author('V. N. Gorbuzov'), arxiv.Result.Author('A. F. Pranevich')]",
664,Complex Systems + Systems Engineering = Complex Systems Engineeri,"One may define a complex system as a system in which phenomena emerge as a
consequence of multiscale interaction among the system's components and their
environments. The field of Complex Systems is the study of such
systems--usually naturally occurring, either bio-logical or social. Systems
Engineering may be understood to include the conceptualising and building of
systems that consist of a large number of concurrently operating and
interacting components--usually including both human and non-human elements. It
has become increasingly apparent that the kinds of systems that systems
engineers build have many of the same multiscale characteristics as those of
naturally occurring complex systems. In other words, systems engineering is the
engineering of complex systems. This paper and the associated panel will
explore some of the connections between the fields of complex systems and
systems engineering.",cs/0603127v1,cs.MA,2006-03-30 22:58:12+00:00,[arxiv.Result.Author('Russ Abbott')],
665,Systems of quotients of Lie triple systems,"In this paper, we introduce the notion of system of quotients of Lie triple
systems and investigate some properties which can be lifted from a Lie triple
system to its systems of quotients. We relate the notion of Lie triple system
of Martindale-like quotients with respect to a filter of ideals and the notion
of system of quotients, and prove that the system of quotients of a Lie triple
system is equivalent to the algebra of quotients of a Lie algebra in some
sense, and these allow us to construct the maximal system of quotients for
nondegenerate Lie triple systems.",1304.7340v1,math.RA,2013-04-27 07:10:20+00:00,"[arxiv.Result.Author('Yao Ma'), arxiv.Result.Author('Liangyun Chen'), arxiv.Result.Author('Jie Lin')]","Communications in Algebra, 42(2014)(8), 3339-3349"
666,Equivariant Filter Design for Kinematic Systems on Lie Groups,"It is known that invariance and equivariance properties for systems on Lie
groups can be exploited in the design of high performance and robust observers
and filters for real-world robotic systems. This paper proposes an analysis
framework that allows any kinematic system on a Lie group to be embedded in a
natural manner into an equivariant kinematic system. This framework allows us
to characterise the properties of, and relationships between, invariant
systems, group affine systems, and equivariant systems. We propose a new filter
design, the Equivariant Filter (EqF), that exploits the equivariance properties
of the system embedding and can be applied to any kinematic system on a Lie
group.",2004.00828v2,eess.SY,2020-04-02 05:39:17+00:00,"[arxiv.Result.Author('Robert Mahony'), arxiv.Result.Author('Jochen Trumpf')]",
667,Linearly repetitive Delone systems have a finite number of non periodic Delone system factors,"We prove linearly repetitive Delone systems have finitely many Delone system
factors up to conjugacy. This result is also applicable to linearly repetitive
tiling systems.",0807.2907v1,math.DS,2008-07-18 14:17:40+00:00,"[arxiv.Result.Author('Maria Isabel Cortez'), arxiv.Result.Author('Fabien Durand'), arxiv.Result.Author('Samuel Petite')]",
668,Integral equivalence of multidimensional differential systems,"The bases of the theory of integrals for multidimensional differential
systems are stated. The integral equivalence of total differential systems,
linear homogeneous systems of partial differential equations, and Pfaff systems
of equations is established.",0909.3220v1,math.DS,2009-09-17 13:51:38+00:00,[arxiv.Result.Author('V. N. Gorbuzov')],
669,Fractional Multidimensional System,"The multidimensional ($n$-D) systems described by Roesser model are presented
in this paper. These $n$-D systems consist of discrete systems and continuous
fractional order systems with fractional order $\nu$, $0<\nu<1$. The stability
and Robust stability of such $n$-D systems are investigated.",1704.08427v1,math.OC,2017-04-27 04:05:56+00:00,"[arxiv.Result.Author('Xiaogang Zhu'), arxiv.Result.Author('Junguo Lu')]",
670,A new type of 4D Hybrid Chaos Systems,"In this paper a new type of chaotic system based on sin and logistic systems
is introduced. Also the behavior of this new system is studied by using various
tests. The results of these tests indicate the appropriate behavior for the
proposed new system.",2101.09493v1,math.DS,2021-01-23 12:39:53+00:00,[arxiv.Result.Author('Reza Parvaz')],
671,Cubical token systems,"The paper deals with combinatorial and stochastic structures of cubical token
systems. A cubical token system is an instance of a token system, which in turn
is an instance of a transition system. It is shown that some basic results of
combinatorial and stochastic parts of media theory hold almost in identical
form for cubical token systems, although some underlying concepts are quite
different. A representation theorem for a cubical token system is established
asserting that the graph of such a system is cubical.",math/0612696v1,math.CO,2006-12-22 11:36:36+00:00,[arxiv.Result.Author('Sergei Ovchinnikov')],
672,Separable bi-Hamiltonian systems with quadratic in momenta first integrals,"Geometric separability theory of Gel'fand-Zakharevich bi-Hamiltonian systems
on Riemannian manifolds is reviewed and developed. Particular attention is paid
to the separability of systems generated by the so-called special conformal
Killing tensors, i.e. Benenti systems. Then, infinitely many new classes of
separable systems are constructed by appropriate deformations of Benenti class
systems. All such systems can be lifted to the Gel'fand-Zakharevich
bi-Hamiltonian form.",nlin/0312025v2,nlin.SI,2003-12-11 12:21:56+00:00,[arxiv.Result.Author('Maciej Blaszak')],
673,Variability and Evolution in Systems of Systems,"In this position paper (1) we discuss two particular aspects of Systems of
Systems, i.e., variability and evolution. (2) We argue that concepts from
Product Line Engineering and Software Evolution are relevant to Systems of
Systems Engineering. (3) Conversely, concepts from Systems of Systems
Engineering can be helpful in Product Line Engineering and Software Evolution.
Hence, we argue that an exchange of concepts between the disciplines would be
beneficial.",1311.3627v1,cs.SE,2013-11-14 19:40:33+00:00,[arxiv.Result.Author('Goetz Botterweck')],"EPTCS 133, 2013, pp. 8-23"
674,Information-theoretic multi-time-scale partially observable systems with relevance to leukemia treatment,"Inspired by a leukemia treatment challenge, we study a partially observable
non-linear stochastic system with unknown parameters, where the given time
scales of the states and measurements may be distinct. Key words: Stochastic
control; Non-linear systems; Partially observable systems; System
identification; Biomedical systems.",2204.12604v1,eess.SY,2022-04-26 21:35:36+00:00,"[arxiv.Result.Author('Margaret P. Chapman'), arxiv.Result.Author('Emily Jensen'), arxiv.Result.Author('Steven M. Chan'), arxiv.Result.Author('Laurent Lessard')]",
675,A Step towards an Easy Interconversion of Various Number Systems,"Any system that is used for naming or representing numbers is a number
system, also known as numeral system. The modern civilization is familiar with
decimal number system using ten digits. However digital devices and computers
use binary number system instead of decimal number system, using only two
digits namely, 0 and 1 based on the fundamental concept of the decimal number
system. Various other number systems also used this fundamental concept of
decimal number system, for example octal system and hexadecimal number systems
using eight and sixteen digits respectively. The knowledge of number systems
and their inter conversion is essential for understanding of computers. More
over, successful programming for digital devices requires a precise
understanding of data formats, number systems and their inter conversion. The
inter conversion (a process in which things are each converted into the other)
of number system requires allot of time and techniques to expertise. In this
paper the interconversion of four most common number systems is taken under the
consideration in tabulated form. It is a step towards the easy interconversion
of theses number systems to understand as well as memorise it. The four number
systems are binary, octal, decimal and hexadecimal.",1107.1663v1,cs.DM,2011-07-08 15:59:35+00:00,"[arxiv.Result.Author('Shahid Latif'), arxiv.Result.Author('Rahat Ullah'), arxiv.Result.Author('Hamid Jan')]",
676,Nonlinear Modal Decoupling of Multi-Oscillator Systems with Applications to Power Systems,"Many natural and manmade dynamical systems that are modeled as large
nonlinear multi-oscillator systems like power systems are hard to analyze. For
such a system, we propose a nonlinear modal decoupling (NMD) approach inversely
constructing as many decoupled nonlinear oscillators as the system oscillation
modes so that individual decoupled oscillators can easily be analyzed to infer
dynamics and stability of the original system. The NMD follows a similar idea
to the normal form except that we eliminate inter-modal terms but allow
intra-modal terms of desired nonlinearities in decoupled systems, so decoupled
systems can flexibly be shaped into desired forms of nonlinear oscillators. The
NMD is then applied to power systems towards two types of nonlinear
oscillators, i.e. the single-machine-infinite-bus (SMIB) systems and a proposed
non-SMIB oscillator. Numerical studies on a 3-machine 9-bus system and New
England 10-machine 39-bus system show that (i) decoupled oscillators keep a
majority of the original system modal nonlinearities and the NMD provides a
bigger validity region than the normal form, and (ii) decoupled non-SMIB
oscillators may keep more authentic dynamics of the original system than
decoupled SMIB systems.",1611.04553v1,cs.SY,2016-11-14 20:18:36+00:00,"[arxiv.Result.Author('Bin Wang'), arxiv.Result.Author('Kai Sun'), arxiv.Result.Author('Wei Kang')]",
677,An Networked HIL Simulation System for Modeling Large-scale Power Systems,"This paper presents a network hardware-in-the-loop (HIL) simulation system
for modeling large-scale power systems. Researchers have developed many HIL
test systems for power systems in recent years. Those test systems can model
both microsecond-level dynamic responses of power electronic systems and
millisecond-level transients of transmission and distribution grids. By
integrating individual HIL test systems into a network of HIL test systems, we
can create large-scale power grid digital twins with flexible structures at
required modeling resolution that fits for a wide range of system operating
conditions. This will not only significantly reduce the need for field tests
when developing new technologies but also greatly shorten the model development
cycle. In this paper, we present a networked OPAL-RT based HIL test system for
developing transmission-distribution coordinative Volt-VAR regulation
technologies as an example to illustrate system setups, communication
requirements among different HIL simulation systems, and system connection
mechanisms. Impacts of communication delays, information exchange cycles, and
computing delays are illustrated. Simulation results show that the performance
of a networked HIL test system is satisfactory.",2002.07257v1,eess.SY,2020-02-17 21:27:55+00:00,"[arxiv.Result.Author('Fuhong Xie'), arxiv.Result.Author('Catie McEntee'), arxiv.Result.Author('Mingzhi Zhang'), arxiv.Result.Author('Ning Lu'), arxiv.Result.Author('Xinda Ke'), arxiv.Result.Author('Mallikarjuna R. Vallem'), arxiv.Result.Author('Nader Samaan')]",
678,Using Structure-Behavior Coalescence Method for Systems Definition 2.0,"Systems definition is an artifact created by humans to describe what a system
is. A system has been defined, by systems definition 1.0, hopefully to be an
integrated whole, embodied in its components, their interrelationships with
each other and the environment, and the principles and guidelines governing its
design and evolution. This systems definition 1.0 defining the system possesses
one cardinal deficiency. The deficiency comes from that it does not describe
the integration of systems structure and systems behavior. Structure-behavior
coalescence (SBC) architecture provides an elegant way to integrate the
structure and behavior of a system. A system is therefore redefined, by systems
definition 2.0, truly to be an integrated whole, using the SBC architecture,
embodied in its assembled components, their interactions with each other and
the environment, and the principles and guidelines governing its design and
evolution. Since systems definition 2.0 describes the integration of systems
structure and systems behavior, definitely it is able to form an integrated
whole of a system. In this situation, systems definition 2.0 is fully capable
of defining a system.",2110.08998v4,cs.SE,2021-10-18 03:34:27+00:00,[arxiv.Result.Author('William S. Chao')],
679,Delocalization of a Dynamic System with Preservation or Self-Resurection of Informational Functionality. Ghost machines or can a system survive its destruction,"We analyzed the problem of a dynamic system delocalization due to changes in
the system environment - universe and system architecture. We developed a
Delocalization of Dynamic Cores model to analyze the migration of functional
properties in open information and dynamic systems undergoing architecture
transition and modifications. Information geometry and topological formalisms
are proposed to analyze informational dynamic systems. Different physical and
holographic models are proposed to construct systems able to conserve their
functional properties under delocalization transition. We found several
constraints for the system environment - universe which conserve the dynamic
core system functionality under transition from localized explicit
implementation of functions to the implicit distributed implementation.",nlin/0701026v1,nlin.AO,2007-01-13 09:42:25+00:00,"[arxiv.Result.Author('Vadim Astakhov'), arxiv.Result.Author('Tamara Astakhova')]",
680,Non-Hamiltonian systems separable by Hamilton-Jacobi method,"We show that with every separable calssical Stackel system of Benenti type on
a Riemannian space one can associate, by a proper deformation of the metric
tensor, a multi-parameter family of non-Hamiltonian systems on the same space,
sharing the same trajectories and related to the seed system by appropriate
reciprocal transformations. These system are known as bi-cofactor systems and
are integrable in quadratures as the seed Hamiltonian system is. We show that
with each class of bi-cofactor systems a pair of separation curves can be
related. We also investigate conditions under which a given flat bi-cofactor
system can be deformed to a family of geodesically equivalent flat bi-cofactor
systems.",0707.1113v1,nlin.SI,2007-07-07 20:24:28+00:00,"[arxiv.Result.Author('Krzysztof Marciniak'), arxiv.Result.Author('Maciej Blaszak')]",
681,Information-Theoretic Secure and Private Voting System,"In this paper, we present a private voting system that consists of N
authorized voters who may vote to one of the K candidates or vote abstain. Each
voter wants to compute the final tally while staying private and robust against
malicious voters, who try to gain information about the vote of the other
voters beyond the final result, or send incorrect information to affect the
final tally. We design an information-theoretic private voting system based on
Shamir secret sharing, which is secure and robust as long as there are up to
(N-1)/3 malicious voters.",2203.07355v1,cs.IT,2022-03-14 17:53:35+00:00,"[arxiv.Result.Author('Seyed Reza Hoseini Najarkolaei'), arxiv.Result.Author('Narges Kazempour'), arxiv.Result.Author('Hasti Rostami'), arxiv.Result.Author('Mohammad Reza Aref')]",
682,Information-Theoretically Secure Voting Without an Honest Majority,"We present three voting protocols with unconditional privacy and
information-theoretic correctness, without assuming any bound on the number of
corrupt voters or voting authorities. All protocols have polynomial complexity
and require private channels and a simultaneous broadcast channel. Our first
protocol is a basic voting scheme which allows voters to interact in order to
compute the tally. Privacy of the ballot is unconditional, but any voter can
cause the protocol to fail, in which case information about the tally may
nevertheless transpire. Our second protocol introduces voting authorities which
allow the implementation of the first protocol, while reducing the interaction
and limiting it to be only between voters and authorities and among the
authorities themselves. The simultaneous broadcast is also limited to the
authorities. As long as a single authority is honest, the privacy is
unconditional, however, a single corrupt authority or a single corrupt voter
can cause the protocol to fail. Our final protocol provides a safeguard against
corrupt voters by enabling a verification technique to allow the authorities to
revoke incorrect votes. We also discuss the implementation of a simultaneous
broadcast channel with the use of temporary computational assumptions, yielding
versions of our protocols achieving everlasting security.",0806.1931v1,cs.CR,2008-06-11 18:51:04+00:00,"[arxiv.Result.Author('Anne Broadbent'), arxiv.Result.Author('Alain Tapp')]",
683,"Exact, Efficient and Information-Theoretically Secure Voting with an Arbitrary Number of Cheaters","We present three voting protocols with unconditional privacy and correctness,
without assuming any bound on the number of corrupt participants. All protocols
have polynomial complexity and require private channels and a simultaneous
broadcast channel. Unlike previously proposed protocols in this model, the
protocols that we present deterministically output the exact tally. Our first
protocol is a basic voting scheme which allows voters to interact in order to
compute the tally. Privacy of the ballot is unconditional in the sense that
regardless of the behavior of the dishonest participants nothing can be learned
through the protocol that could not be learned in an ideal realisation.
Unfortunately, a single dishonest participant can make the protocol abort, in
which case the dishonest participants can nevertheless learn the outcome of the
tally. Our second protocol introduces voting authorities which improves the
communication complexity by limiting interaction to be only between voters and
authorities and among the authorities themselves; the simultaneous broadcast is
also limited to the authorities. In the second protocol, as long as a single
authority is honest, the privacy is unconditional, however, a single corrupt
authority or a single corrupt voter can cause the protocol to abort. Our final
protocol provides a safeguard against corrupt voters by enabling a verification
technique to allow the authorities to revoke incorrect votes without aborting
the protocol. Finally, we discuss the implementation of a simultaneous
broadcast channel with the use of temporary computational assumptions, yielding
versions of our protocols that achieve everlasting security.",1011.5242v1,cs.CR,2010-11-23 21:33:50+00:00,"[arxiv.Result.Author('Anne Broadbent'), arxiv.Result.Author('Stacey Jeffery'), arxiv.Result.Author('Alain Tapp')]",
684,(Universal) Unconditional Verifiability in E-Voting without Trusted Parties,"In traditional e-voting protocols, privacy is often provided by a trusted
authority that learns the votes and computes the tally. Some protocols replace
the trusted authority by a set of authorities, and privacy is guaranteed if
less than a threshold number of authorities are corrupt. For verifiability,
stronger security guarantees are demanded. Typically, corrupt authorities that
try to fake the result of the tally must always be detected.
  To provide verifiability, many e-voting protocols use Non-Interactive
Zero-Knowledge proofs (NIZKs). Thanks to their non-interactive nature, NIZKs
allow anybody, including third parties that do not participate in the protocol,
to verify the correctness of the tally. Therefore, NIZKs can be used to obtain
universal verifiability. Additionally, NIZKs also improve usability because
they allow voters to cast a vote using a non-interactive protocol.
  The disadvantage of NIZKs is that their security is based on setup
assumptions such as the common reference string (CRS) or the random oracle (RO)
model. The former requires a trusted party for the generation of a common
reference string. The latter, though a popular methodology for designing secure
protocols, has been shown to be unsound.
  In this paper, we address the design of an e-voting protocol that provides
verifiability without any trust assumptions, where verifiability here is meant
without eligibility verification. We show that Non-Interactive
Witness-Indistinguishable proofs (NIWI) can be used for this purpose. The
e-voting scheme is private under the Decision Linear assumption, while
verifiability holds unconditionally. To our knowledge, this is the first
private e-voting scheme with perfect universal verifiability, i.e. one in which
the probability of a fake tally not being detected is 0, and with {\em
non-interactive} protocols that does not rely on trust assumptions.",1610.06343v1,cs.CR,2016-10-20 09:57:12+00:00,"[arxiv.Result.Author('Gina Gallegos-Garcia'), arxiv.Result.Author('Vincenzo Iovino'), arxiv.Result.Author('Alfredo Rial'), arxiv.Result.Author('Peter B. Roenne'), arxiv.Result.Author('Peter Y. A. Ryan')]",
685,Effects of Mirror Seeing on High-Contrast Adaptive Optics Instruments,"Ground-based direct imaging surveys like the Gemini Planet Imager Exoplanet
Survey (GPIES) rely on Adaptive Optics (AO) systems to image and characterize
exoplanets that are up to a million times fainter than their host stars. One
factor that can reduce AO performance is turbulence induced by temperature
differences in the instrument's immediate surroundings (e.g.: ""dome seeing"" or
""mirror seeing""). In this analysis we use science observations, AO telemetry,
and environmental data from September 2014 to February 2017 of the GPIES
campaign to quantify the effects of ""mirror seeing"" on the performance of the
GPI instrument. We show that GPI performance is optimal when the primary mirror
(M1) is in equilibrium with the outside air temperature. We then examine the
characteristics of mirror seeing by calculating the power spectral densities
(PSD) of spatial and temporal Fourier modes. Inside the inertial range of the
PSDs, we find that the spatial PSD amplitude increases when M1 is out of
equilibrium and that the integrated turbulence may exhibit deviations from
Kolmogorov atmospheric turbulence models and from the 1-layer frozen flow
model. We conclude with an assessment of the current temperature control and
ventilation strategy at Gemini South.",2002.04649v1,astro-ph.IM,2020-02-11 19:52:21+00:00,"[arxiv.Result.Author('Melisa Tallis'), arxiv.Result.Author('Vanessa P. Bailey'), arxiv.Result.Author('Bruce Macintosh'), arxiv.Result.Author('Lisa A. Poyneer'), arxiv.Result.Author('Jean-Baptiste Ruffio'), arxiv.Result.Author('Thomas L. Hayward'), arxiv.Result.Author('Fredrik T. Rantakyrö'), arxiv.Result.Author('Jeffrey K. Chilcote'), arxiv.Result.Author('Dmitry Savransky')]","J. Astron. Telesc. Instrum. Syst. 6(1), 015002 (2020)"
686,VoteAgain: A scalable coercion-resistant voting system,"The strongest threat model for voting systems considers coercion resistance:
protection against coercers that force voters to modify their votes, or to
abstain. Existing remote voting systems either do not provide this property;
require an expensive tallying phase; or burden users with the need to store
cryptographic key material and with the responsibility to deceive their
coercers. We propose VoteAgain, a scalable voting scheme that relies on the
revoting paradigm to provide coercion resistance. VoteAgain uses a novel
deterministic ballot padding mechanism to ensure that coercers cannot see
whether a vote has been replaced. This mechanism ensures tallies take
quasilinear time, making VoteAgain the first revoting scheme that can handle
elections with millions of voters. We prove that VoteAgain provides ballot
privacy, coercion resistance, and verifiability; and we demonstrate its
scalability using a prototype implementation of all cryptographic primitives.",2005.11189v3,cs.CR,2020-05-22 13:51:34+00:00,"[arxiv.Result.Author('Wouter Lueks'), arxiv.Result.Author('Iñigo Querejeta-Azurmendi'), arxiv.Result.Author('Carmela Troncoso')]",
687,New results with colour-sextet quarks,"We study QCD with 2 and 3 flavours of colour-sextet quarks. The 2-flavour
theory is a candidate Walking Technicolor theory. Since we are attempting to
distinguish whether this theory is walking or conformal, we also study the
3-flavour theory, which is believed to be conformal, for comparison. We
simulate lattice QCD with 2 and 3 flavours of colour-sextet staggered quarks at
finite temperatures to determine the scales of confinement and chiral-symmetry
breaking from the positions of the deconfinement and chiral-symmetry
restoration transitions. Unlike the case with fundamental quarks, these
transitions are far apart. For 2 flavours the values of beta=6/g^2 for both
transitions increase as Ta is decreased from 1/4 to 1/6 to 1/8, as expected for
a theory whose coupling runs to smaller values as the lattice spacing is
decreased. However, for the chiral transition, the increase in beta between
Ta=1/4 and Ta=1/6 is much larger than the increase between Ta=1/6 and Ta=1/8.
This suggests that between Ta=1/4 and Ta=1/6 we are at strong coupling where
the theory is effectively quenched, while between Ta=1/6 and Ta=1/8 we are
emerging into the weak coupling regime. It will require even smaller Ta values
to determine whether the running of the chiral-transition coupling is
controlled by asymptotic freedom and the theory walks, or if it reaches a
non-zero limit when the transition becomes a bulk transition and the theory is
conformal. The 3 flavour case at Ta=1/4 and Ta=1/6 behaves similarly to the 2
flavour case. Since this theory is expected to be conformal, the interpretation
that we are seeing strong-coupling behaviour, inaccessible from the
weak-coupling limit (continuum) is the most likely interpretation.",1008.2468v1,hep-lat,2010-08-14 19:35:23+00:00,"[arxiv.Result.Author('D. K. Sinclair'), arxiv.Result.Author('J. B. Kogut')]","PoS Lattice2010:071,2010"
688,An efficient and effective Decentralized Anonymous Voting System,"A trusted electronic election system requires that all the involved
information must go public, that is, it focuses not only on transparency but
also privacy issues. In other words, each ballot should be counted anonymously,
correctly, and efficiently. In this work, a lightweight E-voting system is
proposed for voters to minimize their trust in the authority or government. We
ensure the transparency of election by putting all message on the Ethereum
blockchain, in the meantime, the privacy of individual voter is protected via
an efficient and effective ring signature mechanism. Besides, the attractive
self-tallying feature is also built in our system, which guarantees that
everyone who can access the blockchain network is able to tally the result on
his own, no third party is required after voting phase. More importantly, we
ensure the correctness of voting results and keep the Ethereum gas cost of
individual participant as low as possible, at the same time. Clearly, the
pre-described characteristics make our system more suitable for large-scale
election.",1804.06674v1,cs.CR,2018-04-18 12:19:44+00:00,[arxiv.Result.Author('Wei-Jr Lai Ja-Ling Wu')],
689,On the topological equivalence of S-metric and cone S-metric spaces,"The aim of this paper is to establish the equivalence between the concepts of
an $S$-metric space and a cone $S$-metric space using\ some topological
approaches. We introduce a new notion of $TVS$-cone $S$-metric space using some
facts about topological vector spaces. We see that the known results on cone
$S$-metric spaces (or $N$-cone metric spaces) can be directly obtained from the
studies on $S$-metric spaces.",1801.00024v1,math.GN,2017-12-29 19:42:12+00:00,[arxiv.Result.Author('Nihal Taş')],
690,Mentoring Partnerships in Science Education,"The authors use an action research (AR) approach in a collegiate studio
physics class to investigate the power of partnerships via conferences as they
relate to issues of establishing a student/mentor rapport, empowering students
to reduce inequity, and the successes and barriers to hearing students' voices.
The graduate teaching assistant (TA, Author 1) conducted one-on-one conferences
with 29 students, elicited student opinions about the progress of the course,
and talked with faculty, TAs, and an undergraduate supplemental instructor for
other sections of the course. At the end of the semester, the students reported
increased knowledge of the TA as a person and as an instructor, and vice versa.
Sixty-five percent of students reported no interest in changing circumstances
to make it easier to talk about personal concerns with the TA. College students
reluctantly voiced their opinions about the course, possibly due to the power
structure of the classroom. Other TAs in the department expressed mostly
disinterest in the project, while faculty members were interested in student
learning but skeptical of student empowerment. A case study of one student is
presented, wherein his attendance improved in the course and he received
additional help outside class, both possibly as a result of the student/TA
conferences. Students in this studio physics section were more likely to
interact directly with faculty or TAs during lectures, but less likely to do so
during lab sessions, than were students in a non-studio physics section.",1610.04808v1,physics.ed-ph,2016-10-16 01:46:34+00:00,"[arxiv.Result.Author('Andria C. Schwortz'), arxiv.Result.Author('Andrea C. Burrows'), arxiv.Result.Author('Sarah Katie Guffey')]","Educational Action Research, 25(4): 630-649 (2017.)"
691,Blind proxy voting,"A secret ballot mechanism that enables voting in absence is proposed. It
amends standard vote collection methods that use ballot box as anonymizer,
adding the option for absent voters to vote by a proxy blinded to the content
of the ballot paper. Votes are cast under unique and hidden identification
numbers generated solely for the purpose of that election. Voters prepare their
ballot papers from scratch and submit them to the tallying authority in two
parts via separate routes, each part being meaningless without the other.",1812.11128v1,cs.CR,2018-12-28 17:41:13+00:00,[arxiv.Result.Author('Zuzana Haniková')],
692,"Structural, Elastic, Electronic and Optical Properties of a New Layered-Ternary Ta4SiC3 Compound","We propose a new layered-ternary Ta4SiC3 with two different stacking
sequences ({\alpha}- and {\beta}-phases) of the metal atoms along c axis and
study their structural stability. The mechanical, electronic and optical
properties are then calculated and compared with those of other compounds M4AX3
(M = V, Nb, Ta; A = Al, Si and X = C). The predicted compound in the
{\alpha}-phase is found to possess higher hardness than any of these compounds.
The independent elastic constants of the two phases are also evaluated and the
results discussed. The electronic band structures for {\alpha}- and
{\beta}-Ta4SiC3 show metallic conductivity. Ta 5d electrons are mainly
contributing to the total density of states (DOS). We see that the
hybridization peak of Ta 5d and C 2p lies lower in energy and the Ta 5d-C 2p
bond is stronger than Ta 5d-Si 3p bond. Further an analysis of the different
optical properties shows the compound to possess improved behavior compared to
similar types of compounds.",1009.0595v1,cond-mat.mtrl-sci,2010-09-03 06:47:49+00:00,"[arxiv.Result.Author('M. S. Islam'), arxiv.Result.Author('A. K. M. A. Islam')]",
693,Repairing Timed Automata Clock Guards through Abstraction and Testing,"Timed automata (TAs) are a widely used formalism to specify systems having
temporal requirements. However, exactly specifying the system may be difficult,
as the user may not know the exact clock constraints triggering state
transitions. In this work, we assume the user already specified a TA, and (s)he
wants to validate it against an oracle that can be queried for acceptance.
Under the assumption that the user only wrote wrong guard transitions (i.e.,
the structure of the TA is correct), the search space for the correct TA can be
represented by a Parametric Timed Automaton (PTA), i.e., a TA in which some
constants are parametrized. The paper presents a process that i) abstracts the
initial (faulty) TA tainit in a PTA pta; ii) generates some test data (i.e.,
timed traces) from pta; iii) assesses the correct evaluation of the traces with
the oracle; iv) uses the IMITATOR tool for synthesizing some constraints phi on
the parameters of pta; v) instantiate from phi a TA tarep as final repaired
model. Experiments show that the approach is successfully able to partially
repair the initial design of the user.",1907.02133v1,cs.LO,2019-06-27 08:45:25+00:00,"[arxiv.Result.Author('Étienne André'), arxiv.Result.Author('Paolo Arcaini'), arxiv.Result.Author('Angelo Gargantini'), arxiv.Result.Author('Marco Radavelli')]",
694,On the Security of MTA-OTIBASs (Multiple-TA One-Time Identity-Based Aggregate Signatures),"In [3] the authors proposed a new aggregate signature scheme referred to as
multiple-TA (trusted authority) one-time identity-based aggregate signature
(MTA-OTIBAS). Further, they gave a concrete MTA-OTIBAS scheme. We recall here
the definition of MTA-OTIBAS and the concrete proposed scheme. Then we prove
that our MTA-OTIBAS concrete scheme is existentially unforgeable against
adaptively chosen-message attacks in the random oracle model under the co-CDH
problem assumption.",1506.08548v1,cs.CR,2015-06-29 08:55:49+00:00,"[arxiv.Result.Author('Lei Zhang'), arxiv.Result.Author('Qianhong Wu'), arxiv.Result.Author('Josep Domingo-Ferrer'), arxiv.Result.Author('Bo Qin'), arxiv.Result.Author('Chuanyan Hu')]",
695,Teachable Agent,"Teachable Agent (TA) is a special type of pedagogical agent which
instantiates the educational theory of Learning by Teaching. Soon after its
emergence, research of TA becomes an active field, as it can solve the over
scaffolded problem in traditional pedagogical systems, and encourage students
to take the responsibility of learning. Apart from the benefits, existing TA
design also has limitations. One is the lack of enough proactive interactions
with students during the learning process, and the other is the lack of
believability to arouse students empathy so as to offer students an immersive
learning experience. To solve these two problems, we propose a new type of TA,
Affective Teachable Agent, and use a goal oriented approach to design and
implement the agent system allowing agents to proactively interact with
students with affective expressions. The ATA model begins with the analysis of
pedagogical requirements and teaching goals, using Learning by Teaching theory
to design interventions which can authentically promote the learning behaviors
of students. Two crucial capabilities of ATA are highlighted Teachability, to
learn new knowledge and apply the knowledge to certain tasks, and
Affectivability, to establish good relationship with students and encourage
them to teach well. Through executing a hierarchy of goals, the proposed TA can
interact with students by pursuing its own agenda. When a student teaches the
agent, the agent is performed as a naive learning companion, and when an
educator teaches the agent during the design and maintenance time, the agent
can perform as an authoring tool. To facilitate the involvement of educators
into the game design, we develop an authoring tool for proposed ATA system,
which can encapsulate the technical details and provide educational experts a
natural way to convey domain knowledge to agent knowledge base.",1502.02370v1,cs.CY,2015-02-09 05:38:43+00:00,[arxiv.Result.Author('Ailiya Borjigin')],
696,Zone extrapolations in parametric timed automata,"Timed automata (TAs) are an efficient formalism to model and verify systems
with hard timing constraints, and concurrency. While TAs assume exact timing
constants with infinite precision, parametric TAs (PTAs) leverage this
limitation and increase their expressiveness, at the cost of undecidability. A
practical explanation for the efficiency of TAs is zone extrapolation, where
clock valuations beyond a given constant are considered equivalent. This
concept cannot be easily extended to PTAs, due to the fact that parameters can
be unbounded. In this work, we propose several definitions of extrapolation for
PTAs based on the M-extrapolation, and we study their correctness. Our
experiments show an overall decrease of the computation time and, most
importantly, allow termination of some previously unsolvable benchmarks.",2203.13173v1,cs.FL,2022-03-24 16:47:13+00:00,"[arxiv.Result.Author('Johan Arcile'), arxiv.Result.Author('Étienne André')]","Lecture Notes in Computer Science, volume 13260, 2022"
697,"ElectAnon: A Blockchain-Based, Anonymous, Robust and Scalable Ranked-Choice Voting Protocol","Remote voting has become more critical in recent years, especially after the
Covid-19 outbreak. Blockchain technology and its benefits like
decentralization, security, and transparency have encouraged remote voting
systems to use blockchains. Analysis of existing solutions reveals that
anonymity, robustness, and scalability are common problems in blockchain-based
election systems. In this work, we propose ElectAnon, a blockchain-based,
ranked-choice election protocol focusing on anonymity, robustness, and
scalability. ElectAnon achieves anonymity by enabling voters to cast their
votes via zero-knowledge proofs anonymously. Robustness is realized by removing
the direct control of the authorities in the voting process by using
timed-state machines. Results show that ElectAnon is scalable amongst existing
works as it reduces the gas consumption up to 89% compared to previous works.
The proposed protocol includes a candidate proposal system and swappable
tallying libraries. An extension is also proposed to minimize the trust
assumption on election authorities. Our code is available on
https://github.com/ceyonur/electanon.",2204.00057v2,cs.CR,2022-03-31 19:46:27+00:00,"[arxiv.Result.Author('Ceyhun Onur'), arxiv.Result.Author('Arda Yurdakul')]",
698,Atomic Carbon Is a Temperature Probe in Dark Clouds,"We have mapped the C I 3P1-3P0 line at 492 GHzin three molecular clouds
immersed in weak ultraviolet radiation fields, TMC-1, L134N, and IC 5146. In
all three clouds, the CI peak TA* ~ 1 K, with very small dispersion. The
spatial C I distribution is extended and rather smooth. The J = 2-1 transitions
of CO isotopomers were observed at the same angular resolution as C I. The C I
peak TA* is typically a third of the peak TA* of 13CO J = 2-1, and the C I
emission is usually more extended than emission in 13CO or C18O J=2-1. The C I
linewidth is close to the 13CO J = 2-1 linewidth, larger than the C18O J = 2-1
line width, and smaller than the 12CO J = 2-1 linewidth. The uniformity of the
C I peak TA* is remarkable for a line in the Wien portion of the Planck
function and indicates a very uniform excitation temperature. This uniformity
is best explained if the line if opaque and thermalized. If so, the CI line
probes kinetic temperature in clouds exposed to low ultraviolet fluxes. This
conclusion has significant implications for the thermal balance in such clouds.
At Av ~ 2, these clouds have a remarkably constant temperature from place to
place and from cloud to cloud (7.9+/-0.8 K). Photodissociation region models of
clouds immersed in the mean interstellar radiation field tend to predict
stronger lines than we see, but this may be an artifact of assumptions about
the temperature.",astro-ph/9906284v1,astro-ph,1999-06-17 01:09:57+00:00,"[arxiv.Result.Author('K. Tatematsu'), arxiv.Result.Author('D. T. Jaffe'), arxiv.Result.Author('R. Plume'), arxiv.Result.Author('N. J. Evans II'), arxiv.Result.Author('J. Keene')]",
699,MgO barrier-perpendicular magnetic tunnel junctions with CoFe/Pd multilayers and ferromagnetic insertion layers,"The authors studied an effect of ferromagnetic (Co20Fe60B20 or Fe) layer
insertion on tunnel magnetoresistance (TMR) properties of MgO-barrier magnetic
tunnel junctions (MTJs) with CoFe/Pd multilayer electrodes. TMR ratio in MTJs
with CoFeB/MgO/Fe stack reached 67% at an-nealing temperature (Ta) of 200
degree C and then decreased rapidly at Ta over 250 degree C. The degradation of
the TMR ratio may be related to crystallization of CoFe(B) into fcc(111) or
bcc(011) texture result-ing from diffusion of B into Pd layers. MTJs which were
in-situ annealed at 350oC just after depo-siting bottom CoFe/Pd multilayer
showed TMR ratio of 78% by post annealing at Ta =200 degree C.",0910.4204v1,cond-mat.mtrl-sci,2009-10-22 00:19:37+00:00,"[arxiv.Result.Author('K. Mizunuma'), arxiv.Result.Author('S. Ikeda'), arxiv.Result.Author('J. H. Park'), arxiv.Result.Author('H. Yamamoto'), arxiv.Result.Author('H. Gan'), arxiv.Result.Author('K. Miura'), arxiv.Result.Author('H. Hasegawa'), arxiv.Result.Author('J. Hayakawa'), arxiv.Result.Author('F. Matsukura'), arxiv.Result.Author('H. Ohno')]",
700,Parametric Timed Model Checking for Guaranteeing Timed Opacity,"Information leakage can have dramatic consequences on systems security. Among
harmful information leaks, the timing information leakage is the ability for an
attacker to deduce internal information depending on the system execution time.
We address the following problem: given a timed system, synthesize the
execution times for which one cannot deduce whether the system performed some
secret behavior. We solve this problem in the setting of timed automata (TAs).
We first provide a general solution, and then extend the problem to parametric
TAs, by synthesizing internal timings making the TA secure. We study
decidability, devise algorithms, and show that our method can also apply to
program analysis.",1907.00537v2,cs.CR,2019-07-01 04:27:31+00:00,"[arxiv.Result.Author('Étienne André'), arxiv.Result.Author('Jun Sun')]","Proceedings of the 17th International Symposium on Automated
  Technology for Verification and Analysis (ATVA 2019), Springer LNCS 11781,
  pages 115-130, 2019"
701,Efficient Model-Based Deep Reinforcement Learning with Variational State Tabulation,"Modern reinforcement learning algorithms reach super-human performance on
many board and video games, but they are sample inefficient, i.e. they
typically require significantly more playing experience than humans to reach an
equal performance level. To improve sample efficiency, an agent may build a
model of the environment and use planning methods to update its policy. In this
article we introduce Variational State Tabulation (VaST), which maps an
environment with a high-dimensional state space (e.g. the space of visual
inputs) to an abstract tabular model. Prioritized sweeping with small backups,
a highly efficient planning method, can then be used to update state-action
values. We show how VaST can rapidly learn to maximize reward in tasks like 3D
navigation and efficiently adapt to sudden changes in rewards or transition
probabilities.",1802.04325v2,cs.LG,2018-02-12 19:38:44+00:00,"[arxiv.Result.Author('Dane Corneil'), arxiv.Result.Author('Wulfram Gerstner'), arxiv.Result.Author('Johanni Brea')]",
702,PROVIDENCE: a Flexible Round-by-Round Risk-Limiting Audit,"A Risk-Limiting Audit (RLA) is a statistical election tabulation audit with a
rigorous error guarantee. We present ballot polling RLA PROVIDENCE, an audit
with the efficiency of MINERVA and flexibility of BRAVO. We prove that
PROVIDENCE is risk-limiting in the presence of an adversary who can choose
subsequent round sizes given knowledge of previous samples. We describe a
measure of audit workload as a function of the number of rounds, precincts
touched, and ballots drawn.We quantify the problem of obtaining a misleading
audit sample when rounds are too small, demonstrating the importance of the
resulting constraint on audit planning. We present simulation results
demonstrating the superiority of PROVIDENCE using these measures and describing
an approach to planning audit round schedules.
  We describe the use of PROVIDENCE by the Rhode Island Board of Elections in a
tabulation audit of the 2021 election. Our implementation of PROVIDENCE and
audit planning tools in the open source R2B2 library should be useful to the
states of Georgia and Pennsylvania, which are planning pre-certification ballot
polling RLAs for the 2022 general election.",2210.08717v1,cs.CR,2022-10-17 03:14:46+00:00,"[arxiv.Result.Author('Oliver Broadrick'), arxiv.Result.Author('Poorvi L. Vora'), arxiv.Result.Author('Filip Zagórski')]",
703,One Table to Count Them All: Parallel Frequency Estimation on Single-Board Computers,"Sketches are probabilistic data structures that can provide approximate
results within mathematically proven error bounds while using orders of
magnitude less memory than traditional approaches. They are tailored for
streaming data analysis on architectures even with limited memory such as
single-board computers that are widely exploited for IoT and edge computing.
Since these devices offer multiple cores, with efficient parallel sketching
schemes, they are able to manage high volumes of data streams. However, since
their caches are relatively small, a careful parallelization is required. In
this work, we focus on the frequency estimation problem and evaluate the
performance of a high-end server, a 4-core Raspberry Pi and an 8-core Odroid.
As a sketch, we employed the widely used Count-Min Sketch. To hash the stream
in parallel and in a cache-friendly way, we applied a novel tabulation approach
and rearranged the auxiliary tables into a single one. To parallelize the
process with performance, we modified the workflow and applied a form of
buffering between hash computations and sketch updates. Today, many
single-board computers have heterogeneous processors in which slow and fast
cores are equipped together. To utilize all these cores to their full
potential, we proposed a dynamic load-balancing mechanism which significantly
increased the performance of frequency estimation.",1903.00729v1,cs.DS,2019-03-02 16:18:00+00:00,"[arxiv.Result.Author('Fatih Taşyaran'), arxiv.Result.Author('Kerem Yıldırır'), arxiv.Result.Author('Kamer Kaya'), arxiv.Result.Author('Mustafa Kemal Taş')]",
704,Non-equilibrium ionization effects on solar EUV and X-ray imaging observations,"During transient events such as major solar eruptions, the plasma can be far
from the equilibrium ionization state because of rapid heating or cooling.
Non-equilibrium ionization~(NEI) is important in rapidly evolving systems where
the thermodynamical timescale is shorter than the ionization or recombination
time scales. We investigate the effects of NEI on EUV and X-ray observations by
the Atmospheric Imaging Assembly (AIA) on board Solar Dynamic Observatory and
X-ray Telescope (XRT) on board Hinode. Our model assumes that the plasma is
initially in ionization equilibrium at low temperature, and it is heated
rapidly by a shock or magnetic reconnection. We tabulate the responses of the
AIA and XRT passbands as functions of temperature and a characteristic
timescale, $n_{e}t$. We find that most of the ions reach equilibrium at
$n_{e}t\leq$10$^{12}$ cm$^{-3}$s. Comparing ratios of the responses between
different passbands allows us to determine whether a combination of plasmas at
temperatures in ionization equilibrium can account for a given AIA and XRT
observation. It also expresses how far the observed plasma is from equilibrium
ionization. We apply the ratios to a supra-arcade plasma sheet on 2012 January
27. We find that the closer the plasma is to the arcade, the closer it is to a
single-temperature plasma in ionization equilibrium. We also utilize the set of
responses to estimate the temperature and density for shocked plasma associated
with a coronal mass ejection on 2010 June 13. The temperature and density
ranges we obtain are in reasonable agreement with previous works.",1905.11632v1,astro-ph.SR,2019-05-28 06:40:13+00:00,"[arxiv.Result.Author('Jin-Yi Lee'), arxiv.Result.Author('John C. Raymond'), arxiv.Result.Author('Katharine K. Reeves'), arxiv.Result.Author('Chengcai Shen'), arxiv.Result.Author('Yong-Jae Moon'), arxiv.Result.Author('Yeon-Han Kim')]",
705,Arranging the order of passengers on the boarding bridge to reduce the boarding time for single-aisle aircraft,"Reducing the aircraft boarding time is a common problem not only for
airlines, but also for passengers and airports. Group boarding is a popular
boarding strategy that separates the passengers into several groups and those
groups, which are then called in a certain order. Group boarding can reduce the
boarding time compared with that in random order boarding; however, it is
insufficient in several real scenarios because the passengers are not separated
strictly into groups. In this paper, we propose a boarding strategy that
arranges the order of the boarding passengers at the boarding gate. Although
this approach appears more time-consuming, we show that such a rearrangement
can be applied efficiently to the waiting queue of a single-aisle aircraft. We
quantitatively demonstrate the boarding times for various patterns of this
approach and discuss the mechanism underlying the reduction of boarding time.
This strategy is a promising approach to reduce boarding times and can replace
the conventional boarding strategy.",2109.13431v1,physics.soc-ph,2021-09-28 02:01:00+00:00,"[arxiv.Result.Author('Sakurako Tanida'), arxiv.Result.Author('Katsuhiro Nishinari')]",
706,Tuning Parameter-Free Nonparametric Density Estimation from Tabulated Summary Data,"Administrative data are often easier to access as tabulated summaries than in
the original format due to confidentiality concerns. Motivated by this
practical feature, we propose a novel nonparametric density estimation method
from tabulated summary data based on maximum entropy and prove its strong
uniform consistency. Unlike existing kernel-based estimators, our estimator is
free from tuning parameters and admits a closed-form density that is convenient
for post-estimation analysis. We apply the proposed method to the tabulated
summary data of the U.S. tax returns to estimate the income distribution.",2204.05480v2,econ.EM,2022-04-12 02:11:41+00:00,"[arxiv.Result.Author('Ji Hyung Lee'), arxiv.Result.Author('Yuya Sasaki'), arxiv.Result.Author('Alexis Akira Toda'), arxiv.Result.Author('Yulong Wang')]",
707,Voting with Limited Information and Many Alternatives,"The traditional axiomatic approach to voting is motivated by the problem of
reconciling differences in subjective preferences. In contrast, a dominant line
of work in the theory of voting over the past 15 years has considered a
different kind of scenario, also fundamental to voting, in which there is a
genuinely ""best"" outcome that voters would agree on if they only had enough
information. This type of scenario has its roots in the classical Condorcet
Jury Theorem; it includes cases such as jurors in a criminal trial who all want
to reach the correct verdict but disagree in their inferences from the
available evidence, or a corporate board of directors who all want to improve
the company's revenue, but who have different information that favors different
options.
  This style of voting leads to a natural set of questions: each voter has a
{\em private signal} that provides probabilistic information about which option
is best, and a central question is whether a simple plurality voting system,
which tabulates votes for different options, can cause the group decision to
arrive at the correct option. We show that plurality voting is powerful enough
to achieve this: there is a way for voters to map their signals into votes for
options in such a way that --- with sufficiently many voters --- the correct
option receives the greatest number of votes with high probability. We show
further, however, that any process for achieving this is inherently expensive
in the number of voters it requires: succeeding in identifying the correct
option with probability at least $1 - \eta$ requires $\Omega(n^3 \epsilon^{-2}
\log \eta^{-1})$ voters, where $n$ is the number of options and $\epsilon$ is a
distributional measure of the minimum difference between the options.",1110.1785v1,cs.DM,2011-10-09 03:22:04+00:00,"[arxiv.Result.Author('Flavio Chierichetti'), arxiv.Result.Author('Jon Kleinberg')]",
708,Newly Improved Ionization Corrections for the Neutral Interstellar Medium: Enabling Accurate Abundance Determinations in Star-forming Galaxies throughout the Universe,"Studies measuring the chemical abundances of the neutral gas in star-forming
galaxies (SFGs) require ionization correction factors (ICFs) to accurately
measure their metal contents. In the work presented here we calculate newly
improved ICFs for a sample of SFGs. These new corrections include both the
contaminating ionized gas along the line of sight (ICF$_{\rm ionized}$) and
unaccounted higher ionization stages in the neutral gas (ICF$_{\rm neutral}$).
We make use of recently acquired spectroscopic observations taken with the
Cosmic Origins Spectrograph (COS) on board Hubble to measure column densities
for Fe II and Fe III. Using the Fe III/Fe II ratios as well as other physical
properties (i.e. $\log$[L$_{\rm UV}$], $N$(H I), T, and $Z$) we generate ad-hoc
photoionization models with CLOUDY to quantify the corrections required for
each of the targets. We identify a luminosity threshold of $\log$[L$_{\rm
UV}$]$\sim$ 40.75 erg s$^{-1}$ above which the ICF$_{\rm neutral}$ values for
nitrogen are relatively higher (ICF$_{\rm neutral}=0.05$-0.7) than those for
the rest of the elements (ICF$_{\rm neutral}\sim 0.01$). This behavior
indicates that for the high UV luminosity objects, N II is found in
non-negligible quantities in the neutral gas, making these ICF$_{\rm neutral}$
corrections critical for determining the true abundances in the interstellar
medium. In addition, we calculate ICFs from a uniform grid of models covering a
wide range of physical properties typically observed in studies of SFGs and
extragalactic H II regions. We provide the community with tabulated ICF values
for the neutral gas abundances measured from a variety of environments and
applicable to chemical studies of the high redshift universe.",2002.07831v1,astro-ph.GA,2020-02-18 19:05:59+00:00,"[arxiv.Result.Author('Svea Hernandez'), arxiv.Result.Author('Alessandra Aloisi'), arxiv.Result.Author('Bethan L. James'), arxiv.Result.Author('Gary J. Ferland'), arxiv.Result.Author('Andrew J. Fox'), arxiv.Result.Author('Monica Tosi'), arxiv.Result.Author('Jason Tumlinson')]",
709,Fast and Powerful Hashing using Tabulation,"Randomized algorithms are often enjoyed for their simplicity, but the hash
functions employed to yield the desired probabilistic guarantees are often too
complicated to be practical. Here we survey recent results on how simple
hashing schemes based on tabulation provide unexpectedly strong guarantees.
  Simple tabulation hashing dates back to Zobrist [1970]. Keys are viewed as
consisting of $c$ characters and we have precomputed character tables
$h_1,...,h_c$ mapping characters to random hash values. A key $x=(x_1,...,x_c)$
is hashed to $h_1[x_1] \oplus h_2[x_2].....\oplus h_c[x_c]$. This schemes is
very fast with character tables in cache. While simple tabulation is not even
4-independent, it does provide many of the guarantees that are normally
obtained via higher independence, e.g., linear probing and Cuckoo hashing.
  Next we consider twisted tabulation where one input character is ""twisted"" in
a simple way. The resulting hash function has powerful distributional
properties: Chernoff-Hoeffding type tail bounds and a very small bias for
min-wise hashing. This also yields an extremely fast pseudo-random number
generator that is provably good for many classic randomized algorithms and
data-structures.
  Finally, we consider double tabulation where we compose two simple tabulation
functions, applying one to the output of the other, and show that this yields
very high independence in the classic framework of Carter and Wegman [1977]. In
fact, w.h.p., for a given set of size proportional to that of the space
consumed, double tabulation gives fully-random hashing. We also mention some
more elaborate tabulation schemes getting near-optimal independence for given
time and space.
  While these tabulation schemes are all easy to implement and use, their
analysis is not.",1505.01523v5,cs.DS,2015-05-06 21:47:25+00:00,[arxiv.Result.Author('Mikkel Thorup')],
710,"Train on Small, Play the Large: Scaling Up Board Games with AlphaZero and GNN","Playing board games is considered a major challenge for both humans and AI
researchers. Because some complicated board games are quite hard to learn,
humans usually begin with playing on smaller boards and incrementally advance
to master larger board strategies. Most neural network frameworks that are
currently tasked with playing board games neither perform such incremental
learning nor possess capabilities to automatically scale up. In this work, we
look at the board as a graph and combine a graph neural network architecture
inside the AlphaZero framework, along with some other innovative improvements.
Our ScalableAlphaZero is capable of learning to play incrementally on small
boards, and advancing to play on large ones. Our model can be trained quickly
to play different challenging board games on multiple board sizes, without
using any domain knowledge. We demonstrate the effectiveness of
ScalableAlphaZero and show, for example, that by training it for only three
days on small Othello boards, it can defeat the AlphaZero model on a large
board, which was trained to play the large board for $30$ days.",2107.08387v1,cs.LG,2021-07-18 08:36:00+00:00,"[arxiv.Result.Author('Shai Ben-Assayag'), arxiv.Result.Author('Ran El-Yaniv')]",
711,The Central Logic Board and its auxiliary boards for the optical module of the KM3NeT detector,"The KM3NeT neutrino telescope will be composed of many optical modules, each
of them containing 31 (3"") photomultipliers, connected to a Central Logic
Board. The Central Logic Board integrates Time to Digital Converters that
measure Time Over Threshold of the photomulti- pliers signals while White
Rabbit is used for the optical modules time synchronization. Auxiliary boards
have also been designed and built in order to test and extend the performance
of the Cen- tral Logic Board. The Central Logic Board, as well as the auxiliary
boards, will be presented by focusing on the design consideration, prototyping
issues and tests.",1411.0421v2,astro-ph.IM,2014-11-03 10:48:25+00:00,"[arxiv.Result.Author('S. Biagi'), arxiv.Result.Author('A. Orzelli')]",
712,Fast hashing with Strong Concentration Bounds,"Previous work on tabulation hashing by Patrascu and Thorup from STOC'11 on
simple tabulation and from SODA'13 on twisted tabulation offered Chernoff-style
concentration bounds on hash based sums, e.g., the number of balls/keys hashing
to a given bin, but under some quite severe restrictions on the expected values
of these sums. The basic idea in tabulation hashing is to view a key as
consisting of $c=O(1)$ characters, e.g., a 64-bit key as $c=8$ characters of
8-bits. The character domain $\Sigma$ should be small enough that character
tables of size $|\Sigma|$ fit in fast cache. The schemes then use $O(1)$ tables
of this size, so the space of tabulation hashing is $O(|\Sigma|)$. However, the
concentration bounds by Patrascu and Thorup only apply if the expected sums are
$\ll |\Sigma|$.
  To see the problem, consider the very simple case where we use tabulation
hashing to throw $n$ balls into $m$ bins and want to analyse the number of
balls in a given bin. With their concentration bounds, we are fine if $n=m$,
for then the expected value is $1$. However, if $m=2$, as when tossing $n$
unbiased coins, the expected value $n/2$ is $\gg |\Sigma|$ for large data sets,
e.g., data sets that do not fit in fast cache.
  To handle expectations that go beyond the limits of our small space, we need
a much more advanced analysis of simple tabulation, plus a new tabulation
technique that we call \emph{tabulation-permutation} hashing which is at most
twice as slow as simple tabulation. No other hashing scheme of comparable speed
offers similar Chernoff-style concentration bounds.",1905.00369v5,cs.DS,2019-05-01 16:33:11+00:00,"[arxiv.Result.Author('Anders Aamand'), arxiv.Result.Author('Jakob B. T. Knudsen'), arxiv.Result.Author('Mathias B. T. Knudsen'), arxiv.Result.Author('Peter M. R. Rasmussen'), arxiv.Result.Author('Mikkel Thorup')]",
713,Understanding the Moments of Tabulation Hashing via Chaoses,"Simple tabulation hashing dates back to Zobrist in 1970 and is defined as
follows: Each key is viewed as $c$ characters from some alphabet $\Sigma$, we
have $c$ fully random hash functions $h_0, \ldots, h_{c - 1} \colon \Sigma \to
\{0, \ldots, 2^l - 1\}$, and a key $x = (x_0, \ldots, x_{c - 1})$ is hashed to
$h(x) = h_0(x_0) \oplus \ldots \oplus h_{c - 1}(x_{c - 1})$ where $\oplus$ is
the bitwise XOR operation. The previous results on tabulation hashing by P{\v
a}tra{\c s}cu and Thorup~[J.ACM'11] and by Aamand et al.~[STOC'20] focused on
proving Chernoff-style tail bounds on hash-based sums, e.g., the number keys
hashing to a given value, for simple tabulation hashing, but their bounds do
not cover the entire tail.
  Chaoses are random variables of the form $\sum a_{i_0, \ldots, i_{c - 1}}
X_{i_0} \cdot \ldots \cdot X_{i_{c - 1}}$ where $X_i$ are independent random
variables. Chaoses are a well-studied concept from probability theory, and
tight analysis has been proven in several instances, e.g., when the independent
random variables are standard Gaussian variables and when the independent
random variables have logarithmically convex tails. We notice that hash-based
sums of simple tabulation hashing can be seen as a sum of chaoses that are not
independent. This motivates us to use techniques from the theory of chaoses to
analyze hash-based sums of simple tabulation hashing.
  In this paper, we obtain bounds for all the moments of hash-based sums for
simple tabulation hashing which are tight up to constants depending only on
$c$. In contrast with the previous attempts, our approach will mostly be
analytical and does not employ intricate combinatorial arguments. The improved
analysis of simple tabulation hashing allows us to obtain bounds for the
moments of hash-based sums for the mixed tabulation hashing introduced by
Dahlgaard et al.~[FOCS'15].",2205.01453v1,cs.DS,2022-05-03 12:32:06+00:00,"[arxiv.Result.Author('Jakob Bæk Tejs Houen'), arxiv.Result.Author('Mikkel Thorup')]",
714,Studies in Tours of Knight on Rectangular Boards,"The author has constructed and enumerated tours of knight having various
magic properties on 4 x n and 6 x n boards. 16 magic tours of knight have been
discovered on 4 x 18 board, 88 on 4 x 20 board, 464 on 4 x 22 board, 2076 on 4
x 24 board, 9904 on 4 x 26 board and 47456 on 4 x 28 board. Magic tours exist
on all boards of size 4 x 2k for k > 8. Quasi-magic tour exists on 6 x 11
board. 8 magic tours of knight have been discovered on 6 x 12 board and magic
tours exist on all boards of size 6 x 4k for k > 2.",1802.09340v2,math.GM,2018-02-19 14:58:27+00:00,[arxiv.Result.Author('Awani Kumar')],
715,"Board games, random boards and long boards","For any odd integer $n\geq3$ a board (of size $n$) is a square array of
$n\times n$ positions with a simple rule of how to move between positions. The
goal of the game we introduce is to find a path from the upper left corner of a
board to the center of the square. If there exists such a path we say that the
board is solvable, and we say that the length of this board is the length of a
shortest such path. There are $8^{n^2}$ different boards. We discuss various
properties of these boards and present some questions and conjectures. In
particular, we show that for $n\gg1$ roughly $\frac{1}{3}$ of the boards are
solvable, and that the expected length of a random solvable board tends to
$\frac{209}{96}$, i.e., very big solvable boards tend to have extremely short
solutions.",2110.05416v1,math.CO,2021-10-11 17:01:00+00:00,[arxiv.Result.Author('Ary Shaviv')],
716,Approximately Minwise Independence with Twisted Tabulation,"A random hash function $h$ is $\varepsilon$-minwise if for any set $S$,
$|S|=n$, and element $x\in S$, $\Pr[h(x)=\min h(S)]=(1\pm\varepsilon)/n$.
Minwise hash functions with low bias $\varepsilon$ have widespread applications
within similarity estimation.
  Hashing from a universe $[u]$, the twisted tabulation hashing of
P\v{a}tra\c{s}cu and Thorup [SODA'13] makes $c=O(1)$ lookups in tables of size
$u^{1/c}$. Twisted tabulation was invented to get good concentration for
hashing based sampling. Here we show that twisted tabulation yields $\tilde
O(1/u^{1/c})$-minwise hashing.
  In the classic independence paradigm of Wegman and Carter [FOCS'79] $\tilde
O(1/u^{1/c})$-minwise hashing requires $\Omega(\log u)$-independence [Indyk
SODA'99]. P\v{a}tra\c{s}cu and Thorup [STOC'11] had shown that simple
tabulation, using same space and lookups yields $\tilde O(1/n^{1/c})$-minwise
independence, which is good for large sets, but useless for small sets. Our
analysis uses some of the same methods, but is much cleaner bypassing a
complicated induction argument.",1404.6724v2,cs.DS,2014-04-27 07:59:38+00:00,"[arxiv.Result.Author('Søren Dahlgaard'), arxiv.Result.Author('Mikkel Thorup')]",
717,A tabulation of the bound-state energies of atomic hydrogen,"We present tables for the bound-state energies for atomic hydrogen. The
tabulated energies include the hyperfine structure, and thus this work extends
the work of Rev. Mod. Phys. {\bf 84}, 1527 (2012), which excludes hyperfine
structure. The tabulation includes corrections of the hyperfine structure due
to the anomalous moment of the electron, due to the finite mass of the proton,
and due to off-diagonal matrix elements of the hyperfine Hamiltonian. These
corrections are treated incorrectly in most other works. Simple formulas valid
for all quantum numbers are presented for the hyperfine corrections. The
tabulated energies have uncertainties of less than 1 kHz for all states. This
accuracy is possible because of the recent precision measurement [Nature, {\bf
466}, 213 (2010); Science, {\bf 339}, 417] of the proton radius. The effect of
this new radius on the energy levels is also tabulated, and the energies are
compared to precision measurements of atomic hydrogen energy intervals.",1601.01057v1,physics.atom-ph,2016-01-06 02:40:01+00:00,"[arxiv.Result.Author('M. Horbatsch'), arxiv.Result.Author('E. A. Hessels')]","Phys. Rev. A 93, 022513 (2016)"
718,Notes on solving and playing peg solitaire on a computer,"We consider the one-person game of peg solitaire played on a computer. Two
popular board shapes are the 33-hole cross-shaped board, and the 15-hole
triangle board---we use them as examples throughout. The basic game begins from
a full board with one peg missing and the goal is to finish at a board position
with one peg. First, we discuss ways to solve the basic game on a computer.
Then we consider the problem of quickly distinguishing board positions where
the goal can still be reached (""winning"" board positions) from those where it
cannot. This enables a computer to alert the player if a jump under
consideration leads to a dead end. On the 15-hole triangle board, it is
possible to identify all winning board positions (from any single vacancy
start) by storing a key set of 437 board positions. For the ""central game"" on
the 33-hole cross-shaped board, we can identify all winning board positions by
storing 839,536 board positions. By viewing a successful game as a traversal of
a directed graph of winning board positions, we apply a simple algorithm to
count the number of ways to traverse this graph, and calculate that the total
number of solutions to the central game is 40,861,647,040,079,968. Our analysis
can also determine how quickly we can reach a ""dead board position"", where a
one peg finish is no longer possible.",0903.3696v4,math.CO,2009-03-23 18:55:32+00:00,[arxiv.Result.Author('George I. Bell')],
719,Zernike Basis to Cartesian Transformations,"The radial polynomials of the 2D (circular) and 3D (spherical) Zernike
functions are tabulated as powers of the radial distance. The reciprocal
tabulation of powers of the radial distance in series of radial polynomials is
also given, based on projections that take advantage of the orthogonality of
the polynomials over the unit interval. They may play a role in the expansion
of products of the polynomials into sums, which is demonstrated by some
examples. Multiplication of the polynomials by the angular bases (azimuth,
polar angle) defines the Zernike functions, for which we derive and tabulate
transformations to and from the Cartesian coordinate system centered at the
middle of the circle or sphere.",0809.2368v1,math-ph,2008-09-13 20:51:47+00:00,[arxiv.Result.Author('Richard J. Mathar')],Serb. Astr. J. 179 (2009) 107-120.
720,Fast tabulation of challenge pseudoprimes,"We provide a new algorithm for tabulating composite numbers which are
pseudoprimes to both a Fermat test and a Lucas test. Our algorithm is optimized
for parameter choices that minimize the occurrence of pseudoprimes, and for
pseudoprimes with a fixed number of prime factors. Using this, we have
confirmed that there are no PSW challenge pseudoprimes with two or three prime
factors up to $2^{80}$. In the case where one is tabulating challenge
pseudoprimes with a fixed number of prime factors, we prove our algorithm gives
an unconditional asymptotic improvement over previous methods.",1806.08697v1,math.NT,2018-06-22 14:33:39+00:00,"[arxiv.Result.Author('Andrew Shallue'), arxiv.Result.Author('Jonathan Webster')]",Open Book Series 2 (2019) 411-423
721,Tactical Voting in Plurality Elections,"How often will elections end in landslides? What is the probability for a
head-to-head race? Analyzing ballot results from several large countries rather
anomalous and yet unexplained distributions have been observed. We identify
tactical voting as the driving ingredient for the anomalies and introduce a
model to study its effect on plurality elections, characterized by the relative
strength of the feedback from polls and the pairwise interaction between
individuals in the society. With this model it becomes possible to explain the
polarization of votes between two candidates, understand the small margin of
victories frequently observed for different elections, and analyze the polls'
impact in American, Canadian, and Brazilian ballots. Moreover, the model
reproduces, quantitatively, the distribution of votes obtained in the Brazilian
mayor elections with two, three, and four candidates.",1009.3099v1,physics.soc-ph,2010-09-16 06:20:27+00:00,"[arxiv.Result.Author('Nuno A. M. Araújo'), arxiv.Result.Author('José S. Andrade Jr'), arxiv.Result.Author('Hans J. Herrmann')]","PLoS One 5, e12446, 2010"
722,Latent Space Modeling of Multidimensional Networks with Application to the Exchange of Votes in Eurovision Song Contest,"The Eurovision Song Contest is a popular TV singing competition held annually
among country members of the European Broadcasting Union. In this competition,
each member can be both contestant and jury, as it can participate with a song
and/or vote for other countries' tunes. Throughout the years, the voting system
has repeatedly been accused of being biased by the presence of tactical voting,
according to which votes would represent strategic interests rather than actual
musical preferences of the voting countries. In this work, we develop a latent
space model to investigate the presence of a latent structure underlying the
exchange of votes. Focusing on the period from 1998 to 2015, we represent the
vote exchange as a multivariate network: each edition is a network, where
countries are the nodes and two countries are linked by an edge if one voted
for the other. The different networks are taken to be independent replicates of
a common latent space capturing the overall relationships among the countries.
Proximity denotes similarity, and countries close in the latent space are
assumed to be more likely to exchange votes. Therefore, if the exchange of
votes depends on the similarity between countries, the quality of the competing
songs might not be a relevant factor in the determination of the voting
preferences, and this would suggest the presence of bias. A Bayesian
hierarchical modelling approach is employed to model the probability of a
connection between any two countries as a function of their distance in the
latent space, and of network-specific parameters and edge-specific covariates.
The inferred latent space is found to be relevant in the determination of edge
probabilities, however, the positions of the countries in such space only
partially correspond to their actual geographical positions.",1803.07166v1,stat.AP,2018-03-13 17:43:38+00:00,"[arxiv.Result.Author(""Silvia D'Angelo""), arxiv.Result.Author('Thomas Brendan Murphy'), arxiv.Result.Author('Marco Alfò')]",Ann. Appl. Stat. 13(2): 900-930 (June 2019)
723,Evidence of bias in the Eurovision song contest: modelling the votes using Bayesian hierarchical models,"The Eurovision Song Contest is an annual musical competition held among
active members of the European Broadcasting Union since 1956. The event is
televised live across Europe. Each participating country presents a song and
receive a vote based on a combination of tele-voting and jury. Over the years,
this has led to speculations of tactical voting, discriminating against some
participants and thus inducing bias in the final results. In this paper we
investigate the presence of positive or negative bias (which may roughly
indicate favouritisms or discrimination) in the votes based on geographical
proximity, migration and cultural characteristics of the participating
countries through a Bayesian hierarchical model. Our analysis found no evidence
of negative bias, although mild positive bias does seem to emerge
systematically, linking voters to performers.",1308.6312v1,stat.AP,2013-08-28 21:12:15+00:00,"[arxiv.Result.Author('Marta Blangiardo'), arxiv.Result.Author('Gianluca Baio')]",
724,Comparing Voting Districts with Uncertain Data Envelopment Analysis,"Gerrymandering voting districts is one of the most salient concerns of
contemporary American society, and the creation of new voting maps, along with
their subsequent legal challenges, speaks for much of our modern political
discourse. The legal, societal, and political debate over serviceable voting
districts demands a concept of fairness, which is a loosely characterized, but
amorphous, concept that has evaded precise definition. We advance a new
paradigm to compare voting maps that avoids the pitfalls associated with an a
priori metric being used to uniformly assess maps. Our evaluative method
instead shows how to use uncertain data envelopment analysis to assess maps on
a variety of metrics, a tactic that permits each district to be assessed
separately and optimally. We test our methodology on a collection of proposed
and publicly available maps to illustrate our assessment strategy.",2212.07779v1,physics.soc-ph,2022-09-02 20:12:27+00:00,"[arxiv.Result.Author('Casey Garner'), arxiv.Result.Author('Allen Holder')]",
725,Quantum voting and violation of Arrow's Impossibility Theorem,"We propose a quantum voting system, in the spirit of quantum games such as
the quantum Prisoner's Dilemma. Our scheme enables a constitution to violate a
quantum analog of Arrow's Impossibility Theorem. Arrow's Theorem is a claim
proved deductively in economics: Every (classical) constitution endowed with
three innocuous-seeming properties is a dictatorship. We construct quantum
analogs of constitutions, of the properties, and of Arrow's Theorem. A quantum
version of majority rule, we show, violates this Quantum Arrow Conjecture. Our
voting system allows for tactical-voting strategies reliant on entanglement,
interference, and superpositions. This contribution to quantum game theory
helps elucidate how quantum phenomena can be harnessed for strategic advantage.",1501.00458v3,quant-ph,2015-01-02 19:08:22+00:00,"[arxiv.Result.Author('Ning Bao'), arxiv.Result.Author('Nicole Yunger Halpern')]","Phys. Rev. A 95, 062306 (2017)"
726,What They Don't Want: An Analysis of Brexit's First Round of Indicative Votes,"Since the result of the 2016 referendum, Brexit has been an unpredictable
democratic adventure, the finale of which remains unclear. This year, in the
final days of March, parliamentarians seized control of the order paper from
the Government and held their own indicative votes in an attempt to break the
deadlock. In this paper we analyse the results of this unusual cardinal ballot.
We express the various motions in terms of `how much Brexit' they deliver, and
employ Monte Carlo in an attempt to determine this from the data. We find
solutions which reproduce our intuitive understanding of the debate. Finally,
we construct hypothetical ordinal ballots for the various Brexit scenarios,
using three different processes. The results suggest that the Government would
be more successful taking a softer position, and we quantify this.
Additionally, there is some discussion of how tactical voting might manifest
itself in the event of such an exercise.",1905.12109v2,physics.soc-ph,2019-05-28 21:52:21+00:00,[arxiv.Result.Author('Thomas Sayer')],
727,Quantum Metrology: Towards an alternative definition for the meter,"The motivation for this article came from an attempt to give an alternative
definition for the meter, the SI unit for measuring length. As a starting point
towards this goal, in this piece of work we present the underlying theory
behind our approach which uses ideas from quantum field theory and
noncommutative geometry, in particular the notion of an odd K-cycle which is
based on the Dirac operator (and its inverse, the Dirac propagator). Using (the
perhaps more familiar) physics terminology, the key point in our strategy is
this: instead of measuring length directly in space-time we measure the
""algebraic (spectral) length"" in the space of the corresponding quantum states
of some particle (fermion) acted upon by the Dirac propagator. This approach
shares the spirit of the unanimus vote of the 24th General Conference of
Standards and Measures (21st October 2011) in Serves, France for the
redefinition of the fundamental units using Planck's constant.",1203.0832v2,math-ph,2012-03-05 08:58:32+00:00,[arxiv.Result.Author('Ioannis P. Zois')],Journal of Physics: Conference Series 738 (2016) 012067
728,Addressing Tactic Volatility in Self-Adaptive Systems Using Evolved Recurrent Neural Networks and Uncertainty Reduction Tactics,"Self-adaptive systems frequently use tactics to perform adaptations. Tactic
examples include the implementation of additional security measures when an
intrusion is detected, or activating a cooling mechanism when temperature
thresholds are surpassed. Tactic volatility occurs in real-world systems and is
defined as variable behavior in the attributes of a tactic, such as its latency
or cost. A system's inability to effectively account for tactic volatility
adversely impacts its efficiency and resiliency against the dynamics of
real-world environments. To enable systems' efficiency against tactic
volatility, we propose a Tactic Volatility Aware (TVA-E) process utilizing
evolved Recurrent Neural Networks (eRNN) to provide accurate tactic
predictions. TVA-E is also the first known process to take advantage of
uncertainty reduction tactics to provide additional information to the
decision-making process and reduce uncertainty. TVA-E easily integrates into
popular adaptation processes enabling it to immediately benefit a large number
of existing self-adaptive systems. Simulations using 52,106 tactic records
demonstrate that: I) eRNN is an effective prediction mechanism, II) TVA-E
represents an improvement over existing state-of-the-art processes in
accounting for tactic volatility, and III) Uncertainty reduction tactics are
beneficial in accounting for tactic volatility. The developed dataset and tool
can be found at https://tacticvolatility.github.io/",2204.10308v1,cs.LG,2022-04-21 17:47:09+00:00,"[arxiv.Result.Author('Aizaz Ul Haq'), arxiv.Result.Author('Niranjana Deshpande'), arxiv.Result.Author('AbdElRahman ElSaid'), arxiv.Result.Author('Travis Desell'), arxiv.Result.Author('Daniel E. Krutz')]",
729,Improving the Decision-Making Process of Self-Adaptive Systems by Accounting for Tactic Volatility,"When self-adaptive systems encounter changes within their surrounding
environments, they enact tactics to perform necessary adaptations. For example,
a self-adaptive cloud-based system may have a tactic that initiates additional
computing resources when response time thresholds are surpassed, or there may
be a tactic to activate a specific security measure when an intrusion is
detected. In real-world environments, these tactics frequently experience
tactic volatility which is variable behavior during the execution of the
tactic.
  Unfortunately, current self-adaptive approaches do not account for tactic
volatility in their decision-making processes, and merely assume that tactics
do not experience volatility. This limitation creates uncertainty in the
decision-making process and may adversely impact the system's ability to
effectively and efficiently adapt. Additionally, many processes do not properly
account for volatility that may effect the system's Service Level Agreement
(SLA). This can limit the system's ability to act proactively, especially when
utilizing tactics that contain latency.
  To address the challenge of sufficiently accounting for tactic volatility, we
propose a Tactic Volatility Aware (TVA) solution. Using Multiple Regression
Analysis (MRA), TVA enables self-adaptive systems to accurately estimate the
cost and time required to execute tactics. TVA also utilizes Autoregressive
Integrated Moving Average (ARIMA) for time series forecasting, allowing the
system to proactively maintain specifications.",2004.11302v1,cs.AI,2020-04-23 16:34:28+00:00,"[arxiv.Result.Author('Jeffrey Palmerino'), arxiv.Result.Author('Qi Yu'), arxiv.Result.Author('Travis Desell'), arxiv.Result.Author('Daniel E. Krutz')]",
730,Tactical decompositions of designs over finite fields,"An automorphism group of an incidence structure I induces a tactical
decomposition on I. It is well known that tactical decompositions of t-designs
satisfy certain necessary conditions which can be expressed as equations in
terms of the coefficients of tactical decomposition matrices. In this article
we present results obtained for tactical decompositions of q-analogs of
t-designs, more precisely, of 2-(v,k,lambda_2;q) designs. We show that
coefficients of tactical decomposition matrices of a design over finite field
satisfy an equation system analog to the one known for block designs.
Furthermore, taking into consideration specific properties of designs over the
binary field, we obtain an additional system of inequations for these
coefficients in that case.",1311.5499v1,math.CO,2013-11-21 18:16:33+00:00,"[arxiv.Result.Author('Anamari Nakic'), arxiv.Result.Author('Mario Osvin Pavcevic')]",
731,Automatic Detection of Search Tactic in Individual Information Seeking: A Hidden Markov Model Approach,"Information seeking process is an important topic in information seeking
behavior research. Both qualitative and empirical methods have been adopted in
analyzing information seeking processes, with major focus on uncovering the
latent search tactics behind user behaviors. Most of the existing works require
defining search tactics in advance and coding data manually. Among the few
works that can recognize search tactics automatically, they missed making sense
of those tactics. In this paper, we proposed using an automatic technique, i.e.
the Hidden Markov Model (HMM), to explicitly model the search tactics. HMM
results show that the identified search tactics of individual information
seeking behaviors are consistent with Marchioninis Information seeking process
model. With the advantages of showing the connections between search tactics
and search actions and the transitions among search tactics, we argue that HMM
is a useful tool to investigate information seeking process, or at least it
provides a feasible way to analyze large scale dataset.",1304.1924v1,cs.IR,2013-04-06 19:13:41+00:00,"[arxiv.Result.Author('Shuguang Han'), arxiv.Result.Author('Zhen Yue'), arxiv.Result.Author('Daqing He')]",
732,Architectural Tactics for Big Data Cybersecurity Analytic Systems: A Review,"Context: Big Data Cybersecurity Analytics is aimed at protecting networks,
computers, and data from unauthorized access by analysing security event data
using big data tools and technologies. Whilst a plethora of Big Data
Cybersecurity Analytic Systems have been reported in the literature, there is a
lack of a systematic and comprehensive review of the literature from an
architectural perspective. Objective: This paper reports a systematic review
aimed at identifying the most frequently reported quality attributes and
architectural tactics for Big Data Cybersecurity Analytic Systems. Method: We
used Systematic Literature Review (SLR) method for reviewing 74 primary studies
selected using well-defined criteria. Results: Our findings are twofold: (i)
identification of 12 most frequently reported quality attributes and the
justification for their significance for Big Data Cybersecurity Analytic
Systems; and (ii) identification and codification of 17 architectural tactics
for addressing the quality attributes that are commonly associated with Big
Data Cybersecurity Analytic systems. The identified tactics include six
performance tactics, four accuracy tactics, two scalability tactics, three
reliability tactics, and one security and usability tactic each. Conclusion:
Our findings have revealed that (a) despite the significance of
interoperability, modifiability, adaptability, generality, stealthiness, and
privacy assurance, these quality attributes lack explicit architectural support
in the literature (b) empirical investigation is required to evaluate the
impact of codified architectural tactics (c) a good deal of research effort
should be invested to explore the trade-offs and dependencies among the
identified tactics and (d) there is a general lack of effective collaboration
between academia and industry for supporting the field of Big Data
Cybersecurity Analytic Systems.",1802.03178v1,cs.CR,2018-02-09 09:16:22+00:00,"[arxiv.Result.Author('Faheem Ullah'), arxiv.Result.Author('M. Ali Babar')]",
733,Generating Single Peaked Votes,"We discuss how to generate singled peaked votes uniformly from the Impartial
Culture model.",1503.02766v1,cs.GT,2015-03-10 04:15:23+00:00,[arxiv.Result.Author('Toby Walsh')],
734,Normalized Range Voting Broadly Resists Control,"We study the behavior of Range Voting and Normalized Range Voting with
respect to electoral control. Electoral control encompasses attempts from an
election chair to alter the structure of an election in order to change the
outcome. We show that a voting system resists a case of control by proving that
performing that case of control is computationally infeasible. Range Voting is
a natural extension of approval voting, and Normalized Range Voting is a simple
variant which alters each vote to maximize the potential impact of each voter.
We show that Normalized Range Voting has among the largest number of control
resistances among natural voting systems.",1005.5698v3,cs.GT,2010-05-31 15:34:11+00:00,[arxiv.Result.Author('Curtis Menton')],
735,Learning to Reason with HOL4 tactics,"Techniques combining machine learning with translation to automated reasoning
have recently become an important component of formal proof assistants. Such
""hammer"" tech- niques complement traditional proof assistant automation as
implemented by tactics and decision procedures. In this paper we present a
unified proof assistant automation approach which attempts to automate the
selection of appropriate tactics and tactic-sequences com- bined with an
optimized small-scale hammering approach. We implement the technique as a
tactic-level automation for HOL4: TacticToe. It implements a modified
A*-algorithm directly in HOL4 that explores different tactic-level proof paths,
guiding their selection by learning from a large number of previous
tactic-level proofs. Unlike the existing hammer methods, TacticToe avoids
translation to FOL, working directly on the HOL level. By combining tactic
prediction and premise selection, TacticToe is able to re-prove 39 percent of
7902 HOL4 theorems in 5 seconds whereas the best single HOL(y)Hammer strategy
solves 32 percent in the same amount of time.",1804.00595v1,cs.AI,2018-04-02 15:41:09+00:00,"[arxiv.Result.Author('Thibault Gauthier'), arxiv.Result.Author('Cezary Kaliszyk'), arxiv.Result.Author('Josef Urban')]",
736,Strategic Voting Under Uncertainty About the Voting Method,"Much of the theoretical work on strategic voting makes strong assumptions
about what voters know about the voting situation. A strategizing voter is
typically assumed to know how other voters will vote and to know the rules of
the voting method. A growing body of literature explores strategic voting when
there is uncertainty about how others will vote. In this paper, we study
strategic voting when there is uncertainty about the voting method. We
introduce three notions of manipulability for a set of voting methods: sure,
safe, and expected manipulability. With the help of a computer program, we
identify voting scenarios in which uncertainty about the voting method may
reduce or even eliminate a voter's incentive to misrepresent her preferences.
Thus, it may be in the interest of an election designer who wishes to reduce
strategic voting to leave voters uncertain about which of several reasonable
voting methods will be used to determine the winners of an election.",1907.09110v1,cs.MA,2019-07-22 03:17:19+00:00,"[arxiv.Result.Author('Wesley H. Holliday'), arxiv.Result.Author('Eric Pacuit')]","EPTCS 297, 2019, pp. 252-272"
737,Vote Delegation and Misbehavior,"We study vote delegation with ""well-behaving"" and ""misbehaving"" agents and
compare it with conventional voting. Typical examples for vote delegation are
validation or governance tasks on blockchains. There is a majority of
well-behaving agents, but they may abstain or delegate their vote to other
agents since voting is costly. Misbehaving agents always vote. We compare
conventional voting allowing for abstention with vote delegation. Preferences
of voters are private information and a positive outcome is achieved if
well-behaving agents win. We illustrate that vote delegation leads to quite
different outcomes than conventional voting with abstention. In particular, we
obtain three insights: First, if the number of misbehaving voters, denoted by f
, is high, both voting methods fail to deliver a positive outcome. Second, if f
takes an intermediate value, conventional voting delivers a positive outcome,
while vote delegation fails with probability one. Third, if f is low,
delegation delivers a positive outcome with higher probability than
conventional voting. Finally, our results characterize worst-case outcomes that
can happen in a liquid democracy.",2102.08823v2,cs.GT,2021-02-17 15:32:32+00:00,"[arxiv.Result.Author('Hans Gersbach'), arxiv.Result.Author('Akaki Mamageishvili'), arxiv.Result.Author('Manvir Schneider')]",
738,Lassie: HOL4 Tactics by Example,"Proof engineering efforts using interactive theorem proving have yielded
several impressive projects in software systems and mathematics. A key obstacle
to such efforts is the requirement that the domain expert is also an expert in
the low-level details in constructing the proof in a theorem prover. In
particular, the user needs to select a sequence of tactics that lead to a
successful proof, a task that in general requires knowledge of the exact names
and use of a large set of tactics.
  We present Lassie, a tactic framework for the HOL4 theorem prover that allows
individual users to define their own tactic language by example and give
frequently used tactics or tactic combinations easier-to-remember names. The
core of Lassie is an extensible semantic parser, which allows the user to
interactively extend the tactic language through a process of definitional
generalization. Defining tactics in Lassie thus does not require any knowledge
in implementing custom tactics, while proofs written in Lassie retain the
correctness guarantees provided by the HOL4 system. We show through case
studies how Lassie can be used in small and larger proofs by novice and more
experienced interactive theorem prover users, and how we envision it to ease
the learning curve in a HOL4 tutorial.",2101.00930v1,cs.PL,2021-01-04 12:50:36+00:00,"[arxiv.Result.Author('Heiko Becker'), arxiv.Result.Author('Nathaniel Bos'), arxiv.Result.Author('Ivan Gavran'), arxiv.Result.Author('Eva Darulova'), arxiv.Result.Author('Rupak Majumdar')]",
739,Voting Power of Teams Working Together,"Voting power determines the ""power"" of individuals who cast votes; their
power is based on their ability to influence the winning-ness of a coalition.
Usually each individual acts alone, casting either all or none of their votes
and is equally likely to do either. This paper extends this standard ""random
voting"" model to allow probabilistic voting, partial voting, and correlated
team voting. We extend the standard Banzhaf metric to account for these cases;
our generalization reduces to the standard metric under ""random voting"", This
new paradigm allows us to answer questions such as ""In the 2013 US Senate, how
much more unified would the Republicans have to be in order to have the same
power as the Democrats in attaining cloture?""",1312.3394v1,cs.GT,2013-12-12 03:19:17+00:00,[arxiv.Result.Author('Daniel Zwillinger')],
740,The Computational Impact of Partial Votes on Strategic Voting,"In many real world elections, agents are not required to rank all candidates.
We study three of the most common methods used to modify voting rules to deal
with such partial votes. These methods modify scoring rules (like the Borda
count), elimination style rules (like single transferable vote) and rules based
on the tournament graph (like Copeland) respectively. We argue that with an
elimination style voting rule like single transferable vote, partial voting
does not change the situations where strategic voting is possible. However,
with scoring rules and rules based on the tournament graph, partial voting can
increase the situations where strategic voting is possible. As a consequence,
the computational complexity of computing a strategic vote can change. For
example, with Borda count, the complexity of computing a strategic vote can
decrease or stay the same depending on how we score partial votes.",1405.7714v1,cs.GT,2014-05-28 12:13:52+00:00,"[arxiv.Result.Author('Nina Narodytska'), arxiv.Result.Author('Toby Walsh')]",
741,SBvote: Scalable Self-Tallying Blockchain-Based Voting,"Decentralized electronic voting solutions represent a promising advancement
in electronic voting. One of the e-voting paradigms, the self-tallying scheme,
offers strong protection of the voters' privacy while making the whole voting
process verifiable. Decentralized smart contract platforms became interesting
practical instantiation of the immutable bulletin board that this scheme
requires to preserve its properties. Existing smart contract-based approaches
employing the self-tallying scheme (such as OVN or BBB-Voting) are only
suitable for a boardroom voting scenario due to their scalability limitation.
The goal of our work is to build on existing solutions to achieve scalability
without losing privacy guarantees and verifiability. We present SBvote, a
blockchain-based self-tallying voting protocol that is scalable in the number
of voters and therefore suitable for large-scale elections. The evaluation of
our proof-of-concept implementation shows that the protocol's scalability is
limited only by the underlying blockchain platform. We evaluated the
scalability of SBvote on two public smart contract platforms -- Gnosis and
Harmony. Despite the limitations imposed by the throughput of the blockchain
platform, SBvote can accommodate elections with millions of voters.",2206.06019v1,cs.CR,2022-06-13 10:18:00+00:00,"[arxiv.Result.Author('Ivana Stančíková'), arxiv.Result.Author('Ivan Homoliak')]",
742,A Peered Bulletin Board for Robust Use in Verifiable Voting Systems,"The Web Bulletin Board (WBB) is a key component of verifiable election
systems. It is used in the context of election verification to publish evidence
of voting and tallying that voters and officials can check, and where
challenges can be launched in the event of malfeasance. In practice, the
election authority has responsibility for implementing the web bulletin board
correctly and reliably, and will wish to ensure that it behaves correctly even
in the presence of failures and attacks. To ensure robustness, an
implementation will typically use a number of peers to be able to provide a
correct service even when some peers go down or behave dishonestly. In this
paper we propose a new protocol to implement such a Web Bulletin Board,
motivated by the needs of the vVote verifiable voting system. Using a
distributed algorithm increases the complexity of the protocol and requires
careful reasoning in order to establish correctness. Here we use the Event-B
modelling and refinement approach to establish correctness of the peered design
against an idealised specification of the bulletin board behaviour. In
particular we show that for n peers, a threshold of t > 2n/3 peers behaving
correctly is sufficient to ensure correct behaviour of the bulletin board
distributed design. The algorithm also behaves correctly even if honest or
dishonest peers temporarily drop out of the protocol and then return. The
verification approach also establishes that the protocols used within the
bulletin board do not interfere with each other. This is the first time a
peered web bulletin board suite of protocols has been formally verified.",1401.4151v1,cs.CR,2014-01-16 20:11:42+00:00,"[arxiv.Result.Author('Chris Culnane'), arxiv.Result.Author('Steve Schneider')]",
743,"Electryo, In-person Voting with Transparent Voter Verifiability and Eligibility Verifiability","Selene is an e-voting protocol that allows voters to directly check their
individual vote, in cleartext, in the final tally via a tracker system, while
providing good coercion mitigation. This is in contrast to conventional,
end-to-end verifiable schemes in which the voter verifies the presence of an
encryption of her vote on the bulletin board. The Selene mechanism can be
applied to many e-voting schemes, but here we present an application to the
polling station context, resulting in a voter-verifiable electronic tally with
a paper audit trail. The system uses a smartcard-based public key system to
provide the individual verification and universal eligibility verifiability.
The paper record contains an encrypted link to the voter's identity, requiring
stronger assumptions on ballot privacy than normal paper voting, but with the
benefit of providing good auditability and dispute resolution as well as
supporting (comparison) risk limiting audits.",2105.14783v1,cs.CR,2021-05-31 08:22:29+00:00,"[arxiv.Result.Author('Peter B. Roenne'), arxiv.Result.Author('Peter Y. A Ryan'), arxiv.Result.Author('Marie-Laure Zollinger')]",
744,Heuristics in Multi-Winner Approval Voting,"In many real world situations, collective decisions are made using voting.
Moreover, scenarios such as committee or board elections require voting rules
that return multiple winners. In multi-winner approval voting (AV), an agent
may vote for as many candidates as they wish. Winners are chosen by tallying up
the votes and choosing the top-$k$ candidates receiving the most votes. An
agent may manipulate the vote to achieve a better outcome by voting in a way
that does not reflect their true preferences. In complex and uncertain
situations, agents may use heuristics to strategize, instead of incurring the
additional effort required to compute the manipulation which most favors them.
In this paper, we examine voting behavior in multi-winner approval voting
scenarios with complete information. We show that people generally manipulate
their vote to obtain a better outcome, but often do not identify the optimal
manipulation. Instead, voters tend to prioritize the candidates with the
highest utilities. Using simulations, we demonstrate the effectiveness of these
heuristics in situations where agents only have access to partial information.",1905.12104v2,cs.GT,2019-05-28 21:44:07+00:00,"[arxiv.Result.Author('Jaelle Scheuerman'), arxiv.Result.Author('Jason L. Harman'), arxiv.Result.Author('Nicholas Mattei'), arxiv.Result.Author('K. Brent Venable')]",
745,Conservative statistical post-election audits,"There are many sources of error in counting votes: the apparent winner might
not be the rightful winner. Hand tallies of the votes in a random sample of
precincts can be used to test the hypothesis that a full manual recount would
find a different outcome. This paper develops a conservative sequential test
based on the vote-counting errors found in a hand tally of a simple or
stratified random sample of precincts. The procedure includes a natural
escalation: If the hypothesis that the apparent outcome is incorrect is not
rejected at stage $s$, more precincts are audited. Eventually, either the
hypothesis is rejected--and the apparent outcome is confirmed--or all precincts
have been audited and the true outcome is known. The test uses a priori bounds
on the overstatement of the margin that could result from error in each
precinct. Such bounds can be derived from the reported counts in each precinct
and upper bounds on the number of votes cast in each precinct. The test allows
errors in different precincts to be treated differently to reflect voting
technology or precinct sizes. It is not optimal, but it is conservative: the
chance of erroneously confirming the outcome of a contest if a full manual
recount would show a different outcome is no larger than the nominal
significance level. The approach also gives a conservative $P$-value for the
hypothesis that a full manual recount would find a different outcome, given the
errors found in a fixed size sample. This is illustrated with two contests from
November, 2006: the U.S. Senate race in Minnesota and a school board race for
the Sausalito Marin City School District in California, a small contest in
which voters could vote for up to three candidates.",0807.4005v1,stat.AP,2008-07-25 06:54:40+00:00,[arxiv.Result.Author('Philip B. Stark')],"Annals of Applied Statistics 2008, Vol. 2, No. 2, 550-581"
746,Modeling Voters in Multi-Winner Approval Voting,"In many real world situations, collective decisions are made using voting
and, in scenarios such as committee or board elections, employing voting rules
that return multiple winners. In multi-winner approval voting (AV), an agent
submits a ballot consisting of approvals for as many candidates as they wish,
and winners are chosen by tallying up the votes and choosing the top-$k$
candidates receiving the most approvals. In many scenarios, an agent may
manipulate the ballot they submit in order to achieve a better outcome by
voting in a way that does not reflect their true preferences. In complex and
uncertain situations, agents may use heuristics instead of incurring the
additional effort required to compute the manipulation which most favors them.
In this paper, we examine voting behavior in single-winner and multi-winner
approval voting scenarios with varying degrees of uncertainty using behavioral
data obtained from Mechanical Turk. We find that people generally manipulate
their vote to obtain a better outcome, but often do not identify the optimal
manipulation. There are a number of predictive models of agent behavior in the
COMSOC and psychology literature that are based on cognitively plausible
heuristic strategies. We show that the existing approaches do not adequately
model real-world data. We propose a novel model that takes into account the
size of the winning set and human cognitive constraints, and demonstrate that
this model is more effective at capturing real-world behaviors in multi-winner
approval voting scenarios.",2012.02811v1,cs.GT,2020-12-04 19:24:28+00:00,"[arxiv.Result.Author('Jaelle Scheuerman'), arxiv.Result.Author('Jason Harman'), arxiv.Result.Author('Nicholas Mattei'), arxiv.Result.Author('K. Brent Venable')]",
747,BVOT: Self-Tallying Boardroom Voting with Oblivious Transfer,"A boardroom election is an election with a small number of voters carried out
with public communications. We present BVOT, a self-tallying boardroom voting
protocol with ballot secrecy, fairness (no tally information is available
before the polls close), and dispute-freeness (voters can observe that all
voters correctly followed the protocol).
  BVOT works by using a multiparty threshold homomorphic encryption system in
which each candidate is associated with a masked unique prime. Each voter
engages in an oblivious transfer with an untrusted distributor: the voter
selects the index of a prime associated with a candidate and receives the
selected prime in masked form. The voter then casts their vote by encrypting
their masked prime and broadcasting it to everyone. The distributor does not
learn the voter's choice, and no one learns the mapping between primes and
candidates until the audit phase. By hiding the mapping between primes and
candidates, BVOT provides voters with insufficient information to carry out
effective cheating. The threshold feature prevents anyone from computing any
partial tally---until everyone has voted. Multiplying all votes, their
decryption shares, and the unmasking factor yields a product of the primes each
raised to the number of votes received.
  In contrast to some existing boardroom voting protocols, BVOT does not rely
on any zero-knowledge proof; instead, it uses oblivious transfer to assure
ballot secrecy and correct vote casting. Also, BVOT can handle multiple
candidates in one election. BVOT prevents cheating by hiding crucial
information: an attempt to increase the tally of one candidate might increase
the tally of another candidate. After all votes are cast, any party can tally
the votes.",2010.02421v1,cs.CR,2020-10-06 01:28:34+00:00,"[arxiv.Result.Author('Farid Javani'), arxiv.Result.Author('Alan T. Sherman')]",
748,Multi-Domain Long-Tailed Learning by Augmenting Disentangled Representations,"There is an inescapable long-tailed class-imbalance issue in many real-world
classification problems. Existing long-tailed classification methods focus on
the single-domain setting, where all examples are drawn from the same
distribution. However, real-world scenarios often involve multiple domains with
distinct imbalanced class distributions. We study this multi-domain long-tailed
learning problem and aim to produce a model that generalizes well across all
classes and domains. Towards that goal, we introduce TALLY, which produces
invariant predictors by balanced augmenting hidden representations over domains
and classes. Built upon a proposed selective balanced sampling strategy, TALLY
achieves this by mixing the semantic representation of one example with the
domain-associated nuisances of another, producing a new representation for use
as data augmentation. To improve the disentanglement of semantic
representations, TALLY further utilizes a domain-invariant class prototype that
averages out domain-specific effects. We evaluate TALLY on four long-tailed
variants of classical domain generalization benchmarks and two real-world
imbalanced multi-domain datasets. The results indicate that TALLY consistently
outperforms other state-of-the-art methods in both subpopulation shift and
domain shift.",2210.14358v1,cs.LG,2022-10-25 21:54:26+00:00,"[arxiv.Result.Author('Huaxiu Yao'), arxiv.Result.Author('Xinyu Yang'), arxiv.Result.Author('Allan Zhou'), arxiv.Result.Author('Chelsea Finn')]",
749,A Blockchain-based Self-tallying Voting Scheme in Decentralized IoT,"The Internet of Things (IoT) is experiencing explosive growth and has gained
extensive attention from academia and industry in recent years. Most of the
existing IoT infrastructures are centralized, in which the presence of a cloud
server is mandatory. However, centralized frameworks suffer from the issues of
unscalability and single-point-of-failure. Consequently, decentralized IoT has
been proposed by taking advantage of the emerging technology of Blockchain.
Voting systems are widely adopted in IoT, such as a leader election in wireless
sensor networks. Self-tallying voting systems are alternatives to traditional
centralized voting systems in decentralized IoT since the traditional ones are
not suitable for such scenarios. Unfortunately, self-tallying voting systems
inherently suffer from fairness issues, such as adaptive and abortive issues
caused by malicious voters. In this paper, we introduce a framework of
self-tallying systems in decentralized IoT based on Blockchain. We propose a
concrete construction and prove the proposed system satisfies all the security
requirements including fairness, dispute-freeness and maximal ballot secrecy.
The implementations on mobile phones demonstrate the practicability of our
system.",1902.03710v1,cs.CR,2019-02-11 03:28:55+00:00,"[arxiv.Result.Author('Yannan Li'), arxiv.Result.Author('Willy Susilo'), arxiv.Result.Author('Guomin Yang'), arxiv.Result.Author('Yong Yu'), arxiv.Result.Author('Dongxi Liu'), arxiv.Result.Author('Mohsen Guizani')]",
750,Complete Policy Regret Bounds for Tallying Bandits,"Policy regret is a well established notion of measuring the performance of an
online learning algorithm against an adaptive adversary. We study restrictions
on the adversary that enable efficient minimization of the \emph{complete
policy regret}, which is the strongest possible version of policy regret. We
identify a gap in the current theoretical understanding of what sorts of
restrictions permit tractability in this challenging setting. To resolve this
gap, we consider a generalization of the stochastic multi armed bandit, which
we call the \emph{tallying bandit}. This is an online learning setting with an
$m$-memory bounded adversary, where the average loss for playing an action is
an unknown function of the number (or tally) of times that the action was
played in the last $m$ timesteps. For tallying bandit problems with $K$ actions
and time horizon $T$, we provide an algorithm that w.h.p achieves a complete
policy regret guarantee of $\tilde{\mathcal{O}}(mK\sqrt{T})$, where the
$\tilde{\mathcal{O}}$ notation hides only logarithmic factors. We additionally
prove an $\tilde\Omega(\sqrt{m K T})$ lower bound on the expected complete
policy regret of any tallying bandit algorithm, demonstrating the near
optimality of our method.",2204.11174v1,stat.ML,2022-04-24 03:10:27+00:00,"[arxiv.Result.Author('Dhruv Malik'), arxiv.Result.Author('Yuanzhi Li'), arxiv.Result.Author('Aarti Singh')]",
751,Exploiting re-voting in the Helios election system,"Election systems must ensure that representatives are chosen by voters.
Moreover, each voter should have equal influence. Traditionally, this has been
achieved by permitting voters to cast at most one ballot. More recently, this
has been achieved by tallying the last ballot cast by each voter. We show this
is not achieved by the Helios election system, because an adversary can cause a
ballot other than a voter's last to be tallied. Moreover, we show how the
adversary can choose the contents of such a ballot, thus the adversary can
unduly influence the selection of representatives.",1612.04099v3,cs.CR,2016-12-13 11:07:22+00:00,"[arxiv.Result.Author('Maxime Meyer'), arxiv.Result.Author('Ben Smyth')]",
752,Computational Complexity of Space-Bounded Real Numbers,"In this work we study the space complexity of computable real numbers
represented by fast convergent Cauchy sequences. We show the existence of
families of trascendental numbers which are logspace computable, as opposed to
algebraic irrational numbers which seem to required linear space. We
characterized the complexity of space-bounded real numbers by quantifying the
space complexities of tally sets. The latter result introduces a technique to
prove the space complexity of real numbers by studying its corresponding tally
sets, which is arguably a more natural approach. Results of this work present a
new approach to study real numbers whose transcendence is unknown.",1805.02572v1,cs.CC,2018-05-07 15:28:31+00:00,"[arxiv.Result.Author('Masaki Nakanishi'), arxiv.Result.Author('Marcos Villagra')]",
753,Information-Theoretic Secure and Private Voting System,"In this paper, we present a private voting system that consists of N
authorized voters who may vote to one of the K candidates or vote abstain. Each
voter wants to compute the final tally while staying private and robust against
malicious voters, who try to gain information about the vote of the other
voters beyond the final result, or send incorrect information to affect the
final tally. We design an information-theoretic private voting system based on
Shamir secret sharing, which is secure and robust as long as there are up to
(N-1)/3 malicious voters.",2203.07355v1,cs.IT,2022-03-14 17:53:35+00:00,"[arxiv.Result.Author('Seyed Reza Hoseini Najarkolaei'), arxiv.Result.Author('Narges Kazempour'), arxiv.Result.Author('Hasti Rostami'), arxiv.Result.Author('Mohammad Reza Aref')]",
754,Electrochemical polymerization of anilinium hydrochloride,"Electropolymerization of anilinium hydrochloride was carried out on platinum
plate electrode in a protic medium by cyclic voltammetry. The effects on the
electrodeposition of the sweep rate, monomer concentration, pH of the medium
and electrode nature are discussed.",1307.5668v1,cond-mat.mtrl-sci,2013-07-22 12:08:26+00:00,"[arxiv.Result.Author('Yomen Atassi'), arxiv.Result.Author('Mohammad Tally')]",
755,Risk-Limiting Tallies,"Many voter-verifiable, coercion-resistant schemes have been proposed, but
even the most carefully designed systems necessarily leak information via the
announced result. In corner cases, this may be problematic. For example, if all
the votes go to one candidate then all vote privacy evaporates. The mere
possibility of candidates getting no or few votes could have implications for
security in practice: if a coercer demands that a voter cast a vote for such an
unpopular candidate, then the voter may feel obliged to obey, even if she is
confident that the voting system satisfies the standard coercion resistance
definitions. With complex ballots, there may also be a danger of ""Italian""
style (aka ""signature"") attacks: the coercer demands the voter cast a ballot
with a specific, identifying pattern. Here we propose an approach to tallying
end-to-end verifiable schemes that avoids revealing all the votes but still
achieves whatever confidence level in the announced result is desired. Now a
coerced voter can claim that the required vote must be amongst those that
remained shrouded. Our approach is based on the well-established notion of
Risk-Limiting Audits, but here applied to the tally rather than to the audit.
We show that this approach counters coercion threats arising in extreme tallies
and ""Italian"" attacks. We illustrate our approach by applying it to the Selene
scheme, and we extend the approach to Risk-Limiting Verification, where not all
vote trackers are revealed, thereby enhancing the coercion mitigation
properties of Selene.",1908.04947v1,cs.CR,2019-08-14 04:23:10+00:00,"[arxiv.Result.Author('Wojciech Jamroga'), arxiv.Result.Author('Peter B. Roenne'), arxiv.Result.Author('Peter Y. A. Ryan'), arxiv.Result.Author('Philip B. Stark')]",
756,A Sharper discrepancy measure for post-election audits,"Post-election audits use the discrepancy between machine counts and a hand
tally of votes in a random sample of precincts to infer whether error affected
the electoral outcome. The maximum relative overstatement of pairwise margins
(MRO) quantifies that discrepancy. The electoral outcome a full hand tally
shows must agree with the apparent outcome if the MRO is less than 1. This
condition is sharper than previous ones when there are more than two candidates
or when voters may vote for more than one candidate. For the 2006 U.S. Senate
race in Minnesota, a test using MRO gives a $P$-value of 4.05% for the
hypothesis that a full hand tally would find a different winner, less than half
the value Stark [Ann. Appl. Statist. 2 (2008) 550--581] finds.",0811.1697v1,stat.AP,2008-11-11 12:22:39+00:00,[arxiv.Result.Author('Philip B. Stark')],"Annals of Applied Statistics 2008, Vol. 2, No. 3, 982-985"
757,Arranging the order of passengers on the boarding bridge to reduce the boarding time for single-aisle aircraft,"Reducing the aircraft boarding time is a common problem not only for
airlines, but also for passengers and airports. Group boarding is a popular
boarding strategy that separates the passengers into several groups and those
groups, which are then called in a certain order. Group boarding can reduce the
boarding time compared with that in random order boarding; however, it is
insufficient in several real scenarios because the passengers are not separated
strictly into groups. In this paper, we propose a boarding strategy that
arranges the order of the boarding passengers at the boarding gate. Although
this approach appears more time-consuming, we show that such a rearrangement
can be applied efficiently to the waiting queue of a single-aisle aircraft. We
quantitatively demonstrate the boarding times for various patterns of this
approach and discuss the mechanism underlying the reduction of boarding time.
This strategy is a promising approach to reduce boarding times and can replace
the conventional boarding strategy.",2109.13431v1,physics.soc-ph,2021-09-28 02:01:00+00:00,"[arxiv.Result.Author('Sakurako Tanida'), arxiv.Result.Author('Katsuhiro Nishinari')]",
758,"Train on Small, Play the Large: Scaling Up Board Games with AlphaZero and GNN","Playing board games is considered a major challenge for both humans and AI
researchers. Because some complicated board games are quite hard to learn,
humans usually begin with playing on smaller boards and incrementally advance
to master larger board strategies. Most neural network frameworks that are
currently tasked with playing board games neither perform such incremental
learning nor possess capabilities to automatically scale up. In this work, we
look at the board as a graph and combine a graph neural network architecture
inside the AlphaZero framework, along with some other innovative improvements.
Our ScalableAlphaZero is capable of learning to play incrementally on small
boards, and advancing to play on large ones. Our model can be trained quickly
to play different challenging board games on multiple board sizes, without
using any domain knowledge. We demonstrate the effectiveness of
ScalableAlphaZero and show, for example, that by training it for only three
days on small Othello boards, it can defeat the AlphaZero model on a large
board, which was trained to play the large board for $30$ days.",2107.08387v1,cs.LG,2021-07-18 08:36:00+00:00,"[arxiv.Result.Author('Shai Ben-Assayag'), arxiv.Result.Author('Ran El-Yaniv')]",
759,The Central Logic Board and its auxiliary boards for the optical module of the KM3NeT detector,"The KM3NeT neutrino telescope will be composed of many optical modules, each
of them containing 31 (3"") photomultipliers, connected to a Central Logic
Board. The Central Logic Board integrates Time to Digital Converters that
measure Time Over Threshold of the photomulti- pliers signals while White
Rabbit is used for the optical modules time synchronization. Auxiliary boards
have also been designed and built in order to test and extend the performance
of the Cen- tral Logic Board. The Central Logic Board, as well as the auxiliary
boards, will be presented by focusing on the design consideration, prototyping
issues and tests.",1411.0421v2,astro-ph.IM,2014-11-03 10:48:25+00:00,"[arxiv.Result.Author('S. Biagi'), arxiv.Result.Author('A. Orzelli')]",
760,"Exact, Efficient and Information-Theoretically Secure Voting with an Arbitrary Number of Cheaters","We present three voting protocols with unconditional privacy and correctness,
without assuming any bound on the number of corrupt participants. All protocols
have polynomial complexity and require private channels and a simultaneous
broadcast channel. Unlike previously proposed protocols in this model, the
protocols that we present deterministically output the exact tally. Our first
protocol is a basic voting scheme which allows voters to interact in order to
compute the tally. Privacy of the ballot is unconditional in the sense that
regardless of the behavior of the dishonest participants nothing can be learned
through the protocol that could not be learned in an ideal realisation.
Unfortunately, a single dishonest participant can make the protocol abort, in
which case the dishonest participants can nevertheless learn the outcome of the
tally. Our second protocol introduces voting authorities which improves the
communication complexity by limiting interaction to be only between voters and
authorities and among the authorities themselves; the simultaneous broadcast is
also limited to the authorities. In the second protocol, as long as a single
authority is honest, the privacy is unconditional, however, a single corrupt
authority or a single corrupt voter can cause the protocol to abort. Our final
protocol provides a safeguard against corrupt voters by enabling a verification
technique to allow the authorities to revoke incorrect votes without aborting
the protocol. Finally, we discuss the implementation of a simultaneous
broadcast channel with the use of temporary computational assumptions, yielding
versions of our protocols that achieve everlasting security.",1011.5242v1,cs.CR,2010-11-23 21:33:50+00:00,"[arxiv.Result.Author('Anne Broadbent'), arxiv.Result.Author('Stacey Jeffery'), arxiv.Result.Author('Alain Tapp')]",
761,BVOT: Self-Tallying Boardroom Voting with Oblivious Transfer,"A boardroom election is an election with a small number of voters carried out
with public communications. We present BVOT, a self-tallying boardroom voting
protocol with ballot secrecy, fairness (no tally information is available
before the polls close), and dispute-freeness (voters can observe that all
voters correctly followed the protocol).
  BVOT works by using a multiparty threshold homomorphic encryption system in
which each candidate is associated with a masked unique prime. Each voter
engages in an oblivious transfer with an untrusted distributor: the voter
selects the index of a prime associated with a candidate and receives the
selected prime in masked form. The voter then casts their vote by encrypting
their masked prime and broadcasting it to everyone. The distributor does not
learn the voter's choice, and no one learns the mapping between primes and
candidates until the audit phase. By hiding the mapping between primes and
candidates, BVOT provides voters with insufficient information to carry out
effective cheating. The threshold feature prevents anyone from computing any
partial tally---until everyone has voted. Multiplying all votes, their
decryption shares, and the unmasking factor yields a product of the primes each
raised to the number of votes received.
  In contrast to some existing boardroom voting protocols, BVOT does not rely
on any zero-knowledge proof; instead, it uses oblivious transfer to assure
ballot secrecy and correct vote casting. Also, BVOT can handle multiple
candidates in one election. BVOT prevents cheating by hiding crucial
information: an attempt to increase the tally of one candidate might increase
the tally of another candidate. After all votes are cast, any party can tally
the votes.",2010.02421v1,cs.CR,2020-10-06 01:28:34+00:00,"[arxiv.Result.Author('Farid Javani'), arxiv.Result.Author('Alan T. Sherman')]",
762,Multi-Domain Long-Tailed Learning by Augmenting Disentangled Representations,"There is an inescapable long-tailed class-imbalance issue in many real-world
classification problems. Existing long-tailed classification methods focus on
the single-domain setting, where all examples are drawn from the same
distribution. However, real-world scenarios often involve multiple domains with
distinct imbalanced class distributions. We study this multi-domain long-tailed
learning problem and aim to produce a model that generalizes well across all
classes and domains. Towards that goal, we introduce TALLY, which produces
invariant predictors by balanced augmenting hidden representations over domains
and classes. Built upon a proposed selective balanced sampling strategy, TALLY
achieves this by mixing the semantic representation of one example with the
domain-associated nuisances of another, producing a new representation for use
as data augmentation. To improve the disentanglement of semantic
representations, TALLY further utilizes a domain-invariant class prototype that
averages out domain-specific effects. We evaluate TALLY on four long-tailed
variants of classical domain generalization benchmarks and two real-world
imbalanced multi-domain datasets. The results indicate that TALLY consistently
outperforms other state-of-the-art methods in both subpopulation shift and
domain shift.",2210.14358v1,cs.LG,2022-10-25 21:54:26+00:00,"[arxiv.Result.Author('Huaxiu Yao'), arxiv.Result.Author('Xinyu Yang'), arxiv.Result.Author('Allan Zhou'), arxiv.Result.Author('Chelsea Finn')]",
763,A Blockchain-based Self-tallying Voting Scheme in Decentralized IoT,"The Internet of Things (IoT) is experiencing explosive growth and has gained
extensive attention from academia and industry in recent years. Most of the
existing IoT infrastructures are centralized, in which the presence of a cloud
server is mandatory. However, centralized frameworks suffer from the issues of
unscalability and single-point-of-failure. Consequently, decentralized IoT has
been proposed by taking advantage of the emerging technology of Blockchain.
Voting systems are widely adopted in IoT, such as a leader election in wireless
sensor networks. Self-tallying voting systems are alternatives to traditional
centralized voting systems in decentralized IoT since the traditional ones are
not suitable for such scenarios. Unfortunately, self-tallying voting systems
inherently suffer from fairness issues, such as adaptive and abortive issues
caused by malicious voters. In this paper, we introduce a framework of
self-tallying systems in decentralized IoT based on Blockchain. We propose a
concrete construction and prove the proposed system satisfies all the security
requirements including fairness, dispute-freeness and maximal ballot secrecy.
The implementations on mobile phones demonstrate the practicability of our
system.",1902.03710v1,cs.CR,2019-02-11 03:28:55+00:00,"[arxiv.Result.Author('Yannan Li'), arxiv.Result.Author('Willy Susilo'), arxiv.Result.Author('Guomin Yang'), arxiv.Result.Author('Yong Yu'), arxiv.Result.Author('Dongxi Liu'), arxiv.Result.Author('Mohsen Guizani')]",
764,Complete Policy Regret Bounds for Tallying Bandits,"Policy regret is a well established notion of measuring the performance of an
online learning algorithm against an adaptive adversary. We study restrictions
on the adversary that enable efficient minimization of the \emph{complete
policy regret}, which is the strongest possible version of policy regret. We
identify a gap in the current theoretical understanding of what sorts of
restrictions permit tractability in this challenging setting. To resolve this
gap, we consider a generalization of the stochastic multi armed bandit, which
we call the \emph{tallying bandit}. This is an online learning setting with an
$m$-memory bounded adversary, where the average loss for playing an action is
an unknown function of the number (or tally) of times that the action was
played in the last $m$ timesteps. For tallying bandit problems with $K$ actions
and time horizon $T$, we provide an algorithm that w.h.p achieves a complete
policy regret guarantee of $\tilde{\mathcal{O}}(mK\sqrt{T})$, where the
$\tilde{\mathcal{O}}$ notation hides only logarithmic factors. We additionally
prove an $\tilde\Omega(\sqrt{m K T})$ lower bound on the expected complete
policy regret of any tallying bandit algorithm, demonstrating the near
optimality of our method.",2204.11174v1,stat.ML,2022-04-24 03:10:27+00:00,"[arxiv.Result.Author('Dhruv Malik'), arxiv.Result.Author('Yuanzhi Li'), arxiv.Result.Author('Aarti Singh')]",
765,SBvote: Scalable Self-Tallying Blockchain-Based Voting,"Decentralized electronic voting solutions represent a promising advancement
in electronic voting. One of the e-voting paradigms, the self-tallying scheme,
offers strong protection of the voters' privacy while making the whole voting
process verifiable. Decentralized smart contract platforms became interesting
practical instantiation of the immutable bulletin board that this scheme
requires to preserve its properties. Existing smart contract-based approaches
employing the self-tallying scheme (such as OVN or BBB-Voting) are only
suitable for a boardroom voting scenario due to their scalability limitation.
The goal of our work is to build on existing solutions to achieve scalability
without losing privacy guarantees and verifiability. We present SBvote, a
blockchain-based self-tallying voting protocol that is scalable in the number
of voters and therefore suitable for large-scale elections. The evaluation of
our proof-of-concept implementation shows that the protocol's scalability is
limited only by the underlying blockchain platform. We evaluated the
scalability of SBvote on two public smart contract platforms -- Gnosis and
Harmony. Despite the limitations imposed by the throughput of the blockchain
platform, SBvote can accommodate elections with millions of voters.",2206.06019v1,cs.CR,2022-06-13 10:18:00+00:00,"[arxiv.Result.Author('Ivana Stančíková'), arxiv.Result.Author('Ivan Homoliak')]",
766,Exploiting re-voting in the Helios election system,"Election systems must ensure that representatives are chosen by voters.
Moreover, each voter should have equal influence. Traditionally, this has been
achieved by permitting voters to cast at most one ballot. More recently, this
has been achieved by tallying the last ballot cast by each voter. We show this
is not achieved by the Helios election system, because an adversary can cause a
ballot other than a voter's last to be tallied. Moreover, we show how the
adversary can choose the contents of such a ballot, thus the adversary can
unduly influence the selection of representatives.",1612.04099v3,cs.CR,2016-12-13 11:07:22+00:00,"[arxiv.Result.Author('Maxime Meyer'), arxiv.Result.Author('Ben Smyth')]",
767,Computational Complexity of Space-Bounded Real Numbers,"In this work we study the space complexity of computable real numbers
represented by fast convergent Cauchy sequences. We show the existence of
families of trascendental numbers which are logspace computable, as opposed to
algebraic irrational numbers which seem to required linear space. We
characterized the complexity of space-bounded real numbers by quantifying the
space complexities of tally sets. The latter result introduces a technique to
prove the space complexity of real numbers by studying its corresponding tally
sets, which is arguably a more natural approach. Results of this work present a
new approach to study real numbers whose transcendence is unknown.",1805.02572v1,cs.CC,2018-05-07 15:28:31+00:00,"[arxiv.Result.Author('Masaki Nakanishi'), arxiv.Result.Author('Marcos Villagra')]",
768,Information-Theoretic Secure and Private Voting System,"In this paper, we present a private voting system that consists of N
authorized voters who may vote to one of the K candidates or vote abstain. Each
voter wants to compute the final tally while staying private and robust against
malicious voters, who try to gain information about the vote of the other
voters beyond the final result, or send incorrect information to affect the
final tally. We design an information-theoretic private voting system based on
Shamir secret sharing, which is secure and robust as long as there are up to
(N-1)/3 malicious voters.",2203.07355v1,cs.IT,2022-03-14 17:53:35+00:00,"[arxiv.Result.Author('Seyed Reza Hoseini Najarkolaei'), arxiv.Result.Author('Narges Kazempour'), arxiv.Result.Author('Hasti Rostami'), arxiv.Result.Author('Mohammad Reza Aref')]",
769,Electrochemical polymerization of anilinium hydrochloride,"Electropolymerization of anilinium hydrochloride was carried out on platinum
plate electrode in a protic medium by cyclic voltammetry. The effects on the
electrodeposition of the sweep rate, monomer concentration, pH of the medium
and electrode nature are discussed.",1307.5668v1,cond-mat.mtrl-sci,2013-07-22 12:08:26+00:00,"[arxiv.Result.Author('Yomen Atassi'), arxiv.Result.Author('Mohammad Tally')]",
770,Risk-Limiting Tallies,"Many voter-verifiable, coercion-resistant schemes have been proposed, but
even the most carefully designed systems necessarily leak information via the
announced result. In corner cases, this may be problematic. For example, if all
the votes go to one candidate then all vote privacy evaporates. The mere
possibility of candidates getting no or few votes could have implications for
security in practice: if a coercer demands that a voter cast a vote for such an
unpopular candidate, then the voter may feel obliged to obey, even if she is
confident that the voting system satisfies the standard coercion resistance
definitions. With complex ballots, there may also be a danger of ""Italian""
style (aka ""signature"") attacks: the coercer demands the voter cast a ballot
with a specific, identifying pattern. Here we propose an approach to tallying
end-to-end verifiable schemes that avoids revealing all the votes but still
achieves whatever confidence level in the announced result is desired. Now a
coerced voter can claim that the required vote must be amongst those that
remained shrouded. Our approach is based on the well-established notion of
Risk-Limiting Audits, but here applied to the tally rather than to the audit.
We show that this approach counters coercion threats arising in extreme tallies
and ""Italian"" attacks. We illustrate our approach by applying it to the Selene
scheme, and we extend the approach to Risk-Limiting Verification, where not all
vote trackers are revealed, thereby enhancing the coercion mitigation
properties of Selene.",1908.04947v1,cs.CR,2019-08-14 04:23:10+00:00,"[arxiv.Result.Author('Wojciech Jamroga'), arxiv.Result.Author('Peter B. Roenne'), arxiv.Result.Author('Peter Y. A. Ryan'), arxiv.Result.Author('Philip B. Stark')]",
771,A Sharper discrepancy measure for post-election audits,"Post-election audits use the discrepancy between machine counts and a hand
tally of votes in a random sample of precincts to infer whether error affected
the electoral outcome. The maximum relative overstatement of pairwise margins
(MRO) quantifies that discrepancy. The electoral outcome a full hand tally
shows must agree with the apparent outcome if the MRO is less than 1. This
condition is sharper than previous ones when there are more than two candidates
or when voters may vote for more than one candidate. For the 2006 U.S. Senate
race in Minnesota, a test using MRO gives a $P$-value of 4.05% for the
hypothesis that a full hand tally would find a different winner, less than half
the value Stark [Ann. Appl. Statist. 2 (2008) 550--581] finds.",0811.1697v1,stat.AP,2008-11-11 12:22:39+00:00,[arxiv.Result.Author('Philip B. Stark')],"Annals of Applied Statistics 2008, Vol. 2, No. 3, 982-985"
772,Coverings of open books,"We study a coverings of open books and virtually overtwisted contact
manifolds using open book foliations. We show that open book coverings produces
interesting examples such as transverse knots with depth grater than 1. We also
demonstrate explicit examples of virtually overtwisted open books.",1509.00352v1,math.GT,2015-09-01 15:26:45+00:00,"[arxiv.Result.Author('Tetsuya Ito'), arxiv.Result.Author('Keiko Kawamuro')]",
773,Non-prime 3-Manifolds with Open Book Genus Two,"An open book decomposition of a 3-manifold $M$ induces a Heegaard splitting
for $M$, and the minimal genus among all Heegaard splittings induced by open
book decompositions is called the \emph{open book genus} of $M$. It is
conjectured by Ozbagci \cite{O} that the open book genus is additive under the
connected sum of 3-manifolds. In this paper, we prove that a non-prime
3-manifold which has open book genus 2 is homeomorphic to $L(p,1)\#L(q,1)$ for
some integers $p,q\neq\pm1$, that is, it has non-trivial prime pieces of open
book genus 1. In particular, there cannot be a counter-example to additivity of
the open book genus such that the connected sum has open book genus 2.",1702.07115v1,math.GT,2017-02-23 07:07:35+00:00,[arxiv.Result.Author('Mustafa Cengiz')],
774,"Exact, Efficient and Information-Theoretically Secure Voting with an Arbitrary Number of Cheaters","We present three voting protocols with unconditional privacy and correctness,
without assuming any bound on the number of corrupt participants. All protocols
have polynomial complexity and require private channels and a simultaneous
broadcast channel. Unlike previously proposed protocols in this model, the
protocols that we present deterministically output the exact tally. Our first
protocol is a basic voting scheme which allows voters to interact in order to
compute the tally. Privacy of the ballot is unconditional in the sense that
regardless of the behavior of the dishonest participants nothing can be learned
through the protocol that could not be learned in an ideal realisation.
Unfortunately, a single dishonest participant can make the protocol abort, in
which case the dishonest participants can nevertheless learn the outcome of the
tally. Our second protocol introduces voting authorities which improves the
communication complexity by limiting interaction to be only between voters and
authorities and among the authorities themselves; the simultaneous broadcast is
also limited to the authorities. In the second protocol, as long as a single
authority is honest, the privacy is unconditional, however, a single corrupt
authority or a single corrupt voter can cause the protocol to abort. Our final
protocol provides a safeguard against corrupt voters by enabling a verification
technique to allow the authorities to revoke incorrect votes without aborting
the protocol. Finally, we discuss the implementation of a simultaneous
broadcast channel with the use of temporary computational assumptions, yielding
versions of our protocols that achieve everlasting security.",1011.5242v1,cs.CR,2010-11-23 21:33:50+00:00,"[arxiv.Result.Author('Anne Broadbent'), arxiv.Result.Author('Stacey Jeffery'), arxiv.Result.Author('Alain Tapp')]",
775,Phrase-Verified Voting: Verifiable Low-Tech Remote Boardroom Voting,"We present Phrase-Verified Voting, a voter-verifiable remote voting system
assembled from commercial off-the-shelf software for small private elections.
The system is transparent and enables each voter to verify that the tally
includes their ballot selection without requiring any understanding of
cryptography. This paper describes the system and its use in fall 2020, to vote
remotely in promotion committees in a university. Each voter fills out a form
in the cloud with their vote V (YES, NO, ABSTAIN) and a passphrase P-two words
entered by the voter. The system generates a verification prompt of the (P,V)
pairs and a tally of the votes, organized to help visualize how the votes add
up. After the polls close, each voter verifies that this table lists their
(P,V) pair and that the tally is computed correctly. The system is especially
appropriate for any small group making sensitive decisions. Because the system
would not prevent a coercer from demanding that their victim use a specified
passphrase, it is not designed for applications where such malfeasance would be
likely or go undetected. Results from 43 voters show that the system was
well-accepted, performed effectively for its intended purpose, and introduced
users to the concept of voter-verified elections. Compared to the commonly-used
alternatives of paper ballots or voting by email, voters found the system
easier to use, and that it provided greater privacy and outcome integrity.",2103.07180v1,cs.CR,2021-03-12 09:59:55+00:00,"[arxiv.Result.Author('Enka Blanchard'), arxiv.Result.Author('Ryan Robucci'), arxiv.Result.Author('Ted Selker'), arxiv.Result.Author('Alan Sherman')]",
776,Dispute-free Scalable Open Vote Network using zk-SNARKs,"The Open Vote Network is a self-tallying decentralized e-voting protocol
suitable for boardroom elections. Currently, it has two Ethereum-based
implementations: the first, by McCorry et al., has a scalability issue since
all the computations are performed on-chain. The second implementation, by
Seifelnasr et al., solves this issue partially by assigning a part of the heavy
computations to an off-chain untrusted administrator in a verifiable manner. As
a side effect, this second implementation became not dispute-free; there is a
need for a tally dispute phase where an observer interrupts the protocol when
the administrator cheats, i.e., announces a wrong tally result. In this work,
we propose a new smart contract design to tackle the problems in the previous
implementations by (i) preforming all the heavy computations off-chain hence
achieving higher scalability, and (ii) utilizing zero-knowledge Succinct
Non-interactive Argument of Knowledge (zk-SNARK) to verify the correctness of
the off-chain computations, hence maintaining the dispute-free property. To
demonstrate the effectiveness of our design, we develop prototype
implementations on Ethereum and conduct multiple experiments for different
implementation options that show a trade-off between the zk-SNARK proof
generation time and the smart contract gas cost, including an implementation in
which the smart contract consumes a constant amount of gas independent of the
number of voters.",2203.03363v1,cs.CR,2022-03-07 13:12:28+00:00,"[arxiv.Result.Author('Muhammad ElSheikh'), arxiv.Result.Author('Amr M. Youssef')]",
777,Experiments with zeta zeros and Perron's formula,"Of what use are the zeros of the Riemann zeta function? We can use sums
involving zeta zeros to count the primes up to $x$. Perron's formula leads to
sums over zeta zeros that can count the squarefree integers up to $x$, or tally
Euler's $\phi$ function and other arithmetical functions. This is largely a
presentation of experimental results.",1103.6226v1,math.NT,2011-03-31 16:11:36+00:00,[arxiv.Result.Author('Robert Baillie')],
778,A Simple Voting Protocol on Quantum Blockchain,"This paper proposes a simple voting protocol based on quantum blockchain.
Besides being simple, our voting protocol is anonymous, binding, non-reusable,
verifiable, eligible, fair and self-tallying. Our protocol is also realizable
by the current technology.",1805.11979v2,quant-ph,2018-05-29 10:54:53+00:00,"[arxiv.Result.Author('Xin Sun'), arxiv.Result.Author('Quanlong Wang'), arxiv.Result.Author('Piotr Kulicki')]",
779,(Universal) Unconditional Verifiability in E-Voting without Trusted Parties,"In traditional e-voting protocols, privacy is often provided by a trusted
authority that learns the votes and computes the tally. Some protocols replace
the trusted authority by a set of authorities, and privacy is guaranteed if
less than a threshold number of authorities are corrupt. For verifiability,
stronger security guarantees are demanded. Typically, corrupt authorities that
try to fake the result of the tally must always be detected.
  To provide verifiability, many e-voting protocols use Non-Interactive
Zero-Knowledge proofs (NIZKs). Thanks to their non-interactive nature, NIZKs
allow anybody, including third parties that do not participate in the protocol,
to verify the correctness of the tally. Therefore, NIZKs can be used to obtain
universal verifiability. Additionally, NIZKs also improve usability because
they allow voters to cast a vote using a non-interactive protocol.
  The disadvantage of NIZKs is that their security is based on setup
assumptions such as the common reference string (CRS) or the random oracle (RO)
model. The former requires a trusted party for the generation of a common
reference string. The latter, though a popular methodology for designing secure
protocols, has been shown to be unsound.
  In this paper, we address the design of an e-voting protocol that provides
verifiability without any trust assumptions, where verifiability here is meant
without eligibility verification. We show that Non-Interactive
Witness-Indistinguishable proofs (NIWI) can be used for this purpose. The
e-voting scheme is private under the Decision Linear assumption, while
verifiability holds unconditionally. To our knowledge, this is the first
private e-voting scheme with perfect universal verifiability, i.e. one in which
the probability of a fake tally not being detected is 0, and with {\em
non-interactive} protocols that does not rely on trust assumptions.",1610.06343v1,cs.CR,2016-10-20 09:57:12+00:00,"[arxiv.Result.Author('Gina Gallegos-Garcia'), arxiv.Result.Author('Vincenzo Iovino'), arxiv.Result.Author('Alfredo Rial'), arxiv.Result.Author('Peter B. Roenne'), arxiv.Result.Author('Peter Y. A. Ryan')]",
780,Soliton stars in the breather limit,"This paper presents an asymptotic reduction of the Einstein-Klein-Gordon
system with real scalar field (""soliton star problem""). A periodic solution of
the reduced system, similar to the sine-Gordon breather, is obtained by a
variational method. This tallies with numerical computations. As a consequence,
a time-periodic redshift for sources close to the center of the star is
obtained.",1709.07760v1,gr-qc,2017-09-22 14:04:33+00:00,[arxiv.Result.Author('Satyanad Kichenassamy')],"Classical and Quantum Gravity, 25 (2008) 245004"
781,Phrase-Verified Voting: Verifiable Low-Tech Remote Boardroom Voting,"We present Phrase-Verified Voting, a voter-verifiable remote voting system
assembled from commercial off-the-shelf software for small private elections.
The system is transparent and enables each voter to verify that the tally
includes their ballot selection without requiring any understanding of
cryptography. This paper describes the system and its use in fall 2020, to vote
remotely in promotion committees in a university. Each voter fills out a form
in the cloud with their vote V (YES, NO, ABSTAIN) and a passphrase P-two words
entered by the voter. The system generates a verification prompt of the (P,V)
pairs and a tally of the votes, organized to help visualize how the votes add
up. After the polls close, each voter verifies that this table lists their
(P,V) pair and that the tally is computed correctly. The system is especially
appropriate for any small group making sensitive decisions. Because the system
would not prevent a coercer from demanding that their victim use a specified
passphrase, it is not designed for applications where such malfeasance would be
likely or go undetected. Results from 43 voters show that the system was
well-accepted, performed effectively for its intended purpose, and introduced
users to the concept of voter-verified elections. Compared to the commonly-used
alternatives of paper ballots or voting by email, voters found the system
easier to use, and that it provided greater privacy and outcome integrity.",2103.07180v1,cs.CR,2021-03-12 09:59:55+00:00,"[arxiv.Result.Author('Enka Blanchard'), arxiv.Result.Author('Ryan Robucci'), arxiv.Result.Author('Ted Selker'), arxiv.Result.Author('Alan Sherman')]",
782,BVOT: Self-Tallying Boardroom Voting with Oblivious Transfer,"A boardroom election is an election with a small number of voters carried out
with public communications. We present BVOT, a self-tallying boardroom voting
protocol with ballot secrecy, fairness (no tally information is available
before the polls close), and dispute-freeness (voters can observe that all
voters correctly followed the protocol).
  BVOT works by using a multiparty threshold homomorphic encryption system in
which each candidate is associated with a masked unique prime. Each voter
engages in an oblivious transfer with an untrusted distributor: the voter
selects the index of a prime associated with a candidate and receives the
selected prime in masked form. The voter then casts their vote by encrypting
their masked prime and broadcasting it to everyone. The distributor does not
learn the voter's choice, and no one learns the mapping between primes and
candidates until the audit phase. By hiding the mapping between primes and
candidates, BVOT provides voters with insufficient information to carry out
effective cheating. The threshold feature prevents anyone from computing any
partial tally---until everyone has voted. Multiplying all votes, their
decryption shares, and the unmasking factor yields a product of the primes each
raised to the number of votes received.
  In contrast to some existing boardroom voting protocols, BVOT does not rely
on any zero-knowledge proof; instead, it uses oblivious transfer to assure
ballot secrecy and correct vote casting. Also, BVOT can handle multiple
candidates in one election. BVOT prevents cheating by hiding crucial
information: an attempt to increase the tally of one candidate might increase
the tally of another candidate. After all votes are cast, any party can tally
the votes.",2010.02421v1,cs.CR,2020-10-06 01:28:34+00:00,"[arxiv.Result.Author('Farid Javani'), arxiv.Result.Author('Alan T. Sherman')]",
783,Characterizing Properties and Trade-offs of Centralized Delegation Mechanisms in Liquid Democracy,"Liquid democracy is a form of transitive delegative democracy that has
received a flurry of scholarly attention from the computer science community in
recent years. In its simplest form, every agent starts with one vote and may
have other votes assigned to them via delegation from other agents. They can
choose to delegate all votes assigned to them to another agent or vote directly
with all votes assigned to them. However, many proposed realizations of liquid
democracy allow for agents to express their delegation/voting preferences in
more complex ways (e.g., a ranked list of potential delegates) and employ a
centralized delegation mechanism to compute the final vote tally. In doing so,
centralized delegation mechanisms can make decisions that affect the outcome of
a vote and where/whether agents are able to delegate their votes. Much of the
analysis thus far has focused on the ability of these mechanisms to make a
correct choice. We extend this analysis by introducing and formalizing other
important properties of a centralized delegation mechanism in liquid democracy
with respect to crucial features such as accountability, transparency,
explainability, fairness, and user agency. In addition, we evaluate existing
methods in terms of these properties, show how some prior work can be augmented
to achieve desirable properties, prove impossibility results for achieving
certain sets of properties simultaneously, and highlight directions for future
work.",2206.05339v1,cs.MA,2022-06-10 20:11:35+00:00,"[arxiv.Result.Author('Brian Brubach'), arxiv.Result.Author('Audrey Ballarin'), arxiv.Result.Author('Heeba Nazeer')]",
784,Multi-Domain Long-Tailed Learning by Augmenting Disentangled Representations,"There is an inescapable long-tailed class-imbalance issue in many real-world
classification problems. Existing long-tailed classification methods focus on
the single-domain setting, where all examples are drawn from the same
distribution. However, real-world scenarios often involve multiple domains with
distinct imbalanced class distributions. We study this multi-domain long-tailed
learning problem and aim to produce a model that generalizes well across all
classes and domains. Towards that goal, we introduce TALLY, which produces
invariant predictors by balanced augmenting hidden representations over domains
and classes. Built upon a proposed selective balanced sampling strategy, TALLY
achieves this by mixing the semantic representation of one example with the
domain-associated nuisances of another, producing a new representation for use
as data augmentation. To improve the disentanglement of semantic
representations, TALLY further utilizes a domain-invariant class prototype that
averages out domain-specific effects. We evaluate TALLY on four long-tailed
variants of classical domain generalization benchmarks and two real-world
imbalanced multi-domain datasets. The results indicate that TALLY consistently
outperforms other state-of-the-art methods in both subpopulation shift and
domain shift.",2210.14358v1,cs.LG,2022-10-25 21:54:26+00:00,"[arxiv.Result.Author('Huaxiu Yao'), arxiv.Result.Author('Xinyu Yang'), arxiv.Result.Author('Allan Zhou'), arxiv.Result.Author('Chelsea Finn')]",
785,A Blockchain-based Self-tallying Voting Scheme in Decentralized IoT,"The Internet of Things (IoT) is experiencing explosive growth and has gained
extensive attention from academia and industry in recent years. Most of the
existing IoT infrastructures are centralized, in which the presence of a cloud
server is mandatory. However, centralized frameworks suffer from the issues of
unscalability and single-point-of-failure. Consequently, decentralized IoT has
been proposed by taking advantage of the emerging technology of Blockchain.
Voting systems are widely adopted in IoT, such as a leader election in wireless
sensor networks. Self-tallying voting systems are alternatives to traditional
centralized voting systems in decentralized IoT since the traditional ones are
not suitable for such scenarios. Unfortunately, self-tallying voting systems
inherently suffer from fairness issues, such as adaptive and abortive issues
caused by malicious voters. In this paper, we introduce a framework of
self-tallying systems in decentralized IoT based on Blockchain. We propose a
concrete construction and prove the proposed system satisfies all the security
requirements including fairness, dispute-freeness and maximal ballot secrecy.
The implementations on mobile phones demonstrate the practicability of our
system.",1902.03710v1,cs.CR,2019-02-11 03:28:55+00:00,"[arxiv.Result.Author('Yannan Li'), arxiv.Result.Author('Willy Susilo'), arxiv.Result.Author('Guomin Yang'), arxiv.Result.Author('Yong Yu'), arxiv.Result.Author('Dongxi Liu'), arxiv.Result.Author('Mohsen Guizani')]",
786,Complete Policy Regret Bounds for Tallying Bandits,"Policy regret is a well established notion of measuring the performance of an
online learning algorithm against an adaptive adversary. We study restrictions
on the adversary that enable efficient minimization of the \emph{complete
policy regret}, which is the strongest possible version of policy regret. We
identify a gap in the current theoretical understanding of what sorts of
restrictions permit tractability in this challenging setting. To resolve this
gap, we consider a generalization of the stochastic multi armed bandit, which
we call the \emph{tallying bandit}. This is an online learning setting with an
$m$-memory bounded adversary, where the average loss for playing an action is
an unknown function of the number (or tally) of times that the action was
played in the last $m$ timesteps. For tallying bandit problems with $K$ actions
and time horizon $T$, we provide an algorithm that w.h.p achieves a complete
policy regret guarantee of $\tilde{\mathcal{O}}(mK\sqrt{T})$, where the
$\tilde{\mathcal{O}}$ notation hides only logarithmic factors. We additionally
prove an $\tilde\Omega(\sqrt{m K T})$ lower bound on the expected complete
policy regret of any tallying bandit algorithm, demonstrating the near
optimality of our method.",2204.11174v1,stat.ML,2022-04-24 03:10:27+00:00,"[arxiv.Result.Author('Dhruv Malik'), arxiv.Result.Author('Yuanzhi Li'), arxiv.Result.Author('Aarti Singh')]",
787,SBvote: Scalable Self-Tallying Blockchain-Based Voting,"Decentralized electronic voting solutions represent a promising advancement
in electronic voting. One of the e-voting paradigms, the self-tallying scheme,
offers strong protection of the voters' privacy while making the whole voting
process verifiable. Decentralized smart contract platforms became interesting
practical instantiation of the immutable bulletin board that this scheme
requires to preserve its properties. Existing smart contract-based approaches
employing the self-tallying scheme (such as OVN or BBB-Voting) are only
suitable for a boardroom voting scenario due to their scalability limitation.
The goal of our work is to build on existing solutions to achieve scalability
without losing privacy guarantees and verifiability. We present SBvote, a
blockchain-based self-tallying voting protocol that is scalable in the number
of voters and therefore suitable for large-scale elections. The evaluation of
our proof-of-concept implementation shows that the protocol's scalability is
limited only by the underlying blockchain platform. We evaluated the
scalability of SBvote on two public smart contract platforms -- Gnosis and
Harmony. Despite the limitations imposed by the throughput of the blockchain
platform, SBvote can accommodate elections with millions of voters.",2206.06019v1,cs.CR,2022-06-13 10:18:00+00:00,"[arxiv.Result.Author('Ivana Stančíková'), arxiv.Result.Author('Ivan Homoliak')]",
788,Exploiting re-voting in the Helios election system,"Election systems must ensure that representatives are chosen by voters.
Moreover, each voter should have equal influence. Traditionally, this has been
achieved by permitting voters to cast at most one ballot. More recently, this
has been achieved by tallying the last ballot cast by each voter. We show this
is not achieved by the Helios election system, because an adversary can cause a
ballot other than a voter's last to be tallied. Moreover, we show how the
adversary can choose the contents of such a ballot, thus the adversary can
unduly influence the selection of representatives.",1612.04099v3,cs.CR,2016-12-13 11:07:22+00:00,"[arxiv.Result.Author('Maxime Meyer'), arxiv.Result.Author('Ben Smyth')]",
789,Computational Complexity of Space-Bounded Real Numbers,"In this work we study the space complexity of computable real numbers
represented by fast convergent Cauchy sequences. We show the existence of
families of trascendental numbers which are logspace computable, as opposed to
algebraic irrational numbers which seem to required linear space. We
characterized the complexity of space-bounded real numbers by quantifying the
space complexities of tally sets. The latter result introduces a technique to
prove the space complexity of real numbers by studying its corresponding tally
sets, which is arguably a more natural approach. Results of this work present a
new approach to study real numbers whose transcendence is unknown.",1805.02572v1,cs.CC,2018-05-07 15:28:31+00:00,"[arxiv.Result.Author('Masaki Nakanishi'), arxiv.Result.Author('Marcos Villagra')]",
790,Information-Theoretic Secure and Private Voting System,"In this paper, we present a private voting system that consists of N
authorized voters who may vote to one of the K candidates or vote abstain. Each
voter wants to compute the final tally while staying private and robust against
malicious voters, who try to gain information about the vote of the other
voters beyond the final result, or send incorrect information to affect the
final tally. We design an information-theoretic private voting system based on
Shamir secret sharing, which is secure and robust as long as there are up to
(N-1)/3 malicious voters.",2203.07355v1,cs.IT,2022-03-14 17:53:35+00:00,"[arxiv.Result.Author('Seyed Reza Hoseini Najarkolaei'), arxiv.Result.Author('Narges Kazempour'), arxiv.Result.Author('Hasti Rostami'), arxiv.Result.Author('Mohammad Reza Aref')]",
791,Electrochemical polymerization of anilinium hydrochloride,"Electropolymerization of anilinium hydrochloride was carried out on platinum
plate electrode in a protic medium by cyclic voltammetry. The effects on the
electrodeposition of the sweep rate, monomer concentration, pH of the medium
and electrode nature are discussed.",1307.5668v1,cond-mat.mtrl-sci,2013-07-22 12:08:26+00:00,"[arxiv.Result.Author('Yomen Atassi'), arxiv.Result.Author('Mohammad Tally')]",
792,Risk-Limiting Tallies,"Many voter-verifiable, coercion-resistant schemes have been proposed, but
even the most carefully designed systems necessarily leak information via the
announced result. In corner cases, this may be problematic. For example, if all
the votes go to one candidate then all vote privacy evaporates. The mere
possibility of candidates getting no or few votes could have implications for
security in practice: if a coercer demands that a voter cast a vote for such an
unpopular candidate, then the voter may feel obliged to obey, even if she is
confident that the voting system satisfies the standard coercion resistance
definitions. With complex ballots, there may also be a danger of ""Italian""
style (aka ""signature"") attacks: the coercer demands the voter cast a ballot
with a specific, identifying pattern. Here we propose an approach to tallying
end-to-end verifiable schemes that avoids revealing all the votes but still
achieves whatever confidence level in the announced result is desired. Now a
coerced voter can claim that the required vote must be amongst those that
remained shrouded. Our approach is based on the well-established notion of
Risk-Limiting Audits, but here applied to the tally rather than to the audit.
We show that this approach counters coercion threats arising in extreme tallies
and ""Italian"" attacks. We illustrate our approach by applying it to the Selene
scheme, and we extend the approach to Risk-Limiting Verification, where not all
vote trackers are revealed, thereby enhancing the coercion mitigation
properties of Selene.",1908.04947v1,cs.CR,2019-08-14 04:23:10+00:00,"[arxiv.Result.Author('Wojciech Jamroga'), arxiv.Result.Author('Peter B. Roenne'), arxiv.Result.Author('Peter Y. A. Ryan'), arxiv.Result.Author('Philip B. Stark')]",
793,A Sharper discrepancy measure for post-election audits,"Post-election audits use the discrepancy between machine counts and a hand
tally of votes in a random sample of precincts to infer whether error affected
the electoral outcome. The maximum relative overstatement of pairwise margins
(MRO) quantifies that discrepancy. The electoral outcome a full hand tally
shows must agree with the apparent outcome if the MRO is less than 1. This
condition is sharper than previous ones when there are more than two candidates
or when voters may vote for more than one candidate. For the 2006 U.S. Senate
race in Minnesota, a test using MRO gives a $P$-value of 4.05% for the
hypothesis that a full hand tally would find a different winner, less than half
the value Stark [Ann. Appl. Statist. 2 (2008) 550--581] finds.",0811.1697v1,stat.AP,2008-11-11 12:22:39+00:00,[arxiv.Result.Author('Philip B. Stark')],"Annals of Applied Statistics 2008, Vol. 2, No. 3, 982-985"
794,"Exact, Efficient and Information-Theoretically Secure Voting with an Arbitrary Number of Cheaters","We present three voting protocols with unconditional privacy and correctness,
without assuming any bound on the number of corrupt participants. All protocols
have polynomial complexity and require private channels and a simultaneous
broadcast channel. Unlike previously proposed protocols in this model, the
protocols that we present deterministically output the exact tally. Our first
protocol is a basic voting scheme which allows voters to interact in order to
compute the tally. Privacy of the ballot is unconditional in the sense that
regardless of the behavior of the dishonest participants nothing can be learned
through the protocol that could not be learned in an ideal realisation.
Unfortunately, a single dishonest participant can make the protocol abort, in
which case the dishonest participants can nevertheless learn the outcome of the
tally. Our second protocol introduces voting authorities which improves the
communication complexity by limiting interaction to be only between voters and
authorities and among the authorities themselves; the simultaneous broadcast is
also limited to the authorities. In the second protocol, as long as a single
authority is honest, the privacy is unconditional, however, a single corrupt
authority or a single corrupt voter can cause the protocol to abort. Our final
protocol provides a safeguard against corrupt voters by enabling a verification
technique to allow the authorities to revoke incorrect votes without aborting
the protocol. Finally, we discuss the implementation of a simultaneous
broadcast channel with the use of temporary computational assumptions, yielding
versions of our protocols that achieve everlasting security.",1011.5242v1,cs.CR,2010-11-23 21:33:50+00:00,"[arxiv.Result.Author('Anne Broadbent'), arxiv.Result.Author('Stacey Jeffery'), arxiv.Result.Author('Alain Tapp')]",
795,Dispute-free Scalable Open Vote Network using zk-SNARKs,"The Open Vote Network is a self-tallying decentralized e-voting protocol
suitable for boardroom elections. Currently, it has two Ethereum-based
implementations: the first, by McCorry et al., has a scalability issue since
all the computations are performed on-chain. The second implementation, by
Seifelnasr et al., solves this issue partially by assigning a part of the heavy
computations to an off-chain untrusted administrator in a verifiable manner. As
a side effect, this second implementation became not dispute-free; there is a
need for a tally dispute phase where an observer interrupts the protocol when
the administrator cheats, i.e., announces a wrong tally result. In this work,
we propose a new smart contract design to tackle the problems in the previous
implementations by (i) preforming all the heavy computations off-chain hence
achieving higher scalability, and (ii) utilizing zero-knowledge Succinct
Non-interactive Argument of Knowledge (zk-SNARK) to verify the correctness of
the off-chain computations, hence maintaining the dispute-free property. To
demonstrate the effectiveness of our design, we develop prototype
implementations on Ethereum and conduct multiple experiments for different
implementation options that show a trade-off between the zk-SNARK proof
generation time and the smart contract gas cost, including an implementation in
which the smart contract consumes a constant amount of gas independent of the
number of voters.",2203.03363v1,cs.CR,2022-03-07 13:12:28+00:00,"[arxiv.Result.Author('Muhammad ElSheikh'), arxiv.Result.Author('Amr M. Youssef')]",
796,Experiments with zeta zeros and Perron's formula,"Of what use are the zeros of the Riemann zeta function? We can use sums
involving zeta zeros to count the primes up to $x$. Perron's formula leads to
sums over zeta zeros that can count the squarefree integers up to $x$, or tally
Euler's $\phi$ function and other arithmetical functions. This is largely a
presentation of experimental results.",1103.6226v1,math.NT,2011-03-31 16:11:36+00:00,[arxiv.Result.Author('Robert Baillie')],
797,A Simple Voting Protocol on Quantum Blockchain,"This paper proposes a simple voting protocol based on quantum blockchain.
Besides being simple, our voting protocol is anonymous, binding, non-reusable,
verifiable, eligible, fair and self-tallying. Our protocol is also realizable
by the current technology.",1805.11979v2,quant-ph,2018-05-29 10:54:53+00:00,"[arxiv.Result.Author('Xin Sun'), arxiv.Result.Author('Quanlong Wang'), arxiv.Result.Author('Piotr Kulicki')]",
798,(Universal) Unconditional Verifiability in E-Voting without Trusted Parties,"In traditional e-voting protocols, privacy is often provided by a trusted
authority that learns the votes and computes the tally. Some protocols replace
the trusted authority by a set of authorities, and privacy is guaranteed if
less than a threshold number of authorities are corrupt. For verifiability,
stronger security guarantees are demanded. Typically, corrupt authorities that
try to fake the result of the tally must always be detected.
  To provide verifiability, many e-voting protocols use Non-Interactive
Zero-Knowledge proofs (NIZKs). Thanks to their non-interactive nature, NIZKs
allow anybody, including third parties that do not participate in the protocol,
to verify the correctness of the tally. Therefore, NIZKs can be used to obtain
universal verifiability. Additionally, NIZKs also improve usability because
they allow voters to cast a vote using a non-interactive protocol.
  The disadvantage of NIZKs is that their security is based on setup
assumptions such as the common reference string (CRS) or the random oracle (RO)
model. The former requires a trusted party for the generation of a common
reference string. The latter, though a popular methodology for designing secure
protocols, has been shown to be unsound.
  In this paper, we address the design of an e-voting protocol that provides
verifiability without any trust assumptions, where verifiability here is meant
without eligibility verification. We show that Non-Interactive
Witness-Indistinguishable proofs (NIWI) can be used for this purpose. The
e-voting scheme is private under the Decision Linear assumption, while
verifiability holds unconditionally. To our knowledge, this is the first
private e-voting scheme with perfect universal verifiability, i.e. one in which
the probability of a fake tally not being detected is 0, and with {\em
non-interactive} protocols that does not rely on trust assumptions.",1610.06343v1,cs.CR,2016-10-20 09:57:12+00:00,"[arxiv.Result.Author('Gina Gallegos-Garcia'), arxiv.Result.Author('Vincenzo Iovino'), arxiv.Result.Author('Alfredo Rial'), arxiv.Result.Author('Peter B. Roenne'), arxiv.Result.Author('Peter Y. A. Ryan')]",
799,Soliton stars in the breather limit,"This paper presents an asymptotic reduction of the Einstein-Klein-Gordon
system with real scalar field (""soliton star problem""). A periodic solution of
the reduced system, similar to the sine-Gordon breather, is obtained by a
variational method. This tallies with numerical computations. As a consequence,
a time-periodic redshift for sources close to the center of the star is
obtained.",1709.07760v1,gr-qc,2017-09-22 14:04:33+00:00,[arxiv.Result.Author('Satyanad Kichenassamy')],"Classical and Quantum Gravity, 25 (2008) 245004"
800,iOCR: Informed Optical Character Recognition for Election Ballot Tallies,"The purpose of this study is to explore the performance of Informed OCR or
iOCR. iOCR was developed with a spell correction algorithm to fix errors
introduced by conventional OCR for vote tabulation. The results found that the
iOCR system outperforms conventional OCR techniques.",2208.00865v1,cs.ET,2022-08-01 13:50:13+00:00,"[arxiv.Result.Author('Kenneth U. Oyibo'), arxiv.Result.Author('Jean D. Louis'), arxiv.Result.Author('Juan E. Gilbert')]",
801,"Electryo, In-person Voting with Transparent Voter Verifiability and Eligibility Verifiability","Selene is an e-voting protocol that allows voters to directly check their
individual vote, in cleartext, in the final tally via a tracker system, while
providing good coercion mitigation. This is in contrast to conventional,
end-to-end verifiable schemes in which the voter verifies the presence of an
encryption of her vote on the bulletin board. The Selene mechanism can be
applied to many e-voting schemes, but here we present an application to the
polling station context, resulting in a voter-verifiable electronic tally with
a paper audit trail. The system uses a smartcard-based public key system to
provide the individual verification and universal eligibility verifiability.
The paper record contains an encrypted link to the voter's identity, requiring
stronger assumptions on ballot privacy than normal paper voting, but with the
benefit of providing good auditability and dispute resolution as well as
supporting (comparison) risk limiting audits.",2105.14783v1,cs.CR,2021-05-31 08:22:29+00:00,"[arxiv.Result.Author('Peter B. Roenne'), arxiv.Result.Author('Peter Y. A Ryan'), arxiv.Result.Author('Marie-Laure Zollinger')]",
802,TRIP: Trustless Coercion-Resistant In-Person Voter Registration,"Most existing remote electronic voting systems are vulnerable to voter
coercion and vote buying. While coercion-resistant voting systems address this
challenge, current schemes assume that the voter has access to an untappable,
incorruptible device during voter registration. We present TRIP, an in-person
voter registration scheme enabling voters to create verifiable and
indistinguishable real and fake credentials using an untrusted kiosk inside a
privacy booth at a supervised location, e.g., the registrar's office. TRIP
ensures the integrity of the voter's real credential while enabling the
creation of fake credentials using interactive zero-knowledge proofs between
the voter as the verifier and the kiosk as the prover, unbeknownst to the
average voter. TRIP ensures that even voters who are under extreme coercion,
and cannot leave the booth with a real credential, can delegate their vote to a
political party, with the caveat that they must then trust the kiosk. TRIP
optimizes the tallying process by limiting the number of credentials a voter
can receive and capping the number of votes that a credential can cast per
election. We conduct a preliminary usability study among 41 participants at a
university and found that 42.5% of participants rated TRIP a B or higher in
usability, a promising result for a voter registration scheme that
substantially reduces trust in the registrar.",2202.06692v1,cs.CR,2022-02-14 13:35:46+00:00,"[arxiv.Result.Author('Louis-Henri Merino'), arxiv.Result.Author('Simone Colombo'), arxiv.Result.Author('Jeff Allen'), arxiv.Result.Author('Vero Estrada-Galiñanes'), arxiv.Result.Author('Bryan Ford')]",
803,BVOT: Self-Tallying Boardroom Voting with Oblivious Transfer,"A boardroom election is an election with a small number of voters carried out
with public communications. We present BVOT, a self-tallying boardroom voting
protocol with ballot secrecy, fairness (no tally information is available
before the polls close), and dispute-freeness (voters can observe that all
voters correctly followed the protocol).
  BVOT works by using a multiparty threshold homomorphic encryption system in
which each candidate is associated with a masked unique prime. Each voter
engages in an oblivious transfer with an untrusted distributor: the voter
selects the index of a prime associated with a candidate and receives the
selected prime in masked form. The voter then casts their vote by encrypting
their masked prime and broadcasting it to everyone. The distributor does not
learn the voter's choice, and no one learns the mapping between primes and
candidates until the audit phase. By hiding the mapping between primes and
candidates, BVOT provides voters with insufficient information to carry out
effective cheating. The threshold feature prevents anyone from computing any
partial tally---until everyone has voted. Multiplying all votes, their
decryption shares, and the unmasking factor yields a product of the primes each
raised to the number of votes received.
  In contrast to some existing boardroom voting protocols, BVOT does not rely
on any zero-knowledge proof; instead, it uses oblivious transfer to assure
ballot secrecy and correct vote casting. Also, BVOT can handle multiple
candidates in one election. BVOT prevents cheating by hiding crucial
information: an attempt to increase the tally of one candidate might increase
the tally of another candidate. After all votes are cast, any party can tally
the votes.",2010.02421v1,cs.CR,2020-10-06 01:28:34+00:00,"[arxiv.Result.Author('Farid Javani'), arxiv.Result.Author('Alan T. Sherman')]",
804,SimAEN -- Simulated Automated Exposure Notification,"Mitigation strategies that remove infectious individuals from the greater
population have to balance their efficacy with the economic effects associated
with quarantine and have to contend with the limited resources available to the
public health authorities. Prior strategies have relied on testing and contact
tracing to find individuals before they become infectious and in order to limit
their interactions with others until after their infectious period has passed.
Manual contact tracing is a public health intervention where individuals
testing positive are interviewed to identify other members of the community who
they may have come into contact with. These interviews can take a significant
amount of time that has to be tallied in the overall accounting of the outbreak
cost. The concept of contact tracing has been expanded recently into Automated
Exposure Notification whereby cellphones can be used as sensor platforms to log
close contacts and notify the owner in the event that one of their close
contacts tests positive. The intention is that this notification will prompt
the person to be tested and then restrict their interactions with others until
their status is determined. In this paper we describe our efforts to
investigate the effectiveness of contact tracing interventions on controlling
an outbreak. This is accomplished by creating a model of disease spread and
then observing the impact that simulated tracing and testing have on the number
of infected individuals. Model parameters are explored to identify critical
transition points where interventions become effective. We estimate the
benefits as well as costs in order to offer insight to public health officials
as they select courses of action.",2012.04399v1,q-bio.QM,2020-12-08 12:36:27+00:00,"[arxiv.Result.Author('Ted Londner'), arxiv.Result.Author('Jonathan Saunders'), arxiv.Result.Author('Dieter W. Schuldt'), arxiv.Result.Author('Bill Streilein')]",
805,Multi-Domain Long-Tailed Learning by Augmenting Disentangled Representations,"There is an inescapable long-tailed class-imbalance issue in many real-world
classification problems. Existing long-tailed classification methods focus on
the single-domain setting, where all examples are drawn from the same
distribution. However, real-world scenarios often involve multiple domains with
distinct imbalanced class distributions. We study this multi-domain long-tailed
learning problem and aim to produce a model that generalizes well across all
classes and domains. Towards that goal, we introduce TALLY, which produces
invariant predictors by balanced augmenting hidden representations over domains
and classes. Built upon a proposed selective balanced sampling strategy, TALLY
achieves this by mixing the semantic representation of one example with the
domain-associated nuisances of another, producing a new representation for use
as data augmentation. To improve the disentanglement of semantic
representations, TALLY further utilizes a domain-invariant class prototype that
averages out domain-specific effects. We evaluate TALLY on four long-tailed
variants of classical domain generalization benchmarks and two real-world
imbalanced multi-domain datasets. The results indicate that TALLY consistently
outperforms other state-of-the-art methods in both subpopulation shift and
domain shift.",2210.14358v1,cs.LG,2022-10-25 21:54:26+00:00,"[arxiv.Result.Author('Huaxiu Yao'), arxiv.Result.Author('Xinyu Yang'), arxiv.Result.Author('Allan Zhou'), arxiv.Result.Author('Chelsea Finn')]",
806,A Blockchain-based Self-tallying Voting Scheme in Decentralized IoT,"The Internet of Things (IoT) is experiencing explosive growth and has gained
extensive attention from academia and industry in recent years. Most of the
existing IoT infrastructures are centralized, in which the presence of a cloud
server is mandatory. However, centralized frameworks suffer from the issues of
unscalability and single-point-of-failure. Consequently, decentralized IoT has
been proposed by taking advantage of the emerging technology of Blockchain.
Voting systems are widely adopted in IoT, such as a leader election in wireless
sensor networks. Self-tallying voting systems are alternatives to traditional
centralized voting systems in decentralized IoT since the traditional ones are
not suitable for such scenarios. Unfortunately, self-tallying voting systems
inherently suffer from fairness issues, such as adaptive and abortive issues
caused by malicious voters. In this paper, we introduce a framework of
self-tallying systems in decentralized IoT based on Blockchain. We propose a
concrete construction and prove the proposed system satisfies all the security
requirements including fairness, dispute-freeness and maximal ballot secrecy.
The implementations on mobile phones demonstrate the practicability of our
system.",1902.03710v1,cs.CR,2019-02-11 03:28:55+00:00,"[arxiv.Result.Author('Yannan Li'), arxiv.Result.Author('Willy Susilo'), arxiv.Result.Author('Guomin Yang'), arxiv.Result.Author('Yong Yu'), arxiv.Result.Author('Dongxi Liu'), arxiv.Result.Author('Mohsen Guizani')]",
807,Complete Policy Regret Bounds for Tallying Bandits,"Policy regret is a well established notion of measuring the performance of an
online learning algorithm against an adaptive adversary. We study restrictions
on the adversary that enable efficient minimization of the \emph{complete
policy regret}, which is the strongest possible version of policy regret. We
identify a gap in the current theoretical understanding of what sorts of
restrictions permit tractability in this challenging setting. To resolve this
gap, we consider a generalization of the stochastic multi armed bandit, which
we call the \emph{tallying bandit}. This is an online learning setting with an
$m$-memory bounded adversary, where the average loss for playing an action is
an unknown function of the number (or tally) of times that the action was
played in the last $m$ timesteps. For tallying bandit problems with $K$ actions
and time horizon $T$, we provide an algorithm that w.h.p achieves a complete
policy regret guarantee of $\tilde{\mathcal{O}}(mK\sqrt{T})$, where the
$\tilde{\mathcal{O}}$ notation hides only logarithmic factors. We additionally
prove an $\tilde\Omega(\sqrt{m K T})$ lower bound on the expected complete
policy regret of any tallying bandit algorithm, demonstrating the near
optimality of our method.",2204.11174v1,stat.ML,2022-04-24 03:10:27+00:00,"[arxiv.Result.Author('Dhruv Malik'), arxiv.Result.Author('Yuanzhi Li'), arxiv.Result.Author('Aarti Singh')]",
808,SBvote: Scalable Self-Tallying Blockchain-Based Voting,"Decentralized electronic voting solutions represent a promising advancement
in electronic voting. One of the e-voting paradigms, the self-tallying scheme,
offers strong protection of the voters' privacy while making the whole voting
process verifiable. Decentralized smart contract platforms became interesting
practical instantiation of the immutable bulletin board that this scheme
requires to preserve its properties. Existing smart contract-based approaches
employing the self-tallying scheme (such as OVN or BBB-Voting) are only
suitable for a boardroom voting scenario due to their scalability limitation.
The goal of our work is to build on existing solutions to achieve scalability
without losing privacy guarantees and verifiability. We present SBvote, a
blockchain-based self-tallying voting protocol that is scalable in the number
of voters and therefore suitable for large-scale elections. The evaluation of
our proof-of-concept implementation shows that the protocol's scalability is
limited only by the underlying blockchain platform. We evaluated the
scalability of SBvote on two public smart contract platforms -- Gnosis and
Harmony. Despite the limitations imposed by the throughput of the blockchain
platform, SBvote can accommodate elections with millions of voters.",2206.06019v1,cs.CR,2022-06-13 10:18:00+00:00,"[arxiv.Result.Author('Ivana Stančíková'), arxiv.Result.Author('Ivan Homoliak')]",
809,Exploiting re-voting in the Helios election system,"Election systems must ensure that representatives are chosen by voters.
Moreover, each voter should have equal influence. Traditionally, this has been
achieved by permitting voters to cast at most one ballot. More recently, this
has been achieved by tallying the last ballot cast by each voter. We show this
is not achieved by the Helios election system, because an adversary can cause a
ballot other than a voter's last to be tallied. Moreover, we show how the
adversary can choose the contents of such a ballot, thus the adversary can
unduly influence the selection of representatives.",1612.04099v3,cs.CR,2016-12-13 11:07:22+00:00,"[arxiv.Result.Author('Maxime Meyer'), arxiv.Result.Author('Ben Smyth')]",
810,Computational Complexity of Space-Bounded Real Numbers,"In this work we study the space complexity of computable real numbers
represented by fast convergent Cauchy sequences. We show the existence of
families of trascendental numbers which are logspace computable, as opposed to
algebraic irrational numbers which seem to required linear space. We
characterized the complexity of space-bounded real numbers by quantifying the
space complexities of tally sets. The latter result introduces a technique to
prove the space complexity of real numbers by studying its corresponding tally
sets, which is arguably a more natural approach. Results of this work present a
new approach to study real numbers whose transcendence is unknown.",1805.02572v1,cs.CC,2018-05-07 15:28:31+00:00,"[arxiv.Result.Author('Masaki Nakanishi'), arxiv.Result.Author('Marcos Villagra')]",
811,Information-Theoretic Secure and Private Voting System,"In this paper, we present a private voting system that consists of N
authorized voters who may vote to one of the K candidates or vote abstain. Each
voter wants to compute the final tally while staying private and robust against
malicious voters, who try to gain information about the vote of the other
voters beyond the final result, or send incorrect information to affect the
final tally. We design an information-theoretic private voting system based on
Shamir secret sharing, which is secure and robust as long as there are up to
(N-1)/3 malicious voters.",2203.07355v1,cs.IT,2022-03-14 17:53:35+00:00,"[arxiv.Result.Author('Seyed Reza Hoseini Najarkolaei'), arxiv.Result.Author('Narges Kazempour'), arxiv.Result.Author('Hasti Rostami'), arxiv.Result.Author('Mohammad Reza Aref')]",
812,Electrochemical polymerization of anilinium hydrochloride,"Electropolymerization of anilinium hydrochloride was carried out on platinum
plate electrode in a protic medium by cyclic voltammetry. The effects on the
electrodeposition of the sweep rate, monomer concentration, pH of the medium
and electrode nature are discussed.",1307.5668v1,cond-mat.mtrl-sci,2013-07-22 12:08:26+00:00,"[arxiv.Result.Author('Yomen Atassi'), arxiv.Result.Author('Mohammad Tally')]",
813,Risk-Limiting Tallies,"Many voter-verifiable, coercion-resistant schemes have been proposed, but
even the most carefully designed systems necessarily leak information via the
announced result. In corner cases, this may be problematic. For example, if all
the votes go to one candidate then all vote privacy evaporates. The mere
possibility of candidates getting no or few votes could have implications for
security in practice: if a coercer demands that a voter cast a vote for such an
unpopular candidate, then the voter may feel obliged to obey, even if she is
confident that the voting system satisfies the standard coercion resistance
definitions. With complex ballots, there may also be a danger of ""Italian""
style (aka ""signature"") attacks: the coercer demands the voter cast a ballot
with a specific, identifying pattern. Here we propose an approach to tallying
end-to-end verifiable schemes that avoids revealing all the votes but still
achieves whatever confidence level in the announced result is desired. Now a
coerced voter can claim that the required vote must be amongst those that
remained shrouded. Our approach is based on the well-established notion of
Risk-Limiting Audits, but here applied to the tally rather than to the audit.
We show that this approach counters coercion threats arising in extreme tallies
and ""Italian"" attacks. We illustrate our approach by applying it to the Selene
scheme, and we extend the approach to Risk-Limiting Verification, where not all
vote trackers are revealed, thereby enhancing the coercion mitigation
properties of Selene.",1908.04947v1,cs.CR,2019-08-14 04:23:10+00:00,"[arxiv.Result.Author('Wojciech Jamroga'), arxiv.Result.Author('Peter B. Roenne'), arxiv.Result.Author('Peter Y. A. Ryan'), arxiv.Result.Author('Philip B. Stark')]",
814,A Sharper discrepancy measure for post-election audits,"Post-election audits use the discrepancy between machine counts and a hand
tally of votes in a random sample of precincts to infer whether error affected
the electoral outcome. The maximum relative overstatement of pairwise margins
(MRO) quantifies that discrepancy. The electoral outcome a full hand tally
shows must agree with the apparent outcome if the MRO is less than 1. This
condition is sharper than previous ones when there are more than two candidates
or when voters may vote for more than one candidate. For the 2006 U.S. Senate
race in Minnesota, a test using MRO gives a $P$-value of 4.05% for the
hypothesis that a full hand tally would find a different winner, less than half
the value Stark [Ann. Appl. Statist. 2 (2008) 550--581] finds.",0811.1697v1,stat.AP,2008-11-11 12:22:39+00:00,[arxiv.Result.Author('Philip B. Stark')],"Annals of Applied Statistics 2008, Vol. 2, No. 3, 982-985"
815,"Exact, Efficient and Information-Theoretically Secure Voting with an Arbitrary Number of Cheaters","We present three voting protocols with unconditional privacy and correctness,
without assuming any bound on the number of corrupt participants. All protocols
have polynomial complexity and require private channels and a simultaneous
broadcast channel. Unlike previously proposed protocols in this model, the
protocols that we present deterministically output the exact tally. Our first
protocol is a basic voting scheme which allows voters to interact in order to
compute the tally. Privacy of the ballot is unconditional in the sense that
regardless of the behavior of the dishonest participants nothing can be learned
through the protocol that could not be learned in an ideal realisation.
Unfortunately, a single dishonest participant can make the protocol abort, in
which case the dishonest participants can nevertheless learn the outcome of the
tally. Our second protocol introduces voting authorities which improves the
communication complexity by limiting interaction to be only between voters and
authorities and among the authorities themselves; the simultaneous broadcast is
also limited to the authorities. In the second protocol, as long as a single
authority is honest, the privacy is unconditional, however, a single corrupt
authority or a single corrupt voter can cause the protocol to abort. Our final
protocol provides a safeguard against corrupt voters by enabling a verification
technique to allow the authorities to revoke incorrect votes without aborting
the protocol. Finally, we discuss the implementation of a simultaneous
broadcast channel with the use of temporary computational assumptions, yielding
versions of our protocols that achieve everlasting security.",1011.5242v1,cs.CR,2010-11-23 21:33:50+00:00,"[arxiv.Result.Author('Anne Broadbent'), arxiv.Result.Author('Stacey Jeffery'), arxiv.Result.Author('Alain Tapp')]",
816,Phrase-Verified Voting: Verifiable Low-Tech Remote Boardroom Voting,"We present Phrase-Verified Voting, a voter-verifiable remote voting system
assembled from commercial off-the-shelf software for small private elections.
The system is transparent and enables each voter to verify that the tally
includes their ballot selection without requiring any understanding of
cryptography. This paper describes the system and its use in fall 2020, to vote
remotely in promotion committees in a university. Each voter fills out a form
in the cloud with their vote V (YES, NO, ABSTAIN) and a passphrase P-two words
entered by the voter. The system generates a verification prompt of the (P,V)
pairs and a tally of the votes, organized to help visualize how the votes add
up. After the polls close, each voter verifies that this table lists their
(P,V) pair and that the tally is computed correctly. The system is especially
appropriate for any small group making sensitive decisions. Because the system
would not prevent a coercer from demanding that their victim use a specified
passphrase, it is not designed for applications where such malfeasance would be
likely or go undetected. Results from 43 voters show that the system was
well-accepted, performed effectively for its intended purpose, and introduced
users to the concept of voter-verified elections. Compared to the commonly-used
alternatives of paper ballots or voting by email, voters found the system
easier to use, and that it provided greater privacy and outcome integrity.",2103.07180v1,cs.CR,2021-03-12 09:59:55+00:00,"[arxiv.Result.Author('Enka Blanchard'), arxiv.Result.Author('Ryan Robucci'), arxiv.Result.Author('Ted Selker'), arxiv.Result.Author('Alan Sherman')]",
817,Dispute-free Scalable Open Vote Network using zk-SNARKs,"The Open Vote Network is a self-tallying decentralized e-voting protocol
suitable for boardroom elections. Currently, it has two Ethereum-based
implementations: the first, by McCorry et al., has a scalability issue since
all the computations are performed on-chain. The second implementation, by
Seifelnasr et al., solves this issue partially by assigning a part of the heavy
computations to an off-chain untrusted administrator in a verifiable manner. As
a side effect, this second implementation became not dispute-free; there is a
need for a tally dispute phase where an observer interrupts the protocol when
the administrator cheats, i.e., announces a wrong tally result. In this work,
we propose a new smart contract design to tackle the problems in the previous
implementations by (i) preforming all the heavy computations off-chain hence
achieving higher scalability, and (ii) utilizing zero-knowledge Succinct
Non-interactive Argument of Knowledge (zk-SNARK) to verify the correctness of
the off-chain computations, hence maintaining the dispute-free property. To
demonstrate the effectiveness of our design, we develop prototype
implementations on Ethereum and conduct multiple experiments for different
implementation options that show a trade-off between the zk-SNARK proof
generation time and the smart contract gas cost, including an implementation in
which the smart contract consumes a constant amount of gas independent of the
number of voters.",2203.03363v1,cs.CR,2022-03-07 13:12:28+00:00,"[arxiv.Result.Author('Muhammad ElSheikh'), arxiv.Result.Author('Amr M. Youssef')]",
818,Experiments with zeta zeros and Perron's formula,"Of what use are the zeros of the Riemann zeta function? We can use sums
involving zeta zeros to count the primes up to $x$. Perron's formula leads to
sums over zeta zeros that can count the squarefree integers up to $x$, or tally
Euler's $\phi$ function and other arithmetical functions. This is largely a
presentation of experimental results.",1103.6226v1,math.NT,2011-03-31 16:11:36+00:00,[arxiv.Result.Author('Robert Baillie')],
819,A Simple Voting Protocol on Quantum Blockchain,"This paper proposes a simple voting protocol based on quantum blockchain.
Besides being simple, our voting protocol is anonymous, binding, non-reusable,
verifiable, eligible, fair and self-tallying. Our protocol is also realizable
by the current technology.",1805.11979v2,quant-ph,2018-05-29 10:54:53+00:00,"[arxiv.Result.Author('Xin Sun'), arxiv.Result.Author('Quanlong Wang'), arxiv.Result.Author('Piotr Kulicki')]",
820,(Universal) Unconditional Verifiability in E-Voting without Trusted Parties,"In traditional e-voting protocols, privacy is often provided by a trusted
authority that learns the votes and computes the tally. Some protocols replace
the trusted authority by a set of authorities, and privacy is guaranteed if
less than a threshold number of authorities are corrupt. For verifiability,
stronger security guarantees are demanded. Typically, corrupt authorities that
try to fake the result of the tally must always be detected.
  To provide verifiability, many e-voting protocols use Non-Interactive
Zero-Knowledge proofs (NIZKs). Thanks to their non-interactive nature, NIZKs
allow anybody, including third parties that do not participate in the protocol,
to verify the correctness of the tally. Therefore, NIZKs can be used to obtain
universal verifiability. Additionally, NIZKs also improve usability because
they allow voters to cast a vote using a non-interactive protocol.
  The disadvantage of NIZKs is that their security is based on setup
assumptions such as the common reference string (CRS) or the random oracle (RO)
model. The former requires a trusted party for the generation of a common
reference string. The latter, though a popular methodology for designing secure
protocols, has been shown to be unsound.
  In this paper, we address the design of an e-voting protocol that provides
verifiability without any trust assumptions, where verifiability here is meant
without eligibility verification. We show that Non-Interactive
Witness-Indistinguishable proofs (NIWI) can be used for this purpose. The
e-voting scheme is private under the Decision Linear assumption, while
verifiability holds unconditionally. To our knowledge, this is the first
private e-voting scheme with perfect universal verifiability, i.e. one in which
the probability of a fake tally not being detected is 0, and with {\em
non-interactive} protocols that does not rely on trust assumptions.",1610.06343v1,cs.CR,2016-10-20 09:57:12+00:00,"[arxiv.Result.Author('Gina Gallegos-Garcia'), arxiv.Result.Author('Vincenzo Iovino'), arxiv.Result.Author('Alfredo Rial'), arxiv.Result.Author('Peter B. Roenne'), arxiv.Result.Author('Peter Y. A. Ryan')]",
821,BVOT: Self-Tallying Boardroom Voting with Oblivious Transfer,"A boardroom election is an election with a small number of voters carried out
with public communications. We present BVOT, a self-tallying boardroom voting
protocol with ballot secrecy, fairness (no tally information is available
before the polls close), and dispute-freeness (voters can observe that all
voters correctly followed the protocol).
  BVOT works by using a multiparty threshold homomorphic encryption system in
which each candidate is associated with a masked unique prime. Each voter
engages in an oblivious transfer with an untrusted distributor: the voter
selects the index of a prime associated with a candidate and receives the
selected prime in masked form. The voter then casts their vote by encrypting
their masked prime and broadcasting it to everyone. The distributor does not
learn the voter's choice, and no one learns the mapping between primes and
candidates until the audit phase. By hiding the mapping between primes and
candidates, BVOT provides voters with insufficient information to carry out
effective cheating. The threshold feature prevents anyone from computing any
partial tally---until everyone has voted. Multiplying all votes, their
decryption shares, and the unmasking factor yields a product of the primes each
raised to the number of votes received.
  In contrast to some existing boardroom voting protocols, BVOT does not rely
on any zero-knowledge proof; instead, it uses oblivious transfer to assure
ballot secrecy and correct vote casting. Also, BVOT can handle multiple
candidates in one election. BVOT prevents cheating by hiding crucial
information: an attempt to increase the tally of one candidate might increase
the tally of another candidate. After all votes are cast, any party can tally
the votes.",2010.02421v1,cs.CR,2020-10-06 01:28:34+00:00,"[arxiv.Result.Author('Farid Javani'), arxiv.Result.Author('Alan T. Sherman')]",
822,Multi-Domain Long-Tailed Learning by Augmenting Disentangled Representations,"There is an inescapable long-tailed class-imbalance issue in many real-world
classification problems. Existing long-tailed classification methods focus on
the single-domain setting, where all examples are drawn from the same
distribution. However, real-world scenarios often involve multiple domains with
distinct imbalanced class distributions. We study this multi-domain long-tailed
learning problem and aim to produce a model that generalizes well across all
classes and domains. Towards that goal, we introduce TALLY, which produces
invariant predictors by balanced augmenting hidden representations over domains
and classes. Built upon a proposed selective balanced sampling strategy, TALLY
achieves this by mixing the semantic representation of one example with the
domain-associated nuisances of another, producing a new representation for use
as data augmentation. To improve the disentanglement of semantic
representations, TALLY further utilizes a domain-invariant class prototype that
averages out domain-specific effects. We evaluate TALLY on four long-tailed
variants of classical domain generalization benchmarks and two real-world
imbalanced multi-domain datasets. The results indicate that TALLY consistently
outperforms other state-of-the-art methods in both subpopulation shift and
domain shift.",2210.14358v1,cs.LG,2022-10-25 21:54:26+00:00,"[arxiv.Result.Author('Huaxiu Yao'), arxiv.Result.Author('Xinyu Yang'), arxiv.Result.Author('Allan Zhou'), arxiv.Result.Author('Chelsea Finn')]",
823,A Blockchain-based Self-tallying Voting Scheme in Decentralized IoT,"The Internet of Things (IoT) is experiencing explosive growth and has gained
extensive attention from academia and industry in recent years. Most of the
existing IoT infrastructures are centralized, in which the presence of a cloud
server is mandatory. However, centralized frameworks suffer from the issues of
unscalability and single-point-of-failure. Consequently, decentralized IoT has
been proposed by taking advantage of the emerging technology of Blockchain.
Voting systems are widely adopted in IoT, such as a leader election in wireless
sensor networks. Self-tallying voting systems are alternatives to traditional
centralized voting systems in decentralized IoT since the traditional ones are
not suitable for such scenarios. Unfortunately, self-tallying voting systems
inherently suffer from fairness issues, such as adaptive and abortive issues
caused by malicious voters. In this paper, we introduce a framework of
self-tallying systems in decentralized IoT based on Blockchain. We propose a
concrete construction and prove the proposed system satisfies all the security
requirements including fairness, dispute-freeness and maximal ballot secrecy.
The implementations on mobile phones demonstrate the practicability of our
system.",1902.03710v1,cs.CR,2019-02-11 03:28:55+00:00,"[arxiv.Result.Author('Yannan Li'), arxiv.Result.Author('Willy Susilo'), arxiv.Result.Author('Guomin Yang'), arxiv.Result.Author('Yong Yu'), arxiv.Result.Author('Dongxi Liu'), arxiv.Result.Author('Mohsen Guizani')]",
824,Complete Policy Regret Bounds for Tallying Bandits,"Policy regret is a well established notion of measuring the performance of an
online learning algorithm against an adaptive adversary. We study restrictions
on the adversary that enable efficient minimization of the \emph{complete
policy regret}, which is the strongest possible version of policy regret. We
identify a gap in the current theoretical understanding of what sorts of
restrictions permit tractability in this challenging setting. To resolve this
gap, we consider a generalization of the stochastic multi armed bandit, which
we call the \emph{tallying bandit}. This is an online learning setting with an
$m$-memory bounded adversary, where the average loss for playing an action is
an unknown function of the number (or tally) of times that the action was
played in the last $m$ timesteps. For tallying bandit problems with $K$ actions
and time horizon $T$, we provide an algorithm that w.h.p achieves a complete
policy regret guarantee of $\tilde{\mathcal{O}}(mK\sqrt{T})$, where the
$\tilde{\mathcal{O}}$ notation hides only logarithmic factors. We additionally
prove an $\tilde\Omega(\sqrt{m K T})$ lower bound on the expected complete
policy regret of any tallying bandit algorithm, demonstrating the near
optimality of our method.",2204.11174v1,stat.ML,2022-04-24 03:10:27+00:00,"[arxiv.Result.Author('Dhruv Malik'), arxiv.Result.Author('Yuanzhi Li'), arxiv.Result.Author('Aarti Singh')]",
825,SBvote: Scalable Self-Tallying Blockchain-Based Voting,"Decentralized electronic voting solutions represent a promising advancement
in electronic voting. One of the e-voting paradigms, the self-tallying scheme,
offers strong protection of the voters' privacy while making the whole voting
process verifiable. Decentralized smart contract platforms became interesting
practical instantiation of the immutable bulletin board that this scheme
requires to preserve its properties. Existing smart contract-based approaches
employing the self-tallying scheme (such as OVN or BBB-Voting) are only
suitable for a boardroom voting scenario due to their scalability limitation.
The goal of our work is to build on existing solutions to achieve scalability
without losing privacy guarantees and verifiability. We present SBvote, a
blockchain-based self-tallying voting protocol that is scalable in the number
of voters and therefore suitable for large-scale elections. The evaluation of
our proof-of-concept implementation shows that the protocol's scalability is
limited only by the underlying blockchain platform. We evaluated the
scalability of SBvote on two public smart contract platforms -- Gnosis and
Harmony. Despite the limitations imposed by the throughput of the blockchain
platform, SBvote can accommodate elections with millions of voters.",2206.06019v1,cs.CR,2022-06-13 10:18:00+00:00,"[arxiv.Result.Author('Ivana Stančíková'), arxiv.Result.Author('Ivan Homoliak')]",
826,Exploiting re-voting in the Helios election system,"Election systems must ensure that representatives are chosen by voters.
Moreover, each voter should have equal influence. Traditionally, this has been
achieved by permitting voters to cast at most one ballot. More recently, this
has been achieved by tallying the last ballot cast by each voter. We show this
is not achieved by the Helios election system, because an adversary can cause a
ballot other than a voter's last to be tallied. Moreover, we show how the
adversary can choose the contents of such a ballot, thus the adversary can
unduly influence the selection of representatives.",1612.04099v3,cs.CR,2016-12-13 11:07:22+00:00,"[arxiv.Result.Author('Maxime Meyer'), arxiv.Result.Author('Ben Smyth')]",
827,Computational Complexity of Space-Bounded Real Numbers,"In this work we study the space complexity of computable real numbers
represented by fast convergent Cauchy sequences. We show the existence of
families of trascendental numbers which are logspace computable, as opposed to
algebraic irrational numbers which seem to required linear space. We
characterized the complexity of space-bounded real numbers by quantifying the
space complexities of tally sets. The latter result introduces a technique to
prove the space complexity of real numbers by studying its corresponding tally
sets, which is arguably a more natural approach. Results of this work present a
new approach to study real numbers whose transcendence is unknown.",1805.02572v1,cs.CC,2018-05-07 15:28:31+00:00,"[arxiv.Result.Author('Masaki Nakanishi'), arxiv.Result.Author('Marcos Villagra')]",
828,Information-Theoretic Secure and Private Voting System,"In this paper, we present a private voting system that consists of N
authorized voters who may vote to one of the K candidates or vote abstain. Each
voter wants to compute the final tally while staying private and robust against
malicious voters, who try to gain information about the vote of the other
voters beyond the final result, or send incorrect information to affect the
final tally. We design an information-theoretic private voting system based on
Shamir secret sharing, which is secure and robust as long as there are up to
(N-1)/3 malicious voters.",2203.07355v1,cs.IT,2022-03-14 17:53:35+00:00,"[arxiv.Result.Author('Seyed Reza Hoseini Najarkolaei'), arxiv.Result.Author('Narges Kazempour'), arxiv.Result.Author('Hasti Rostami'), arxiv.Result.Author('Mohammad Reza Aref')]",
829,Electrochemical polymerization of anilinium hydrochloride,"Electropolymerization of anilinium hydrochloride was carried out on platinum
plate electrode in a protic medium by cyclic voltammetry. The effects on the
electrodeposition of the sweep rate, monomer concentration, pH of the medium
and electrode nature are discussed.",1307.5668v1,cond-mat.mtrl-sci,2013-07-22 12:08:26+00:00,"[arxiv.Result.Author('Yomen Atassi'), arxiv.Result.Author('Mohammad Tally')]",
830,Risk-Limiting Tallies,"Many voter-verifiable, coercion-resistant schemes have been proposed, but
even the most carefully designed systems necessarily leak information via the
announced result. In corner cases, this may be problematic. For example, if all
the votes go to one candidate then all vote privacy evaporates. The mere
possibility of candidates getting no or few votes could have implications for
security in practice: if a coercer demands that a voter cast a vote for such an
unpopular candidate, then the voter may feel obliged to obey, even if she is
confident that the voting system satisfies the standard coercion resistance
definitions. With complex ballots, there may also be a danger of ""Italian""
style (aka ""signature"") attacks: the coercer demands the voter cast a ballot
with a specific, identifying pattern. Here we propose an approach to tallying
end-to-end verifiable schemes that avoids revealing all the votes but still
achieves whatever confidence level in the announced result is desired. Now a
coerced voter can claim that the required vote must be amongst those that
remained shrouded. Our approach is based on the well-established notion of
Risk-Limiting Audits, but here applied to the tally rather than to the audit.
We show that this approach counters coercion threats arising in extreme tallies
and ""Italian"" attacks. We illustrate our approach by applying it to the Selene
scheme, and we extend the approach to Risk-Limiting Verification, where not all
vote trackers are revealed, thereby enhancing the coercion mitigation
properties of Selene.",1908.04947v1,cs.CR,2019-08-14 04:23:10+00:00,"[arxiv.Result.Author('Wojciech Jamroga'), arxiv.Result.Author('Peter B. Roenne'), arxiv.Result.Author('Peter Y. A. Ryan'), arxiv.Result.Author('Philip B. Stark')]",
831,A Sharper discrepancy measure for post-election audits,"Post-election audits use the discrepancy between machine counts and a hand
tally of votes in a random sample of precincts to infer whether error affected
the electoral outcome. The maximum relative overstatement of pairwise margins
(MRO) quantifies that discrepancy. The electoral outcome a full hand tally
shows must agree with the apparent outcome if the MRO is less than 1. This
condition is sharper than previous ones when there are more than two candidates
or when voters may vote for more than one candidate. For the 2006 U.S. Senate
race in Minnesota, a test using MRO gives a $P$-value of 4.05% for the
hypothesis that a full hand tally would find a different winner, less than half
the value Stark [Ann. Appl. Statist. 2 (2008) 550--581] finds.",0811.1697v1,stat.AP,2008-11-11 12:22:39+00:00,[arxiv.Result.Author('Philip B. Stark')],"Annals of Applied Statistics 2008, Vol. 2, No. 3, 982-985"
832,"Exact, Efficient and Information-Theoretically Secure Voting with an Arbitrary Number of Cheaters","We present three voting protocols with unconditional privacy and correctness,
without assuming any bound on the number of corrupt participants. All protocols
have polynomial complexity and require private channels and a simultaneous
broadcast channel. Unlike previously proposed protocols in this model, the
protocols that we present deterministically output the exact tally. Our first
protocol is a basic voting scheme which allows voters to interact in order to
compute the tally. Privacy of the ballot is unconditional in the sense that
regardless of the behavior of the dishonest participants nothing can be learned
through the protocol that could not be learned in an ideal realisation.
Unfortunately, a single dishonest participant can make the protocol abort, in
which case the dishonest participants can nevertheless learn the outcome of the
tally. Our second protocol introduces voting authorities which improves the
communication complexity by limiting interaction to be only between voters and
authorities and among the authorities themselves; the simultaneous broadcast is
also limited to the authorities. In the second protocol, as long as a single
authority is honest, the privacy is unconditional, however, a single corrupt
authority or a single corrupt voter can cause the protocol to abort. Our final
protocol provides a safeguard against corrupt voters by enabling a verification
technique to allow the authorities to revoke incorrect votes without aborting
the protocol. Finally, we discuss the implementation of a simultaneous
broadcast channel with the use of temporary computational assumptions, yielding
versions of our protocols that achieve everlasting security.",1011.5242v1,cs.CR,2010-11-23 21:33:50+00:00,"[arxiv.Result.Author('Anne Broadbent'), arxiv.Result.Author('Stacey Jeffery'), arxiv.Result.Author('Alain Tapp')]",
833,Phrase-Verified Voting: Verifiable Low-Tech Remote Boardroom Voting,"We present Phrase-Verified Voting, a voter-verifiable remote voting system
assembled from commercial off-the-shelf software for small private elections.
The system is transparent and enables each voter to verify that the tally
includes their ballot selection without requiring any understanding of
cryptography. This paper describes the system and its use in fall 2020, to vote
remotely in promotion committees in a university. Each voter fills out a form
in the cloud with their vote V (YES, NO, ABSTAIN) and a passphrase P-two words
entered by the voter. The system generates a verification prompt of the (P,V)
pairs and a tally of the votes, organized to help visualize how the votes add
up. After the polls close, each voter verifies that this table lists their
(P,V) pair and that the tally is computed correctly. The system is especially
appropriate for any small group making sensitive decisions. Because the system
would not prevent a coercer from demanding that their victim use a specified
passphrase, it is not designed for applications where such malfeasance would be
likely or go undetected. Results from 43 voters show that the system was
well-accepted, performed effectively for its intended purpose, and introduced
users to the concept of voter-verified elections. Compared to the commonly-used
alternatives of paper ballots or voting by email, voters found the system
easier to use, and that it provided greater privacy and outcome integrity.",2103.07180v1,cs.CR,2021-03-12 09:59:55+00:00,"[arxiv.Result.Author('Enka Blanchard'), arxiv.Result.Author('Ryan Robucci'), arxiv.Result.Author('Ted Selker'), arxiv.Result.Author('Alan Sherman')]",
834,Dispute-free Scalable Open Vote Network using zk-SNARKs,"The Open Vote Network is a self-tallying decentralized e-voting protocol
suitable for boardroom elections. Currently, it has two Ethereum-based
implementations: the first, by McCorry et al., has a scalability issue since
all the computations are performed on-chain. The second implementation, by
Seifelnasr et al., solves this issue partially by assigning a part of the heavy
computations to an off-chain untrusted administrator in a verifiable manner. As
a side effect, this second implementation became not dispute-free; there is a
need for a tally dispute phase where an observer interrupts the protocol when
the administrator cheats, i.e., announces a wrong tally result. In this work,
we propose a new smart contract design to tackle the problems in the previous
implementations by (i) preforming all the heavy computations off-chain hence
achieving higher scalability, and (ii) utilizing zero-knowledge Succinct
Non-interactive Argument of Knowledge (zk-SNARK) to verify the correctness of
the off-chain computations, hence maintaining the dispute-free property. To
demonstrate the effectiveness of our design, we develop prototype
implementations on Ethereum and conduct multiple experiments for different
implementation options that show a trade-off between the zk-SNARK proof
generation time and the smart contract gas cost, including an implementation in
which the smart contract consumes a constant amount of gas independent of the
number of voters.",2203.03363v1,cs.CR,2022-03-07 13:12:28+00:00,"[arxiv.Result.Author('Muhammad ElSheikh'), arxiv.Result.Author('Amr M. Youssef')]",
835,Experiments with zeta zeros and Perron's formula,"Of what use are the zeros of the Riemann zeta function? We can use sums
involving zeta zeros to count the primes up to $x$. Perron's formula leads to
sums over zeta zeros that can count the squarefree integers up to $x$, or tally
Euler's $\phi$ function and other arithmetical functions. This is largely a
presentation of experimental results.",1103.6226v1,math.NT,2011-03-31 16:11:36+00:00,[arxiv.Result.Author('Robert Baillie')],
836,A Simple Voting Protocol on Quantum Blockchain,"This paper proposes a simple voting protocol based on quantum blockchain.
Besides being simple, our voting protocol is anonymous, binding, non-reusable,
verifiable, eligible, fair and self-tallying. Our protocol is also realizable
by the current technology.",1805.11979v2,quant-ph,2018-05-29 10:54:53+00:00,"[arxiv.Result.Author('Xin Sun'), arxiv.Result.Author('Quanlong Wang'), arxiv.Result.Author('Piotr Kulicki')]",
837,(Universal) Unconditional Verifiability in E-Voting without Trusted Parties,"In traditional e-voting protocols, privacy is often provided by a trusted
authority that learns the votes and computes the tally. Some protocols replace
the trusted authority by a set of authorities, and privacy is guaranteed if
less than a threshold number of authorities are corrupt. For verifiability,
stronger security guarantees are demanded. Typically, corrupt authorities that
try to fake the result of the tally must always be detected.
  To provide verifiability, many e-voting protocols use Non-Interactive
Zero-Knowledge proofs (NIZKs). Thanks to their non-interactive nature, NIZKs
allow anybody, including third parties that do not participate in the protocol,
to verify the correctness of the tally. Therefore, NIZKs can be used to obtain
universal verifiability. Additionally, NIZKs also improve usability because
they allow voters to cast a vote using a non-interactive protocol.
  The disadvantage of NIZKs is that their security is based on setup
assumptions such as the common reference string (CRS) or the random oracle (RO)
model. The former requires a trusted party for the generation of a common
reference string. The latter, though a popular methodology for designing secure
protocols, has been shown to be unsound.
  In this paper, we address the design of an e-voting protocol that provides
verifiability without any trust assumptions, where verifiability here is meant
without eligibility verification. We show that Non-Interactive
Witness-Indistinguishable proofs (NIWI) can be used for this purpose. The
e-voting scheme is private under the Decision Linear assumption, while
verifiability holds unconditionally. To our knowledge, this is the first
private e-voting scheme with perfect universal verifiability, i.e. one in which
the probability of a fake tally not being detected is 0, and with {\em
non-interactive} protocols that does not rely on trust assumptions.",1610.06343v1,cs.CR,2016-10-20 09:57:12+00:00,"[arxiv.Result.Author('Gina Gallegos-Garcia'), arxiv.Result.Author('Vincenzo Iovino'), arxiv.Result.Author('Alfredo Rial'), arxiv.Result.Author('Peter B. Roenne'), arxiv.Result.Author('Peter Y. A. Ryan')]",
838,Soliton stars in the breather limit,"This paper presents an asymptotic reduction of the Einstein-Klein-Gordon
system with real scalar field (""soliton star problem""). A periodic solution of
the reduced system, similar to the sine-Gordon breather, is obtained by a
variational method. This tallies with numerical computations. As a consequence,
a time-periodic redshift for sources close to the center of the star is
obtained.",1709.07760v1,gr-qc,2017-09-22 14:04:33+00:00,[arxiv.Result.Author('Satyanad Kichenassamy')],"Classical and Quantum Gravity, 25 (2008) 245004"
839,iOCR: Informed Optical Character Recognition for Election Ballot Tallies,"The purpose of this study is to explore the performance of Informed OCR or
iOCR. iOCR was developed with a spell correction algorithm to fix errors
introduced by conventional OCR for vote tabulation. The results found that the
iOCR system outperforms conventional OCR techniques.",2208.00865v1,cs.ET,2022-08-01 13:50:13+00:00,"[arxiv.Result.Author('Kenneth U. Oyibo'), arxiv.Result.Author('Jean D. Louis'), arxiv.Result.Author('Juan E. Gilbert')]",
840,Tally NP Sets and Easy Census Functions,"We study the question of whether every P set has an easy (i.e.,
polynomial-time computable) census function. We characterize this question in
terms of unlikely collapses of language and function classes such as the
containment of #P_1 in FP, where #P_1 is the class of functions that count the
witnesses for tally NP sets. We prove that every #P_{1}^{PH} function can be
computed in FP^{#P_{1}^{#P_{1}}}. Consequently, every P set has an easy census
function if and only if every set in the polynomial hierarchy does. We show
that the assumption of #P_1 being contained in FP implies P = BPP and that PH
is contained in MOD_{k}P for each k \geq 2, which provides further evidence
that not all sets in P have an easy census function. We also relate a set's
property of having an easy census function to other well-studied properties of
sets, such as rankability and scalability (the closure of the rankable sets
under P-isomorphisms). Finally, we prove that it is no more likely that the
census function of any set in P can be approximated (more precisely, can be
n^{\alpha}-enumerated in time n^{\beta} for fixed \alpha and \beta) than that
it can be precisely computed in polynomial time.",cs/9809002v1,cs.CC,1998-09-01 12:15:55+00:00,"[arxiv.Result.Author('Judy Goldsmith'), arxiv.Result.Author('Mitsunori Ogihara'), arxiv.Result.Author('Joerg Rothe')]",
841,Information-Theoretic Secure and Private Voting System,"In this paper, we present a private voting system that consists of N
authorized voters who may vote to one of the K candidates or vote abstain. Each
voter wants to compute the final tally while staying private and robust against
malicious voters, who try to gain information about the vote of the other
voters beyond the final result, or send incorrect information to affect the
final tally. We design an information-theoretic private voting system based on
Shamir secret sharing, which is secure and robust as long as there are up to
(N-1)/3 malicious voters.",2203.07355v1,cs.IT,2022-03-14 17:53:35+00:00,"[arxiv.Result.Author('Seyed Reza Hoseini Najarkolaei'), arxiv.Result.Author('Narges Kazempour'), arxiv.Result.Author('Hasti Rostami'), arxiv.Result.Author('Mohammad Reza Aref')]",
842,Information-Theoretically Secure Voting Without an Honest Majority,"We present three voting protocols with unconditional privacy and
information-theoretic correctness, without assuming any bound on the number of
corrupt voters or voting authorities. All protocols have polynomial complexity
and require private channels and a simultaneous broadcast channel. Our first
protocol is a basic voting scheme which allows voters to interact in order to
compute the tally. Privacy of the ballot is unconditional, but any voter can
cause the protocol to fail, in which case information about the tally may
nevertheless transpire. Our second protocol introduces voting authorities which
allow the implementation of the first protocol, while reducing the interaction
and limiting it to be only between voters and authorities and among the
authorities themselves. The simultaneous broadcast is also limited to the
authorities. As long as a single authority is honest, the privacy is
unconditional, however, a single corrupt authority or a single corrupt voter
can cause the protocol to fail. Our final protocol provides a safeguard against
corrupt voters by enabling a verification technique to allow the authorities to
revoke incorrect votes. We also discuss the implementation of a simultaneous
broadcast channel with the use of temporary computational assumptions, yielding
versions of our protocols achieving everlasting security.",0806.1931v1,cs.CR,2008-06-11 18:51:04+00:00,"[arxiv.Result.Author('Anne Broadbent'), arxiv.Result.Author('Alain Tapp')]",
843,"Exact, Efficient and Information-Theoretically Secure Voting with an Arbitrary Number of Cheaters","We present three voting protocols with unconditional privacy and correctness,
without assuming any bound on the number of corrupt participants. All protocols
have polynomial complexity and require private channels and a simultaneous
broadcast channel. Unlike previously proposed protocols in this model, the
protocols that we present deterministically output the exact tally. Our first
protocol is a basic voting scheme which allows voters to interact in order to
compute the tally. Privacy of the ballot is unconditional in the sense that
regardless of the behavior of the dishonest participants nothing can be learned
through the protocol that could not be learned in an ideal realisation.
Unfortunately, a single dishonest participant can make the protocol abort, in
which case the dishonest participants can nevertheless learn the outcome of the
tally. Our second protocol introduces voting authorities which improves the
communication complexity by limiting interaction to be only between voters and
authorities and among the authorities themselves; the simultaneous broadcast is
also limited to the authorities. In the second protocol, as long as a single
authority is honest, the privacy is unconditional, however, a single corrupt
authority or a single corrupt voter can cause the protocol to abort. Our final
protocol provides a safeguard against corrupt voters by enabling a verification
technique to allow the authorities to revoke incorrect votes without aborting
the protocol. Finally, we discuss the implementation of a simultaneous
broadcast channel with the use of temporary computational assumptions, yielding
versions of our protocols that achieve everlasting security.",1011.5242v1,cs.CR,2010-11-23 21:33:50+00:00,"[arxiv.Result.Author('Anne Broadbent'), arxiv.Result.Author('Stacey Jeffery'), arxiv.Result.Author('Alain Tapp')]",
844,(Universal) Unconditional Verifiability in E-Voting without Trusted Parties,"In traditional e-voting protocols, privacy is often provided by a trusted
authority that learns the votes and computes the tally. Some protocols replace
the trusted authority by a set of authorities, and privacy is guaranteed if
less than a threshold number of authorities are corrupt. For verifiability,
stronger security guarantees are demanded. Typically, corrupt authorities that
try to fake the result of the tally must always be detected.
  To provide verifiability, many e-voting protocols use Non-Interactive
Zero-Knowledge proofs (NIZKs). Thanks to their non-interactive nature, NIZKs
allow anybody, including third parties that do not participate in the protocol,
to verify the correctness of the tally. Therefore, NIZKs can be used to obtain
universal verifiability. Additionally, NIZKs also improve usability because
they allow voters to cast a vote using a non-interactive protocol.
  The disadvantage of NIZKs is that their security is based on setup
assumptions such as the common reference string (CRS) or the random oracle (RO)
model. The former requires a trusted party for the generation of a common
reference string. The latter, though a popular methodology for designing secure
protocols, has been shown to be unsound.
  In this paper, we address the design of an e-voting protocol that provides
verifiability without any trust assumptions, where verifiability here is meant
without eligibility verification. We show that Non-Interactive
Witness-Indistinguishable proofs (NIWI) can be used for this purpose. The
e-voting scheme is private under the Decision Linear assumption, while
verifiability holds unconditionally. To our knowledge, this is the first
private e-voting scheme with perfect universal verifiability, i.e. one in which
the probability of a fake tally not being detected is 0, and with {\em
non-interactive} protocols that does not rely on trust assumptions.",1610.06343v1,cs.CR,2016-10-20 09:57:12+00:00,"[arxiv.Result.Author('Gina Gallegos-Garcia'), arxiv.Result.Author('Vincenzo Iovino'), arxiv.Result.Author('Alfredo Rial'), arxiv.Result.Author('Peter B. Roenne'), arxiv.Result.Author('Peter Y. A. Ryan')]",
845,An efficient and effective Decentralized Anonymous Voting System,"A trusted electronic election system requires that all the involved
information must go public, that is, it focuses not only on transparency but
also privacy issues. In other words, each ballot should be counted anonymously,
correctly, and efficiently. In this work, a lightweight E-voting system is
proposed for voters to minimize their trust in the authority or government. We
ensure the transparency of election by putting all message on the Ethereum
blockchain, in the meantime, the privacy of individual voter is protected via
an efficient and effective ring signature mechanism. Besides, the attractive
self-tallying feature is also built in our system, which guarantees that
everyone who can access the blockchain network is able to tally the result on
his own, no third party is required after voting phase. More importantly, we
ensure the correctness of voting results and keep the Ethereum gas cost of
individual participant as low as possible, at the same time. Clearly, the
pre-described characteristics make our system more suitable for large-scale
election.",1804.06674v1,cs.CR,2018-04-18 12:19:44+00:00,[arxiv.Result.Author('Wei-Jr Lai Ja-Ling Wu')],
846,Blind proxy voting,"A secret ballot mechanism that enables voting in absence is proposed. It
amends standard vote collection methods that use ballot box as anonymizer,
adding the option for absent voters to vote by a proxy blinded to the content
of the ballot paper. Votes are cast under unique and hidden identification
numbers generated solely for the purpose of that election. Voters prepare their
ballot papers from scratch and submit them to the tallying authority in two
parts via separate routes, each part being meaningless without the other.",1812.11128v1,cs.CR,2018-12-28 17:41:13+00:00,[arxiv.Result.Author('Zuzana Haniková')],
847,"ElectAnon: A Blockchain-Based, Anonymous, Robust and Scalable Ranked-Choice Voting Protocol","Remote voting has become more critical in recent years, especially after the
Covid-19 outbreak. Blockchain technology and its benefits like
decentralization, security, and transparency have encouraged remote voting
systems to use blockchains. Analysis of existing solutions reveals that
anonymity, robustness, and scalability are common problems in blockchain-based
election systems. In this work, we propose ElectAnon, a blockchain-based,
ranked-choice election protocol focusing on anonymity, robustness, and
scalability. ElectAnon achieves anonymity by enabling voters to cast their
votes via zero-knowledge proofs anonymously. Robustness is realized by removing
the direct control of the authorities in the voting process by using
timed-state machines. Results show that ElectAnon is scalable amongst existing
works as it reduces the gas consumption up to 89% compared to previous works.
The proposed protocol includes a candidate proposal system and swappable
tallying libraries. An extension is also proposed to minimize the trust
assumption on election authorities. Our code is available on
https://github.com/ceyonur/electanon.",2204.00057v2,cs.CR,2022-03-31 19:46:27+00:00,"[arxiv.Result.Author('Ceyhun Onur'), arxiv.Result.Author('Arda Yurdakul')]",
848,BVOT: Self-Tallying Boardroom Voting with Oblivious Transfer,"A boardroom election is an election with a small number of voters carried out
with public communications. We present BVOT, a self-tallying boardroom voting
protocol with ballot secrecy, fairness (no tally information is available
before the polls close), and dispute-freeness (voters can observe that all
voters correctly followed the protocol).
  BVOT works by using a multiparty threshold homomorphic encryption system in
which each candidate is associated with a masked unique prime. Each voter
engages in an oblivious transfer with an untrusted distributor: the voter
selects the index of a prime associated with a candidate and receives the
selected prime in masked form. The voter then casts their vote by encrypting
their masked prime and broadcasting it to everyone. The distributor does not
learn the voter's choice, and no one learns the mapping between primes and
candidates until the audit phase. By hiding the mapping between primes and
candidates, BVOT provides voters with insufficient information to carry out
effective cheating. The threshold feature prevents anyone from computing any
partial tally---until everyone has voted. Multiplying all votes, their
decryption shares, and the unmasking factor yields a product of the primes each
raised to the number of votes received.
  In contrast to some existing boardroom voting protocols, BVOT does not rely
on any zero-knowledge proof; instead, it uses oblivious transfer to assure
ballot secrecy and correct vote casting. Also, BVOT can handle multiple
candidates in one election. BVOT prevents cheating by hiding crucial
information: an attempt to increase the tally of one candidate might increase
the tally of another candidate. After all votes are cast, any party can tally
the votes.",2010.02421v1,cs.CR,2020-10-06 01:28:34+00:00,"[arxiv.Result.Author('Farid Javani'), arxiv.Result.Author('Alan T. Sherman')]",
849,Temporal Clustering of Disorder Events During the COVID-19 Pandemic,"The COVID-19 pandemic has unleashed multiple public health, socio-economic,
and institutional crises. Measures taken to slow the spread of the virus have
fostered significant strain between authorities and citizens, leading to waves
of social unrest and anti-government demonstrations. We study the temporal
nature of pandemic-related disorder events as tallied by the ""COVID-19 Disorder
Tracker"" initiative by focusing on the three countries with the largest number
of incidents, India, Israel, and Mexico. By fitting Poisson and Hawkes
processes to the stream of data, we find that disorder events are
inter-dependent and self-excite in all three countries. Geographic clustering
confirms these features at the subnational level, indicating that nationwide
disorders emerge as the convergence of meso-scale patterns of self-excitation.
Considerable diversity is observed among countries when computing correlations
of events between subnational clusters; these are discussed in the context of
specific political, societal and geographic characteristics. Israel, the most
territorially compact and where large scale protests were coordinated in
response to government lockdowns, displays the largest reactivity and the
shortest period of influence following an event, as well as the strongest
nationwide synchrony. In Mexico, where complete lockdown orders were never
mandated, reactivity and nationwide synchrony are lowest. Our work highlights
the need for authorities to promote local information campaigns to ensure that
livelihoods and virus containment policies are not perceived as mutually
exclusive.",2101.06458v2,physics.soc-ph,2021-01-16 15:34:42+00:00,"[arxiv.Result.Author('Gian Maria Campedelli'), arxiv.Result.Author(""Maria Rita D'Orsogna"")]","PLOS ONE, 16(4), e0250433 (2021)"
850,Multi-Domain Long-Tailed Learning by Augmenting Disentangled Representations,"There is an inescapable long-tailed class-imbalance issue in many real-world
classification problems. Existing long-tailed classification methods focus on
the single-domain setting, where all examples are drawn from the same
distribution. However, real-world scenarios often involve multiple domains with
distinct imbalanced class distributions. We study this multi-domain long-tailed
learning problem and aim to produce a model that generalizes well across all
classes and domains. Towards that goal, we introduce TALLY, which produces
invariant predictors by balanced augmenting hidden representations over domains
and classes. Built upon a proposed selective balanced sampling strategy, TALLY
achieves this by mixing the semantic representation of one example with the
domain-associated nuisances of another, producing a new representation for use
as data augmentation. To improve the disentanglement of semantic
representations, TALLY further utilizes a domain-invariant class prototype that
averages out domain-specific effects. We evaluate TALLY on four long-tailed
variants of classical domain generalization benchmarks and two real-world
imbalanced multi-domain datasets. The results indicate that TALLY consistently
outperforms other state-of-the-art methods in both subpopulation shift and
domain shift.",2210.14358v1,cs.LG,2022-10-25 21:54:26+00:00,"[arxiv.Result.Author('Huaxiu Yao'), arxiv.Result.Author('Xinyu Yang'), arxiv.Result.Author('Allan Zhou'), arxiv.Result.Author('Chelsea Finn')]",
851,A Peered Bulletin Board for Robust Use in Verifiable Voting Systems,"The Web Bulletin Board (WBB) is a key component of verifiable election
systems. It is used in the context of election verification to publish evidence
of voting and tallying that voters and officials can check, and where
challenges can be launched in the event of malfeasance. In practice, the
election authority has responsibility for implementing the web bulletin board
correctly and reliably, and will wish to ensure that it behaves correctly even
in the presence of failures and attacks. To ensure robustness, an
implementation will typically use a number of peers to be able to provide a
correct service even when some peers go down or behave dishonestly. In this
paper we propose a new protocol to implement such a Web Bulletin Board,
motivated by the needs of the vVote verifiable voting system. Using a
distributed algorithm increases the complexity of the protocol and requires
careful reasoning in order to establish correctness. Here we use the Event-B
modelling and refinement approach to establish correctness of the peered design
against an idealised specification of the bulletin board behaviour. In
particular we show that for n peers, a threshold of t > 2n/3 peers behaving
correctly is sufficient to ensure correct behaviour of the bulletin board
distributed design. The algorithm also behaves correctly even if honest or
dishonest peers temporarily drop out of the protocol and then return. The
verification approach also establishes that the protocols used within the
bulletin board do not interfere with each other. This is the first time a
peered web bulletin board suite of protocols has been formally verified.",1401.4151v1,cs.CR,2014-01-16 20:11:42+00:00,"[arxiv.Result.Author('Chris Culnane'), arxiv.Result.Author('Steve Schneider')]",
852,SimAEN -- Simulated Automated Exposure Notification,"Mitigation strategies that remove infectious individuals from the greater
population have to balance their efficacy with the economic effects associated
with quarantine and have to contend with the limited resources available to the
public health authorities. Prior strategies have relied on testing and contact
tracing to find individuals before they become infectious and in order to limit
their interactions with others until after their infectious period has passed.
Manual contact tracing is a public health intervention where individuals
testing positive are interviewed to identify other members of the community who
they may have come into contact with. These interviews can take a significant
amount of time that has to be tallied in the overall accounting of the outbreak
cost. The concept of contact tracing has been expanded recently into Automated
Exposure Notification whereby cellphones can be used as sensor platforms to log
close contacts and notify the owner in the event that one of their close
contacts tests positive. The intention is that this notification will prompt
the person to be tested and then restrict their interactions with others until
their status is determined. In this paper we describe our efforts to
investigate the effectiveness of contact tracing interventions on controlling
an outbreak. This is accomplished by creating a model of disease spread and
then observing the impact that simulated tracing and testing have on the number
of infected individuals. Model parameters are explored to identify critical
transition points where interventions become effective. We estimate the
benefits as well as costs in order to offer insight to public health officials
as they select courses of action.",2012.04399v1,q-bio.QM,2020-12-08 12:36:27+00:00,"[arxiv.Result.Author('Ted Londner'), arxiv.Result.Author('Jonathan Saunders'), arxiv.Result.Author('Dieter W. Schuldt'), arxiv.Result.Author('Bill Streilein')]",
853,Exploratory Analysis of Academic Collaborations between French and US,"International academic collaborations cultivate diversity in the research
landscape and facilitate multiperspective methods, as the scope of each
country's science depends on its needs, history, wealth etc. Moreover the
quality of science differ significantly amongst
nations\cite{king2004scientific}, which renders international collaborations a
potential source to understand the dynamics between countries and their
advancements. Analyzing these collaborations can reveal sharing expertise
between two countries in different fields, the most well-known institutions of
a nation, the overall success of collaborative efforts compared to local ones
etc. Such analysis were initially performed using statistical metrics
\cite{melin1996studying}, but network analysis has later proven much more
expressive \cite{wagner2005mapping,gonzalez2008coauthorship}. In this
exploratory analysis, we aim to examine the collaboration patterns between
French and US institutions. Towards this, we capitalize on the Microsoft
Academic Graph MAG \cite{sinha2015overview}, the largest open bibliographic
dataset that contains detailed information for authors, publications and
institutions. We use the coordinates of the world map to tally affiliations to
France or USA. In cases where the coordinates of an affiliation were absent, we
used its Wikipedia url and named entity recognition to identify the country of
its address in the Wikipedia page. We need to stress that institute names have
been volatile (due to University federations created) in the last decade in
France, so this is a best effort trial. The results indicate an intensive and
increasing scientific production in with , with certain institutions such as
Harvard, MIT and CNRS standing out.",2201.01346v2,cs.DL,2022-01-04 20:41:26+00:00,"[arxiv.Result.Author('George Panagopoulos'), arxiv.Result.Author('Michalis Vazirgiannis')]",
854,Methods for measuring the citations and productivity of scientists across time and discipline,"Publication statistics are ubiquitous in the ratings of scientific
achievement, with citation counts and paper tallies factoring into an
individual's consideration for postdoctoral positions, junior faculty, tenure,
and even visa status for international scientists. Citation statistics are
designed to quantify individual career achievement, both at the level of a
single publication, and over an individual's entire career. While some academic
careers are defined by a few significant papers (possibly out of many), other
academic careers are defined by the cumulative contribution made by the
author's publications to the body of science. Several metrics have been
formulated to quantify an individual's publication career, yet none of these
metrics account for the dependence of citation counts and journal size on time.
In this paper, we normalize publication metrics across both time and discipline
in order to achieve a universal framework for analyzing and comparing
scientific achievement. We study the publication careers of individual authors
over the 50-year period 1958-2008 within six high-impact journals: CELL, the
New England Journal of Medicine (NEJM), Nature, the Proceedings of the National
Academy of Science (PNAS), Physical Review Letters (PRL), and Science. In
comparing the achievement of authors within each journal, we uncover
quantifiable statistical regularity in the probability density function (pdf)
of scientific achievement across both time and discipline. The universal
distribution of career success within these arenas for publication raises the
possibility that a fundamental driving force underlying scientific achievement
is the competitive nature of scientific advancement.",0911.1322v2,physics.soc-ph,2009-11-06 18:30:57+00:00,"[arxiv.Result.Author('Alexander M. Petersen'), arxiv.Result.Author('Fengzhong Wang'), arxiv.Result.Author('H. Eugene Stanley')]","Phys. Rev. E 81, 036114 (2010)"
855,A Blockchain-based Self-tallying Voting Scheme in Decentralized IoT,"The Internet of Things (IoT) is experiencing explosive growth and has gained
extensive attention from academia and industry in recent years. Most of the
existing IoT infrastructures are centralized, in which the presence of a cloud
server is mandatory. However, centralized frameworks suffer from the issues of
unscalability and single-point-of-failure. Consequently, decentralized IoT has
been proposed by taking advantage of the emerging technology of Blockchain.
Voting systems are widely adopted in IoT, such as a leader election in wireless
sensor networks. Self-tallying voting systems are alternatives to traditional
centralized voting systems in decentralized IoT since the traditional ones are
not suitable for such scenarios. Unfortunately, self-tallying voting systems
inherently suffer from fairness issues, such as adaptive and abortive issues
caused by malicious voters. In this paper, we introduce a framework of
self-tallying systems in decentralized IoT based on Blockchain. We propose a
concrete construction and prove the proposed system satisfies all the security
requirements including fairness, dispute-freeness and maximal ballot secrecy.
The implementations on mobile phones demonstrate the practicability of our
system.",1902.03710v1,cs.CR,2019-02-11 03:28:55+00:00,"[arxiv.Result.Author('Yannan Li'), arxiv.Result.Author('Willy Susilo'), arxiv.Result.Author('Guomin Yang'), arxiv.Result.Author('Yong Yu'), arxiv.Result.Author('Dongxi Liu'), arxiv.Result.Author('Mohsen Guizani')]",
856,Complete Policy Regret Bounds for Tallying Bandits,"Policy regret is a well established notion of measuring the performance of an
online learning algorithm against an adaptive adversary. We study restrictions
on the adversary that enable efficient minimization of the \emph{complete
policy regret}, which is the strongest possible version of policy regret. We
identify a gap in the current theoretical understanding of what sorts of
restrictions permit tractability in this challenging setting. To resolve this
gap, we consider a generalization of the stochastic multi armed bandit, which
we call the \emph{tallying bandit}. This is an online learning setting with an
$m$-memory bounded adversary, where the average loss for playing an action is
an unknown function of the number (or tally) of times that the action was
played in the last $m$ timesteps. For tallying bandit problems with $K$ actions
and time horizon $T$, we provide an algorithm that w.h.p achieves a complete
policy regret guarantee of $\tilde{\mathcal{O}}(mK\sqrt{T})$, where the
$\tilde{\mathcal{O}}$ notation hides only logarithmic factors. We additionally
prove an $\tilde\Omega(\sqrt{m K T})$ lower bound on the expected complete
policy regret of any tallying bandit algorithm, demonstrating the near
optimality of our method.",2204.11174v1,stat.ML,2022-04-24 03:10:27+00:00,"[arxiv.Result.Author('Dhruv Malik'), arxiv.Result.Author('Yuanzhi Li'), arxiv.Result.Author('Aarti Singh')]",
857,SBvote: Scalable Self-Tallying Blockchain-Based Voting,"Decentralized electronic voting solutions represent a promising advancement
in electronic voting. One of the e-voting paradigms, the self-tallying scheme,
offers strong protection of the voters' privacy while making the whole voting
process verifiable. Decentralized smart contract platforms became interesting
practical instantiation of the immutable bulletin board that this scheme
requires to preserve its properties. Existing smart contract-based approaches
employing the self-tallying scheme (such as OVN or BBB-Voting) are only
suitable for a boardroom voting scenario due to their scalability limitation.
The goal of our work is to build on existing solutions to achieve scalability
without losing privacy guarantees and verifiability. We present SBvote, a
blockchain-based self-tallying voting protocol that is scalable in the number
of voters and therefore suitable for large-scale elections. The evaluation of
our proof-of-concept implementation shows that the protocol's scalability is
limited only by the underlying blockchain platform. We evaluated the
scalability of SBvote on two public smart contract platforms -- Gnosis and
Harmony. Despite the limitations imposed by the throughput of the blockchain
platform, SBvote can accommodate elections with millions of voters.",2206.06019v1,cs.CR,2022-06-13 10:18:00+00:00,"[arxiv.Result.Author('Ivana Stančíková'), arxiv.Result.Author('Ivan Homoliak')]",
858,Interacting Models of Generalised Chaplygin Gas and Modified Chaplygin Gas with Barotropic Fluid,"In this letter we consider two different models of our present universe. We
choose the models which are consisting different sets of two seperate fluids.
The first one of each set tries to justify the late time acceleration and the
second one is barotropic fluid. The former model considers our present time
universe to be homogeneously filled up by Generalized Chaplygin Gas which is
interacting with barotropic fluid. On the other hand, the latter model
considers that the cosmic acceleration is generated by Modified Chaplygin Gas
which is interacting with matter depicted by barotropic equation of state. For
both the models, we consider the interaction term to vary proportionally with
Hubble's parameter as well as with the exotic matter/dark energy's energy
density. We find an explicit function form of the energy density of the cosmos
which is found to depend on different cosmological parameters like scale
factor, dark energy and barotropic fluid's EoS parameters and other constants
like interacting constants etc. We draw curves of effective EoS-s, different
cosmological parameters like deceleration parameter $q$, statefinder parameters
$r$ and $s$ with repect to the redshift $z$ (for different values of dark
energy and barotopic fluid parameters) and study them thoroughly. We compare
two models as well as the nature of dependencies on these models' interaction
coefficients. We point out the particular redshift for which the universe may
transit from a deceleration to acceleration phase. We tally all these values
with different observational data. Here we also analyse how this value of
particular redshift does change for different values of interaction
coefficients and different dark energy models.",1805.03962v3,physics.gen-ph,2018-05-07 15:56:46+00:00,"[arxiv.Result.Author('Promila Biswas'), arxiv.Result.Author('Ritabrata Biswas')]",Modern Physics Letters A 34 No. 9 (2019) 1950064
859,Towards end-to-end verifiable online voting: adding verifiability to established voting systems,"Online voting for independent elections is generally supported by trusted
election providers. Typically these providers do not offer any way in which a
voter can verify their vote, so the providers are trusted with ballot privacy
and ensuring correctness. Despite the desire to offer online voting for
political elections, this lack of transparency and verifiability is often seen
as a significant barrier to the large-scale adoption of online elections.
Adding verifiability to an online election increases transparency and
integrity, allowing voters to verify that their vote has been recorded
correctly and included in the tally. However, replacing existing online systems
with those that provide verifiable voting requires new algorithms and code to
be deployed, and this presents a significant business risk to commercial
election providers. In this paper we present the first step in an incremental
approach which minimises the business risk but demonstrates the advantages of
verifiability, by developing an implementation of key elements of a
Selene-based verifiability layer and adding it to an operational online voting
system. Selene is a verifiable voting protocol that uses trackers to enable
voters to confirm that their votes have been captured correctly while
protecting voter anonymity. This results in a system where even the election
authority running the system cannot change the result in an undetectable way,
and gives stronger guarantees on the integrity of the election than were
previously present. We explore the challenges presented by adding a
verifiability layer to an operational system. We describe the results of two
initial trials, which obtained that survey respondents found this form of
verifiability easy to use and that they broadly appreciated it. We conclude by
outlining the further steps in the road-map towards the deployment of a fully
trustworthy online voting system.",1912.00288v2,cs.CR,2019-12-01 00:06:51+00:00,"[arxiv.Result.Author('Mohammed Alsadi'), arxiv.Result.Author('Matthew Casey'), arxiv.Result.Author('Constantin Catalin Dragan'), arxiv.Result.Author('Francois Dupressoir'), arxiv.Result.Author('Luke Riley'), arxiv.Result.Author('Muntadher Sallal'), arxiv.Result.Author('Steve Schneider'), arxiv.Result.Author('Helen Treharne'), arxiv.Result.Author('Joe Wadsworth'), arxiv.Result.Author('Phil Wright')]",
860,Exploiting re-voting in the Helios election system,"Election systems must ensure that representatives are chosen by voters.
Moreover, each voter should have equal influence. Traditionally, this has been
achieved by permitting voters to cast at most one ballot. More recently, this
has been achieved by tallying the last ballot cast by each voter. We show this
is not achieved by the Helios election system, because an adversary can cause a
ballot other than a voter's last to be tallied. Moreover, we show how the
adversary can choose the contents of such a ballot, thus the adversary can
unduly influence the selection of representatives.",1612.04099v3,cs.CR,2016-12-13 11:07:22+00:00,"[arxiv.Result.Author('Maxime Meyer'), arxiv.Result.Author('Ben Smyth')]",
861,"Non-Malleable Extractors and Codes for Composition of Tampering, Interleaved Tampering and More","Non-malleable codes were introduced by Dziembowski, Pietrzak, and Wichs (JACM
2018) as a generalization of standard error correcting codes to handle severe
forms of tampering on codewords. This notion has attracted a lot of recent
research, resulting in various explicit constructions, which have found
applications in tamper-resilient cryptography and connections to other
pseudorandom objects in theoretical computer science.
  We continue the line of investigation on explicit constructions of
non-malleable codes in the information theoretic setting, and give explicit
constructions for several new classes of tampering functions.
  (1) Interleaved split-state tampering: Here the codeword is partitioned in an
unknown way by an adversary, and then tampered with by a split-state tampering
function. (2) Linear function composed with split-state tampering: In this
model, the codeword is first tampered with by a split-state adversary, and then
the whole tampered codeword is further tampered with by a linear function. In
fact our results are stronger, and we can handle linear function composed with
interleaved split-state tampering. (3) Bounded communication split-state
tampering: In this model, the two split-state tampering adversaries are allowed
to participate in a communication protocol with a bounded communication budget.
  Our results are the first explicit constructions of non-malleable codes in
any of these tampering models. We derive all these results from explicit
constructions of seedless non-malleable extractors, which we believe are of
independent interest.
  Using our techniques, we also give an improved seedless extractor for an
unknown interleaving of two independent sources.",1804.05228v2,cs.CR,2018-04-14 14:35:12+00:00,"[arxiv.Result.Author('Eshan Chattopadhyay'), arxiv.Result.Author('Xin Li')]",
862,ReLoc: A Restoration-Assisted Framework for Robust Image Tampering Localization,"With the spread of tampered images, locating the tampered regions in digital
images has drawn increasing attention. The existing image tampering
localization methods, however, suffer from severe performance degradation when
the tampered images are subjected to some post-processing, as the tampering
traces would be distorted by the post-processing operations. The poor
robustness against post-processing has become a bottleneck for the practical
applications of image tampering localization techniques. In order to address
this issue, this paper proposes a novel restoration-assisted framework for
image tampering localization (ReLoc). The ReLoc framework mainly consists of an
image restoration module and a tampering localization module. The key idea of
ReLoc is to use the restoration module to recover a high-quality counterpart of
the distorted tampered image, such that the distorted tampering traces can be
re-enhanced, facilitating the tampering localization module to identify the
tampered regions. To achieve this, the restoration module is optimized not only
with the conventional constraints on image visual quality but also with a
forensics-oriented objective function. Furthermore, the restoration module and
the localization module are trained alternately, which can stabilize the
training process and is beneficial for improving the performance. The proposed
framework is evaluated by fighting against JPEG compression, the most commonly
used post-processing. Extensive experimental results show that ReLoc can
significantly improve the robustness against JPEG compression. The restoration
module in a well-trained ReLoc model is transferable. Namely, it is still
effective when being directly deployed with another tampering localization
module.",2211.03930v1,cs.CV,2022-11-08 01:00:00+00:00,"[arxiv.Result.Author('Peiyu Zhuang'), arxiv.Result.Author('Haodong Li'), arxiv.Result.Author('Rui Yang'), arxiv.Result.Author('Jiwu Huang')]",
863,Two-Stream Neural Networks for Tampered Face Detection,"We propose a two-stream network for face tampering detection. We train
GoogLeNet to detect tampering artifacts in a face classification stream, and
train a patch based triplet network to leverage features capturing local noise
residuals and camera characteristics as a second stream. In addition, we use
two different online face swapping applications to create a new dataset that
consists of 2010 tampered images, each of which contains a tampered face. We
evaluate the proposed two-stream network on our newly collected dataset.
Experimental results demonstrate the effectiveness of our method.",1803.11276v1,cs.CV,2018-03-29 22:36:11+00:00,"[arxiv.Result.Author('Peng Zhou'), arxiv.Result.Author('Xintong Han'), arxiv.Result.Author('Vlad I. Morariu'), arxiv.Result.Author('Larry S. Davis')]",2017 CVPR workshop
864,Leakage-Resilient Non-Malleable Secret Sharing in Non-compartmentalized Models,"Non-malleable secret sharing was recently proposed by Goyal and Kumar in
independent tampering and joint tampering models for threshold secret sharing
(STOC18) and secret sharing with general access structure (CRYPTO18). The idea
of making secret sharing non-malleable received great attention and by now has
generated many papers exploring new frontiers in this topic, such as
multiple-time tampering and adding leakage resiliency to the one-shot tampering
model. Non-compartmentalized tampering model was first studied by Agrawal et.al
(CRYPTO15) for non-malleability against permutation composed with bit-wise
independent tampering, and shown useful in constructing non-malleable string
commitments. We initiate the study of leakage-resilient secret sharing in the
non-compartmentalized model. The leakage adversary can corrupt several players
and obtain their shares, as in normal secret sharing. The leakage adversary can
apply arbitrary affine functions with bounded total output length to the full
share vector and obtain the outputs as leakage. These two processes can be both
non-adaptive and do not depend on each other, or both adaptive and depend on
each other with arbitrary ordering. We construct such leakage-resilient secret
sharing schemes and achieve constant information ratio (the scheme for
non-adaptive adversary is near optimal). We then explore making the
non-compartmentalized leakage-resilient secret sharing also non-malleable
against tampering. We consider a tampering model, where the adversary can use
the shares obtained from the corrupted players and the outputs of the global
leakage functions to choose a tampering function from a tampering family F. We
give two constructions of such leakage-resilient non-malleable secret sharing
for the case F is the bit-wise independent tampering and, respectively, for the
case F is the affine tampering functions.",1902.06195v2,cs.CR,2019-02-17 03:34:13+00:00,"[arxiv.Result.Author('Fuchun Lin'), arxiv.Result.Author('Mahdi Cheraghchi'), arxiv.Result.Author('Venkatesan Guruswami'), arxiv.Result.Author('Reihaneh Safavi-Naini'), arxiv.Result.Author('Huaxiong Wang')]",
865,Right to Sign: Safeguarding data immutability in blockchain systems with cryptographic signatures over a broad range of available consensus finding scenarios,"The choice of the consensus method ultimately determines throughput,
scalability, tamper resistance, and consistency of a blockchain system.
However, across all the types of blockchain (private, semi-private, consortium,
or public), there is no consensus method that uniformly addresses all these
traits. Verifiable lottery algorithms (Proof of ...) increase tamper resistance
but show weakness in throughput and scalability, while established methods like
PAXOS and RAFT provide no additional protection against tampering. In this
paper, we introduce Right to Sign which aims to provide additional tamper
resistance by cryptographic signatures over a broad range of available
consensus finding methods.",1811.05284v1,cs.CR,2018-11-13 13:35:19+00:00,[arxiv.Result.Author('Ernst-Georg Schmid')],
866,Detecting Tampering in a Random Hypercube,"Consider the random hypercube $H_2^n(p_n)$ obtained from the hypercube
$H_2^n$ by deleting any given edge with probabilty $1-p_n$, independently of
all the other edges. A diameter path in $H_2^n$ is a longest geodesic path in
$H_2^n$. Consider the following two ways of tampering with the random graph
$H_2^n(p_n)$: (i) choose a diameter path at random and adjoin all of its edges
to $H_2^n(p_n)$; (ii) choose a diameter path at random from among those that
start at $0=(0,..., 0)$, and adjoin all of its edges to $H_2^n(p_n)$. We study
the question of whether these tamperings are detectable asymptotically as
$n\to\infty$.",1201.3555v2,math.PR,2012-01-17 16:49:32+00:00,[arxiv.Result.Author('Ross G. Pinsky')],
867,Non-Malleable Coding Against Bit-wise and Split-State Tampering,"Non-malleable coding, introduced by Dziembowski, Pietrzak and Wichs (ICS
2010), aims for protecting the integrity of information against tampering
attacks in situations where error-detection is impossible. Intuitively,
information encoded by a non-malleable code either decodes to the original
message or, in presence of any tampering, to an unrelated message. Dziembowski
et al. show existence of non-malleable codes for any class of tampering
functions of bounded size.
  We consider constructions of coding schemes against two well-studied classes
of tampering functions: bit-wise tampering functions (where the adversary
tampers each bit of the encoding independently) and split-state adversaries
(where two independent adversaries arbitrarily tamper each half of the encoded
sequence).
  1. For bit-tampering, we obtain explicit and efficiently encodable and
decodable codes of length $n$ achieving rate $1-o(1)$ and error (security)
$\exp(-\tilde{\Omega}(n^{1/7}))$. We improve the error to
$\exp(-\tilde{\Omega}(n))$ at the cost of making the construction Monte Carlo
with success probability $1-\exp(-\Omega(n))$. Previously, the best known
construction of bit-tampering codes was the Monte Carlo construction of
Dziembowski et al. (ICS 2010) achieving rate ~.1887.
  2. We initiate the study of seedless non-malleable extractors as a variation
of non-malleable extractors introduced by Dodis and Wichs (STOC 2009). We show
that construction of non-malleable codes for the split-state model reduces to
construction of non-malleable two-source extractors. We prove existence of such
extractors, which implies that codes obtained from our reduction can achieve
rates arbitrarily close to 1/5 and exponentially small error. Currently, the
best known explicit construction of split-state coding schemes is due to
Aggarwal, Dodis and Lovett (ECCC TR13-081) which only achieves vanishing
(polynomially small) rate.",1309.1151v2,cs.IT,2013-09-04 19:52:59+00:00,"[arxiv.Result.Author('Mahdi Cheraghchi'), arxiv.Result.Author('Venkatesan Guruswami')]",
868,Tamper Detection against Unitary Operators,"We consider (Enc, Dec) schemes which are used to encode a classical/quantum
message $m$ and derive an $n$-qubit quantum codeword $\psi_m$. The quantum
codeword $\psi_m$ can adversarially tamper via a unitary $U \in \mathcal{U}$
from some known tampering unitary family $\mathcal{U}$, resulting in $U \psi_m
U^\dagger$.
  Firstly, we initiate the general study of quantum tamper detection codes,
which must detect that tampering occurred with high probability. In case there
was no tampering, we would like to output the message $m$ with a probability of
$1$. We show that quantum tamper detection codes exist for both classical
messages and quantum messages for any family of unitaries $\mathcal{U}$, such
that $|\mathcal{U}| < 2^{2^{\alpha n}}$ for some known constant $\alpha \in
(0,1)$ and all the unitaries satisfy one additional condition :
  \begin{itemize}
  \item Far from Identity : For each $U \in \mathcal{U}$, we require that its
modulus of trace value isn't too much i.e. $ |Trace(U)| \leq \phi N$, where
$N=2^n.$
  \end{itemize}
  Quantum tamper-detection codes are quantum generalizations of classical
tamper detection codes studied by Jafargholi et al. \cite{JW15}.
  Additionally for classical message $m$, if we must either output message $m$
or detect that tampering occurred and output $\perp$ with high probability, we
show that it is possible without the restriction of Far from Identity condition
for any family of unitaries $\mathcal{U}$, such that $|\mathcal{U} | <
2^{2^{\alpha n}}$. We also provide efficient (Enc, Dec) schemes when the family
of tampering unitaries are from Pauli group $\mathcal{P}_n$, which can be
thought of as a quantum version of the algebraic manipulation detection (AMD)
codes of Cramer et al. \cite{CDFPW08}.",2105.04487v3,cs.CR,2021-05-10 16:26:41+00:00,"[arxiv.Result.Author('Naresh Goud Boddu'), arxiv.Result.Author('Upendra S. Kapshikar')]",
869,Cross-Referencing Method for Scalable Public Blockchain,"We previously proposed a cross-referencing method for enabling multiple
peer-to-peer network domains to manage their own public blockchains and
periodically exchanging the state of the latest fixed block in the blockchain
with hysteresis signatures among all the domains via an upper network layer. In
this study, we evaluated the effectiveness of our method from three theoretical
viewpoints: decentralization, scalability, and tamper resistance. We show that
the performance of the entire system can be improved because transactions and
blocks are distributed only inside the domain. We argue that the transaction
processing capacity will increase to 56,000 transactions per second, which is
as much as that of a VISA credit card system. The capacity is also evaluated by
multiplying the number of domains by the average reduction in
transaction-processing time due to the increase in block size and reduction in
the block-generation-time interval by domain partition. For tamper resistance,
each domain has evidence of the hysteresis signatures of the other domains in
the blockchain. We introduce two types of tamper-resistance-improvement ratios
as evaluation measures of tamper resistance for a blockchain and theoretically
explain how tamper resistance is improved using our cross-referencing method.
With our method, tamper resistance improves as the number of domains increases.
The proposed system of 1,000 domains are 3-10 times more tamper-resistant than
that of 100 domains, and the capacity is 10 times higher. We conclude that our
method enables a more scalable and tamper-resistant public blockchain balanced
with decentralization.",2107.12981v1,cs.DC,2021-07-27 17:50:37+00:00,"[arxiv.Result.Author('Takaaki Yanagihara'), arxiv.Result.Author('Akihiro Fujihara')]",
870,Reward Tampering Problems and Solutions in Reinforcement Learning: A Causal Influence Diagram Perspective,"Can humans get arbitrarily capable reinforcement learning (RL) agents to do
their bidding? Or will sufficiently capable RL agents always find ways to
bypass their intended objectives by shortcutting their reward signal? This
question impacts how far RL can be scaled, and whether alternative paradigms
must be developed in order to build safe artificial general intelligence. In
this paper, we study when an RL agent has an instrumental goal to tamper with
its reward process, and describe design principles that prevent instrumental
goals for two different types of reward tampering (reward function tampering
and RF-input tampering). Combined, the design principles can prevent both types
of reward tampering from being instrumental goals. The analysis benefits from
causal influence diagrams to provide intuitive yet precise formalizations.",1908.04734v5,cs.AI,2019-08-13 16:50:00+00:00,"[arxiv.Result.Author('Tom Everitt'), arxiv.Result.Author('Marcus Hutter'), arxiv.Result.Author('Ramana Kumar'), arxiv.Result.Author('Victoria Krakovna')]",
871,A Novel Region Duplication Detection Algorithm Based on Hybrid Approach,"The digital images from various sources are ubiquitous due to easy
availability of high bandwidth Internet. Digital images are easy to tamper with
good or bad intentions. Non-availability of pre-embedded information in digital
images makes the tampering detection process more difficult in case of digital
forensics. Thus, passive image tampering is difficult to detect. There are
various algorithms available for detecting image tampering. However, these
algorithms have some drawbacks, due to which all types of tampering cannot be
detected. In this paper researchers intend to present the types of image
tampering and its detection techniques with example based approach. This paper
also illustrates insights into the various existing algorithms and tries to
find out efficient algorithm out of them.",2204.08545v1,cs.CV,2022-04-10 12:17:13+00:00,"[arxiv.Result.Author('Kshipra Tatkare'), arxiv.Result.Author('Manoj Devare')]",
872,Learning to Immunize Images for Tamper Localization and Self-Recovery,"Digital images are vulnerable to nefarious tampering attacks such as content
addition or removal that severely alter the original meaning. It is somehow
like a person without protection that is open to various kinds of viruses.
Image immunization (Imuge) is a technology of protecting the images by
introducing trivial perturbation, so that the protected images are immune to
the viruses in that the tampered contents can be auto-recovered. This paper
presents Imuge+, an enhanced scheme for image immunization. By observing the
invertible relationship between image immunization and the corresponding
self-recovery, we employ an invertible neural network to jointly learn image
immunization and recovery respectively in the forward and backward pass. We
also introduce an efficient attack layer that involves both malicious tamper
and benign image post-processing, where a novel distillation-based JPEG
simulator is proposed for improved JPEG robustness. Our method achieves
promising results in real-world tests where experiments show accurate tamper
localization as well as high-fidelity content recovery. Additionally, we show
superior performance on tamper localization compared to state-of-the-art
schemes based on passive forensics.",2210.15902v1,eess.IV,2022-10-28 05:16:56+00:00,"[arxiv.Result.Author('Qichao Ying'), arxiv.Result.Author('Hang Zhou'), arxiv.Result.Author('Zhenxing Qian'), arxiv.Result.Author('Sheng Li'), arxiv.Result.Author('Xinpeng Zhang')]",
873,N-Version Obfuscation: Impeding Software Tampering Replication with Program Diversity,"Tamper-resistance is a fundamental software security research area. Many
approaches have been proposed to thwart specific procedures of tampering, e.g.,
obfuscation and self-checksumming. However, to our best knowledge, none of them
can achieve theoretically tamper-resistance. Our idea is to impede the
replication of tampering via program diversification, and thus increasing the
complexity to break the whole software system. To this end, we propose to
deliver same featured, but functionally nonequivalent software copies to
different machines. We formally define the problem as N-version obfuscation,
and provide a viable means to solve the problem. Our evaluation result shows
that the time required for breaking a software system is linearly increased
with the number of software versions, which is O(n) complexity.",1506.03032v1,cs.CR,2015-06-08 10:10:47+00:00,"[arxiv.Result.Author('Hui Xu'), arxiv.Result.Author('Yangfan Zhou'), arxiv.Result.Author('Michael R. Lyu')]",
874,Learning Rich Features for Image Manipulation Detection,"Image manipulation detection is different from traditional semantic object
detection because it pays more attention to tampering artifacts than to image
content, which suggests that richer features need to be learned. We propose a
two-stream Faster R-CNN network and train it endto- end to detect the tampered
regions given a manipulated image. One of the two streams is an RGB stream
whose purpose is to extract features from the RGB image input to find tampering
artifacts like strong contrast difference, unnatural tampered boundaries, and
so on. The other is a noise stream that leverages the noise features extracted
from a steganalysis rich model filter layer to discover the noise inconsistency
between authentic and tampered regions. We then fuse features from the two
streams through a bilinear pooling layer to further incorporate spatial
co-occurrence of these two modalities. Experiments on four standard image
manipulation datasets demonstrate that our two-stream framework outperforms
each individual stream, and also achieves state-of-the-art performance compared
to alternative methods with robustness to resizing and compression.",1805.04953v1,cs.CV,2018-05-13 21:29:38+00:00,"[arxiv.Result.Author('Peng Zhou'), arxiv.Result.Author('Xintong Han'), arxiv.Result.Author('Vlad I. Morariu'), arxiv.Result.Author('Larry S. Davis')]",
875,Scientific Image Tampering Detection Based On Noise Inconsistencies: A Method And Datasets,"Scientific image tampering is a problem that affects not only authors but
also the general perception of the research community. Although previous
researchers have developed methods to identify tampering in natural images,
these methods may not thrive under the scientific setting as scientific images
have different statistics, format, quality, and intentions. Therefore, we
propose a scientific-image specific tampering detection method based on noise
inconsistencies, which is capable of learning and generalizing to different
fields of science. We train and test our method on a new dataset of manipulated
western blot and microscopy imagery, which aims at emulating problematic images
in science. The test results show that our method can detect various types of
image manipulation in different scenarios robustly, and it outperforms existing
general-purpose image tampering detection schemes. We discuss applications
beyond these two types of images and suggest next steps for making detection of
problematic images a systematic step in peer review and science in general.",2001.07799v2,cs.CV,2020-01-21 22:29:56+00:00,"[arxiv.Result.Author('Ziyue Xiang'), arxiv.Result.Author('Daniel E. Acuna')]",
876,Deep Localization of Mixed Image Tampering Techniques,"With technological advances leading to an increase in mechanisms for image
tampering, fraud detection methods must continue to be upgraded to match their
sophistication. One problem with current methods is that they require prior
knowledge of the method of forgery in order to determine which features to
extract from the image to localize the region of interest. When a machine
learning algorithm is used to learn different types of tampering from a large
set of various image types, with a large enough database we can easily classify
which images are tampered. However, we still are left with the question of
which features to train on, and how to localize the manipulation. In this work,
deep learning for object detection is adapted to tampering detection to solve
these two problems, while fusing features from multiple classic techniques for
improved accuracy. A Multi-stream version of the Faster RCNN network will be
employed with the second stream having an input of the element-wise sum of the
ELA and BAG error maps to provide even higher accuracy than a single stream
alone.",1904.08484v3,cs.CV,2019-04-07 19:39:17+00:00,[arxiv.Result.Author('Robin Elizabeth Yancey')],
877,A Cross-Verification Approach for Protecting World Leaders from Fake and Tampered Audio,"This paper tackles the problem of verifying the authenticity of speech
recordings from world leaders. Whereas previous work on detecting deep fake or
tampered audio focus on scrutinizing an audio recording in isolation, we
instead reframe the problem and focus on cross-verifying a questionable
recording against trusted references. We present a method for cross-verifying a
speech recording against a reference that consists of two steps: aligning the
two recordings and then classifying each query frame as matching or
non-matching. We propose a subsequence alignment method based on the
Needleman-Wunsch algorithm and show that it significantly outperforms dynamic
time warping in handling common tampering operations. We also explore several
binary classification models based on LSTM and Transformer architectures to
verify content at the frame level. Through extensive experiments on tampered
speech recordings of Donald Trump, we show that our system can reliably detect
audio tampering operations of different types and durations. Our best model
achieves 99.7% accuracy for the alignment task at an error tolerance of 50 ms
and a 0.43% equal error rate in classifying audio frames as matching or
non-matching.",2010.12173v1,eess.AS,2020-10-23 05:34:51+00:00,"[arxiv.Result.Author('Mengyi Shan'), arxiv.Result.Author('TJ Tsai')]",
878,Using Channel State Information for Physical Tamper Attack Detection in OFDM Systems: A Deep Learning Approach,"This letter proposes a deep learning approach to detect a change in the
antenna orientation of transmitter or receiver as a physical tamper attack in
OFDM systems using channel state information. We treat the physical tamper
attack problem as a semi-supervised anomaly detection problem and utilize a
deep convolutional autoencoder (DCAE) to tackle it. The past observations of
the estimated channel state information (CSI) are used to train the DCAE. Then,
a post-processing is deployed on the trained DCAE output to perform the
physical tamper detection. Our experimental results show that the proposed
approach, deployed in an office and a hall environment, is able to detect on
average 99.6% of tamper events (TPR = 99.6%) while creating zero false alarms
(FPR = 0%).",2011.03573v3,eess.SP,2020-11-06 19:52:26+00:00,"[arxiv.Result.Author('Eshagh Dehmollaian'), arxiv.Result.Author('Bernhard Etzlinger'), arxiv.Result.Author('Núria Ballber Torres'), arxiv.Result.Author('Andreas Springer')]",IEEE Wireless Communications Letters 2021
879,Robust Watermarking for Video Forgery Detection with Improved Imperceptibility and Robustness,"Videos are prone to tampering attacks that alter the meaning and deceive the
audience. Previous video forgery detection schemes find tiny clues to locate
the tampered areas. However, attackers can successfully evade supervision by
destroying such clues using video compression or blurring. This paper proposes
a video watermarking network for tampering localization. We jointly train a
3D-UNet-based watermark embedding network and a decoder that predicts the
tampering mask. The perturbation made by watermark embedding is close to
imperceptible. Considering that there is no off-the-shelf differentiable video
codec simulator, we propose to mimic video compression by ensembling simulation
results of other typical attacks, e.g., JPEG compression and blurring, as an
approximation. Experimental results demonstrate that our method generates
watermarked videos with good imperceptibility and robustly and accurately
locates tampered areas within the attacked version.",2207.03409v1,cs.CV,2022-07-07 16:27:10+00:00,"[arxiv.Result.Author('Yangming Zhou'), arxiv.Result.Author('Qichao Ying'), arxiv.Result.Author('Xiangyu Zhang'), arxiv.Result.Author('Zhenxing Qian'), arxiv.Result.Author('Sheng Li'), arxiv.Result.Author('Xinpeng Zhang')]",
880,Artificial Image Tampering Distorts Spatial Distribution of Texture Landmarks and Quality Characteristics,"Advances in AI based computer vision has led to a significant growth in
synthetic image generation and artificial image tampering with serious
implications for unethical exploitations that undermine person identification
and could make render AI predictions less explainable.Morphing, Deepfake and
other artificial generation of face photographs undermine the reliability of
face biometrics authentication using different electronic ID documents.Morphed
face photographs on e-passports can fool automated border control systems and
human guards.This paper extends our previous work on using the persistent
homology (PH) of texture landmarks to detect morphing attacks.We demonstrate
that artificial image tampering distorts the spatial distribution of texture
landmarks (i.e. their PH) as well as that of a set of image quality
characteristics.We shall demonstrate that the tamper caused distortion of these
two slim feature vectors provide significant potentials for building
explainable (Handcrafted) tamper detectors with low error rates and suitable
for implementation on constrained devices.",2208.02710v1,cs.CV,2022-08-04 15:13:00+00:00,"[arxiv.Result.Author('Tahir Hassan'), arxiv.Result.Author('Aras Asaad'), arxiv.Result.Author('Dashti Ali'), arxiv.Result.Author('Sabah Jassim')]",
881,Characterization of Commercial Thermoelectric Modules for Precision Heat FLux Measurement,"In this article, we present a cost-effective approach to the precision
measurement of heat flux using commercial thermoelectric modules (TEMs). Two
different methods of measuring heat flux with TEMs are investigated, namely
passive mode based on the Seebeck effect and active mode based on the Peltier
effect. For both modes, a TEM as a heat fluxmeter is calibrated to show a
linear relation between the voltage across the TEM and the heat flow rate from
0 to 100 mW. While both modes exhibit sufficiently high sensitivities suitable
for low heat flow measurement, active mode is shown to be $\sim$7 times more
sensitive than passive mode. From the speculation on the origin of the
measurement uncertainty, we propose a dual TEM scheme by operating the top TEM
in passive mode while its bottom temperature maintains constant by the
feedback-controlled bottom TEM. The dual-TEM scheme can suppress the
sensitivity uncertainty by up to 4 times when compared to the single-TEM
passive mode by stabilizing the bottom temperature. The response time of a 1.5
cm $\times$ 1.5 cm TEM is measured to be 8.90 $\pm$ 0.97 seconds for heating
and 10.83 $\pm$ 0.65 seconds for cooling, which is slower than commercial heat
fluxmeters but still fast enough to measure heat flux with a time resolution on
the order of 10 seconds. We believe that the obtained results can facilitate
the use of a commercial TEM for heat flux measurement in various thermal
experiments",2208.04265v1,physics.ins-det,2022-08-08 16:53:57+00:00,"[arxiv.Result.Author('Jacob Crossley'), arxiv.Result.Author('A. N. M. Taufiq Elahi'), arxiv.Result.Author('Mohammad Ghashami'), arxiv.Result.Author('Keunhan Park')]",
882,An optimized TEM specimen preparation method of quantum nanostructures,"Electron transparent TEM lamella with unaltered microstructure and chemistry
is the prerequisite for successful TEM explorations. Currently, TEM specimen
preparation of quantum nanostructures, such as quantum dots (QDs), remains a
challenge. In this work, we optimize the sample-preparation routine for
achieving high-quality TEM specimens consisting of SrRuO3 (SRO) QDs grown on
SrTiO3 (STO) substrates. We demonstrate that a combination of ion-beam-milling
techniques can produce higher-quality specimens of quantum nanostructures
compared to TEM specimens prepared by a combination of tripod polishing
followed by Ar+ ion milling. In the proposed method, simultaneous imaging in a
focused ion-beam device enables accurate positioning of the QD regions and
assures the presence of dots in the thin lamella by cutting the sample inclined
by 5{\deg} relative to the dots array. Furthermore, the preparation of TEM
lamellae with several large electron-transparent regions that are separated by
thicker walls effectively reduces the bending of the specimen and offers broad
thin areas. The final use of a NanoMill efficiently removes the amorphous layer
without introducing any additional damage.",2202.03840v1,cond-mat.mes-hall,2022-02-08 13:06:14+00:00,"[arxiv.Result.Author('Hongguang Wang'), arxiv.Result.Author('Vesna Srot'), arxiv.Result.Author('Bernhard Fenk'), arxiv.Result.Author('Gennadii Laskin'), arxiv.Result.Author('Jochen Mannhart'), arxiv.Result.Author('Peter A. van Aken')]",published 2020
883,Compressed IF-TEM: Time Encoding Analog-To-Digital Compression,"An integrate-and-fire time-encoding-machine (IF-TEM) is an energy-efficient
asynchronous sampler. Utilizing the IF-TEM sampler for bandlimited signals, we
introduce designs for time encoding and decoding with analog compression prior
to the quantization phase. Before the quantizer, efficient analog compression
is conducted based on the stationarity of the encoded signal, which is a
fundamental characteristic of IF-TEM processing. Low-bit-rate reconstruction is
achieved by subdividing the known IF-TEM dynamic range into tighter windows,
which can be either fixed size or dynamically changed, and detecting in which
window the sample resides. We demonstrate empirically that employing the same
number of samples and up to 7% additional bits than the conventional IF-TEM
results in a 5-20dB improvement in MSE. Fixing the reconstruction MSE target
and the number of samples, using the compressed IF-TEM enables the use of 1-2
fewer bits compared to the classical IF-TEM.",2210.17544v2,cs.IT,2022-10-31 17:55:37+00:00,"[arxiv.Result.Author('Saar Tarnopolsky'), arxiv.Result.Author('Hila Naaman'), arxiv.Result.Author('Yonina C. Eldar'), arxiv.Result.Author('Alejandro Cohen')]",
884,Rapid appearance of domains upon phase change in KNbO3 - a TEM in-situ heating study,"TEM specimens from potassium niobate single crystals were observed while
being heated in a TEM. DWs and dislocations were observed; the DWs were mobile.
In certain cases the DWs became pinned by the dislocations, at least for a
short time, most likely due to interaction of strain fields. Both phase changes
were observed with accompanying rapid appearance of new domain patterns.",1406.7619v1,cond-mat.mtrl-sci,2014-06-30 07:18:07+00:00,"[arxiv.Result.Author('A. F. Mark'), arxiv.Result.Author('W. Sigle')]",
885,Symmetries in TEM imaging of crystals with strain,"TEM images of strained crystals often exhibit symmetries, the source of which
is not always clear. To understand these symmetries we distinguish between
symmetries that occur from the imaging process itself and symmetries of the
inclusion that might affect the image. For the imaging process we prove
mathematically that the intensities are invariant under specific
transformations. A combination of these invariances with specific properties of
the strain profile can then explain symmetries observed in TEM images. We
demonstrate our approach to the study of symmetries in TEM images using
selected examples in the field of semiconductor nanostructures such as quantum
wells and quantum dots.",2206.01689v1,cond-mat.mtrl-sci,2022-05-24 18:22:22+00:00,"[arxiv.Result.Author('Thomas Koprucki'), arxiv.Result.Author('Anieza Maltsi'), arxiv.Result.Author('Alexander Mielke')]",
886,Atomic-Number (Z)-Correlated Atomic Sizes for Deciphering Electron Microscopic Molecular Images,"With the advent of atomic-resolution transmission electron microscopy
(AR-TEM) achieving sub-{\AA}ngstrom image resolution and submillisecond time
resolution, an era of visual molecular science where chemists can visually
study the time evolution of molecular motions and reactions at atomistic
precision has arrived. However, the appearance of experimental TEM images often
differs greatly from that of conventional molecular models, and the images are
difficult to decipher unless we know in advance the structure of the specimen
molecules. The difference arises from the fundamental design of the molecular
models that represent atomic connectivity and/or the electronic properties of
molecules rather than the nuclear charge of atoms and electrostatic potentials
that are felt by the e-beam in TEM imaging. We found a good correlation between
the atomic number (Z) and the atomic size seen in TEM images when we consider
shot noise in digital images. We propose here Z-correlated (ZC) atomic radii
for modeling AR-TEM images of single molecules and ultrathin crystals, with
which we can develop a good estimate of the molecular structure from the TEM
image much more easily than with conventional molecular models. Two parameter
sets were developed for TEM images recorded under high-noise (ZCHN) and
low-noise (ZCLN) conditions. The new molecular models will stimulate the
imaginations of chemists planning to use AR-TEM for their research.",2107.01490v2,cond-mat.mtrl-sci,2021-07-03 20:15:12+00:00,"[arxiv.Result.Author('Junfei Xing'), arxiv.Result.Author('Keishi Takeuchi'), arxiv.Result.Author('Ko Kamei'), arxiv.Result.Author('Takayuki Nakamuro'), arxiv.Result.Author('Koji Harano'), arxiv.Result.Author('Eiichi Nakamura')]",
887,Adaptive texture energy measure method,"Recent developments in image quality, data storage, and computational
capacity have heightened the need for texture analysis in image process. To
date various methods have been developed and introduced for assessing textures
in images. One of the most popular texture analysis methods is the Texture
Energy Measure (TEM) and it has been used for detecting edges, levels, waves,
spots and ripples by employing predefined TEM masks to images. Despite several
success- ful studies, TEM has a number of serious weaknesses in use. The major
drawback is; the masks are predefined therefore they cannot be adapted to
image. A new method, Adaptive Texture Energy Measure Method (aTEM), was offered
to over- come this disadvantage of TEM by using adaptive masks by adjusting the
contrast, sharpening and orientation angle of the mask. To assess the
applicability of aTEM, it is compared with TEM. The accuracy of the
classification of butterfly, flower seed and Brodatz datasets are 0.08, 0.3292
and 0.3343, respectively by TEM and 0.0053, 0.2417 and 0.3153, respectively by
aTEM. The results of this study indicate that aTEM is a successful method for
texture analysis.",1406.7075v1,cs.CV,2014-06-27 06:00:17+00:00,[arxiv.Result.Author('Omer Faruk Ertugrul')],"International Journal of Intelligent Information Systems. Vol. 3,
  No. 2, 2014, pp. 13-18"
888,TEM turbulence optimisation in stellarators,"With the advent of neoclassically optimised stellarators, optimising
stellarators for turbulent transport is an important next step. The reduction
of ion-temperature-gradient-driven turbulence has been achieved via shaping of
the magnetic field, and the reduction of trapped-electron mode (TEM) turbulence
is adressed in the present paper. Recent analytical and numerical findings
suggest TEMs are stabilised when a large fraction of trapped particles
experiences favourable bounce-averaged curvature. This is the case for example
in Wendelstein 7-X [C.D. Beidler $\textit{et al}$ Fusion Technology $\bf{17}$,
148 (1990)] and other Helias-type stellarators. Using this knowledge, a proxy
function was designed to estimate the TEM dynamics, allowing optimal
configurations for TEM stability to be determined with the STELLOPT [D.A. Spong
$\textit{et al}$ Nucl. Fusion $\bf{41}$, 711 (2001)] code without extensive
turbulence simulations. A first proof-of-principle optimised equilibrium
stemming from the TEM-dominated stellarator experiment HSX [F.S.B. Anderson
$\textit{et al}$, Fusion Technol. $\bf{27}$, 273 (1995)] is presented for which
a reduction of the linear growth rates is achieved over a broad range of the
operational parameter space. As an important consequence of this property, the
turbulent heat flux levels are reduced compared with the initial configuration.",1509.04428v1,physics.plasm-ph,2015-09-15 07:43:56+00:00,"[arxiv.Result.Author('J. H. E. Proll'), arxiv.Result.Author('H. E. Mynick'), arxiv.Result.Author('P. Xanthopoulos'), arxiv.Result.Author('S. A. Lazerson'), arxiv.Result.Author('B. J. Faber')]",
889,Comparison between measured and predicted turbulence frequency spectra in ITG and TEM regimes,"The observation of distinct peaks in tokamak core reflectometry measurements
- named quasi-coherent-modes (QCMs) - are identified as a signature of
Trapped-Electron-Mode (TEM) turbulence [H. Arnichand et al. 2016 Plasma Phys.
Control. Fusion 58 014037]. This phenomenon is investigated with detailed
linear and nonlinear gyrokinetic simulations using the \gene code. A Tore-Supra
density scan is studied, which traverses through a Linear (LOC) to Saturated
(SOC) Ohmic Confinement transition. The LOC and SOC phases are both simulated
separately. In the LOC phase, where QCMs are observed, TEMs are robustly
predicted unstable in linear studies. In the later SOC phase, where QCMs are no
longer observed, ITG modes are identified. In nonlinear simulations, in the ITG
(SOC) phase, a broadband spectrum is seen. In the TEM (LOC) phase, a clear
emergence of a peak at the TEM frequencies is seen. This is due to reduced
nonlinear frequency broadening of the underlying linear modes in the TEM regime
compared with the ITG regime. A synthetic diagnostic of the nonlinearly
simulated frequency spectra reproduces the features observed in the
reflectometry measurements. These results support the identification of core
QCMs as an experimental marker for TEM turbulence",1707.03781v1,physics.plasm-ph,2017-07-12 16:07:57+00:00,"[arxiv.Result.Author('J. Citrin'), arxiv.Result.Author('H. Arnichand'), arxiv.Result.Author('J. Bernardo'), arxiv.Result.Author('C. Bourdelle'), arxiv.Result.Author('X. Garbet'), arxiv.Result.Author('F. Jenko'), arxiv.Result.Author('S. Hacquin'), arxiv.Result.Author('M. J. Pueschel'), arxiv.Result.Author('R. Sabot')]",
890,Wireless power transfer via topological modes in dimer chains,"The topological characteristics, including invariant topological orders, band
inversion, and the topological edge mode (TEM) in the photonic insulators, have
been widely studied. Whether people can take advantage of intriguing
topological modes in simple one-dimensional systems to implement some practical
applications is an issue which people are increasingly concerned about. In this
work, based on a photonic dimer chain composed of ultra-subwavelength
resonators, we verify experimentally that the TEM in the effective second-order
parity-time (PT) system is immune to the inner disorder perturbation, and can
be used to realize the long-range wireless power transfer (WPT) with high
transmission efficiency. To intuitively show the TEM can be used for WPT, a
power signal source is used to excite the TEM. It can be clearly seen that two
LED lamps with 0.5-W at both ends of the structure are lighted up with the aid
of TEMs. In addition, in order to solve the special technical problems of
standby power loss and frequency tracking, we further propose that a WPT system
with effective third-order PT symmetry can be constructed by using one
topological interface mode and two TEMs. Inspired by the long-range WPT with
TEMs in this work, it is expected to use more complex topological structures to
achieve energy transmission with more functions, such as the WPT devices whose
direction can be selected flexibly in the quasiperiodic or trimer topological
chains.",2008.10353v2,physics.app-ph,2020-08-08 18:29:22+00:00,"[arxiv.Result.Author('Juan Song'), arxiv.Result.Author('Fengqing Yang'), arxiv.Result.Author('Zhiwei Guo'), arxiv.Result.Author('Xian Wu'), arxiv.Result.Author('Kejia Zhu'), arxiv.Result.Author('Jun Jiang'), arxiv.Result.Author('Yong Sun'), arxiv.Result.Author('Yunhui Li'), arxiv.Result.Author('Haitao Jiang'), arxiv.Result.Author('Hong Chen')]",Physical Review Applied (2021)
891,On conditios of high figure of merit and methods of search for promising superlattice thermoelectric materials,"This paper presents a rigorous calculation of the figure of merit of
superlattice thermoelectric material (SL TEM) with regard to real
three-dimensionality and nonparabolicity of its energy spectrum with the
arbitrary level of openness of its Fermi surface (FS).It is shown that the
figure of merit of SL TEM in the temperature range of 300-500K is drastically
increased with increasing level of openness of FS. However, due to the presence
of lattice component of thermal conductivity the figure of merit of SL TEM is
rather responsive to the distance between the layers and drastically drops with
its increase. Besides, for the same material, coefficient of performance of a
refrigerator in the framework of its simplest model was calculated. It was
established that if material band spectrum is described by the Fivaz model, the
coefficient of performance is drastically increased with increasing the level
of openness of FS and in case of transient FS it reaches 1.9 between the
temperatures of 300 and 230K. However, as the distance between the layers of SL
TEM increases 2 times, it drops to 0.4 Based on the obtained criteria, four
methods of search for promising SL TEM with the use of quantizing magnetic
fields are proposed.",1509.01782v1,cond-mat.mes-hall,2015-09-06 07:55:16+00:00,[arxiv.Result.Author('P. V. Gorskyi')],
892,High resolution electron microscopy for heterogeneous catalysis research,"Heterogeneous catalysts are the most important catalysts in industrial
reactions. Nanocatalysts, with size ranging from hundreds of nanometers to the
atomic scale, possess activities that are closely connected to their structural
characteristics such as particle size, surface morphology, and
three-dimensional topography. Recently, the development of advanced analytical
transmission electron microscopy (TEM) techniques, especially quantitative
high-angle annular dark-field (HAADF) imaging and high-energy resolution
spectroscopy analysis in scanning transmission electron microscopy (STEM) at
the atomic scale, strengthens the power of (S)TEM in analyzing the
structural/chemical information of heterogeneous catalysts. Three-dimensional
reconstruction from two-dimensional projected images and the real-time
recording of structural evolution during catalytic reactions using in-situ
(S)TEM methods further broaden the scope of (S)TEM observation. The
atomic-scale structural information obtained from high resolution (S)TEM has
proven to be of significance for better understanding and designing of new
catalysts with enhanced performance.",1804.03555v1,cond-mat.mtrl-sci,2018-04-10 14:20:54+00:00,"[arxiv.Result.Author('Yong Zhu'), arxiv.Result.Author('Mingquan Xu'), arxiv.Result.Author('Wu Zhou')]",
893,Understanding the Influence of Receptive Field and Network Complexity in Neural-Network-Guided TEM Image Analysis,"Trained neural networks are promising tools to analyze the ever-increasing
amount of scientific image data, but it is unclear how to best customize these
networks for the unique features in transmission electron micrographs. Here, we
systematically examine how neural network architecture choices affect how
neural networks segment, or pixel-wise separate, crystalline nanoparticles from
amorphous background in transmission electron microscopy (TEM) images. We focus
on decoupling the influence of receptive field, or the area of the input image
that contributes to the output decision, from network complexity, which
dictates the number of trainable parameters. We find that for low-resolution
TEM images which rely on amplitude contrast to distinguish nanoparticles from
background, the receptive field does not significantly influence segmentation
performance. On the other hand, for high-resolution TEM images which rely on a
combination of amplitude and phase contrast changes to identify nanoparticles,
receptive field is a key parameter for increased performance, especially in
images with minimal amplitude contrast. Our results provide insight and
guidance as to how to adapt neural networks for applications with TEM datasets.",2204.04250v1,cond-mat.mtrl-sci,2022-04-08 18:45:15+00:00,"[arxiv.Result.Author('Katherine Sytwu'), arxiv.Result.Author('Catherine Groschner'), arxiv.Result.Author('Mary C. Scott')]",
894,Impact of impurities on drift wave instabilities in reversed-field pinch plasmas,"The drift wave in the presence of impurity ions was investigated numerically
in reversed field pinch (RFP) plasmas, using the gyrokinetic integral eigenmode
equation. It was found that in RFP plasmas with hollow density profiles, an
increase in $k_\theta \rho_s$ increases the growth rate of the ion temperature
gradient (ITG). Comparing the results of regular and hollow plasma density
profile shows that the ITG mode under the hollow density profile is much harder
to be excited. For the impurities' effects, when the impurities' density
gradient is opposite to the primary ions, namely when $L_{ez}$ is negative,
impurities could enhance the instability. On the contrary, when $L_{ez}$ is
positive, the instability is stabilized. Regarding the trapped electron mode
(TEMs), the growth rate under the plasma with hollow density profile remained
minor than that for the standard density gradient. There exists a threshold of
$L_{ez}$. When $L_{ez}$ is less than this value, impurity destabilizes TEMs,
while as $L_{ez}$ is greater than this, impurity stabilizes TEMs. The effects
of $L_{ez}$ on TEM also depend on both the plasma density gradient and the
impurity species. In addition, the influence of collisionality on TEMs was also
studied.",2204.07769v1,physics.plasm-ph,2022-04-16 09:59:26+00:00,"[arxiv.Result.Author('Jingchun Li'), arxiv.Result.Author('Songfen Liu'), arxiv.Result.Author('Yilong Zhang'), arxiv.Result.Author('Jiaqi Dong'), arxiv.Result.Author('Wei Kong')]",
895,Quasi-TEM modes in rectangular waveguides: a study based on the properties of PMC and hard surfaces,"Hard surfaces or magnetic surfaces can be used to propagate quasi-TEM modes
inside closed waveguides. The interesting feature of these modes is an almost
uniform field distribution inside the waveguide. But the mechanisms governing
how these surfaces act, how they can be characterized, and further how the
modes propagate are not detailed in the literature. In this paper, we try to
answer these questions. We give some basic rules that govern the propagation of
the quasi-TEM modes, and show that many of their characteristics (i.e. their
dispersion curves) can be deduced from the simple analysis of the reflection
properties of the involved surfaces.",0809.1497v1,physics.class-ph,2008-09-09 06:55:06+00:00,"[arxiv.Result.Author('Raphaël Pierre'), arxiv.Result.Author('Gérard Tayeb'), arxiv.Result.Author('Boris Gralak'), arxiv.Result.Author('Stefan Enoch')]",
896,Zonal flow generation in collisionless trapped electron mode turbulence,"In the present work the generation of zonal flows in collisionless trapped
electron mode (TEM) turbulence is studied analytically. A reduced model for TEM
turbulence is utilized based on an advanced fluid model for reactive drift
waves. An analytical expression for the zonal flow growth rate is derived and
compared with the linear TEM growth, and its scaling with plasma parameters is
examined for typical tokamak parameter values.",0901.2247v1,physics.plasm-ph,2009-01-15 12:25:35+00:00,"[arxiv.Result.Author('J. Anderson'), arxiv.Result.Author('H. Nordman'), arxiv.Result.Author('R. Singh'), arxiv.Result.Author('J. Weiland')]","Plasma Physics and Controlled Fusion 48, 651 (2006)"
897,Sequential Adaptive Detection for In-Situ Transmission Electron Microscopy (TEM),"We develop new efficient online algorithms for detecting transient sparse
signals in TEM video sequences, by adopting the recently developed framework
for sequential detection jointly with online convex optimization [1]. We cast
the problem as detecting an unknown sparse mean shift of Gaussian observations,
and develop adaptive CUSUM and adaptive SSRS procedures, which are based on
likelihood ratio statistics with post-change mean vector being online maximum
likelihood estimators with $\ell_1$. We demonstrate the meritorious performance
of our algorithms for TEM imaging using real data.",1710.11297v1,stat.AP,2017-10-31 02:04:21+00:00,"[arxiv.Result.Author('Y. Cao'), arxiv.Result.Author('S. Zhu'), arxiv.Result.Author('Y. Xie'), arxiv.Result.Author('J. Key'), arxiv.Result.Author('J. Kacher'), arxiv.Result.Author('R. R. Unocic'), arxiv.Result.Author('C. M. Rouleau')]",
898,TEM observations on palladium samples aged up to 8 years under tritium,"Transmission electron microscopy (TEM) experiments were carried out on aged
under tritium palladium powder samples. The experiments were devoted to the
study of the evolution of 3He bubbles (size, density) appearing during aging.
The study, using a new sample preparation, was focused for the first time on
long aging time, up to 8 years. The TEM results indicated the presence of
nanometer size bubbles (2 - 3 nm in diameter) with densities close to 5x10^23
m-3.",2106.01776v1,cond-mat.mtrl-sci,2021-06-03 11:59:56+00:00,"[arxiv.Result.Author('M. Segard'), arxiv.Result.Author('E. Leroy'), arxiv.Result.Author('B. Evin'), arxiv.Result.Author('S. Thiebaut'), arxiv.Result.Author('A. Fabre'), arxiv.Result.Author('S. Challet'), arxiv.Result.Author('V. Paul-Boncour')]",
899,Is it appropriate to model turbidity currents with the three-equation model?,"The three-equation model (TEM) was developed in the 1980s to model turbidity
currents (TCs) and has been widely used ever since. However, its physical
justification was questioned because self-accelerating TCs simulated with the
steady TEM seemed to violate the turbulent kinetic energy balance. This
violation was considered as a result of very strong sediment erosion that
consumes more turbulent kinetic energy than is produced. To confine bed erosion
and thus remedy this issue, the four-equation model (FEM) was introduced by
assuming a proportionality between the bed shear stress and the turbulent
kinetic energy. Here we analytically proof that self-accelerating TCs simulated
with the original steady TEM actually never violate the turbulent kinetic
energy balance, provided that the bed drag coefficient is not unrealistically
low. We find that stronger bed erosion, surprisingly, leads to more production
of turbulent kinetic energy due to conversion of potential energy of eroded
material into kinetic energy of the current. Furthermore, we analytically show
that, for asymptotically supercritical flow conditions, the original steady TEM
always produces self-accelerating TCs if the upstream boundary conditions
(""ignition"" values) are chosen appropriately, while it never does so for
asymptotically subcritical flow conditions. We numerically show that our novel
method to obtain the ignition values even works for Richardson numbers very
near to unity. Our study also includes a comparison of the TEM and FEM closures
for the bed shear stress to simulation data of a coupled Large Eddy and
Discrete Element Model of sediment transport in water, which suggests that the
TEM closure might be more realistic than the FEM closure.",1505.07066v2,physics.geo-ph,2015-05-26 17:55:45+00:00,"[arxiv.Result.Author('Peng Hu'), arxiv.Result.Author('Thomas Pähtz'), arxiv.Result.Author('Zhiguo He')]","Journal of Geophysical Research: Earth Surface 120 (7), 1153-1170
  (2015)"
900,"Parallel mode differential phase contrast in transmission electron microscopy, II: K$_2$CuF$_4$ phase transition","In Part I of this diptych, we outlined the theory and an analysis methodology
for quantitative phase recovery from real-space distortions of Fresnel images
acquired in the parallel mode of transmission electron microscopy (TEM). In
that work, the properties of the method, termed TEM-differential phase contrast
(TEM-DPC), were highlighted through the use of simulated data. In this work, we
explore the use of the TEM-DPC technique with experimental cryo-TEM images of a
thin lamella of a low temperature two-dimensional (2-D) ferromagnetic material,
K$_2$CuF$_4$, to perform two tasks. First, using images recorded below the
ordering temperature, we compare the TEM-DPC method to the transport of
intensity one for phase recovery, and discuss the relative advantages the
former has for experimental data. Second, by tracking the induction of the
sample as it is driven through a phase transition by heating, we extract
estimates for the critical temperature and critical exponent of the order
parameter. The value of the latter is consistent with the 2-D XY class, raising
the prospect that a Kosterlitz--Thoules transition may have occurred.",2107.06280v1,cond-mat.mtrl-sci,2021-06-30 17:14:32+00:00,"[arxiv.Result.Author('G. W. Paterson'), arxiv.Result.Author('G. M. Macauley'), arxiv.Result.Author('S. McVitie'), arxiv.Result.Author('Y. Togawa')]","Microsc. Microanal. 27, 1123 (2021)"
901,Bisimulations for Verifying Strategic Abilities with an Application to the ThreeBallot Voting Protocol,"We propose a notion of alternating bisimulation for strategic abilities under
imperfect information. The bisimulation preserves formulas of ATL$^*$ for both
the {\em objective} and {\em subjective} variants of the state-based semantics
with imperfect information, which are commonly used in the modeling and
verification of multi-agent systems. Furthermore, we apply the theoretical
result to the verification of coercion-resistance in the ThreeBallot voting
system, a voting protocol that does not use cryptography. In particular, we
show that natural simplifications of an initial model of the protocol are in
fact bisimulations of the original model, and therefore satisfy the same
ATL$^*$ properties, including coercion-resistance. These simplifications allow
the model-checking tool MCMAS to terminate on models with a larger number of
voters and candidates, compared with the initial model.",2203.13692v1,cs.MA,2022-03-25 14:56:20+00:00,"[arxiv.Result.Author('Francesco Belardinelli'), arxiv.Result.Author('Rodica Condurache'), arxiv.Result.Author('Catalin Dima'), arxiv.Result.Author('Wojciech Jamroga'), arxiv.Result.Author('Michal Knapik')]",
902,Bisimulations for Verifying Strategic Abilities with an Application to the ThreeBallot Voting Protocol,"We propose a notion of alternating bisimulation for strategic abilities under
imperfect information. The bisimulation preserves formulas of ATL$^*$ for both
the {\em objective} and {\em subjective} variants of the state-based semantics
with imperfect information, which are commonly used in the modeling and
verification of multi-agent systems. Furthermore, we apply the theoretical
result to the verification of coercion-resistance in the ThreeBallot voting
system, a voting protocol that does not use cryptography. In particular, we
show that natural simplifications of an initial model of the protocol are in
fact bisimulations of the original model, and therefore satisfy the same
ATL$^*$ properties, including coercion-resistance. These simplifications allow
the model-checking tool MCMAS to terminate on models with a larger number of
voters and candidates, compared with the initial model.",2203.13692v1,cs.MA,2022-03-25 14:56:20+00:00,"[arxiv.Result.Author('Francesco Belardinelli'), arxiv.Result.Author('Rodica Condurache'), arxiv.Result.Author('Catalin Dima'), arxiv.Result.Author('Wojciech Jamroga'), arxiv.Result.Author('Michal Knapik')]",
903,Risk Automatic Prediction for Social Economy Companies using Camels,"Governments have to supervise and inspect social economy enterprises (SEEs).
However, inspecting all SEEs is not possible due to the large number of SEEs
and the low number of inspectors in general. We proposed a prediction model
based on a machine learning approach. The method was trained with the random
forest algorithm with historical data provided by each SEE. Three consecutive
periods of data were concatenated. The proposed method uses these periods as
input data and predicts the risk of each SEE in the fourth period. The model
achieved 76\% overall accuracy. In addition, it obtained good accuracy in
predicting the high risk of a SEE. We found that the legal nature and the
variation of the past-due portfolio are good predictors of the future risk of a
SEE. Thus, the risk of a SEE in a future period can be predicted by a
supervised machine learning method. Predicting the high risk of a SEE improves
the daily work of each inspector by focusing only on high-risk SEEs.",2210.05052v1,cs.LG,2022-10-10 23:50:02+00:00,"[arxiv.Result.Author('Joseph Gallego-Mejia'), arxiv.Result.Author('Daniela Martin-Vega'), arxiv.Result.Author('Fabio Gonzalez')]",
904,Triviality and the (Supersymmetric) See-Saw,"For the D=5 Majorana neutrino mass operator to have a see-saw ultraviolet
completion that is viable up to the Planck scale, the see-saw scale is bounded
above due to triviality limits on the see-saw couplings. For supersymmetric
see-saw models, with realistic neutrino mass textures, we compare constraints
on the see-saw scale from triviality bounds, with those arising from
experimental limits on induced charged-lepton flavour violation, for both the
CMSSM and for models with split supersymmetry.",hep-ph/0603053v2,hep-ph,2006-03-07 16:47:09+00:00,"[arxiv.Result.Author('Bruce A. Campbell'), arxiv.Result.Author('David W. Maybury')]","JHEP 0704:077,2007"
905,Astronomical Seeing at Maidanak Observatory during the year 2018,"Astronomical seeing measurements were carried out at Maidanak observatory
during the period from August to November 2018 using DIMM (Differential Image
Motion Monitor). The median value of seeing for the entire period was
determined as 0.54 arcseconds. This value was compared to the seeing data of
the period 1996-2002.",2012.08110v1,astro-ph.IM,2020-12-15 06:19:17+00:00,"[arxiv.Result.Author('Y. A. Tillayev'), arxiv.Result.Author('A. M. Azimov'), arxiv.Result.Author('A. R. Hafizov')]",
906,"The see-saw mechanism: neutrino mixing, leptogenesis and lepton flavor violation","The see-saw mechanism to generate small neutrino masses is reviewed. After
summarizing our current knowledge about the low energy neutrino mass matrix we
consider reconstructing the see-saw mechanism. Low energy neutrino physics is
not sufficient to reconstruct see-saw, a feature which we refer to as ``see-saw
degeneracy''. Indirect tests of see-saw are leptogenesis and lepton flavor
violation in supersymmetric scenarios, which together with neutrino mass and
mixing define the framework of see-saw phenomenology. Several examples are
given, both phenomenological and GUT-related. Variants of the see-saw mechanism
like the type II or triplet see-saw are also discussed. In particular, we
compare many general aspects regarding the dependence of LFV on low energy
neutrino parameters in the extreme cases of a dominating conventional see-saw
term or a dominating triplet term. For instance, the absence of mu -> e gamma
or tau -> e gamma in the pure triplet case means that CP is conserved in
neutrino oscillations. Scanning models, we also find that among the decays mu
-> e gamma, tau -> e gamma and tau -> mu gamma the latter one has the largest
branching ratio in (i) SO(10) type I see-saw models and in (ii) scenarios in
which the triplet term dominates in the neutrino mass matrix.",0804.3925v3,hep-ph,2008-04-24 13:44:29+00:00,[arxiv.Result.Author('Werner Rodejohann')],"Pramana 72:217-227,2009"
907,Statistics of turbulence profile at Cerro Tololo,"Results of 3-month continuous monitoring of turbulence profile and seeing at
Cerro Tololo (Chile) in May-July 2002 are presented. Some 28000 low-resolution
profiles were measured by a new MASS single-star turbulence monitor,
accompanied by seeing data from DIMM. The median seeing was 0.95 arcseconds.
The first 500 m contribute 60% to the total seeing, the free-atmosphere median
seeing was 0.55 arcseconds. Free-atmosphere seeing is almost never better than
0.15 arcseconds because there is always some turbulence above 12 km. A 4-day
period of calm upper atmosphere with a stable free-atmosphere seeing of 0.2-0.3
arcseconds was noted. A gain in resolution from adaptive compensation of ground
layer will be 1.7 times typically and 2-3 times during such calm periods.
Correlations of the free-atmosphere turbulence with the wind speed at
tropopause and of the ground-layer turbulence with ground wind are studied.
Temporal evolution of turbulence is characterized by recurrent bursts, their
typical duration increases from 15 minutes in low layers to 1-2 hours in high
layers. The large data base of turbulence profiles can be used to test
meso-scale modeling of astronomical seeing.",astro-ph/0209432v1,astro-ph,2002-09-20 16:32:20+00:00,"[arxiv.Result.Author('A. Tokovinin'), arxiv.Result.Author('S. Baumont'), arxiv.Result.Author('J. Vasquez')]",Mon.Not.Roy.Astron.Soc. 340 (2003) 52
908,The Spectrum of HD 3651B: An Extrasolar Nemesis?,This article has been withdrawn; see astro-ph/0611542,astro-ph/0609556v2,astro-ph,2006-09-20 00:36:50+00:00,[arxiv.Result.Author('Adam J. Burgasser')],
909,Criticality versus q in the 2+1-dimensional $Z_q$ clock model,"Paper has been withdrawn, see comment.",cond-mat/0212255v2,cond-mat.supr-con,2002-12-11 17:32:31+00:00,"[arxiv.Result.Author('J. Hove'), arxiv.Result.Author('A. Sudbo')]",
910,Closedness of the Space of AHE Metrics on 4-Manifolds,See comment above.,math/0012167v2,math.DG,2000-12-18 19:05:21+00:00,[arxiv.Result.Author('Michael T. Anderson')],
911,A Machine Learning Approach to Correcting Atmospheric Seeing in Solar Flare Observations,"Current post-processing techniques for the correction of atmospheric seeing
in solar observations -- such as Speckle interferometry and Phase Diversity
methods -- have limitations when it comes to their reconstructive capabilities
of solar flare observations. This, combined with the sporadic nature of flares
meaning observers cannot wait until seeing conditions are optimal before taking
measurements, means that many ground-based solar flare observations are marred
with bad seeing. To combat this, we propose a method for dedicated flare seeing
correction based on training a deep neural network to learn to correct
artificial seeing from flare observations taken during good seeing conditions.
This model uses transfer learning, a novel technique in solar physics, to help
learn these corrections. Transfer learning is when another network already
trained on similar data is used to influence the learning of the new network.
Once trained, the model has been applied to two flare datasets: one from
AR12157 on 2014/09/06 and one from AR12673 on 2017/09/06. The results show good
corrections to images with bad seeing with a relative error assigned to the
estimate based on the performance of the model. Further discussion takes place
of improvements to the robustness of the error on these estimates.",2011.12814v1,astro-ph.SR,2020-11-25 15:17:26+00:00,"[arxiv.Result.Author('John A. Armstrong'), arxiv.Result.Author('Lyndsay Fletcher')]",
912,Daytime Seeing and Solar Limb Positions,"A method to measure the seeing from video made during drift-scan solar
transits is proposed. The limb of the Sun is projected over a regular grid
evenly spaced. The temporal dispersion of the time intervals among the contacts
between solar limb and grid's rows is proportional to the atmospheric seeing.
Seeing effects on the position of the inflexion point of the limb's luminosity
profile are calculated numerically with Fast Fourier Transform. Observational
examples from Locarno and Paris Observatories are presented to show the
asymmetric contributions of the seeing at the beginning and the end of each
drift-scan transit.",1106.2539v1,astro-ph.IM,2011-06-13 19:58:47+00:00,[arxiv.Result.Author('Costantino Sigismondi')],
913,The effect of aperture and seeing on the visibility of sunspots when using early modern and modern telescopes of modest size,"Using the convolution of seeing and diffraction, the relation between seeing
and aperture in the visibility of sunspots is explored. It is shown that even
telescopes with apertures smaller than 5 centimetres are significantly affected
by seeing. Although larger aperture instruments suffer more from seeing than
smaller ones, their level of detail always remains better under the same
atmospheric conditions.",2208.07244v3,astro-ph.SR,2022-08-15 15:00:51+00:00,"[arxiv.Result.Author('Nicolàs de Hilster'), arxiv.Result.Author('Siebren van der Werf')]",
914,Typical duration of good seeing sequences at Concordia,"Context: The winter seeing at Concordia is essentially bimodal, excellent or
quite poor, with relative proportions that depend on altitude above the snow
surface. This paper studies the temporal behavior of the good seeing sequences.
Aims: An efficient exploitation of extremely good seeing with an adaptive
optics system needs long integrations. It is then important to explore the
temporal distribution of the fraction of time providing excellent seeing.
Methods: Temporal windows of good seeing are created by a simple binary
process. Good or bad. Their autocorrelations are corrected for those of the
existing data sets, since these are not continuous, being often interrupted by
technical problems in addition to the adverse weather gaps. At the end these
corrected autocorrelations provide the typical duration of good seeing
sequences. This study has to be a little detailed as its results depend on the
season, summer or winter. Results: Using a threshold of 0.5 arcsec to define
the ""good seeing"", three characteristic numbers are found to describe the
temporal evolution of the good seeing windows. The first number is the mean
duration of an uninterrupted good seeing sequence: it is $\tau_0=7.5$ hours at
8 m above the ground (15 hours at 20 m). These sequences are randomly
distributed in time, with a negative exponential law of damping time
$\tau_1=29$ hours (at elevation 8 m and 20 m). The third number is the mean
time between two 29 hours episodes. It is T=10 days at 8 m high (5 days at 20
m).",1003.3583v1,astro-ph.IM,2010-03-18 14:09:06+00:00,"[arxiv.Result.Author('Eric Fossat'), arxiv.Result.Author('Eric Aristidi'), arxiv.Result.Author('Karim Agabi'), arxiv.Result.Author('Erick Bondoux'), arxiv.Result.Author('Zalpha Challita'), arxiv.Result.Author('Francois Jeanneaux'), arxiv.Result.Author('Djamel Mekarnia')]",
915,Excellent daytime seeing at Dome Fuji on the Antarctic plateau,"Context. Dome Fuji, the second highest region on the Antarctic plateau, is
expected to have some of the best astronomical seeing on Earth. However, site
testing at Dome Fuji is still in its very early stages.
  Aims. To investigate the astronomical seeing in the free atmosphere above
Dome Fuji, and to determine the height of the surface boundary layer.
  Methods. A Differential Image Motion Monitor was used to measure the seeing
in the visible (472 nm) at a height of 11 m above the snow surface at Dome Fuji
during the austral summer of 2012/2013.
  Results. Seeing below 0.2'' has been observed. The seeing often has a local
minimum of ~0.3'' near 18 h local time. Some periods of excellent seeing, 0.3''
or smaller, were also observed, sometimes extending for several hours at local
midnight. The median seeing is higher, at 0.52''---this large value is believed
to be caused by periods when the telescope was within the turbulent boundary
layer.
  Conclusions. The diurnal variation of the daytime seeing at Dome Fuji is
similar to that reported for Dome C, and the height of the surface boundary
layer is consistent with previous simulations for Dome Fuji. The free
atmosphere seeing is ~0.2'', and the height of the surface boundary layer can
be as low as ~11 m.",1305.5109v1,astro-ph.IM,2013-05-22 12:38:07+00:00,"[arxiv.Result.Author('H. Okita'), arxiv.Result.Author('T. Ichikawa'), arxiv.Result.Author('M. C. B. Ashley'), arxiv.Result.Author('N. Takato')]",
916,Night-time measurements of astronomical seeing at Dome A in Antarctica,"Seeing, the angular size of stellar images blurred by atmospheric turbulence,
is a critical parameter used to assess the quality of astronomical sites.
Median values at the best mid-latitude sites are generally in the range of
0.6--0.8\,arcsec. Sites on the Antarctic plateau are characterized by
comparatively-weak turbulence in the free-atmosphere above a strong but thin
boundary layer. The median seeing at Dome C is estimated to be 0.23--0.36
arcsec above a boundary layer that has a typical height of 30\,m. At Dome A and
F, the only previous seeing measurements were made during daytime. Here we
report the first direct measurements of night-time seeing at Dome A, using a
Differential Image Motion Monitor. Located at a height of just 8\,m, it
recorded seeing as low as 0.13\,arcsec, and provided seeing statistics that are
comparable to those for a 20\,m height at Dome C. It indicates that the
boundary layer was below 8\,m 31\% of the time. At such times the median seeing
was 0.31\,arcsec, consistent with free-atmosphere seeing. The seeing and
boundary layer thickness are found to be strongly correlated with the
near-surface temperature gradient. The correlation confirms a median thickness
of approximately 14\,m for the boundary layer at Dome A, as found from a sonic
radar. The thinner boundary layer makes it less challenging to locate a
telescope above it, thereby giving greater access to the free-atmosphere.",2007.15365v1,astro-ph.IM,2020-07-30 10:36:24+00:00,"[arxiv.Result.Author('Bin Ma'), arxiv.Result.Author('Zhaohui Shang'), arxiv.Result.Author('Yi Hu'), arxiv.Result.Author('Keliang Hu'), arxiv.Result.Author('Yongjiang Wang'), arxiv.Result.Author('Xu Yang'), arxiv.Result.Author('Michael C. B. Ashley'), arxiv.Result.Author('Paul Hickson'), arxiv.Result.Author('Peng Jiang')]","Nature 583, 771-774 (2020)"
917,Gaze-Vergence-Controlled See-Through Vision in Augmented Reality,"Augmented Reality (AR) see-through vision is an interesting research topic
since it enables users to see through a wall and see the occluded objects. Most
existing research focuses on the visual effects of see-through vision, while
the interaction method is less studied. However, we argue that using common
interaction modalities, e.g., midair click and speech, may not be the optimal
way to control see-through vision. This is because when we want to see through
something, it is physically related to our gaze depth/vergence and thus should
be naturally controlled by the eyes. Following this idea, this paper proposes a
novel gaze-vergence-controlled (GVC) see-through vision technique in AR. Since
gaze depth is needed, we build a gaze tracking module with two infrared cameras
and the corresponding algorithm and assemble it into the Microsoft HoloLens 2
to achieve gaze depth estimation. We then propose two different GVC modes for
see-through vision to fit different scenarios. Extensive experimental results
demonstrate that our gaze depth estimation is efficient and accurate. By
comparing with conventional interaction modalities, our GVC techniques are also
shown to be superior in terms of efficiency and more preferred by users.
Finally, we present four example applications of gaze-vergence-controlled
see-through vision.",2207.02645v1,cs.CV,2022-07-06 13:11:34+00:00,"[arxiv.Result.Author('Zhimin Wang'), arxiv.Result.Author('Yuxin Zhao'), arxiv.Result.Author('Feng Lu')]",
918,Vlasov Simulation of Emissive Plasma Sheath with Energy-Dependent Secondary Emission Coefficient and Improved Modeling for Dielectric Charging Effects,"A one dimensional Vlasov Poisson simulation code is employed to investigate
the plasma sheath considering electron induced secondary electron emission
(SEE) and backscattering. The SEE coefficient is commonly treated as constant
in a range of plasma simulations, here improved SEE model of a charged
dielectric wall is constructed which includes the wall charging effect on SEE
coefficient and the energy dependency of SEE coefficient. Pertinent algorithms
to implement above SEE model in plasma simulation are studied in detail. It is
found that the SEE coefficient increases with the amount of negative wall
charges, which in turn reduces the emissive sheath potential. With energy
dependent SEE coefficient, the sheath potential is a nonlinear function of the
plasma electron temperature, as opposed to the linear relation predicted by
classic emissive sheath theory. Simulation combining both wall charging effect
and SEE coefficient energy dependency suggests that the space charged limited
sheath is formed at high plasma electron temperature levels, where both sheath
potential and surface charging saturate. Additionally, different algorithms to
implement the backscattering in kinetic simulation are tested and compared.
Converting backscattered electron to secondary electron via an effective SEE
coefficient barely affects the sheath properties. The simulation results are
shown to be commensurate with the upgraded sheath theory predictions.",2209.09567v1,physics.plasm-ph,2022-09-20 09:13:56+00:00,"[arxiv.Result.Author('Guang-Yu Sun'), arxiv.Result.Author('Shu Zhang'), arxiv.Result.Author('Bao-Hong Guo'), arxiv.Result.Author('An-Bang Sun'), arxiv.Result.Author('Guan-Jun Zhang')]",
919,Leptogenesis and LHC Physics with Type III See-Saw,"The See-Saw mechanism provides a nice way to explain why neutrino masses are
so much lighter than their charged lepton partners. It also provides a nice way
to explain baryon asymmetry in our universe via the leptogenesis mechanism. In
this talk we review leptogenesis and LHC physics in a See-Saw model proposed in
1989, now termed the Type III See-Saw model. In this model, $SU(2)_L$ triplet
leptons are introduced with the neutral particles of the triplets playing the
role of See-Saw. The triplet leptons have charged partners with standard model
gauge interactions resulting in many new features. The gauge interactions of
these particles make it easier for leptognesis with low masses, as low as a TeV
is possible. The gauge interactions also make the production and detection of
triplet leptons at LHC possible. The See-Saw mechanism and leptogenesis due to
Type III See-Saw may be tested at LHC.",0901.1264v2,hep-ph,2009-01-09 16:14:07+00:00,"[arxiv.Result.Author('Shao-Long Chen'), arxiv.Result.Author('Xiao-Gang He')]",
920,Avoiding the gauge heirarchy problem with see-sawed neutrino masses,"We show that the see-saw neutrino mass mechanism can coexist naturally with
an extended gauge symmetry (i.e. without any gauge heirarchy problem) provided
that the gauge symmetry contains gauged lepton number differences. The simplest
such `natural' see-saw models are constructed and their implications for
neutrino anomalies discussed.",hep-ph/0505154v1,hep-ph,2005-05-18 00:16:53+00:00,[arxiv.Result.Author('R. Foot')],Mod.Phys.Lett. A20 (2005) 3035-3044
921,On the F-expanding of Homoclinic class,"We establish a closing property for thin trapped homoclinic classes. Taking
advantage of this property, we proved that if the homoclinic class $H(p)$
admits a dominated splitting $T_{H(p)}M=E\oplus_{<}F$, where $E$ is thin
trapped (see Definition \ref{Def:TP}) and all periodic points homoclinically
related to $p$ are uniformly $F$-expanding at the period (see Definition
\ref{Def:expanding}), then $F$ is expanded (see Definition \ref{Def:TP}).",1710.08487v1,math.DS,2017-10-23 20:06:47+00:00,"[arxiv.Result.Author('Wanlou Wu'), arxiv.Result.Author('Bo Li')]",
922,Threshold Quantum Cryptography,"Most current research on quantum cryptography requires transmission and
reception of single photons that creates severe implementation challenges and
limits range. This paper argues for the development of threshold quantum
cryptography protocols in which the system is secure so long as the number of
photons being exchanged between Alice and Bob is below a specified threshold.
We speak of a (p-k-n) threshold system where if the number of photons exchanged
is less than p, the system is completely secure, when it is between p and k,
the system is partially secure, and when it exceeds k, the system is insecure.
The BB84 protocol is (1-1-1) whereas the three-stage protocol appears to be
(p-4p-n), where p is the least number of photons necessary to determine the
polarization state of identically prepared photons. New quantum cryptography
systems should be sought that provide greater flexibility in the choice of p
and k.",1310.6333v1,quant-ph,2013-10-23 19:13:34+00:00,[arxiv.Result.Author('Subhash Kak')],
923,Quantum Advantage of Threshold Changeable Secret Sharing Scheme,"In TCSS (Threshold Changeable Secret Sharing) scheme, the threshold can be
changed to deal with share leakage in the long term. But in classical TCSS,
there is no guarantee that old shares are deleted even if the participated
parties are honest. So, the changed threshold may not prevent an adversary from
reconstructing the secret by the old shares and old threshold number of
parties. We show how to tackle this problem quantum mechanically. I.e., quantum
mechanically we can make the changed threshold mandatory. So, there is quantum
advantage of quantum TCSS over classical TCSS.",2209.01365v1,quant-ph,2022-09-03 08:27:34+00:00,"[arxiv.Result.Author('Xiaogang Cheng'), arxiv.Result.Author('Ren Guo'), arxiv.Result.Author('Changli Zhou')]",
924,A Directed Threshold - Signature Scheme,"Directed signature is the solution of such problems when the signed message
contains information sensitive to the signature receiver. Generally, in many
application of directed signature, the signer is generally a single person. But
when the message is on behalf of an organization, a valid sensitive message may
require the approval of several people. Threshold signature schemes are used to
solve these problems. This paper presents a threshold directed signature
scheme.",cs/0411005v1,cs.CR,2004-11-02 13:42:51+00:00,"[arxiv.Result.Author('Sunder Lal'), arxiv.Result.Author('Manoj Kumar')]",
925,Proposed System for data hiding using Cryptography and Steganography Proposed System for data hiding using Cryptography and Steganography,"Steganography and Cryptography are two popular ways of sending vital
information in a secret way. One hides the existence of the message and the
other distorts the message itself. There are many cryptography techniques
available; among them AES is one of the most powerful techniques. In
Steganography we have various techniques in different domains like spatial
domain, frequency domain etc. to hide the message. It is very difficult to
detect hidden message in frequency domain and for this domain we use various
transformations like DCT, FFT and Wavelets etc. In this project we are
developing a system where we develop a new technique in which Cryptography and
Steganography are used as integrated part along with newly developed enhanced
security module. In Cryptography we are using AES algorithm to encrypt a
message and a part of the message is hidden in DCT of an image; remaining part
of the message is used to generate two secret keys which make this system
highly secured. Keyword: Cryptography, Steganography, Stego- image, Threshold
Value, DCT Coefficient",1009.2826v1,cs.CR,2010-09-15 03:47:55+00:00,"[arxiv.Result.Author('Dipti Kapoor Sarmah'), arxiv.Result.Author('Neha Bajpai')]",
926,A Characterization of Ideal Weighted Secret Sharing Schemes,"Beimel, Tassa and Weinreb (2008) and Farras and Padro (2010) partially
characterized access structures of ideal weighted threshold secret sharing
schemes in terms of the operation of composition. They classified
indecomposable ideal weighted threshold access structures, and proved that any
other ideal weighted threshold access structure is a composition of
indecomposable ones. It remained unclear which compositions of indecomposable
weighted threshold access structures are weighted. In this paper we fill the
gap. Using game-theoretic techniques we determine which compositions of
indecomposable ideal access structures are weighted, and obtain an if and only
if characterization of ideal weighted threshold secret sharing schemes.",1308.3763v1,cs.CR,2013-08-17 08:13:36+00:00,"[arxiv.Result.Author('Ali Hameed'), arxiv.Result.Author('Arkadii Slinko')]",
927,Raw-data attacks in quantum cryptography with partial tomography,"We consider a variant of the BB84 protocol for quantum cryptography, the
prototype of tomographically incomplete protocols, where the key is generated
by one-way communication rather than the usual two-way communication. Our
analysis, backed by numerical evidence, establishes thresholds for
eavesdropping attacks on the raw data and on the generated key at quantum bit
error rates of 10% and 6.15%, respectively. Both thresholds are lower than the
threshold for unconditional security in the standard BB84 protocol.",quant-ph/0609175v1,quant-ph,2006-09-22 14:59:57+00:00,"[arxiv.Result.Author('Syed M. Assad'), arxiv.Result.Author('Jun Suzuki'), arxiv.Result.Author('Berthold-Georg Englert')]",International Journal of Quantum Information 4 (2006) 1003-1012
928,Threshold-based Obfuscated Keys with Quantifiable Security against Invasive Readout,"Advances in reverse engineering make it challenging to deploy any on-chip
information in a way that is hidden from a determined attacker. A variety of
techniques have been proposed for design obfuscation including look-alike cells
in which functionality is determined by hard to observe mechanisms including
dummy vias or transistor threshold voltages. Threshold-based obfuscation is
especially promising because threshold voltages cannot be observed optically
and require more sophisticated measurements by the attacker. In this work, we
demonstrate the effectiveness of a methodology that applies threshold-defined
behavior to memory cells, in combination with error correcting codes to achieve
a high degree of protection against invasive reverse engineering. The
combination of error correction and small threshold manipulations is
significant because it makes the attacker's job harder without compromising the
reliability of the obfuscated key. We present analysis to quantify key
reliability of our approach, and its resistance to reverse engineering attacks
that seek to extract the key through imperfect measurement of transistor
threshold voltages. The security analysis and cost metrics we provide allow
designers to make a quantifiable tradeoff between cost and security. We find
that the combination of small threshold offsets and stronger error correcting
codes are advantageous when security is the primary objective.",1708.07150v2,cs.CR,2017-08-23 18:57:29+00:00,"[arxiv.Result.Author('Shahrzad Keshavarz'), arxiv.Result.Author('Daniel Holcomb')]",
929,A Recursive Threshold Visual Cryptography Scheme,"This paper presents a recursive hiding scheme for 2 out of 3 secret sharing.
In recursive hiding of secrets, the user encodes additional information about
smaller secrets in the shares of a larger secret without an expansion in the
size of the latter, thereby increasing the efficiency of secret sharing. We
present applications of our proposed protocol to images as well as text.",0902.2487v1,cs.CR,2009-02-14 20:39:12+00:00,"[arxiv.Result.Author('Abhishek Parakh'), arxiv.Result.Author('Subhash Kak')]",
930,Post-Quantum Cryptography: Code-based Signatures,"This survey provides a comparative overview of code-based signature schemes
with respect to security and performance. Furthermore, we explicitly describe
serveral code-based signature schemes with additional properties such as
identity-based, threshold ring and blind signatures.",1312.4265v1,cs.CR,2013-12-16 08:32:19+00:00,"[arxiv.Result.Author('Pierre-Louis Cayrel'), arxiv.Result.Author('Mohammed Meziani')]","Proceedings of ISA 2010, LNCS 6059, pages 82-99, Springer-Verlag,
  2010"
931,Expected loss analysis of thresholded authentication protocols in noisy conditions,"A number of authentication protocols have been proposed recently, where at
least some part of the authentication is performed during a phase, lasting $n$
rounds, with no error correction. This requires assigning an acceptable
threshold for the number of detected errors. This paper describes a framework
enabling an expected loss analysis for all the protocols in this family.
Furthermore, computationally simple methods to obtain nearly optimal value of
the threshold, as well as for the number of rounds is suggested. Finally, a
method to adaptively select both the number of rounds and the threshold is
proposed.",1009.0278v1,cs.CR,2010-09-01 20:52:36+00:00,"[arxiv.Result.Author('Christos Dimitrakakis'), arxiv.Result.Author('Aikaterini Mitrokotsa'), arxiv.Result.Author('Serge Vaudenay')]",
932,Threshold Trapdoor Functions and Their Applications,"We introduce a cryptographic primitive named threshold trapdoor functions
(TTDFs), from which we give generic constructions of threshold and revocation
encryptions under adaptive corruption model. Then, we show TTDF can be
instantiated under the decisional Diffie-Hellman (DDH) assumption and the
learning with errors (LWE) assumption. By combining the instantiations of TTDF
with the generic constructions, we obtain threshold and revocation encryptions
which compare favorably over existing schemes. The experimental results show
that our proposed schemes are practical.",1804.03783v2,cs.CR,2018-04-11 02:12:44+00:00,"[arxiv.Result.Author('Binbin Tu'), arxiv.Result.Author('Yu Chen'), arxiv.Result.Author('Xueli Wang')]",
933,An Efficient Simulation of Quantum Secret Sharing,"In quantum cryptography, quantum secret sharing $(QSS)$ is a fundamental
primitive. $QSS$ can be used to create complex and secure multiparty quantum
protocols. Existing $QSS$ protocols are either at the $(n, n)$ threshold $2$
level or at the $(t, n)$ threshold $d$ level with a trusted player, where $n$
denotes the number of players and $t$ denotes the threshold number of players.
Here, we propose a secure $d$-level $QSS$ protocol for sharing a secret with
efficient simulation. This protocol is more secure, flexible, and practical as
compared to the existing $QSS$ protocols: $(n, n)$ threshold $2$-level and
$(t,n)$ threshold $d$-level with a trusted player. Further, it does not
disclose any information about the secret to players. Its security analysis
shows that the intercept-resend, intercept, entangle-measure, forgery,
collision and collusion attacks are not possible in this protocol.",2103.11206v1,cs.CR,2021-03-20 16:42:02+00:00,"[arxiv.Result.Author('Kartick Sutradhar'), arxiv.Result.Author('Hari Om')]",
934,A Digital Signature with Threshold Generation and Verification,"This paper proposes a signature scheme where the signatures are generated by
the cooperation of a number of people from a given group of senders and the
signatures are verified by a certain number of people from the group of
recipients. Shamir's threshold scheme and Schnorr's signature scheme are used
to realize the proposed scheme.",cs/0409014v3,cs.CR,2004-09-08 11:55:58+00:00,"[arxiv.Result.Author('Sunder lal'), arxiv.Result.Author('Manoj Kumar')]",
935,Directed Threshold Multi &#8211; Signature Scheme without SDC,"In this paper, we propose a Directed threshold multisignature scheme without
SDC. This signature scheme is applicable when the message is sensitive to the
signature receiver; and the signatures are generated by the cooperation of a
number of people from a given group of senders. In this scheme, any malicious
set of signers cannot impersonate any other set of signers to forge the
signatures. In case of forgery, it is possible to trace the signing set.",cs/0502002v1,cs.CR,2005-02-01 06:29:56+00:00,[arxiv.Result.Author('Manoj Kumar')],
936,Two-way quantum cryptography at different wavelengths,"We study the security of two-way quantum cryptography at different
wavelengths of the electromagnetic spectrum, from the optical range down to the
microwave range. In particular, we consider a two-way quantum communication
protocol where Gaussian-modulated thermal states are subject to random Gaussian
displacements and finally homodyned. We show how its security threshold (in
reverse reconciliation) is extremely robust with respect to the preparation
noise and able to outperform the security thresholds of one-way protocols at
any wavelength. As a result, improved security distances are now accessible for
implementing quantum key distribution at the very challenging regime of
infrared frequencies.",1309.7973v1,quant-ph,2013-09-30 19:20:16+00:00,"[arxiv.Result.Author('Christian Weedbrook'), arxiv.Result.Author('Carlo Ottaviani'), arxiv.Result.Author('Stefano Pirandola')]","Phys. Rev. A 89, 012309 (2014)"
937,Multilevel Threshold Secret and Function Sharing based on the Chinese Remainder Theorem,"A recent work of Harn and Fuyou presents the first multilevel (disjunctive)
threshold secret sharing scheme based on the Chinese Remainder Theorem. In this
work, we first show that the proposed method is not secure and also fails to
work with a certain natural setting of the threshold values on compartments. We
then propose a secure scheme that works for all threshold settings. In this
scheme, we employ a refined version of Asmuth-Bloom secret sharing with a
special and generic Asmuth-Bloom sequence called the {\it anchor sequence}.
Based on this idea, we also propose the first multilevel conjunctive threshold
secret sharing scheme based on the Chinese Remainder Theorem. Lastly, we
discuss how the proposed schemes can be used for multilevel threshold function
sharing by employing it in a threshold RSA cryptosystem as an example.",1605.07988v1,cs.CR,2016-05-25 18:08:26+00:00,"[arxiv.Result.Author('Oguzhan Ersoy'), arxiv.Result.Author('Kamer Kaya'), arxiv.Result.Author('Kerem Kaskaloglu')]",
938,Gaussian one-way thermal quantum cryptography with finite-size effects,"We study the impact of finite-size effects on the security of thermal one-way
quantum cryptography. Our approach considers coherent/squeezed states at the
preparation stage, on the top of which the sender adds trusted thermal noise.
We compute the key rate incorporating finite-size effects, and we obtain the
security threshold at different frequencies. As expected finite-size effects
deteriorate the performance of thermal quantum cryptography. Our analysis is
useful to quantify the impact of this degradation on relevant parameters like
tolerable attenuation, transmission frequencies at which one can achieve
security.",1803.09158v2,quant-ph,2018-03-24 20:12:28+00:00,"[arxiv.Result.Author('Panagiotis Papanastasiou'), arxiv.Result.Author('Carlo Ottaviani'), arxiv.Result.Author('Stefano Pirandola')]","Phys. Rev. A 98, 032314 (2018)"
939,Towards Threshold Key Exchange Protocols,"Threshold schemes exist for many cryptographic primitives like signatures,
key derivation functions, and ciphers. At the same time, practical key exchange
protocols based on Diffie-Hellman (DH) or ECDSA primitives are not designed or
implemented in a threshold setting. In this paper, we implement popular key
exchange protocols in a threshold manner and show that this approach can be
used in practice. First, we introduce two basic threshold DH key agreement
schemes that provide enhanced security features in comparison with the classic
DH primitive: dealerless distributed key generation, threshold shared key
computation, and private key shares refreshing. We implemented the proposed DH
schemes within WireGuard protocol to demonstrate its effectiveness, efficiency,
and usability in practice. The open question is the security of the proposed
schemes and their instantiation from the elliptic curves used in key agreement
protocols: NIST curves, Russian GOST curves, and Curve25519. Second, we propose
an idea of implementing TLS in a threshold setting that can be used instead of
Keyless SSL/TLS technology, and provide the measurements of TLS key exchanges
based on threshold ECDSA. Even if we don't provide any formal definitions,
security analysis, and mathematical proofs, we believe that the ideas and
mechanisms suggested in this paper can be interesting and useful. The main
intention of the paper is to start discussions and raise awareness of the
challenges and problems arising when moving to threshold key exchange
protocols.",2101.00084v2,cs.CR,2020-12-27 07:56:26+00:00,"[arxiv.Result.Author('Denis Kolegov'), arxiv.Result.Author('Yulia Khalniyazova'), arxiv.Result.Author('Denis Varlakov')]",
940,A Directed -Threshold Multi-Signature Scheme,"In this paper, we propose a Directed Threshold Multi-Signature Scheme. In
this threshold signature scheme, any malicious set of signers cannot
impersonate any other set of signers to forge the signatures. In case of
forgery, it is possible to trace the signing set. This threshold signature
scheme is applicable when the message is sensitive to the signature receiver;
and the signatures are generated by the cooperation of a number of people from
a given group of senders.",cs/0409049v3,cs.CR,2004-09-25 12:53:47+00:00,"[arxiv.Result.Author('Sunder lal'), arxiv.Result.Author('Manoj Kumar')]",
941,Threshold Voltage-Defined Switches for Programmable Gates,"Semiconductor supply chain is increasingly getting exposed to variety of
security attacks such as Trojan insertion, cloning, counterfeiting, reverse
engineering (RE), piracy of Intellectual Property (IP) or Integrated Circuit
(IC) and side-channel analysis due to involvement of untrusted parties. In this
paper, we propose transistor threshold voltage-defined switches to camouflage
the logic gate both logically and physically to resist against RE and IP
piracy. The proposed gate can function as NAND, AND, NOR, OR, XOR, XNOR, INV
and BUF robustly using threshold-defined switches. The camouflaged design
operates at nominal voltage and obeys conventional reliability limits. The
proposed gate can also be used to personalize the design during manufacturing.",1512.01581v1,cs.CR,2015-12-04 22:10:23+00:00,"[arxiv.Result.Author('Anirudh Iyengar'), arxiv.Result.Author('Swaroop Ghosh')]",
942,Experimental implementation of an adiabatic quantum optimization algorithm,"We report the realization of a nuclear magnetic resonance computer with three
quantum bits that simulates an adiabatic quantum optimization algorithm.
Adiabatic quantum algorithms offer new insight into how quantum resources can
be used to solve hard problems. This experiment uses a particularly well suited
three quantum bit molecule and was made possible by introducing a technique
that encodes general instances of the given optimization problem into an easily
applicable Hamiltonian. Our results indicate an optimal run time of the
adiabatic algorithm that agrees well with the prediction of a simple
decoherence model.",quant-ph/0302057v2,quant-ph,2003-02-07 22:06:07+00:00,"[arxiv.Result.Author('Matthias Steffen'), arxiv.Result.Author('Wim van Dam'), arxiv.Result.Author('Tad Hogg'), arxiv.Result.Author('Greg Breyta'), arxiv.Result.Author('Isaac Chuang')]","Physical Review Letters, Volume 90, Number 6, Article 067903
  (2003)"
943,"Review of Energy Transition Policies in Singapore, London, and California","The paper contains the online supplementary materials for ""Data-Driven
Prediction and Evaluation on Future Impact of Energy Transition Policies in
Smart Regions"". We review the renewable energy development and policies in the
three metropolitan cities/regions over recent decades. Depending on the
geographic variations in the types and quantities of renewable energy resources
and the levels of policymakers' commitment to carbon neutrality, we classify
Singapore, London, and California as case studies at the primary, intermediate,
and advanced stages of the renewable energy transition, respectively.",2208.01433v1,econ.GN,2022-08-02 13:10:10+00:00,"[arxiv.Result.Author('Chunmeng Yang'), arxiv.Result.Author('Siqi Bu'), arxiv.Result.Author('Yi Fan'), arxiv.Result.Author('Wayne Xinwei Wan'), arxiv.Result.Author('Ruoheng Wang'), arxiv.Result.Author('Aoife Foley')]",
944,Disoriented Chiral Condensate,"The current theoretical understanding of disoriented chiral condensate is
briefly reviewed. I discuss the basic idea, the formation mechanism and
experimental signatures of DCC in high energy collisions.",hep-ph/9501366v1,hep-ph,1995-01-25 01:28:02+00:00,[arxiv.Result.Author('Zheng Huang')],
945,Radiative Higgs-Sector CP Violation in the MSSM,"We briefly review the phenomenological implications of the minimal
supersymmetric standard model (MSSM) with explicit radiative breaking of CP
invariance in the Higgs sector for the LEP2 and Tevatron colliders.",hep-ph/0003232v1,hep-ph,2000-03-23 14:18:47+00:00,[arxiv.Result.Author('Apostolos Pilaftsis')],
946,Progress in lattice QCD at finite temperature,"I review current status of lattice QCD calculations of the deconfining
transition at finite temperature and quarkonia spectral functions.",nucl-th/0606013v1,nucl-th,2006-06-09 16:20:37+00:00,[arxiv.Result.Author('Peter Petreczky')],
947,Charmless three-body decays of b-hadrons,"A review of recent results from LHCb and the B-factories on the charmless
decays of b-hadrons into three-body final states is presented.",1310.0855v1,hep-ex,2013-10-02 21:58:05+00:00,[arxiv.Result.Author('Thomas Latham')],
948,Evolution of Gas in Elliptical Galaxies,"We review the origin and structure of hot (cooling flow) gas in elliptical
galaxies. X-ray observations can be used to determine the stellar mass to light
ratio, the mass profiles of dark matter halos, and the interstellar magnetic
field. Interstellar gas cools over a large volume, forming stars with a
bottom-heavy IMF. For consistency with the thin fundamental plane, young stars
must be optically luminous. Circular X-ray isophotes in rotating elliptical
galaxies indicate distributed radiative cooling or strong interstellar
turbulence.",astro-ph/0010040v1,astro-ph,2000-10-02 18:21:58+00:00,"[arxiv.Result.Author('William G. Mathews'), arxiv.Result.Author('Fabrizio Brighenti')]",
949,Statistical Complexity of Simple 1D Spin Systems,"We present exact results for two complementary measures of spatial structure
generated by 1D spin systems with finite-range interactions. The first, excess
entropy, measures the apparent spatial memory stored in configurations. The
second, statistical complexity, measures the amount of memory needed to
optimally predict the chain of spin values. These statistics capture distinct
properties and are different from existing thermodynamic quantities.",cond-mat/9702191v1,cond-mat.stat-mech,1997-02-21 01:02:16+00:00,"[arxiv.Result.Author('James P. Crutchfield'), arxiv.Result.Author('David P. Feldman')]","Physical Review E, 55:2 (1997) 1239R"
950,FAIR Metadata: A Community-driven Vocabulary Application,"FAIR metadata is critical to supporting FAIR data overall. Transparency,
community engagement, and flexibility are key aspects of FAIR that apply to
metadata. This paper presents YAMZ (Yet Another Metadata Zoo), a
community-driven vocabulary application that supports FAIR. The history ofYAMZ
and its original features are reviewed, followed by a presentation of recent
innovations and a discussion of how YAMZ supports FAIR principles. The
conclusion identifies next steps and key outputs.",2111.03910v1,cs.DL,2021-11-06 15:53:09+00:00,"[arxiv.Result.Author('Christopher B. Rauch'), arxiv.Result.Author('Mat Kelly'), arxiv.Result.Author('John A. Kunze'), arxiv.Result.Author('Jane Greenberg')]",
951,An Empirical Evaluation of the Implementation of the California Consumer Privacy Act (CCPA),"On January 1, 2020, California passed the California Consumer Privacy Act
(CCPA) by more than 56% of voters intended to enhance privacy rights and
consumer protection for residents of California, United States. Since then,
more conditions have been added to the Act to support consumers' privacy. In
addition, two years after the first effective day of CCPA, consumers have seen
California organizations apply approaches to adapt to CCPA. Many organizations
quickly upgrade their policy to comply with the legislation and create
effective platforms such as data portals that allow consumers to exercise their
privacy rights. However, on the other hand, we still noticed aspects of CCPA
being absent on some websites. Additionally, we found no prior evaluation of
the CCPA implementation in organizations. Therefore, the convergence of the
regulatory landscape and the organization's privacy policy needs to be studied.
This paper was about an empirical evaluation of the implementation of the
California Consumer Privacy Act. The report includes the evaluations of the
following industries: social media, financial institutions, mortgages,
healthcare providers, and academic institutions. Our approach was to set up a
criteria table constructed from the CCPA Act and then use that table as a
checklist while reviewing a company's privacy notice. Finally, we concluded
this paper with an online tool application design that verifies the CCPA
implementation. Upon completion, the application would be free to use so
consumers can quickly inspect a website for CCPA compliance. Additionally, it
is an advising tool that a website admin can utilize to enhance CCPA compliance
for their website. The conjunction of this empirical report and a practical
application function as a stimulus to promote CCPA implementation in
organizations and deliver awareness to consumers about privacy rights they can
demand.",2205.09897v2,cs.CY,2022-05-19 23:28:41+00:00,[arxiv.Result.Author('Trong Nguyen')],
952,"Glassy Spin Dynamics in Non-Fermi-Liquid UCu_{5-x}Pd_x, x = 1.0 and 1.5","Local f-electron spin dynamics in the non-Fermi-liquid heavy-fermion alloys
UCu_{5-x}Pd_x, x = 1.0 and 1.5, have been studied using muon spin-lattice
relaxation. The sample-averaged asymmetry function Gbar(t) indicates strongly
inhomogeneous spin fluctuations, and exhibits the scaling Gbar(t,H) =
Gbar(t/H^\gamma) expected from glassy dynamics. At 0.05 K \gamma(x=1.0) = 0.35
\pm 0.1, but \gamma(x=1.5) = 0.7 \pm 0.1. This is in contrast to inelastic
neutron scattering results, which yield \gamma = 0.33 for both concentrations.
There is no sign of static magnetism \gtrsim 10^{-3} \mu_B/U ion in either
material above 0.05 K. Our results strongy suggest that both alloys are quantum
spin glasses.",cond-mat/0012389v2,cond-mat.str-el,2000-12-20 19:58:47+00:00,"[arxiv.Result.Author('D. E. MacLaughlin'), arxiv.Result.Author('O. O. Bernal'), arxiv.Result.Author('R. H. Heffner'), arxiv.Result.Author('G. J. Nieuwenhuys'), arxiv.Result.Author('M. S. Rose'), arxiv.Result.Author('J. E. Sonier'), arxiv.Result.Author('B. Andraka'), arxiv.Result.Author('R. Chau'), arxiv.Result.Author('M. B. Maple')]",
953,Exchange-induced frustration in Fe/NiO multilayers,"Using spin-polarized low-energy electron microscopy to study magnetization in
epitaxial layered systems, we found that the area vs perimeter relationship of
magnetic domains in the top Fe layers of Fe/NiO/Fe(100) structures follows a
power-law distribution, with very small magnetic domain cutoff radius (about 40
nm) and domain wall thickness. This unusual magnetic microstructure can be
understood as resulting from the competition between antiferromagnetic and
ferromagnetic exchange interactions at the Fe/NiO interfaces, rather than from
mechanisms involving the anisotropy and dipolar forces that govern length
scales in conventional magnetic domain structures. Statistical analysis of our
measurements validates a micromagnetic model that accounts for this interfacial
exchange coupling.",0705.4106v2,cond-mat.mtrl-sci,2007-05-28 20:28:45+00:00,"[arxiv.Result.Author('N. Rougemaille'), arxiv.Result.Author('M. Portalupi'), arxiv.Result.Author('A. Brambilla'), arxiv.Result.Author('P. Biagioni'), arxiv.Result.Author('A. Lanzara'), arxiv.Result.Author('M. Finazzi'), arxiv.Result.Author('A. K. Schmid'), arxiv.Result.Author('L. Duò')]","Physical Review B 76, 214425 (2007)"
954,Schools on different corners: An investigation into the effects of ethnicity and socioeconomic status on physics offerings in Northern California public high schools,"In the spring of 2018 the Northern California/Nevada section of the American
Association of Physics Teachers was alerted to a local high school's plans to
eliminate physics for the following school year. As part of the campaign to
support the school's efforts to sustain physics in the following year, the
physics offerings from the surrounding schools in that district were compiled.
It appeared that the demographics of the student population in the district
played a role in the number of different physics courses offered within that
district, particularly the percentage of Hispanic students (%Hispanic) and
percentage of socioeconomically disadvantaged (%SED) students at each school.
Concerned that this trend was more widespread, physics course offerings were
reviewed for Northern California public high schools to determine if there were
correlations between the amount of different physics class offerings and these
populations. It was found that %Hispanic and %SED are strongly correlated in
California public schools, and along with number of students, could be used as
statistically significant predictors of a school's physics offerings.",2010.08476v4,physics.ed-ph,2020-10-16 16:23:59+00:00,"[arxiv.Result.Author('David Marasco'), arxiv.Result.Author('Bree Barnett Dreyfuss')]","The Physics Teacher 58, 673 (2020);"
955,The Formation of Planets,"This paper reviews the dynamics of the growth of solid particles from
micron-sized dust grains to planets in protostellar accretion disks. The
formation and orbital evolution of giant protoplanets is also discussed.",astro-ph/9910331v1,astro-ph,1999-10-18 21:42:22+00:00,[arxiv.Result.Author('Steven P. Ruden')],"1999, in ""The Origins of Stars and Planetary Systems"", eds. C.J.
  Lada and N.D. Kylafis, (Dordrecht: Kluwer), 643 - 679"
956,Supernova Neutrino-Nucleus Astrophysics,"In this brief review we explore the role of neutrino-nucleus interactions in
core-collapse supernovae and discuss open questions. In addition implications
of neutrino mass and mixings in such environments are summarized.",astro-ph/0309519v1,astro-ph,2003-09-19 00:41:48+00:00,"[arxiv.Result.Author('A. B. Balantekin'), arxiv.Result.Author('G. M. Fuller')]","J.Phys.G29:2513-2522,2003"
957,Exploring the Universe beyond the Photon Window,"In this talk I review how to identify cosmic ray accelerators that are high
energy neutrino emitters. I also delineate the prospects for a new
multi-particle astronomy: neutrons as directional pointers + antineutrinos as
inheritors of directionality.",astro-ph/0410087v1,astro-ph,2004-10-05 10:34:24+00:00,[arxiv.Result.Author('Luis A. Anchordoqui')],Acta Phys.Polon. B36 (2005) 495-508
958,R Measurements at High Q^2,"Previous Measurements of R at high Q^2 are reviewed. Recent R measurement
results, including those from the Beijing Spectrometer Experiment, are
described. The present status of R measurements and future measurement
possiblities are summarized.",hep-ex/0106003v1,hep-ex,2001-06-01 19:00:10+00:00,[arxiv.Result.Author('F. A. Harris')],"eConf C010430:M12,2001"
959,Jet production at HERA,"Recent results from jet production in deep inelastic ep scattering to
investigate parton dynamics at low x are reviewed. The results on jet
production in deep inelastic scattering and photoproduction used to test
perturbative QCD are discussed and the values of alphas(Mz) extracted from a
QCD analysis of the data are presented",hep-ex/0410023v1,hep-ex,2004-10-07 16:49:01+00:00,[arxiv.Result.Author('C. Glasman')],"Acta Phys.Polon.B36:441-450,2005"
960,Theory of Rare B Decays,"Theoretical aspects of rare $B$ decays are reviewed. The focus is on the
relation between short-distance interactions and physical observables. It is
argued that there remain significant uncertainties in the theoretical treatment
of certain important quantities. (Talk presented at the International Symposium
on Vector Boson Interactions, University of California, Los Angeles, February
1-3, 1995)",hep-ph/9503485v1,hep-ph,1995-03-31 20:37:09+00:00,[arxiv.Result.Author('Adam F. Falk')],
961,Summary talk: Gauge Boson Self Interactions,"A review is given of the theoretical expectations of the self couplings of
gauge bosons and of the present experimental information on the couplings. The
possibilities for future measurements are also discussed.",hep-ph/9504206v1,hep-ph,1995-04-03 16:39:29+00:00,[arxiv.Result.Author('Ian Hinchliffe')],
962,Does Your Phone Know Your Touch?,"This paper explores supervised techniques for continuous anomaly detection
from biometric touch screen data. A capacitive sensor array used to mimic a
touch screen as used to collect touch and swipe gestures from participants. The
gestures are recorded over fixed segments of time, with position and force
measured for each gesture. Support Vector Machine, Logistic Regression, and
Gaussian mixture models were tested to learn individual touch patterns. Test
results showed true negative and true positive scores of over 95% accuracy for
all gesture types, with logistic regression models far outperforming the other
methods. A more expansive and varied data collection over longer periods of
time is needed to determine pragmatic usage of these results.",1809.03402v1,cs.LG,2018-09-10 15:39:07+00:00,"[arxiv.Result.Author('John Peruzzi'), arxiv.Result.Author('Phillip Andrew Wingard'), arxiv.Result.Author('David Zucker')]",
963,Finger-Stylus for Non Touch-Enable Systems,"Since computer was invented, people are using many devices to interact with
computer. Initially there were keyboard, mouse etc. but with the advancement of
technology, new ways are being discovered that are quite usual and natural to
the humans like stylus, touch-enable systems. In the current age of technology,
user is expected to touch the machine interface to give input. Hand gesture is
such a way to interact with machines where natural bare hand is used to
communicate without touching machine interface. It gives a feeling to user that
he is interacting in natural way to some human, not with traditional machines.
This paper presents a technique where user needs not to touch the machine
interface to draw on screen. Here hand finger draws shapes on monitor like
stylus, without touching the monitor. This method can be used in many
applications including games. The finger was used as an input device that acts
like paint-brush or finger-stylus and is used to make shapes in front of the
camera. Fingertip extraction and motion tracking were done in Matlab with real
time constraints. This work is an early attempt to replace stylus with the
natural finger without touching screen.",1409.3554v2,cs.HC,2014-09-07 19:20:45+00:00,[arxiv.Result.Author('Ankit Chaudhary')],
964,Inventions on GUI for Touch Sensitive Screens,"A touch sensitive screen displays the information on the screen and also
receives the input by sensing a user's touch on the same screen. This mechanism
facilitates system interaction directly through the screen without needing a
mouse or keyboard. This method has the advantage to make the system compact by
removing keyboard, mouse and similar interactive device.
  However there are certain difficulties to implement a touch screen interface.
The display screens of portable devices are becoming smaller thereby leaving
lesser space for display of data, menu or touch screen interaction. Besides
some screens need to display so much of information that they hardly can afford
any space to display touch screen buttons. This article illustrates various
inventions which have successfully eliminated these difficulties by applying
appropriate Inventive principles.",1404.6761v1,cs.HC,2014-04-27 15:05:44+00:00,[arxiv.Result.Author('Umakant Mishra')],"Umakant Mishra, Inventions on GUI for Touch Sensitive Screens
  (September 7, 2007). Available at SSRN: http://ssrn.com/abstract=1264684 or
  http://dx.doi.org/10.2139/ssrn.1264684"
965,Analysis of the 2004 Venezuela Referendum: The Official Results Versus the Petition Signatures,"On August 15th, 2004, Venezuelans had the opportunity to vote in a
Presidential Recall Referendum to decide whether or not President Hugo
Ch\'{a}vez should be removed from office. The process was largely computerized
using a touch-screen system. In general the ballots were not manually counted.
The significance of the high linear correlation (0.99) between the number of
requesting signatures for the recall petition and the number of opposition
votes in computerized centers is analyzed. The same-day audit was found to be
not only ineffective but a source of suspicion. Official results were compared
with the 1998 presidential election and other electoral events and distortions
were found.",1205.5108v1,stat.ME,2012-05-23 07:22:20+00:00,"[arxiv.Result.Author('Gustavo Delfino'), arxiv.Result.Author('Guillermo Salas')]","Statistical Science 2011, Vol. 26, No. 4, 479-501"
966,Blind Recognition of Touched Keys: Attack and Countermeasures,"In this paper, we introduce a novel computer vision based attack that
discloses inputs on a touch enabled device, while the attacker cannot see any
text or popups from a video of the victim tapping on the touch screen. In the
attack, we use the optical flow algorithm to identify touching frames where the
finger touches the screen surface. We innovatively use intersections of
detected edges of the touch screen to derive the homography matrix mapping the
touch screen surface in video frames to a reference image of the virtual
keyboard. We analyze the shadow formation around the fingertip and use the
k-means clustering algorithm to identify touched points. Homography can then
map these touched points to keys of the virtual keyboard. Our work is
substantially different from existing work. We target password input and are
able to achieve a high success rate. We target scenarios like classrooms,
conferences and similar gathering places and use a webcam or smartphone camera.
In these scenes, single-lens reflex (SLR) cameras and high-end camcorders used
in related work will appear suspicious. To defeat such computer vision based
attacks, we design, implement and evaluate the Privacy Enhancing Keyboard (PEK)
where a randomized virtual keyboard is used to input sensitive information.",1403.4829v1,cs.CR,2014-03-19 14:55:17+00:00,"[arxiv.Result.Author('Qinggang Yue'), arxiv.Result.Author('Zhen Ling'), arxiv.Result.Author('Benyuan Liu'), arxiv.Result.Author('Xinwen Fu'), arxiv.Result.Author('Wei Zhao')]",
967,Touchalytics: On the Applicability of Touchscreen Input as a Behavioral Biometric for Continuous Authentication,"We investigate whether a classifier can continuously authenticate users based
on the way they interact with the touchscreen of a smart phone. We propose a
set of 30 behavioral touch features that can be extracted from raw touchscreen
logs and demonstrate that different users populate distinct subspaces of this
feature space. In a systematic experiment designed to test how this behavioral
pattern exhibits consistency over time, we collected touch data from users
interacting with a smart phone using basic navigation maneuvers, i.e., up-down
and left-right scrolling. We propose a classification framework that learns the
touch behavior of a user during an enrollment phase and is able to accept or
reject the current user by monitoring interaction with the touch screen. The
classifier achieves a median equal error rate of 0% for intra-session
authentication, 2%-3% for inter-session authentication and below 4% when the
authentication test was carried out one week after the enrollment phase. While
our experimental findings disqualify this method as a standalone authentication
mechanism for long-term authentication, it could be implemented as a means to
extend screen-lock time or as a part of a multi-modal biometric authentication
system.",1207.6231v2,cs.CR,2012-07-26 10:34:19+00:00,"[arxiv.Result.Author('Mario Frank'), arxiv.Result.Author('Ralf Biedert'), arxiv.Result.Author('Eugene Ma'), arxiv.Result.Author('Ivan Martinovic'), arxiv.Result.Author('Dawn Song')]","IEEE Transactions on Information Forensics and Security (Vol. 8,
  No. 1), pages 136-148, 2013"
968,FASTEN: Fair and Secure Distributed Voting Using Smart Contracts,"Electing democratic representatives via voting has been a common mechanism
since the 17th century. However, these mechanisms raise concerns about
fairness, privacy, vote concealment, fair calculations of tally, and proxies
voting on their behalf for the voters. Ballot voting, and in recent times,
electronic voting via electronic voting machines (EVMs) improves fairness by
relying on centralized trust. Homomorphic encryption-based voting protocols
also assure fairness but cannot scale to large scale elections such as
presidential elections. In this paper, we leverage the blockchain technology of
distributing trust to propose a smart contract-based protocol, namely, \proto.
There are many existing protocols for voting using smart contracts. We observe
that these either are not scalable or leak the vote tally during the voting
stage, i.e., do not provide vote concealment. In contrast, we show that FASTEN
preserves voter's privacy ensures vote concealment, immutability, and avoids
double voting. We prove that the probability of privacy breaches is negligibly
small. Further, our cost analysis of executing FASTEN over Ethereum is
comparable to most of the existing cost of elections.",2102.10594v1,cs.CR,2021-02-21 12:29:23+00:00,"[arxiv.Result.Author('Sankarshan Damle'), arxiv.Result.Author('Sujit Gujar'), arxiv.Result.Author('Moin Hussain Moti')]",
969,Voting Data-Driven Regression Learning for Discovery of Functional Materials and Applications to Two-Dimensional Ferroelectric Materials,"Regression machine learning is widely applied to predict various materials.
However, insufficient materials data usually leads to a poor performance. Here,
we develop a new voting data-driven method that could generally improve the
performance of regression learning model for accurately predicting properties
of materials. We apply it to investigate a large family (2135) of
two-dimensional hexagonal binary compounds focusing on ferroelectric properties
and find that the performance of the model for electric polarization is indeed
greatly improved, where 38 stable ferroelectrics with out-of-plane polarization
including 31 metals and 7 semiconductors are screened out. By an unsupervised
learning, actionable information such as how the number and orbital radius of
valence electrons, ionic polarizability, and electronegativity of constituent
atoms affect polarization was extracted. Our voting data-driven method not only
reduces the size of materials data for constructing a reliable learning model
but also enables to make precise predictions for targeted functional materials.",2010.01765v1,cond-mat.mtrl-sci,2020-10-05 04:06:35+00:00,"[arxiv.Result.Author('Xing-Yu Ma'), arxiv.Result.Author('Hou-Yi Lyu'), arxiv.Result.Author('Xue-Juan Dong'), arxiv.Result.Author('Zhen Zhang'), arxiv.Result.Author('Kuan-Rong Hao'), arxiv.Result.Author('Qing-Bo Yan'), arxiv.Result.Author('Gang Su')]",
970,Open Source Dataset and Deep Learning Models for Online Digit Gesture Recognition on Touchscreens,"This paper presents an evaluation of deep neural networks for recognition of
digits entered by users on a smartphone touchscreen. A new large dataset of
Arabic numerals was collected for training and evaluation of the network. The
dataset consists of spatial and temporal touch data recorded for 80 digits
entered by 260 users. Two neural network models were investigated. The first
model was a 2D convolutional neural (ConvNet) network applied to bitmaps of the
glpyhs created by interpolation of the sensed screen touches and its topology
is similar to that of previously published models for offline handwriting
recognition from scanned images. The second model used a 1D ConvNet
architecture but was applied to the sequence of polar vectors connecting the
touch points. The models were found to provide accuracies of 98.50% and 95.86%,
respectively. The second model was much simpler, providing a reduction in the
number of parameters from 1,663,370 to 287,690. The dataset has been made
available to the community as an open source resource.",1709.06871v1,cs.CV,2017-09-20 14:02:55+00:00,"[arxiv.Result.Author('Philip J. Corr'), arxiv.Result.Author('Guenole C. Silvestre'), arxiv.Result.Author('Chris J. Bleakley')]",
971,Naturally Supervised Learning in Manipulable Technologies,"The relationship between physiological systems and modern electromechanical
technologies is fast becoming intimate with high degrees of complex
interaction. It can be argued that muscular function, limb movements, and touch
perception serve supervisory functions for movement control in motion and
touch-based (e.g. manipulable) devices/interfaces and human-machine interfaces
in general. To get at this hypothesis requires the use of novel techniques and
analyses which demonstrate the multifaceted and regulatory role of adaptive
physiological processes in these interactions. Neuromechanics is an approach
that unifies the role of physiological function, motor performance, and
environmental effects in determining human performance. A neuromechanical
perspective will be used to explain the effect of environmental fluctuations on
supervisory mechanisms, which leads to adaptive physiological responses. Three
experiments are presented using two different types of virtual environment that
allowed for selective switching between two sets of environmental forces. This
switching was done in various ways to maximize the variety of results.
Electromyography (EMG) and kinematic information contributed to the development
of human performance-related measures. Both descriptive and specialized
analyses were conducted: peak amplitude analysis, loop trace analysis, and the
analysis of unmatched muscle power. Results presented here provide a window
into performance under a range of conditions. These analyses also demonstrated
myriad consequences for force-related fluctuations on dynamic physiological
regulation. The findings presented here could be applied to the dynamic control
of touch-based and movement-sensitive human-machine systems. In particular, the
design of systems such as human-robotic systems, touch screen devices, and
rehabilitative technologies could benefit from this research.",1106.1105v2,cs.HC,2011-06-06 16:01:10+00:00,[arxiv.Result.Author('Bradly Alicea')],
972,Machine Learning Enabled Force Sensing of a Smart Skin for Robotics,"Artificial skin with the sense of touch can support robots to interact with
the surrounding environment efficiently and accomplish complex tasks.
Traditional multi-layered artificial skins require complex manufacturing
processes which can result in high cost as well as limitations on the material
and size of the skin. In this paper, we demonstrate a machine learning based
approach to predict positions of point loads using the most direct response as
input signal: strain distribution. Starting with the simplest problem,
predicting the position of a single point load acting on a flat surface, an ML
model is developed, trained, and tested. Accurate predictions are obtained from
the ML model, parameters that affect the accuracy are discussed, and validation
tests are performed. After that, the ML model is modified to solve
multi-objective prediction problems: predicting positions and magnitudes of
multiple point loads. In the end, the ML model is upgraded to a 2-step model to
predict the position of a point load acting on a deformable surface. The
demonstrated approach enables a normal untreated surface to feel a touch no
matter what the surface is made of or how large or small the size of the
surface is. Therefore, we believe this ML-based load position prediction
approach could be a promising tool for applications such as flexible touch
screens, smart skin for robots, and micro touch sensors.",2211.00189v1,physics.app-ph,2022-10-31 23:11:10+00:00,"[arxiv.Result.Author('Fan Liu'), arxiv.Result.Author('Guangyu He'), arxiv.Result.Author('Xihang Jiang'), arxiv.Result.Author('Lifeng Wang')]",
973,Distributed Voting/Ranking with Optimal Number of States per Node,"Considering a network with $n$ nodes, where each node initially votes for one
(or more) choices out of $K$ possible choices, we present a Distributed
Multi-choice Voting/Ranking (DMVR) algorithm to determine either the choice
with maximum vote (the voting problem) or to rank all the choices in terms of
their acquired votes (the ranking problem). The algorithm consolidates node
votes across the network by updating the states of interacting nodes using two
key operations, the union and the intersection. The proposed algorithm is
simple, independent from network size, and easily scalable in terms of the
number of choices $K$, using only $K\times 2^{K-1}$ nodal states for voting,
and $K\times K!$ nodal states for ranking. We prove the number of states to be
optimal in the ranking case, this optimality is conjectured to also apply to
the voting case. The time complexity of the algorithm is analyzed in complete
graphs. We show that the time complexity for both ranking and voting is
$O(\log(n))$ for given vote percentages, and is inversely proportional to the
minimum of the vote percentage differences among various choices.",1703.08838v1,cs.DC,2017-03-26 16:19:31+00:00,"[arxiv.Result.Author('Saber Salehkaleybar'), arxiv.Result.Author('Arsalan Sharif-Nassab'), arxiv.Result.Author('S. Jamaloddin Golestani')]",
974,It is not just about the Melody: How Europe Votes for its Favorite Songs,"The Eurovision Song Contest is a popular annual international song
competition organized by the European Broadcasting Union. The winner is decided
by the audience and expert juries from each participating nation, which is why
the analysis of its voting network offers a great insight into what factors,
besides the quality of the performances, influence the voting decisions.
  In this paper, we present the findings of the analysis of the voting network,
together with the results of a predictive model based on the collected data. We
touch upon the methodology used and describe the dataset we carry the analysis
on. The results include some general features of the voting networks, the
exposed communities of countries that award significantly more points among
themselves than would be expected and some predictions on what the biggest
factors that lead to this phenomenon are. We also include the model to predict
the votes based on network structure of both previous votes and song
preferences of nations, which we found not to offer much improved predictions
than relying on the betting tables alone.",2002.06609v1,cs.SI,2020-02-16 16:04:59+00:00,"[arxiv.Result.Author('Anej Svete'), arxiv.Result.Author('Jakob Hostnik')]",
975,Tracking Ensemble Performance on Touch-Screens with Gesture Classification and Transition Matrices,"We present and evaluate a novel interface for tracking ensemble performances
on touch-screens. The system uses a Random Forest classifier to extract
touch-screen gestures and transition matrix statistics. It analyses the
resulting gesture-state sequences across an ensemble of performers. A series of
specially designed iPad apps respond to this real-time analysis of free-form
gestural performances with calculated modifications to their musical
interfaces. We describe our system and evaluate it through cross-validation and
profiling as well as concert experience.",2012.00296v1,cs.HC,2020-12-01 06:36:26+00:00,"[arxiv.Result.Author('Charles Martin'), arxiv.Result.Author('Henry Gardner'), arxiv.Result.Author('Ben Swift')]","Proceedings of the International Conference on New Interfaces for
  Musical Expression, 2015, pp. 359-364"
976,A novel processing pipeline for optical multi-touch surfaces,"In this thesis a new approach for touch detection on optical multi-touch
devices is proposed that exploits the fact that the camera images reveal not
only the actual touch points but also objects above the screen such as the hand
or arm of a user. The touch processing relies on the Maximally Stable Extremal
Regions algorithm for finding the users' fingertips in the camera image. The
hierarchical structure of the generated extremal regions serves as a starting
point for agglomerative clustering of the fingertips into hands. Furthermore, a
heuristic is suggested that supports the identification of individual fingers
as well as the distinction between left hands and right hands if all five
fingers of a hand are in contact with the touch surface.
  The evaluation confirmed that the system is robust against detection errors
resulting from non-uniform illumination and reliably assigns touch points to
individual hands based on the implicitly tracked context information. The
efficient multi-threaded implementation handles two-handed input from multiple
users in real-time.",1301.1551v1,cs.CV,2013-01-08 14:48:23+00:00,[arxiv.Result.Author('Philipp Ewerling')],
977,SilentSense: Silent User Identification via Dynamics of Touch and Movement Behavioral Biometrics,"With the increased popularity of smartphones, various security threats and
privacy leakages targeting them are discovered and investigated. In this work,
we present \ourprotocoltight, a framework to authenticate users silently and
transparently by exploiting dynamics mined from the user touch behavior
biometrics and the micro-movement of the device caused by user's screen-touch
actions. We build a ""touch-based biometrics"" model of the owner by extracting
some principle features, and then verify whether the current user is the owner
or guest/attacker. When using the smartphone, the unique operating dynamics of
the user is detected and learnt by collecting the sensor data and touch events
silently. When users are mobile, the micro-movement of mobile devices caused by
touch is suppressed by that due to the large scale user-movement which will
render the touch-based biometrics ineffective. To address this, we integrate a
movement-based biometrics for each user with previous touch-based biometrics.
We conduct extensive evaluations of our approaches on the Android smartphone,
we show that the user identification accuracy is over 99%.",1309.0073v1,cs.CR,2013-08-31 08:16:53+00:00,"[arxiv.Result.Author('Cheng Bo'), arxiv.Result.Author('Lan Zhang'), arxiv.Result.Author('Xiang-Yang Li')]",
978,Hand Posture's Effect on Touch Screen Text Input Behaviors: A Touch Area Based Study,"Mobile devices with touch keyboards have become ubiquitous, but text entry on
these devices remains slow and errorprone. Understanding touch patterns during
text entry could be useful in designing robust error-correction algorithms for
soft keyboards. In this paper, we present an analysis of text input behaviors
on a soft QWERTY keyboard in three different text entry postures: index finger
only, one thumb, and two thumb. Our work expands on the work of [1] by
considering the entire surface area of digit contact with the smartphone
keyboard, rather than interpreting each touch as a single point. To do this, we
captured touch areas for every key in a lab study with 8 participants and
calculated offsets, error rates, and size measurements. We then repeated the
original experiment described in [1] and showed that significant differences
exist when basing offset calculations on touch area compared to touch points
for two postures.",1504.02134v1,cs.HC,2015-04-08 21:39:56+00:00,"[arxiv.Result.Author('Christopher Thomas'), arxiv.Result.Author('Brandon Jennings')]",
979,Convolutional neural network based on transfer learning for breast cancer screening,"Breast cancer is the most common cancer in the world and the most prevalent
cause of death among women worldwide. Nevertheless, it is also one of the most
treatable malignancies if detected early. In this paper, a deep convolutional
neural network-based algorithm is proposed to aid in accurately identifying
breast cancer from ultrasonic images. In this algorithm, several neural
networks are fused in a parallel architecture to perform the classification
process and the voting criteria are applied in the final classification
decision between the candidate object classes where the output of each neural
network is representing a single vote. Several experiments were conducted on
the breast ultrasound dataset consisting of 537 Benign, 360 malignant, and 133
normal images. These experiments show an optimistic result and a capability of
the proposed model to outperform many state-of-the-art algorithms on several
measures. Using k-fold cross-validation and a bagging classifier ensemble, we
achieved an accuracy of 99.5% and a sensitivity of 99.6%.",2112.11629v1,cs.CV,2021-12-22 02:27:12+00:00,"[arxiv.Result.Author('Hussin Ragb'), arxiv.Result.Author('Redha Ali'), arxiv.Result.Author('Elforjani Jera'), arxiv.Result.Author('Nagi Buaossa')]",
980,Beyond Exchangeability: The Chinese Voting Process,"Many online communities present user-contributed responses such as reviews of
products and answers to questions. User-provided helpfulness votes can
highlight the most useful responses, but voting is a social process that can
gain momentum based on the popularity of responses and the polarity of existing
votes. We propose the Chinese Voting Process (CVP) which models the evolution
of helpfulness votes as a self-reinforcing process dependent on position and
presentation biases. We evaluate this model on Amazon product reviews and more
than 80 StackExchange forums, measuring the intrinsic quality of individual
responses and behavioral coefficients of different communities.",1610.09428v1,cs.LG,2016-10-28 23:38:22+00:00,"[arxiv.Result.Author('Moontae Lee'), arxiv.Result.Author('Seok Hyun Jin'), arxiv.Result.Author('David Mimno')]",
981,Content Transfer Across Multiple Screens with Combined Eye-Gaze and Touch Interaction -- A Replication Study,"In this paper, we describe the results of replicating one of our studies from
two years ago which compares two techniques for transferring content across
multiple screens in VR. Results from the previous study have shown that a
combined gaze and touch input can outperform a bimanual touch-only input in
terms of task completion time, simulator sickness, task load and usability.
Except for the simulator sickness, these findings could be validated by the
replication. The difference with regards to simulator sickness and variations
in absolute scores of the other measures could be explained by a different set
of user with less VR experience.",2210.13283v1,cs.HC,2022-10-24 14:24:26+00:00,"[arxiv.Result.Author('Verena Biener'), arxiv.Result.Author('Jens Grubert')]",
982,Transparency effect in the emergence of monopolies in social networks,"Power law degree distribution was shown in many complex networks. However, in
most real systems, deviation from power-law behavior is observed in social and
economical networks and emergence of giant hubs is obvious in real network
structures far from the tail of power law. We propose a model based on the
information transparency (transparency means how much the information is
obvious to others). This model can explain power structure in societies with
non-transparency in information delivery. The emergence of ultra powerful nodes
is explained as a direct result of censorship. Based on these assumptions, we
define four distinct transparency regions: perfect non-transparent, low
transparent, perfect transparent and exaggerated regions. We observe the
emergence of some ultra powerful (very high degree) nodes in low transparent
networks, in accordance with the economical and social systems. We show that
the low transparent networks are more vulnerable to attacks and the
controllability of low transparent networks is harder than the others. Also,
the ultra powerful nodes in the low transparent networks have a smaller mean
length and higher clustering coefficients than the other regions.",1301.4634v1,physics.soc-ph,2013-01-20 07:00:23+00:00,"[arxiv.Result.Author('A. H. Shirazi'), arxiv.Result.Author('A. Namaki'), arxiv.Result.Author('A. A. Roohi'), arxiv.Result.Author('G. R. Jafari')]","Journal of Artificial Societies and Social Simulation 16 (1) 1
  (2013)"
983,An Efficient Transparent Test Scheme for Embedded Word-Oriented Memories,"Memory cores are usually the densest portion with the smallest feature size
in system-on-chip (SOC) designs. The reliability of memory cores thus has heavy
impact on the reliability of SOCs. Transparent test is one of useful technique
for improving the reliability of memories during life time. This paper presents
a systematic algorithm used for transforming a bit-oriented march test into a
transparent word-oriented march test. The transformed transparent march test
has shorter test complexity compared with that proposed in the previous works
[Theory of transparent BIST for RAMs, A transparent online memory test for
simultaneous detection of functional faults and soft errors in memories]. For
example, if a memory with 32-bit words is tested with March C-, time complexity
of the transparent word-oriented test transformed by the proposed scheme is
only about 56% or 19% time complexity of the transparent word-oriented test
converted by the scheme reported in [Theory of transparent BIST for RAMs] or [A
transparent online memory test for simultaneous detection of functional faults
and soft errors in memories], respectively.",0710.4747v1,cs.AR,2007-10-25 09:48:22+00:00,"[arxiv.Result.Author('Jin-Fu Li'), arxiv.Result.Author('Tsu-Wei Tseng'), arxiv.Result.Author('Chin-Long Wey')]","Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)"
984,Proposed Spreadsheet Transparency Definition and Measures,"Auditors demand financial models be transparent yet no consensus exists on
what that means precisely. Without a clear modeling transparency definition we
cannot know when our models are ""transparent"". The financial modeling community
debates which methods are more or less transparent as though transparency is a
quantifiable entity yet no measures exist. Without a transparency measure
modelers cannot objectively evaluate methods and know which improves model
transparency.
  This paper proposes a definition for spreadsheet modeling transparency that
is specific enough to create measures and automation tools for auditors to
determine if a model meets transparency requirements. The definition also
provides modelers the ability to objectively compare spreadsheet modeling
methods to select which best meets their goals.",1802.01628v1,cs.SE,2018-02-05 20:06:58+00:00,[arxiv.Result.Author('Craig Hatmaker')],"Proceedings of the EuSpRIG 2017 Conference ""Spreadsheet Risk
  Management"", Imperial College, London, pp49-61 ISBN: 978-1-905404-54-4"
985,"Nuclear transparency from quasielastic A(e,e'p) reactions uo to Q^2=8.1 (GeV/c)^2","The quasielastic (e,e$^\prime$p) reaction was studied on targets of
deuterium, carbon, and iron up to a value of momentum transfer $Q^2$ of 8.1
(GeV/c)$^2$. A nuclear transparency was determined by comparing the data to
calculations in the Plane-Wave Impulse Approximation. The dependence of the
nuclear transparency on $Q^2$ and the mass number $A$ was investigated in a
search for the onset of the Color Transparency phenomenon. We find no evidence
for the onset of Color Transparency within our range of $Q^2$. A fit to the
world's nuclear transparency data reflects the energy dependence of the free
proton-nucleon cross section.",hep-ex/0109027v1,hep-ex,2001-09-18 18:12:56+00:00,[arxiv.Result.Author('K. Garrow')],"Phys.Rev.C66:044613,2002"
986,Nuclear Transparency with the gamma + n -> pi- + p Process in 4He,"We have measured the nuclear transparency of the fundamental process $\gamma$
n $\to \pi^-$ p in $^4$He. These measurements were performed at Jefferson Lab
in the photon energy range of 1.6 to 4.5 GeV and at $\theta^{\pi}_{cm}=
70^\circ$ and $90^\circ$. These measurements are the first of their kind in the
study of nuclear transparency in photoreactions. They also provide a benchmark
test of Glauber calculations based on traditional models of nuclear physics.
The transparency results suggest deviations from the traditional nuclear
physics picture. The momentum transfer dependence of the measured nuclear
transparency is consistent with Glauber calculations which include the quantum
chromodynamics phenomenon of color transparency.",nucl-ex/0305005v1,nucl-ex,2003-05-09 20:16:58+00:00,[arxiv.Result.Author('D. Dutta')],"Phys.Rev.C68:021001,2003"
987,Double-double electromagnetically induced transparency with amplification,"We show that an alkali atom with a tripod electronic structure can yield rich
electromagnetically induced transparency phenomena even at room temperature. In
particular we introduce double-double electromagnetically induced transparency
wherein signal and probe fields each have two transparency windows. Their group
velocities can be matched in either the first or second pair of transparency
windows. Moreover signal and probe fields can each experience coherent gain in
the second transparency windows. We explain using a
semi-classical-dressed-picture to connect the tripod electronic structure to a
double-\Lambda\ scheme.",1310.3318v1,quant-ph,2013-10-12 00:28:25+00:00,"[arxiv.Result.Author('Hessa M. M. Alotaibi'), arxiv.Result.Author('Barry C. Sanders')]","Phys. Rev. A 89, 021802 (2014)"
988,A Categorization of Transparency-Enhancing Technologies,"A variety of Transparency-Enhancing Technologies has been presented during
the past years. However, investigation of frameworks for classification and
assessment of Transparency-Enhancing Technologies has lacked behind. The lack
of precise classification and categorization approaches poses an obstacle not
only to systematic requirements analysis for Transparency-Enhancing
Technologies but also to investigation and analysis of their capabilities and
their suitability to contribute to privacy protection. This paper addresses
this research gap. In particular, it presents a set of categorization
parameters for describing the properties and functionality of a
Transparency-Enhancing Technology on the one hand, and a categorization of
Transparency-Enhancing Technologies on the other hand.",1507.04914v2,cs.CY,2015-07-17 10:46:06+00:00,[arxiv.Result.Author('Christian Zimmermann')],
989,What Are You Hiding? Algorithmic Transparency and User Perceptions,"Extensive recent media focus has been directed towards the dark side of
intelligent systems, how algorithms can influence society negatively. Often,
transparency is proposed as a solution or step in the right direction.
Unfortunately, research is mixed on the impact of transparency on the user
experience. We examine transparency in the context an interactive system that
predicts positive/negative emotion from a users' written text. We unify
seemingly this contradictory research under a single model. We show that
transparency can negatively affect accuracy perceptions for users whose
expectations were not violated by the system's prediction; however,
transparency also limits the damage done when users' expectations are violated
by system predictions.",1812.03220v1,cs.HC,2018-12-07 21:38:05+00:00,"[arxiv.Result.Author('Aaron Springer'), arxiv.Result.Author('Steve Whittaker')]",
990,Transparency in Multi-Human Multi-Robot Interaction,"Transparency is a key factor in improving the performance of human-robot
interaction. A transparent interface allows humans to be aware of the state of
a robot and to assess the progress of the tasks at hand. When multi-robot
systems are involved, transparency is an even greater challenge, due to the
larger number of variables affecting the behavior of the robots as a whole.
Significant effort has been devoted to studying transparency when single
operators interact with multiple robots. However, studies on transparency that
focus on multiple human operators interacting with a multi-robot systems are
limited. This paper aims to fill this gap by presenting a human-swarm
interaction interface with graphical elements that can be enabled and disabled.
Through this interface, we study which graphical elements are contribute to
transparency by comparing four ""transparency modes"": (i) no transparency (no
operator receives information from the robots), (ii) central transparency (the
operators receive information only relevant to their personal task), (iii)
peripheral transparency (the operators share information on each others'
tasks), and (iv) mixed transparency (both central and peripheral). We report
the results in terms of awareness, trust, and workload of a user study
involving 18 participants engaged in a complex multi-robot task.",2101.10495v2,cs.RO,2021-01-26 00:13:58+00:00,"[arxiv.Result.Author('Jayam Patel'), arxiv.Result.Author('Tyagaraja Ramaswamy'), arxiv.Result.Author('Zhi Li'), arxiv.Result.Author('Carlo Pinciroli')]",
991,Waveplate retarders based on overhead transparencies,"We describe procedures for constructing inexpensive waveplates of desired
retardation out of ordinary commercially available transparencies. Various
relevant properties of the transparencies are investigated: the dependence of
retardation on rotation of the film, tilt, wavelength, position, and
temperature. Constructing waveplates out of combinations of transparency sheets
is also explored.",physics/0702225v2,physics.optics,2007-02-25 21:34:16+00:00,"[arxiv.Result.Author('Igor Savukov'), arxiv.Result.Author('Dmitry Budker')]",
992,Notes on socio-economic transparency mechanisms,"Clearly, socio-economic freedom requires some extent of transparency
regarding the implications of choices. In this paper, we review some
established mechanisms for achieving such transparency, without any claim to
completeness, and briefly discuss potential future directions. Our
investigation is structured by four ""challenges"" under which we subsume the
various requirements on, and approaches to, socio-economic transparency
mechanisms. One main focus is on the inference, i.e., statistical, aspect of
such mechanisms.",1606.04703v1,cs.CY,2016-06-15 10:08:09+00:00,[arxiv.Result.Author('Philipp Geiger')],
993,Transparent Forwarders: An Unnoticed Component of the Open DNS Infrastructure,"In this paper, we revisit the open DNS (ODNS) infrastructure and, for the
first time, systematically measure and analyze transparent forwarders, DNS
components that transparently relay between stub resolvers and recursive
resolvers. Our key findings include four takeaways. First, transparent
forwarders contribute 26% (563k) to the current ODNS infrastructure.
Unfortunately, common periodic scanning campaigns such as Shadowserver do not
capture transparent forwarders and thus underestimate the current threat
potential of the ODNS. Second, we find an increased deployment of transparent
forwarders in Asia and South America. In India alone, the ODNS consists of 80%
transparent forwarders. Third, many transparent forwarders relay to a few
selected public resolvers such as Google and Cloudflare, which confirms a
consolidation trend of DNS stakeholders. Finally, we introduce DNSRoute++, a
new traceroute approach to understand the network infrastructure connecting
transparent forwarders and resolvers.",2110.02224v2,cs.NI,2021-10-05 13:01:12+00:00,"[arxiv.Result.Author('Marcin Nawrocki'), arxiv.Result.Author('Maynard Koch'), arxiv.Result.Author('Thomas C. Schmidt'), arxiv.Result.Author('Matthias Wählisch')]",
994,Color Transparency Assumptions,"An exactly solvable model is used to investigate the assumptions behind color
transparency.",nucl-th/9411004v1,nucl-th,1994-11-07 18:14:39+00:00,"[arxiv.Result.Author('D. Makovoz'), arxiv.Result.Author('G. A. Miller')]","Phys.Rev.C51:2716-2722,1995"
995,One-way transparent sheets,"In this paper we introduce the concept of metasurfaces which are fully
transparent when looking from one of the two sides of the sheet and have
controllable functionalities for waves hitting the opposite side (one-way
transparent sheets). We address the question on what functionalities are
allowed, considering limitations due to reciprocity and passivity. In
particular, we have found that it is possible to realize one-way transparent
sheets which have the properties of a twist-polarizer in reflection or
transmission when illuminated from the other side. Also one-way transparent
sheets with controllable co-polarized reflection and transmission from the
opposite side are feasible. We show that particular non-reciprocal
magneto-electric coupling inside the sheet is necessary to realize lossless
non-active transparent sheets. Furthermore, we derive the required
polarizabilities of constituent dipole particles such that the layers composed
of them form one-way transparent sheets. We conclude with design and
simulations of an example of a nonreciprocal one-way transparent sheet
functioning as an isolating twist-polarizer.",1310.4586v1,physics.optics,2013-10-17 05:50:43+00:00,"[arxiv.Result.Author(""Younes Ra'di""), arxiv.Result.Author('Viktar Asadchy'), arxiv.Result.Author('Sergei Tretyakov')]","Phys. Rev. B, vol. 89, no. 7, p. 075109, Feb. 2014"
996,"""I had a solid theory before but it's falling apart"": Polarizing Effects of Algorithmic Transparency","The rise of machine learning has brought closer scrutiny to intelligent
systems, leading to calls for greater transparency and explainable algorithms.
We explore the effects of transparency on user perceptions of a working
intelligent system for emotion detection. In exploratory Study 1, we observed
paradoxical effects of transparency which improves perceptions of system
accuracy for some participants while reducing accuracy perceptions for others.
In Study 2, we test this observation using mixed methods, showing that the
apparent transparency paradox can be explained by a mismatch between
participant expectations and system predictions. We qualitatively examine this
process, indicating that transparency can undermine user confidence by causing
users to fixate on flaws when they already have a model of system operation. In
contrast transparency helps if users lack such a model. Finally, we revisit the
notion of transparency and suggest design considerations for building safe and
successful machine learning systems based on our insights.",1811.02163v1,cs.HC,2018-11-06 05:01:21+00:00,"[arxiv.Result.Author('Aaron Springer'), arxiv.Result.Author('Steve Whittaker')]",
997,GlassLoc: Plenoptic Grasp Pose Detection in Transparent Clutter,"Transparent objects are prevalent across many environments of interest for
dexterous robotic manipulation. Such transparent material leads to considerable
uncertainty for robot perception and manipulation, and remains an open
challenge for robotics. This problem is exacerbated when multiple transparent
objects cluster into piles of clutter. In household environments, for example,
it is common to encounter piles of glassware in kitchens, dining rooms, and
reception areas, which are essentially invisible to modern robots. We present
the GlassLoc algorithm for grasp pose detection of transparent objects in
transparent clutter using plenoptic sensing. GlassLoc classifies graspable
locations in space informed by a Depth Likelihood Volume (DLV) descriptor. We
extend the DLV to infer the occupancy of transparent objects over a given space
from multiple plenoptic viewpoints. We demonstrate and evaluate the GlassLoc
algorithm on a Michigan Progress Fetch mounted with a first-generation Lytro.
The effectiveness of our algorithm is evaluated through experiments for grasp
detection and execution with a variety of transparent glassware in minor
clutter.",1909.04269v2,cs.RO,2019-09-10 03:53:15+00:00,"[arxiv.Result.Author('Zheming Zhou'), arxiv.Result.Author('Tianyang Pan'), arxiv.Result.Author('Shiyu Wu'), arxiv.Result.Author('Haonan Chang'), arxiv.Result.Author('Odest Chadwicke Jenkins')]",
998,A Comparison of Rendering Techniques for Large 3D Line Sets with Transparency,"This paper presents a comprehensive study of interactive rendering techniques
for large 3D line sets with transparency. The rendering of transparent lines is
widely used for visualizing trajectories of tracer particles in flow fields.
Transparency is then used to fade out lines deemed unimportant, based on, for
instance, geometric properties or attributes defined along them. Since accurate
blending of transparent lines requires rendering the lines in back-to-front or
front-to-back order, enforcing this order for 3D line sets with tens or even
hundreds of thousands of elements becomes challenging. In this paper, we study
CPU and GPU rendering techniques for large transparent 3D line sets. We compare
accurate and approximate techniques using optimized implementations and a
number of benchmark data sets. We discuss the effects of data size and
transparency on quality, performance and memory consumption. Based on our
study, we propose two improvements to per-pixel fragment lists and multi-layer
alpha blending. The first improves the rendering speed via an improved GPU
sorting operation, and the second improves rendering quality via a
transparency-based bucketing.",1912.08485v2,cs.GR,2019-12-18 09:44:34+00:00,"[arxiv.Result.Author('Michael Kern'), arxiv.Result.Author('Christoph Neuhauser'), arxiv.Result.Author('Torben Maack'), arxiv.Result.Author('Mengjiao Han'), arxiv.Result.Author('Will Usher'), arxiv.Result.Author('Rüdiger Westermann')]",
999,Price of Transparency in Strategic Machine Learning,"Based on the observation that the transparency of an algorithm comes with a
cost for the algorithm designer when the users (data providers) are strategic,
this paper studies the impact of strategic intent of the users on the design
and performance of transparent ML algorithms. We quantitatively study the {\bf
price of transparency} in the context of strategic classification algorithms,
by modeling the problem as a nonzero-sum game between the users and the
algorithm designer. The cost of having a transparent algorithm is measured by a
quantity, named here as price of transparency which is the ratio of the
designer cost at the Stackelberg equilibrium, when the algorithm is transparent
(which allows users to be strategic) to that of the setting where the algorithm
is not transparent.",1610.08210v1,cs.GT,2016-10-26 07:17:27+00:00,"[arxiv.Result.Author('Emrah Akyol'), arxiv.Result.Author('Cedric Langbort'), arxiv.Result.Author('Tamer Basar')]",
1000,Colored Transparent Object Matting from a Single Image Using Deep Learning,"This paper proposes a deep learning based method for colored transparent
object matting from a single image. Existing approaches for transparent object
matting often require multiple images and long processing times, which greatly
hinder their applications on real-world transparent objects. The recently
proposed TOM-Net can produce a matte for a colorless transparent object from a
single image in a single fast feed-forward pass. In this paper, we extend
TOM-Net to handle colored transparent object by modeling the intrinsic color of
a transparent object with a color filter. We formulate the problem of colored
transparent object matting as simultaneously estimating an object mask, a color
filter, and a refractive flow field from a single image, and present a deep
learning framework for learning this task. We create a large-scale synthetic
dataset for training our network. We also capture a real dataset for
evaluation. Experiments on both synthetic and real datasets show promising
results, which demonstrate the effectiveness of our method.",1910.02222v1,cs.CV,2019-10-05 06:45:33+00:00,"[arxiv.Result.Author('Jamal Ahmed Rahim'), arxiv.Result.Author('Kwan-Yee Kenneth Wong')]",
1001,Algorithmic Transparency with Strategic Users,"Should firms that apply machine learning algorithms in their decision-making
make their algorithms transparent to the users they affect? Despite growing
calls for algorithmic transparency, most firms have kept their algorithms
opaque, citing potential gaming by users that may negatively affect the
algorithm's predictive power. We develop an analytical model to compare firm
and user surplus with and without algorithmic transparency in the presence of
strategic users and present novel insights. We identify a broad set of
conditions under which making the algorithm transparent benefits the firm. We
show that, in some cases, even the predictive power of machine learning
algorithms may increase if the firm makes them transparent. By contrast, users
may not always be better off under algorithmic transparency. The results hold
even when the predictive power of the opaque algorithm comes largely from
correlational features and the cost for users to improve on them is close to
zero. Overall, our results show that firms should not view manipulation by
users as bad. Rather, they should use algorithmic transparency as a lever to
motivate users to invest in more desirable features.",2008.09283v1,cs.GT,2020-08-21 03:10:42+00:00,"[arxiv.Result.Author('Qiaochu Wang'), arxiv.Result.Author('Yan Huang'), arxiv.Result.Author('Stefanus Jasin'), arxiv.Result.Author('Param Vir Singh')]",
1002,"STAR-Vote: A Secure, Transparent, Auditable, and Reliable Voting System","In her 2011 EVT/WOTE keynote, Travis County, Texas County Clerk Dana
DeBeauvoir described the qualities she wanted in her ideal election system to
replace their existing DREs. In response, in April of 2012, the authors,
working with DeBeauvoir and her staff, jointly architected STAR-Vote, a voting
system with a DRE-style human interface and a ""belt and suspenders"" approach to
verifiability. It provides both a paper trail and end-to-end cryptography using
COTS hardware. It is designed to support both ballot-level risk-limiting
audits, and auditing by individual voters and observers. The human interface
and process flow is based on modern usability research. This paper describes
the STAR-Vote architecture, which could well be the next-generation voting
system for Travis County and perhaps elsewhere.",1211.1904v1,cs.CR,2012-11-08 17:06:33+00:00,"[arxiv.Result.Author('Josh Benaloh'), arxiv.Result.Author('Mike Byrne'), arxiv.Result.Author('Philip Kortum'), arxiv.Result.Author('Neal McBurnett'), arxiv.Result.Author('Olivier Pereira'), arxiv.Result.Author('Philip B. Stark'), arxiv.Result.Author('Dan S. Wallach')]",
1003,OpenEMS: an open-source Package for Two-Stage Stochastic and Robust Optimization for Ambulance Location and Routing with Applications to Austin-Travis County EMS Data,"Emergency Medical Systems (EMS) provide crucial pre-hospital care and
transportation. Faster EMS response time provides quicker pre-hospital care and
thus increases survival rate. We reduce response time by providing optimal
ambulance stationing and routing decisions by solving two stage stochastic and
robust linear programs. Although operational research on ambulance systems is
decades old, there is little open-source code and consistency in simulations.
We begin to bridge this gap by publishing OpenEMS, in collaboration with the
Austin-Travis County EMS (ATCEMS) in Texas, an end-to-end pipeline to optimize
ambulance strategic decisions. It includes data handling, optimization, and a
calibrated simulation. We hope this open source framework will foster future
research with and for EMS. Finally, we provide a detailed case study on the
city of Austin, Texas. We find that optimal stationing would increase response
time by 88.02 seconds. Further, we design optimal strategies in the case where
Austin EMS must permanently add or remove one ambulance from their fleet.",2201.11208v1,stat.AP,2022-01-26 22:17:35+00:00,"[arxiv.Result.Author('Joshua Ong'), arxiv.Result.Author('David Kulpanowski'), arxiv.Result.Author('Yangxinyu Xie'), arxiv.Result.Author('Evdokia Nikolova'), arxiv.Result.Author('Ngoc Mai Tran')]",
1004,Associating Ridesourcing with Road Safety Outcomes: Insights from Austin Texas,"Improving road safety and setting targets for reducing traffic-related
crashes and deaths are highlighted as part of the United Nation's sustainable
development goals and vision zero efforts around the globe. The advent of
transportation network companies, such as ridesourcing, expands mobility
options in cities and may impact road safety outcomes. In this study, we
analyze the effects of ridesourcing use on road crashes, injuries, fatalities,
and driving while intoxicated (DWI) offenses in Travis County Texas. Our
approach leverages real-time ridesourcing volume to explain variation in road
safety outcomes. Spatial panel data models with fixed effects are deployed to
examine whether the use of ridesourcing is significantly associated with road
crashes and other safety metrics. Our results suggest that for a 10% increase
in ridesourcing trips, we expect a 0.12% decrease in road crashes (p<0.05), a
0.25% decrease in road injuries (p<0.001), and a 0.36% decrease in DWI offenses
(p<0.0001) in Travis County. Ridesourcing use is not associated with road
fatalities at a 0.05 significance level. This study augments existing work
because it moves beyond binary indicators of ridesourcing presence or absence
and analyzes patterns within an urbanized area rather than metropolitan-level
variation. Contributions include developing a data-rich approach for assessing
the impacts of ridesourcing use on our transportation system's safety, which
may serve as a template for future analyses of other US cities. Our findings
provide feedback to policymakers by clarifying associations between
ridesourcing use and traffic safety, while helping identify sets of actions to
achieve safer and more efficient shared mobility systems.",2001.03461v4,econ.GN,2020-01-08 22:36:26+00:00,"[arxiv.Result.Author('Eleftheria Kontou'), arxiv.Result.Author('Noreen C. McDonald')]",
1005,Predicting Covid-19 EMS Incidents from Daily Hospitalization Trends,"Introduction: The aim of our retrospective study was to quantify the impact
of Covid-19 on the temporal distribution of Emergency Medical Services (EMS)
demand in Travis County, Austin, Texas and propose a robust model to forecast
Covid-19 EMS incidents. Methods: We analyzed the temporal distribution of EMS
calls in the Austin-Travis County area between January 1st, 2019, and December
31st, 2020. Change point detection was performed to identify critical dates
marking changes in EMS call distributions, and time series regression was
applied for forecasting Covid-19 EMS incidents. Results: Two critical dates
marked the impact of Covid-19 on the distribution of EMS calls: March 17th,
when the daily number of non-pandemic EMS incidents dropped significantly, and
May 13th, by which the daily number of EMS calls climbed back to 75% of the
number in pre-Covid-19 time. The new daily count of the hospitalization of
Covid-19 patients alone proves a powerful predictor of the number of pandemic
EMS calls, with an r2 value equal to 0.85. In particular, for every 2.5 cases
where EMS takes a Covid-19 patient to a hospital, one person is admitted.
Conclusion: The mean daily number of non-pandemic EMS demand was significantly
less than the period before Covid-19 pandemic. The number of EMS calls for
Covid-19 symptoms can be predicted from the daily new hospitalization of
Covid-19 patients. These findings may be of interest to EMS departments as they
plan for future pandemics, including the ability to predict pandemic-related
calls in an effort to adjust a targeted response.",2103.10885v6,stat.AP,2021-03-19 16:09:38+00:00,"[arxiv.Result.Author('Yangxinyu Xie'), arxiv.Result.Author('David Kulpanowski'), arxiv.Result.Author('Joshua Ong'), arxiv.Result.Author('Evdokia Nikolova'), arxiv.Result.Author('Ngoc Mai Tran')]",
1006,The Impact of Heavy-Duty Vehicle Electrification on Large Power Grids: a Synthetic Texas Case Study,"The electrification of heavy-duty vehicles (HDEVs) is a nascent and rapidly
emerging avenue for decarbonization of the transportation sector. In this
paper, we examine the impacts of increased vehicle electrification on the power
grid infrastructure, with particular focus on HDEVs. We utilize a synthetic
representation of the 2000-bus Texas transmission grid, and realistic
representations of multiple distribution grids in Travis county, Texas, as well
as transit data pertaining to HDEVs, to uncover the consequences of HDEV
electrification, and expose the limitations imposed by existing electric grid
infrastructure. Our analysis reveals that grid-wide voltage problems that are
spatiotemporally correlated with the mobility of HDEVs may occur even at modest
penetration levels. In fact, we find that as little as 11% of heavy duty
vehicles in Texas charging simultaneously can lead to significant voltage
violations on the transmission network that compromise grid reliability.
Furthermore, we find that just a few dozen EVs charging simultaneously can lead
to voltage violations at the distribution level.",2203.04430v1,eess.SY,2022-03-08 22:40:07+00:00,"[arxiv.Result.Author('Rayan El Helou'), arxiv.Result.Author('S. Sivaranjani'), arxiv.Result.Author('Dileep Kalathil'), arxiv.Result.Author('Andrew Schaper'), arxiv.Result.Author('Le Xie')]",
1007,"A Further (Itakura-Saito/beta=0) Bi-stochaticization and Associated Clustering/Regionalization of the 3,107-County 1995-2000 U. S. Migration Network","We extend to the beta-divergence (Itakura-Saito) case beta =0, the
comparative bi-stochaticization analyses-previously conducted (arXiv:1208.3428)
for the (Kullback-Leibler) beta=1 and (squared-Euclidean) beta = 2 cases -of
the 3,107 - county 1995-2000 U. S. migration network. A heuristic, ""greedy""
algorithm is devised. While the largest 25,329 entries of the 735,531 non-zero
entries of the bi-stochasticized table - in the beta=1 case - are required to
complete the widely-applied two-stage (double-standardization and
strong-component hierarchical clustering) procedure, 105,363 of the 735,531 are
needed (reflective of greater uniformity of entries) in the beta=0 instance.
The North Carolina counties of Mecklenburg (Charlotte) and Wake (Raleigh) are
considerably relatively more cosmopolitan in the beta=0 study. The Colorado
county of El Paso (Colorado Springs) replaces the Florida Atlantic county of
Brevard (the ""Space Coast"") as the most cosmopolitan, with Brevard becoming the
second-most. Honolulu County splinters away from the other four (still-grouped)
Hawaiian counties, becoming the fifth most cosmopolitan county nation-wide. The
five counties of Rhode Island remain intact as a regional entity, but the eight
counties of Connecticut fragment, leaving only five counties clustered.",1210.1840v2,physics.soc-ph,2012-10-05 19:27:30+00:00,[arxiv.Result.Author('Paul B. Slater')],
1008,Optimal Legislative County Clustering in North Carolina,"North Carolina's constitution requires that state legislative districts
should not split counties. However, counties must be split to comply with the
""one person, one vote"" mandate of the U.S. Supreme Court. Given that counties
must be split, the North Carolina legislature and courts have provided
guidelines that seek to reduce counties split across districts while also
complying with the ""one person, one vote"" criteria. Under these guidelines, the
counties are separated into clusters. The primary goal of this work is to
develop, present, and publicly release an algorithm to optimally cluster
counties according to the guidelines set by the court in 2015. We use this tool
to investigate the optimality and uniqueness of the enacted clusters under the
2017 redistricting process. We verify that the enacted clusters are optimal,
but find other optimal choices. We emphasize that the tool we provide lists
\textit{all} possible optimal county clusterings. We also explore the stability
of clustering under changing statewide populations and project what the county
clusters may look like in the next redistricting cycle beginning in 2020/2021.",1908.11801v1,cs.CY,2019-08-30 15:48:26+00:00,"[arxiv.Result.Author('Daniel Carter'), arxiv.Result.Author('Zach Hunter'), arxiv.Result.Author('Dan Teague'), arxiv.Result.Author('Gregory Herschlag'), arxiv.Result.Author('Jonathan Mattingly')]",
1009,"When Local Governments' Stay-at-Home Orders Meet the White House's ""Opening Up America Again""","On April 16th, The White House launched ""Opening up America Again"" (OuAA)
campaign while many U.S. counties had stay-at-home orders in place. We created
a panel data set of 1,563 U.S. counties to study the impact of U.S. counties'
stay-at-home orders on community mobility before and after The White House's
campaign to reopen the country. Our results suggest that before the OuAA
campaign stay-at-home orders brought down time spent in retail and recreation
businesses by about 27% for typical conservative and liberal counties. However,
after the launch of OuAA campaign, the time spent at retail and recreational
businesses in a typical conservative county increased significantly more than
in liberal counties (15% increase in a typical conservative county Vs. 9%
increase in a typical liberal county). We also found that in conservative
counties with stay-at-home orders in place, time spent at retail and
recreational businesses increased less than that of conservative counties
without stay-at-home orders. These findings illuminate to what extent
residents' political ideology could determine to what extent they follow local
orders and to what extent the White House's OuAA campaign polarized the
obedience between liberal and conservative counties. The silver lining in our
study is that even when the federal government was reopening the country, the
local authorities that enforced stay-at-home restrictions were to some extent
effective.",2009.14097v2,econ.GN,2020-09-29 15:27:25+00:00,"[arxiv.Result.Author('Reza Mousavi'), arxiv.Result.Author('Bin Gu')]",
1010,Estimation of Residential Radon Concentration in Pennsylvania Counties by Data Fusion,"A data fusion method for the estimation of residential radon level
distribution in any Pennsylvania county is proposed. The method is based on a
multi-sample density ratio model with variable tilts and is applied to combined
radon data from a reference county of interest and its neighboring counties.
Beaver county and its four immediate neighbors are taken as a case in point.
The distribution of radon concentration is estimated in each of six periods,
and then the analysis is repeated combining the data from all the periods to
obtain estimates of Beaver threshold probabilities and the corresponding
confidence intervals.",1912.08149v1,stat.AP,2019-12-17 17:33:43+00:00,"[arxiv.Result.Author('Xuze Zhang'), arxiv.Result.Author('Saumyadipta Pyne'), arxiv.Result.Author('Benjamin Kedem')]",
1011,Unraveling the Dynamic Importance of County-level Features in Trajectory of COVID-19,"The objective of this study was to investigate the importance of multiple
county-level features in the trajectory of COVID-19. We examined feature
importance across 2,787 counties in the United States using a data-driven
machine learning model. We trained random forest models using 23 features
representing six key influencing factors affecting pandemic spread: social
demographics of counties, population activities, mobility within the counties,
movement across counties, disease attributes, and social network structure.
Also, we categorized counties into multiple groups according to their
population densities, and we divided the trajectory of COVID-19 into three
stages: the outbreak stage, the social distancing stage, and the reopening
stage. The study aims to answer two research questions: (1) The extent to which
the importance of heterogeneous features evolves in different stages; (2) The
extent to which the importance of heterogeneous features varies across counties
with different characteristics. We fitted a set of random forest models to
determine weekly feature importance. The results showed that: (1) Social
demographic features, such as gross domestic product, population density, and
minority status maintained high-importance features throughout stages of
COVID-19 across the 2787 studied counties; (2) Within-county mobility features
had the highest importance in county clusters with higher population densities;
(3) The feature reflecting the social network structure (Facebook, social
connectedness index), had higher importance in the models for counties with
higher population densities. The results show that the data-driven machine
learning models could provide important insights to inform policymakers
regarding feature importance for counties with various population densities and
in different stages of a pandemic life cycle.",2101.03458v2,physics.soc-ph,2021-01-10 02:39:41+00:00,"[arxiv.Result.Author('Qingchun Li'), arxiv.Result.Author('Yang Yang'), arxiv.Result.Author('Wangqiu Wang'), arxiv.Result.Author('Sanghyeon Lee'), arxiv.Result.Author('Xin Xiao'), arxiv.Result.Author('Xinyu Gao'), arxiv.Result.Author('Bora Oztekin'), arxiv.Result.Author('Chao Fan'), arxiv.Result.Author('Ali Mostafavi')]",
1012,Allocation of COVID-19 Testing Budget on a Commute Network of Counties,"The screening testing is an effective tool to control the early spread of an
infectious disease such as COVID-19. When the total testing capacity is
limited, we aim to optimally allocate testing resources among n counties. We
build a (weighted) commute network on counties, with the weight between two
counties a decreasing function of their traffic distance. We introduce a
network-based disease model, in which the number of newly confirmed cases of
each county depends on the numbers of hidden cases of all counties on the
network. Our proposed testing allocation strategy first uses historical data to
learn model parameters and then decides the testing rates for all counties by
solving an optimization problem. We apply the method on the commute networks of
Massachusetts, USA and Hubei, China and observe its advantages over testing
allocation strategies that ignore the network structure. Our approach can also
be extended to study the vaccine allocation problem.",2110.04381v2,stat.ME,2021-10-08 21:07:59+00:00,"[arxiv.Result.Author('Yaxuan Huang'), arxiv.Result.Author('Zheng Tracy Ke'), arxiv.Result.Author('Jiashun Jin')]",
1013,Exploring the Urban - Rural Incarceration Divide: Drivers of Local Jail Incarceration Rates in the U.S,"As the rate of incarceration in the United States continues to grow, a large
body of research has been primarily focused on understanding the determinants
and drivers of federal and state prison growth. However, local jail systems,
with 11 million admissions each year, have generated less research attention
even though they have a far broader impact on communities. Preliminary time
trend analysis conducted by the Vera Institute of Justice (Vera) uncovered
disparities in county jail incarceration rates by geography. Contrary to
assumptions that incarceration is an urban phenomenon, Vera discovered that
during the past few decades, pretrial jail rates have declined in many urban
areas whereas rates have grown or remained flat in rural counties. In an effort
to uncover the factors contributing to continued jail growth in rural areas,
Vera joined forces with Two Sigma's Data Clinic, a volunteer-based program that
leverages employees' data science expertise. Using county jail data from 2000 -
2013 and county-specific demographic, political, socioeconomic, jail and prison
population variables, a generalized estimating equations (GEE) model was
specified to account for correlations within counties over time. The results
revealed that county-level poverty, police expenditures, and spillover effects
from other county and state authorities are all significant predictors of local
jail rates. In addition, geographic investigation of model residuals revealed
clusters of counties where observed rates were much higher (and much lower)
than expected conditioned upon county variables.",1710.02453v1,cs.CY,2017-10-06 15:36:37+00:00,"[arxiv.Result.Author('Rachael Weiss Riley'), arxiv.Result.Author('Jacob Kang-Brown'), arxiv.Result.Author('Chris Mulligan'), arxiv.Result.Author('Vinod Valsalam'), arxiv.Result.Author('Soumyo Chakraborty'), arxiv.Result.Author('Christian Henrichson')]",
1014,"Estimating the treatment effect of the juvenile stay-at-home order on SARS-CoV-2 infection spread in Saline County, Arkansas","We investigate the treatment effect of the juvenile stay-at-home order
(JSAHO) adopted in Saline County, Arkansas, from April 6 to May 7, in
mitigating the growth of SARS-CoV-2 infection rates. To estimate the
counterfactual control outcome for Saline County, we apply
Difference-in-Differences and Synthetic Control design methodologies. Both
approaches show that stay-at-home order (SAHO) significantly reduced the growth
rate of the infections in Saline County during the period the policy was in
effect, contrary to some of the findings in the literature that cast doubt on
the general causal impact of SAHO with narrower scopes.",2009.08691v1,stat.AP,2020-09-18 08:48:54+00:00,"[arxiv.Result.Author('Neil Hwang'), arxiv.Result.Author('Shirshendu Chatterjee'), arxiv.Result.Author('Yanming Di'), arxiv.Result.Author('Sharmodeep Bhattacharyya')]",
1015,Towards Better Shale Gas Production Forecasting Using Transfer Learning,"Deep neural networks can generate more accurate shale gas production
forecasts in counties with a limited number of sample wells by utilizing
transfer learning. This paper provides a way of transferring the knowledge
gained from other deep neural network models trained on adjacent counties into
the county of interest. The paper uses data from more than 6000 shale gas wells
across 17 counties from Texas Barnett and Pennsylvania Marcellus shale
formations to test the capabilities of transfer learning. The results reduce
the forecasting error between 11% and 47% compared to the widely used Arps
decline curve model.",2106.11051v1,cs.LG,2021-06-21 12:37:44+00:00,"[arxiv.Result.Author('Omar S. Alolayan'), arxiv.Result.Author('Samuel J. Raymond'), arxiv.Result.Author('Justin B. Montgomery'), arxiv.Result.Author('John R. Williams')]",
1016,Quantifying the influence of inter-county mobility patterns on the COVID-19 outbreak in the United States,"As a highly infectious respiratory disease, COVID-19 has become a pandemic
that threatens global health. Without an effective treatment,
non-pharmaceutical interventions, such as travel restrictions, have been widely
promoted to mitigate the outbreak. Current studies analyze mobility metrics
such as travel distance; however, there is a lack of research on interzonal
travel flow and its impact on the pandemic. Our study specifically focuses on
the inter-county mobility pattern and its influence on the COVID-19 spread in
the United States. To retrieve real-world mobility patterns, we utilize an
integrated set of mobile device location data including over 100 million
anonymous devices. We first investigate the nationwide temporal trend and
spatial distribution of inter-county mobility. Then we zoom in on the epicenter
of the U.S. outbreak, New York City, and evaluate the impacts of its outflow on
other counties. Finally, we develop a ""log-linear double-risk"" model at the
county level to quantify the influence of both ""external risk"" imported by
inter-county mobility flows and the ""internal risk"" defined as the
vulnerability of a county in terms of population with high-risk phenotypes. Our
study enhances the situation awareness of inter-county mobility in the U.S. and
can help improve non-pharmaceutical interventions for COVID-19.",2006.13860v1,cs.SI,2020-06-24 16:43:55+00:00,"[arxiv.Result.Author('Qianqian Sun'), arxiv.Result.Author('Yixuan Pan'), arxiv.Result.Author('Weiyi Zhou'), arxiv.Result.Author('Chenfeng Xiong'), arxiv.Result.Author('Lei Zhang')]",
1017,Applying Machine Learning and AI Explanations to Analyze Vaccine Hesitancy,"The paper quantifies the impact of race, poverty, politics, and age on
COVID-19 vaccination rates in counties in the continental US. Both, OLS
regression analysis and Random Forest machine learning algorithms are applied
to quantify factors for county-level vaccination hesitancy. The machine
learning model considers joint effects of variables (race/ethnicity,
partisanship, age, etc.) simultaneously to capture the unique combination of
these factors on the vaccination rate. By implementing a state-of-the-art
Artificial Intelligence Explanations (AIX) algorithm, it is possible to solve
the black box problem with machine learning models and provide answers to the
""how much"" question for each measured impact factor in every county. For most
counties, a higher percentage vote for Republicans, a greater African American
population share, and a higher poverty rate lower the vaccination rate. While a
higher Asian population share increases the predicted vaccination rate. The
impact on the vaccination rate from the Hispanic population proportion is
positive in the OLS model, but only positive for counties with a high Hispanic
population (>65%) in the Random Forest model. Both the proportion of seniors
and the one for young people in a county have a significant impact in the OLS
model - positive and negative, respectively. In contrast, the impacts are
ambiguous in the Random Forest model. Because results vary between geographies
and since the AIX algorithm is able to quantify vaccine impacts individually
for each county, this research can be tailored to local communities. An
interactive online mapping dashboard that identifies impact factors for
individual U.S. counties is available at
https://www.cpp.edu/~clange/vacmap.html. It is apparent that the influence of
impact factors is not universally the same across different geographies.",2201.05070v1,cs.LG,2022-01-07 22:50:17+00:00,"[arxiv.Result.Author('Carsten Lange'), arxiv.Result.Author('Jian Lange')]",
1018,Attributed Network Embedding Model for Exposing COVID-19 Spread Trajectory Archetypes,"The spread of COVID-19 revealed that transmission risk patterns are not
homogenous across different cities and communities, and various heterogeneous
features can influence the spread trajectories. Hence, for predictive pandemic
monitoring, it is essential to explore latent heterogeneous features in cities
and communities that distinguish their specific pandemic spread trajectories.
To this end, this study creates a network embedding model capturing
cross-county visitation networks, as well as heterogeneous features to uncover
clusters of counties in the United States based on their pandemic spread
transmission trajectories. We collected and computed location intelligence
features from 2,787 counties from March 3 to June 29, 2020 (initial wave).
Second, we constructed a human visitation network, which incorporated county
features as node attributes, and visits between counties as network edges. Our
attributed network embeddings approach integrates both typological
characteristics of the cross-county visitation network, as well as
heterogeneous features. We conducted clustering analysis on the attributed
network embeddings to reveal four archetypes of spread risk trajectories
corresponding to four clusters of counties. Subsequently, we identified four
features as important features underlying the distinctive transmission risk
patterns among the archetypes. The attributed network embedding approach and
the findings identify and explain the non-homogenous pandemic risk trajectories
across counties for predictive pandemic monitoring. The study also contributes
to data-driven and deep learning-based approaches for pandemic analytics to
complement the standard epidemiological models for policy analysis in
pandemics.",2209.09448v2,cs.LG,2022-09-20 03:55:43+00:00,"[arxiv.Result.Author('Junwei Ma'), arxiv.Result.Author('Bo Li'), arxiv.Result.Author('Qingchun Li'), arxiv.Result.Author('Chao Fan'), arxiv.Result.Author('Ali Mostafavi')]",
1019,An Analysis of 35+ Million Jobs of Travis CI,"Travis CI handles automatically thousands of builds every day to, amongst
other things, provide valuable feedback to thousands of open-source developers.
In this paper, we investigate Travis CI to firstly understand who is using it,
and when they start to use it. Secondly, we investigate how the developers use
Travis CI and finally, how frequently the developers change the Travis CI
configurations. We observed during our analysis that the main users of Travis
CI are corporate users such as Microsoft. And the programming languages used in
Travis CI by those users do not follow the same popularity trend than on
GitHub, for example, Python is the most popular language on Travis CI, but it
is only the third one on GitHub. We also observe that Travis CI is set up on
average seven days after the creation of the repository and the jobs are still
mainly used (60%) to run tests. And finally, we observe that 7.34% of the
commits modify the Travis CI configuration. We share the biggest benchmark of
Travis CI jobs (to our knowledge): it contains 35,793,144 jobs from 272,917
different GitHub projects.",1904.09416v2,cs.SE,2019-04-20 07:59:27+00:00,"[arxiv.Result.Author('Thomas Durieux'), arxiv.Result.Author('Rui Abreu'), arxiv.Result.Author('Martin Monperrus'), arxiv.Result.Author('Tegawendé F. Bissyandé'), arxiv.Result.Author('Luís Cruz')]","Proceedings of the International Conference on Software
  Maintenance and Evolution (ICSME), 2019"
1020,Consistency between household and county measures of K-12 onsite schooling during the COVID-19 pandemic,"The academic, socioemotional, and health impacts of school policies
throughout the COVID-19 pandemic have been a source of many important questions
that require accurate information about the extent of onsite schooling that has
been occurring throughout the pandemic. This paper investigates school
operational status data sources during the COVID-19 pandemic, comparing
self-report data collected nationally on the household level through a
Facebook-based survey with data collected at district and county levels
throughout the country. The percentage of households reporting in-person
instruction within each county is compared to the district and county data at
the state and county levels. The results show high levels of consistency
between the sources at the state level and for large counties. The consistency
levels across sources support the usage of the Facebook-based COVID-19 Symptom
Survey as a source to answer questions about the educational experiences,
factors, and impacts related to K-12 education across the nation during the
pandemic.",2103.13296v1,stat.AP,2021-03-24 16:15:56+00:00,"[arxiv.Result.Author('Carly Lupton-Smith'), arxiv.Result.Author('Elena Badillo Goicoechea'), arxiv.Result.Author('Megan Collins'), arxiv.Result.Author('Justin Lessler'), arxiv.Result.Author('M. Kate Grabowski'), arxiv.Result.Author('Elizabeth A. Stuart')]",
1021,Competing for Attention -- The Effect of Talk Radio on Elections and Political Polarization in the US,"This paper studies the effects of talk radio, specifically the Rush Limbaugh
Show, on electoral outcomes and attitude polarization in the U.S. We propose a
novel identification strategy that considers the radio space in each county as
a market where multiple stations are competing for listeners' attention. Our
measure of competition is a spatial Herfindahl-Hirschman Index (HHI) in radio
frequencies. To address endogeneity concerns, we exploit the variation in
competition based on accidental frequency overlaps in a county, conditional on
the overall level of radio frequency competition. We find that counties with
higher exposure to the Rush Limbaugh Show have a systematically higher vote
share for Donald Trump in the 2016 and 2020 U.S. presidential elections.
Combining our county-level Rush Limbaugh Show exposure measure with individual
survey data reveals that self-identifying Republicans in counties with higher
exposure to the Show express more conservative political views, while
self-identifying Democrats in these same counties express more moderate
political views. Taken together, these findings provide some of the first
insights on the effects of contemporary talk radio on political outcomes, both
at the aggregate and individual level.",2206.13675v1,econ.GN,2022-06-28 00:45:52+00:00,"[arxiv.Result.Author('Ashani Amarasinghe'), arxiv.Result.Author('Paul A. Raschky')]",
1022,Search for Double Transit Extrasolar Planetary Systems: Another Transiting Planet Around OGLE-TR-111 or a False Positive Detection?,"The search for double transit planetary systems opens new possibilities for
the transit searches and for studies of orbital stability, stellar irradiation,
and migration scenarios, among others. We explore the OGLE lightcurves of stars
with confirmed planetary companions (OGLE-TR-10, OGLE-TR-56, OGLE-TR-111,
OGLE-TR-113, and OGLE-TR-132), searching for additional transits. The most
promising candidate is OGLE-TR-111, where the photometric measurements and the
radial velocities are consistent with the presence of a second planet. If
confirmed, OGLE-TR-111 would be the first extrasolar planetary system detected
by transits. The parameters of the possible new planet OGLE-TR-111c would be:
period P = 16.0644 d, semimajor axis a = 0.12 AU, orbital inclination i = 88-89
deg, mass M = 0.7 M_J, radius R = 0.85 R_J, density \rho = 1.4 g/cm^3. If
confirmed, OGLE-TR-111c would be the smallest and densest extrasolar planet
measured todate, truly a Jovian planet, with properties intermediate between
Jupiter and Saturn, albeit with shorter period. Additional photometric and
spectroscopic data would allow to discriminate between a second transiting
planet around OGLE-TR-111 and a false positive detection.",astro-ph/0501440v1,astro-ph,2005-01-20 19:24:08+00:00,[arxiv.Result.Author('Dante Minniti')],
1023,The Optical Gravitational Lensing Experiment. Additional Planetary and Low-Luminosity Object Transits from the OGLE 2001 and 2002 Observational Campaigns,"The photometric data collected by OGLE-III during the 2001 and 2002
observational campaigns aiming at detection of planetary or low-luminosity
object transits were corrected for small scale systematic effects using the
data pipeline by Kruszewski and Semeniuk and searched again for low amplitude
transits. Sixteen new objects with small transiting companions, additional to
previously found samples, were discovered. Most of them are small amplitude
cases which remained undetected in the original data.
  Several new objects seem to be very promising candidates for systems
containing substellar objects: extrasolar planets or brown dwarfs. Those
include OGLE-TR-122, OGLE-TR-125, OGLE-TR-130, OGLE-TR-131 and a few others.
Those objects are particularly worth spectroscopic follow-up observations for
radial velocity measurements and mass determination. With well known
photometric orbit only a few RV measurements should allow to confirm their
actual status.
  All photometric data of presented objects are available to the astronomical
community from the OGLE Internet archive.",astro-ph/0306444v2,astro-ph,2003-06-23 04:50:03+00:00,"[arxiv.Result.Author('A. Udalski'), arxiv.Result.Author('G. Pietrzynski'), arxiv.Result.Author('M. Szymanski'), arxiv.Result.Author('M. Kubiak'), arxiv.Result.Author('K. Zebrun'), arxiv.Result.Author('I. Soszynski'), arxiv.Result.Author('O. Szewczyk'), arxiv.Result.Author('L. Wyrzykowski')]","Acta Astronomica (2003) 53, 133"
1024,Watching the Weak Link into Your Home: An Inspection and Monitoring Toolkit for TR-069,"TR-069 is a standard for the remote management of end-user devices by service
providers. Despite being implemented in nearly a billion devices, almost no
research has been published on the security and privacy aspects of TR-069. The
first contribution of this paper is a study of the TR-069 ecosystem and
techniques to inspect TR-069 communication. We find that the majority of
analyzed providers do not use recommended security measures, such as TLS.
Second, we present a TR-069 honeyclient to both analyze TR-069 behavior of
providers and test configuration servers for security vulnerabilities. We find
that popular open-source configuration servers use insecure methods to
authenticate clients. TR-069 implementations based on these servers expose, for
instance, their users' internet telephony credentials. Third, we develop
components for a distributed system to continuously monitor activities in
providers' TR-069 deployments. Our setup consists of inexpensive hardware
sensors deployed on customer premises and centralized log collectors. We
perform real-world measurements and find that the purported security benefits
of TR-069 are not realized as providers' firmware update processes are lacking.",2001.02564v1,cs.NI,2020-01-08 15:17:38+00:00,"[arxiv.Result.Author('Maximilian Hils'), arxiv.Result.Author('Rainer Böhme')]",
1025,Performance Enhancement of Multiuser Time Reversal UWB Communication System,"UWB communication is a recent research area for indoor propagation channels.
Time Reversal (TR) communication in UWB has shown promising results for
improving the system performance. In multiuser environment, the system
performance is significantly degraded due to the interference among different
users. TR reduces the interference caused by multiusers due to its spatial
focusing property. The performance of a multiuser TR communication system is
further improved if the TR filter is modified. In this paper, multiuser TR in
UWB communication is investigated using simple TR filter and a modified TR
filter with circular shift operation. The concept of circular shift in TR is
analytically studied. Thereafter, the channel impulse responses (CIR) of a
typical indoor laboratory environment are measured. The measured CIRs are used
to analyze the received signal peak power and signal to interference ratio
(SIR) with and without performing the circular shift operation in a multiuser
environment.",0810.1506v1,cs.NI,2008-10-08 18:54:07+00:00,"[arxiv.Result.Author('Ijaz Haider Naqvi'), arxiv.Result.Author('Ali Khaleghi'), arxiv.Result.Author('Ghaïs El Zein')]","IEEE International Symposium on Wireless Communication Systems
  2007, Trondheim : Norv\`ege (2007)"
1026,Equalized Time Reversal Beamforming for Indoor Wireless Communications,"Time-reversal (TR) is a beamforming technique for frequency-selective
channels, which has received increasing attention due to its high energy
efficiency and low computational complexity for wireless communications. In
this paper, we present two contributions on time-reversal (TR) wireless
beamforming for single-user indoor wideband MISO systems. First, we provide
novel analyses of a baseband TR system using two commonly used indoor
propagation channel models. We derive closed-form approximations for the
inter-symbol interference (ISI) with these channel models in order to
characterize the influence of propagation conditions (such as the power-delay
profile, delay spread, and bandwidth) on TR performance metrics. In particular,
we analyze spatial focusing and time compression performance of TR beamforming,
and their impact on the bit error rate (BER). As a second contribution, we
introduce an equalized TR (ETR) technique that mitigates the ISI of
conventional TR. The proposed ETR utilizes a zero-forcing pre-equalizer at the
transmitter in a cascade configuration with the TR pre-filter. Unlike previous
approaches to ISI mitigation in TR systems, we derive theoretical performance
bounds for ETR and show that it greatly enhances the BER performance of
conventional TR with minimal impact to its beamforming capabilities. By means
of numerical simulations, we verify our closed-form approximations and show
that the proposed ETR technique outperforms conventional TR with respect to the
BER under any SNR.",1411.6897v4,cs.NI,2014-11-24 20:26:48+00:00,"[arxiv.Result.Author('Carlos A. Viteri-Mera'), arxiv.Result.Author('Fernando L. Teixeira')]",
1027,Millimagnitude Photometry for Transiting Extrasolar Planetary Candidates. V. Follow-up of 30 OGLE Transits. New Candidates,"We used VLT/VIMOS images in the V band to obtain light curves of extrasolar
planetary transits OGLE-TR-111 and OGLE-TR-113, and candidate planetary
transits: OGLE-TR-82, OGLE-TR-86, OGLE-TR-91, OGLE-TR-106, OGLE-TR-109,
OGLE-TR-110, OGLE-TR-159, OGLE-TR-167, OGLE-TR-170, OGLE-TR-171. Using
difference imaging photometry, we were able to achieve millimagnitude errors in
the individual data points. We present the analysis of the data and the light
curves, by measuring transit amplitudes and ephemerides, and by calculating
geometrical parameters for some of the systems. We observed 9 OGLE objects at
the predicted transit moments. Two other transits were shifted in time by a few
hours. For another seven objects we expected to observe transits during the
VIMOS run, but they were not detected. The stars OGLE-TR-111 and OGLE-TR-113
are probably the only OGLE objects in the observed sample to host planets, with
the other objects being very likely eclipsing binaries or multiple systems. In
this paper we also report on four new transiting candidates which we have found
in the data.",0910.4892v1,astro-ph.EP,2009-10-26 14:37:38+00:00,"[arxiv.Result.Author('P. Pietrukowicz'), arxiv.Result.Author('D. Minniti'), arxiv.Result.Author('R. F. Diaz'), arxiv.Result.Author('J. M. Fernandez'), arxiv.Result.Author('M. Zoccali'), arxiv.Result.Author('W. Gieren'), arxiv.Result.Author('G. Pietrzynski'), arxiv.Result.Author('M. T. Ruiz'), arxiv.Result.Author('A. Udalski'), arxiv.Result.Author('T. Szeifert'), arxiv.Result.Author('M. Hempel')]",
1028,Frequency-Domain Time-Reversal Precoding in Wideband MISO OFDM Communication Systems,"Time reversal (TR) recently emerged as an interesting communication
technology capable of providing a good spatio-temporal signal focusing effect.
New generations of large-bandwidth devices with reduced cost leverage the use
of TR wideband communication systems. While TR is usually implemented in the
time domain, the same benefit can be obtained in an orthogonal frequency
division multiplexing (OFDM) system by precoding the information in the
frequency domain. Besides using multiple antennas, the focusing effect of TR
also comes from the use of a high rate back-off factor (BOF), which is the
signal up-sampling (or down-sampling) rate in the original time-domain TR
precoding. However, a frequency-domain TR precoding in the literature has only
considered BOF of one, which does not fully exploit the focusing property of
TR. In this paper, we discuss how to properly implement different BOFs using
frequency-domain TR precoding in the OFDM system. Moreover, we demonstrate that
increasing the BOF and/or the number of transmit antennas significantly
improves the focusing gain at the intended position. In contrast, the
unintended positions receive less useful power. Furthermore, closed-form
approximations of the mean-square-errors (MSEs) of equalized received signals
at either intended or unintended positions are derived, expressing the focusing
gain as a function of the BOF and the number of antennas. Numerical simulations
with multi-path channels are carried out to validate the MSE expressions.",1904.10727v1,eess.SP,2019-04-24 10:22:26+00:00,"[arxiv.Result.Author('Trung-Hien Nguyen'), arxiv.Result.Author('Jean-François Determe'), arxiv.Result.Author('Mathieu Van Eeckhaute'), arxiv.Result.Author('Jérôme Louveaux'), arxiv.Result.Author('Philippe De Doncker'), arxiv.Result.Author('François Horlin')]",
1029,Fragility of Time-Reversal Symmetry Protected Topological Phases,"The second law of thermodynamics points to the existence of an `arrow of
time', along which entropy only increases. This arises despite the
time-reversal symmetry (TRS) of the microscopic laws of nature. Within quantum
theory, TRS underpins many interesting phenomena, most notably topological
insulators and the Haldane phase of quantum magnets. Here, we demonstrate that
such TRS-protected effects are fundamentally unstable against coupling to an
environment. Irrespective of the microscopic symmetries, interactions between a
quantum system and its surroundings facilitate processes which would be
forbidden by TRS in an isolated system. This leads not only to entanglement
entropy production and the emergence of macroscopic irreversibility, but also
to the demise of TRS-protected phenomena, including those associated with
certain symmetry-protected topological phases. Our results highlight the
enigmatic nature of TRS in quantum mechanics, and elucidate potential
challenges in utilising topological systems for quantum technologies.",2003.08120v3,cond-mat.str-el,2020-03-18 09:43:54+00:00,"[arxiv.Result.Author('Max McGinley'), arxiv.Result.Author('Nigel R. Cooper')]","Nature Physics 16, 1181-1183 (2020)"
1030,Millimagnitude Photometry for Transiting Extrasolar Planetary Candidates IV: The Puzzle of the Extremely Red OGLE-TR-82 Primary Solved,"We present precise new V, I, and K-band photometry for the planetary transit
candidate star OGLE-TR-82. Good seeing V-band images acquired with VIMOS
instrument at ESO VLT allowed us to measure V=20.6+-0.03 mag star in spite of
the presence of a brighter neighbour about 1"" away. This faint magnitude
answers the question why it has not been possible to measure radial velocities
for this object. One transit of this star has been observed with GMOS-S
instrument of GEMINI-South telescope in i and g-bands. The measurement of the
transit allows us to verify that this is not a false positive, to confirm the
transit amplitude measured by OGLE, and to improve the ephemeris. The transit
is well defined in i-band light curve, with a depth of A_i=0.034 mag. It is
however, less well defined, but deeper (A_g=0.1 mag) in the g-band, in which
the star is significantly fainter. The near-infrared photometry obtained with
SofI array at the ESO-NTT yields K=12.2+-0.1 and V-K=8.4+-0.1, so red that it
is unlike any other transit candidate studied before. Due to the extreme nature
of this object, we have not yet been able to measure velocities for this star,
but based on the new data we consider two different possible configurations:(1)
a nearby M7V star, or (2) a blend with a very reddened distant red giant. The
nearby M7V dwarf hypothesis would give a radius for the companion of
R_p=0.3+-0.1 R_J, i.e. the size of Neptune. Quantitative analysis of near-IR
spectroscopy finally shows that OGLE-TR-82 is a distant, reddened metal poor
early K giant. This result is confirmed by direct comparison with stellar
templates that gives the best match for a K3III star. Therefore, we discard the
planetary nature of the companion. Based on all the new data, we conclude that
this system is a main-sequence binary blended with a background red giant.",0707.1248v1,astro-ph,2007-07-09 13:24:24+00:00,"[arxiv.Result.Author('Sergio Hoyer'), arxiv.Result.Author('Sebastian Ramirez Alegria'), arxiv.Result.Author('Valentin D. Ivanov'), arxiv.Result.Author('Dante Minniti'), arxiv.Result.Author('Grzegorz Pietrzynski'), arxiv.Result.Author('Maria Teresa Ruiz'), arxiv.Result.Author('Wolfgang Gieren'), arxiv.Result.Author('Andrzej Udalski'), arxiv.Result.Author('Manuela Zoccali'), arxiv.Result.Author('Rodrigo Carrasco'), arxiv.Result.Author('Rodrigo F. Diaz'), arxiv.Result.Author('Jose Miguel Fernandez'), arxiv.Result.Author('Jose Gallardo'), arxiv.Result.Author('Marina Rejkuba'), arxiv.Result.Author('Felipe Perez')]","Astrophys.J.669:1345-1353,2007"
1031,Termination of Rewriting with Right-Flat Rules Modulo Permutative Theories,"We present decidability results for termination of classes of term rewriting
systems modulo permutative theories. Termination and innermost termination
modulo permutative theories are shown to be decidable for term rewrite systems
(TRS) whose right-hand side terms are restricted to be shallow (variables occur
at depth at most one) and linear (each variable occurs at most once). Innermost
termination modulo permutative theories is also shown to be decidable for
shallow TRS. We first show that a shallow TRS can be transformed into a flat
(only variables and constants occur at depth one) TRS while preserving
termination and innermost termination. The decidability results are then proved
by showing that (a) for right-flat right-linear (flat) TRS, non-termination
(respectively, innermost non-termination) implies non-termination starting from
flat terms, and (b) for right-flat TRS, the existence of non-terminating
derivations starting from a given term is decidable. On the negative side, we
show PSPACE-hardness of termination and innermost termination for shallow
right-linear TRS, and undecidability of termination for flat TRS.",1006.0706v3,cs.LO,2010-06-03 17:46:20+00:00,"[arxiv.Result.Author('Luis Barguno'), arxiv.Result.Author('Guillem Godoy'), arxiv.Result.Author('Eduard Huntingford'), arxiv.Result.Author('Ashish Tiwari')]","Logical Methods in Computer Science, Volume 6, Issue 3 (August 25,
  2010) lmcs:821"
1032,Solar transition region in the quiet Sun and active regions,"The solar transition region (TR), in which above the photosphere the tempera-
ture increases rapidly and the density drops dramatically, is believed to play
an important role in coronal heating and solar wind acceleration. Long-lasting
up-flows are present in the upper TR and interpreted as signatures of mass
supply to large coronal loops in the quiet Sun. Coronal bright points (BPs) are
local heating phenomena and we found a different Doppler-shift pattern at TR
and coronal temperatures in one BP, which might be related to the twisted loop
system. The dominant energy loss in the lower TR is the Ly-alpha emission. It
has been found that most Ly-alpha radiance profiles are stronger in the blue
peak, an asymmetry opposite to higher order Lyman lines. This asymmetry is
stronger when the downflow in the middle TR is stronger, indicating that the TR
flows play an important role in the line formation process. The peak separation
of Ly-alpha is found to be larger in coronal holes than in the quiet Sun,
reflecting the different magnetic structures and radiation fields between the
two regions. The Lyman line profiles are found to be not reversed in sunspot
plume and umbra regions, while they are obviously reversed in the surrounding
plage region. At TR temperatures, the densities of the sunspot plume and umbra
are a factor of 10 lower than of the plage, indicating that the sunspot plasma
emitting at TR temperatures is higher and possibly more extended above sunspots
than above the plage region.",0912.0345v2,astro-ph.SR,2009-12-02 06:07:30+00:00,"[arxiv.Result.Author('H. Tian'), arxiv.Result.Author('W. Curdt'), arxiv.Result.Author('J. -S. He')]","Adv.Geosci.21:277,2009"
1033,On the precision attainable with various floating-point number systems,"For scientific computations on a digital computer the set of real number is
usually approximated by a finite set F of ""floating-point"" numbers. We compare
the numerical accuracy possible with difference choices of F having
approximately the same range and requiring the same word length. In particular,
we compare different choices of base (or radix) in the usual floating-point
systems. The emphasis is on the choice of F, not on the details of the number
representation or the arithmetic, but both rounded and truncated arithmetic are
considered. Theoretical results are given, and some simulations of typical
floating-point computations (forming sums, solving systems of linear equations,
finding eigenvalues) are described. If the leading fraction bit of a normalized
base 2 number is not stored explicitly (saving a bit), and the criterion is to
minimize the mean square roundoff error, then base 2 is best. If unnormalized
numbers are allowed, so the first bit must be stored explicitly, then base 4
(or sometimes base 8) is the best of the usual systems.",1004.3374v1,cs.NA,2010-04-20 08:17:24+00:00,[arxiv.Result.Author('Richard P. Brent')],"IEEE Transactions on Computers C-22 (1973), 601-607"
1034,Rational Lax operators and their quantization,"We investigate the construction of the quantum commuting hamiltonians for the
Gaudin integrable model. We prove that [Tr L^k(z), Tr L^m(u) ]=0, for k,m < 4 .
However this naive receipt of quantization of classically commuting
hamiltonians fails in general, for example we prove that [Tr L^4(z), Tr L^2(u)
] \ne 0. We investigate in details the case of the one spin Gaudin model with
the magnetic field also known as the model obtained by the ""argument shift
method"". Mathematically speaking this method gives maximal Poisson commutative
subalgebras in the symmetric algebra S(gl(N)). We show that such subalgebras
can be lifted to U(gl(N)), simply considering Tr L(z)^k, k\le N for N<5. For
N=6 this method fails: [Tr L_{MF}(z)^6, L_{MF}(u)^3]\ne 0 . All the proofs are
based on the explicit calculations using r-matrix technique. We also propose
the general receipt to find the commutation formula for powers of Lax operator.
For small power exponents we find the complete commutation relations between
powers of Lax operators.",hep-th/0404106v1,hep-th,2004-04-15 12:34:34+00:00,"[arxiv.Result.Author('A. Chervov'), arxiv.Result.Author('L. Rybnikov'), arxiv.Result.Author('D. Talalaev')]",
1035,A weakly stable algorithm for general Toeplitz systems,"We show that a fast algorithm for the QR factorization of a Toeplitz or
Hankel matrix A is weakly stable in the sense that R^T.R is close to A^T.A.
Thus, when the algorithm is used to solve the semi-normal equations R^T.Rx =
A^Tb, we obtain a weakly stable method for the solution of a nonsingular
Toeplitz or Hankel linear system Ax = b. The algorithm also applies to the
solution of the full-rank Toeplitz or Hankel least squares problem.",1005.0503v1,math.NA,2010-05-04 12:27:15+00:00,"[arxiv.Result.Author('Adam W. Bojanczyk'), arxiv.Result.Author('Richard P. Brent'), arxiv.Result.Author('Frank R. de Hoog')]","Stability analysis of a general Toeplitz system solver, Numerical
  Algorithms 10 (1995), 225-244."
1036,Interference-Nulling Time-Reversal Beamforming for mm-Wave Massive MIMO in Multi-User Frequency-Selective Indoor Channels,"Millimeter wave (mm-wave) and massive MIMO have been proposed for next
generation wireless systems. However, there are many open problems for the
implementation of those technologies. In particular, beamforming is necessary
in mm-wave systems in order to counter high propagation losses. However,
conventional beamsteering is not always appropriate in rich scattering
multipath channels with frequency selective fading, such as those found in
indoor environments. In this context, time-reversal (TR) is considered a
promising beamforming technique for such mm-wave massive MIMO systems. In this
paper, we analyze a baseband TR beamforming system for mm-wave multi-user
massive MIMO. We verify that, as the number of antennas increases, TR yields
good equalization and interference mitigation properties, but inter-user
interference (IUI) remains a main impairment. Thus, we propose a novel
technique called interference-nulling TR (INTR) to minimize IUI. We evaluate
numerically the performance of INTR and compare it with conventional TR and
equalized TR beamforming. We use a 60 GHz MIMO channel model with spatial
correlation based on the IEEE 802.11ad SISO NLoS model. We demonstrate that
INTR outperforms conventional TR with respect to average BER per user and
achievable sum rate under diverse conditions, providing both diversity and
multiplexing gains simultaneously.",1506.05143v2,cs.IT,2015-06-16 20:35:51+00:00,"[arxiv.Result.Author('Carlos A. Viteri-Mera'), arxiv.Result.Author('Fernando L. Teixeira')]",
1037,Ethernet Topology Discovery: A Survey,"Ethernet networks have undergone impressive growth since the past few
decades. This growth can be appreciated in terms of the equipment, such as
switches and links, that have been added, as well as in the number of users
that it supports. In parallel to this expansion, over the past decade the
networking research community has shown a growing interest in discovering and
analyzing the Ethernet topology. Research in this area has concentrated on the
theoretical analysis of Ethernet topology as well as developing tools and
methods for mapping the network layout. These efforts have brought us to a
crucial juncture for Ethernet topology measurement infrastructures: while,
previously, these were both small (in terms of number of measurement points),
we are starting to see the deployment of large-scale distributed systems
composed of hundreds or thousands of monitors. As we look forward to this next
generation of systems, we take stock of what has been achieved so far. In this
survey, we discuss past and current mechanisms for discovering the Ethernet
topology from theoretical and practical prospective. In addition to discovery
techniques, we provide insights into some of the well known open issues related
to Ethernet topology discovery.",0907.3095v1,cs.NI,2009-07-17 15:31:38+00:00,[arxiv.Result.Author('Kamal Ahmat')],
1038,Stability of fast algorithms for structured linear systems,"We survey the numerical stability of some fast algorithms for solving systems
of linear equations and linear least squares problems with a low
displacement-rank structure. For example, the matrices involved may be Toeplitz
or Hankel. We consider algorithms which incorporate pivoting without destroying
the structure, and describe some recent results on the stability of these
algorithms. We also compare these results with the corresponding stability
results for the well known algorithms of Schur/Bareiss and Levinson, and for
algorithms based on the semi-normal equations.",1005.0671v1,math.NA,2010-05-05 04:59:19+00:00,[arxiv.Result.Author('Richard P. Brent')],"Fast reliable algorithms for matrices with structure, SIAM, 1999,
  103-116"
1039,Dynamical generation of superconducting order of different symmetries in hexagonal lattices,"The growth of superconducting order after an interaction quench in a
hexagonal lattice is studied. The cases of both time-reversal (TR) preserving
graphene, as well as the TR broken Haldane model are explored. Spin singlet
superconducting order is studied where the $s$, $d+id$, and $d-id$ wave orders
are the irreducible representations of the hexagonal lattice. For small
quenches, the $d$-wave order parameter grows the fastest, a result also
expected when the system is in thermal equilibrium. For the TR symmetry
preserving case, the growth rate of the two $d$-wave orders is identical, while
the TR-broken case prefers one of the chiral $d$-wave orders over the other,
leading to a TR broken topological superconductor. As the interaction quench
becomes larger, a smooth crossover is found where eventually the growth rate of
the $s$-wave becomes the largest. Thus for large interaction quenches, the
$s$-wave is preferred over the $d$-wave for both TR preserving and TR broken
systems. This result is explained in terms of the high energy quasi-particles
responsible for the dynamics as the interaction quench amplitude grows. The
results are relevant for time-resolved measurements that can probe the symmetry
of the superconducting fluctuations in a transient regime.",1703.01621v3,cond-mat.supr-con,2017-03-05 16:38:09+00:00,"[arxiv.Result.Author('Hossein Dehghani'), arxiv.Result.Author('Aditi Mitra')]","Phys. Rev. B 96, 195110 (2017)"
1040,Magnetic Field Response and Chiral Symmetry of Time Reversal Invariant Topological Superconductors,"We study the magnetic field response of the Majorana Kramers pairs of a
one-dimensional time-reversal invariant (TRI) superconductors (class DIII) with
or without a coexisting chirality symmetry. For unbroken TR and chirality
invariance the parameter regimes for nontrivial values of the (Z_2)
DIII-invariant and the (Z) chiral invariant coincide. However, broken TR may or
may not be accompanied by broken chirality, and if chiral symmetry is unbroken,
the pair of Majorana fermions (MFs) at a given end survives the loss of TR
symmetry in an entire plane perpendicular to the spin-orbit coupling field.
Conversely, we show that broken chirality may or may not be accompanied by
broken TR, and if TR is unbroken, the pair of MFs survives the loss of broken
chirality. In addition to explaining the anomalous magnetic field response of
all the DIII class TS systems proposed in the literature, we provide a
realistic route to engineer a ""true"" TR-invariant TS, whose pair of MFs at each
end is split by an applied Zeeman field in arbitrary direction. We also prove
that, quite generally, the splitting of the MFs by TR-breaking fields in TRI
superconductors is highly anisotropic in spin space, even in the absence of the
topological chiral symmetry.",1310.7938v2,cond-mat.mes-hall,2013-10-29 20:00:01+00:00,"[arxiv.Result.Author('Eugene Dumitrescu'), arxiv.Result.Author('Jay D. Sau'), arxiv.Result.Author('Sumanta Tewari')]","Phys. Rev. B 90, 245438 (2014)"
1041,Programmable Molecular Composites of Tandem Proteins with Graphene-Oxide for Efficient Bimoprh Actuators,"The rapid expansion in the spectrum of two-dimensional (2D) materials has
driven the efforts of research on the fabrication of 2D composites and
heterostructures. Highly ordered structure of 2D materials provides an
excellent platform for controlling the ultimate structure and properties of the
composite material with precision. However, limited control over the structure
of the adherent material and its interactions with highly ordered 2D materials
results in defective composites with inferior performance. Here, we demonstrate
the successful synthesis, integration, and characterization of hybrid 2D
material systems consisting of tandem repeat (TR) proteins inspired by squid
ring teeth and graphene oxide (GO). The TR protein layer acts as a unique
programmable molecular spacer between GO layers. As an application, we further
demonstrate thermal actuation using bimorph molecular composite films. Bimorph
actuators made of molecular composite films (GO/TR) can lead to energy
efficiencies 18 times higher than regular bimorph actuators consisting of a GO
layer and a TR protein layer (i.e., conventional bulk composite of GO and TR).
Additionally, molecular composite bimorph actuators can reach curvature values
as high as 1.2 cm-1 by using TR proteins with higher molecular weight, which is
3 times higher than conventional GO and TR composites.",1701.04019v1,cond-mat.soft,2017-01-15 10:13:21+00:00,"[arxiv.Result.Author('Mert Vural'), arxiv.Result.Author('Yu Lei'), arxiv.Result.Author('Abdon Pena-Francesch'), arxiv.Result.Author('Huihun Jung'), arxiv.Result.Author('Benjamin Allen'), arxiv.Result.Author('Mauricio Terrones'), arxiv.Result.Author('Melik C. Demirel')]",
1042,Repairing Human Trust by Promptly Correcting Robot Mistakes with An Attention Transfer Model,"In human-robot collaboration (HRC), human trust in the robot is the human
expectation that a robot executes tasks with desired performance. A
higher-level trust increases the willingness of a human operator to assign
tasks, share plans, and reduce the interruption during robot executions,
thereby facilitating human-robot integration both physically and mentally.
However, due to real-world disturbances, robots inevitably make mistakes,
decreasing human trust and further influencing collaboration. Trust is fragile
and trust loss is triggered easily when robots show incapability of task
executions, making the trust maintenance challenging. To maintain human trust,
in this research, a trust repair framework is developed based on a
human-to-robot attention transfer (H2R-AT) model and a user trust study. The
rationale of this framework is that a prompt mistake correction restores human
trust. With H2R-AT, a robot localizes human verbal concerns and makes prompt
mistake corrections to avoid task failures in an early stage and to finally
improve human trust. User trust study measures trust status before and after
the behavior corrections to quantify the trust loss. Robot experiments were
designed to cover four typical mistakes, wrong action, wrong region, wrong
pose, and wrong spatial relation, validated the accuracy of H2R-AT in robot
behavior corrections; a user trust study with $252$ participants was conducted,
and the changes in trust levels before and after corrections were evaluated.
The effectiveness of the human trust repairing was evaluated by the mistake
correction accuracy and the trust improvement.",2103.08025v2,cs.RO,2021-03-14 20:15:03+00:00,"[arxiv.Result.Author('Ruijiao Luo'), arxiv.Result.Author('Chao Huang'), arxiv.Result.Author('Yuntao Peng'), arxiv.Result.Author('Boyi Song'), arxiv.Result.Author('Rui Liu')]",
1043,Multi-Task Trust Transfer for Human-Robot Interaction,"Trust is essential in shaping human interactions with one another and with
robots. This paper discusses how human trust in robot capabilities transfers
across multiple tasks. We first present a human-subject study of two distinct
task domains: a Fetch robot performing household tasks and a virtual reality
simulation of an autonomous vehicle performing driving and parking maneuvers.
The findings expand our understanding of trust and inspire new differentiable
models of trust evolution and transfer via latent task representations: (i) a
rational Bayes model, (ii) a data-driven neural network model, and (iii) a
hybrid model that combines the two. Experiments show that the proposed models
outperform prevailing models when predicting trust over unseen tasks and users.
These results suggest that (i) task-dependent functional trust models capture
human trust in robot capabilities more accurately, and (ii) trust transfer
across tasks can be inferred to a good degree. The latter enables
trust-mediated robot decision-making for fluent human-robot interaction in
multi-task settings.",1807.01866v3,cs.RO,2018-07-05 06:58:13+00:00,"[arxiv.Result.Author('Harold Soh'), arxiv.Result.Author('Yaqi Xie'), arxiv.Result.Author('Min Chen'), arxiv.Result.Author('David Hsu')]",
1044,TRUFL: Distributed Trust Management framework in SDN,"Software Defined Networking (SDN) has emerged as a revolutionary paradigm to
manage cloud infrastructure. SDN lacks scalable trust setup and verification
mechanism between Data Plane-Control Plane elements, Control Plane elements,
and Control Plane-Application Plane. Trust management schemes like Public Key
Infrastructure (PKI) used currently in SDN are slow for trust establishment in
a larger cloud environment. We propose a distributed trust mechanism - TRUFL to
establish and verify trust in SDN. The distributed framework utilizes
parallelism in trust management, in effect faster transfer rates and reduced
latency compared to centralized trust management. The TRUFL framework scales
well with the number of OpenFlow rules when compared to existing research
works.",1811.00635v2,cs.CR,2018-11-01 21:10:38+00:00,"[arxiv.Result.Author('Ankur Chowdhary'), arxiv.Result.Author('Adel Alshamrani'), arxiv.Result.Author('Dijiang Huang'), arxiv.Result.Author('Myong Kang'), arxiv.Result.Author('Anya Kim'), arxiv.Result.Author('Alexander Velazquez')]",
1045,"Bluetooth based Proximity, Multi-hop Analysis and Bi-directional Trust: Epidemics and More","In this paper, we propose a trust layer on top of Bluetooth and similar
wireless communication technologies that can form mesh networks. This layer as
a protocol enables computing trust scores based on proximity and bi-directional
transfer of messages in multiple hops across a network of mobile devices. We
describe factors and an approach for determining these trust scores and
highlight its applications during epidemics such as COVID-19 through improved
contact-tracing, better privacy and verification for sensitive data sharing in
the numerous Bluetooth and GPS based mobile applications that are being
developed to track the spread.",2009.06468v1,cs.CR,2020-09-10 17:23:00+00:00,"[arxiv.Result.Author('Ramesh Raskar'), arxiv.Result.Author('Sai Sri Sathya')]",
1046,Clarifying Trust in Social Internet of Things,"A social approach can be exploited for the Internet of Things (IoT) to manage
a large number of connected objects. These objects operate as autonomous agents
to request and provide information and services to users. Establishing
trustworthy relationships among the objects greatly improves the effectiveness
of node interaction in the social IoT and helps nodes overcome perceptions of
uncertainty and risk. However, there are limitations in the existing trust
models. In this paper, a comprehensive model of trust is proposed that is
tailored to the social IoT. The model includes ingredients such as trustor,
trustee, goal, trustworthiness evaluation, decision, action, result, and
context. Building on this trust model, we clarify the concept of trust in the
social IoT in five aspects such as (1) mutuality of trustor and trustee, (2)
inferential transfer of trust, (3) transitivity of trust, (4) trustworthiness
update, and (5) trustworthiness affected by dynamic environment. With network
connectivities that are from real-world social networks, a series of
simulations are conducted to evaluate the performance of the social IoT
operated with the proposed trust model. An experimental IoT network is used to
further validate the proposed trust model.",1704.03554v1,cs.SI,2017-04-11 22:28:52+00:00,"[arxiv.Result.Author('Zhiting Lin'), arxiv.Result.Author('Liang Dong')]","IEEE Transactions on Knowledge and Data Engineering, vol. 30, no.
  2, pp. 234-248, Feb. 2018"
1047,From Pretty Good To Great: Enhancing PGP using Bitcoin and the Blockchain,"PGP is built upon a Distributed Web of Trust in which the trustworthiness of
a user is established by others who can vouch through a digital signature for
that particular identity. Preventing its wholesale adoption are a number of
inherent weaknesses to include (but not limited to) the following: 1) Trust
Relationships are built on a subjective honor system, 2) Only first degree
relationships can be fully trusted, 3) Levels of trust are difficult to
quantify with actual values, and 4) Issues with the Web of Trust itself
(Certification and Endorsement). Although the security that PGP provides is
proven to be reliable, it has largely failed to garner large scale adoption. In
this paper, we propose several novel contributions to address the
aforementioned issues with PGP and associated Web of Trust. To address the
subjectivity of the Web of Trust, we provide a new certificate format based on
Bitcoin which allows a user to verify a PGP certificate using Bitcoin
identity-verification transactions - forming first degree trust relationships
that are tied to actual values (i.e., number of Bitcoins transferred during
transaction). Secondly, we present the design of a novel Distributed PGP key
server that leverages the Bitcoin transaction blockchain to store and retrieve
Bitcoin-Based PGP certificates. Lastly, we provide a web prototype application
that demonstrates several of these capabilities in an actual environment.",1508.04868v2,cs.CR,2015-08-20 03:45:05+00:00,"[arxiv.Result.Author('Duane Wilson'), arxiv.Result.Author('Giuseppe Ateniese')]",
1048,An Evolutionary Game based Secure Clustering Protocol with Fuzzy Trust Evaluation and Outlier Detection for Wireless Sensor Networks,"Trustworthy and reliable data delivery is a challenging task in Wireless
Sensor Networks (WSNs) due to unique characteristics and constraints. To
acquire secured data delivery and address the conflict between security and
energy, in this paper we present an evolutionary game based secure clustering
protocol with fuzzy trust evaluation and outlier detection for WSNs. Firstly, a
fuzzy trust evaluation method is presented to transform the transmission
evidences into trust values while effectively alleviating the trust
uncertainty. And then, a K-Means based outlier detection scheme is proposed to
further analyze plenty of trust values obtained via fuzzy trust evaluation or
trust recommendation. It can discover the commonalities and differences among
sensor nodes while improving the accuracy of outlier detection. Finally, we
present an evolutionary game based secure clustering protocol to achieve a
trade-off between security assurance and energy saving for sensor nodes when
electing for the cluster heads. A sensor node which failed to be the cluster
head can securely choose its own head by isolating the suspicious nodes.
Simulation results verify that our secure clustering protocol can effectively
defend the network against the attacks from internal selfish or compromised
nodes. Correspondingly, the timely data transfer rate can be improved
significantly.",2207.10282v1,cs.NI,2022-07-21 03:24:35+00:00,"[arxiv.Result.Author('Liu Yang'), arxiv.Result.Author('Yinzhi Lu'), arxiv.Result.Author('Simon X. Yang'), arxiv.Result.Author('Yuanchang Zhong'), arxiv.Result.Author('Tan Guo'), arxiv.Result.Author('Zhifang Liang')]",
1049,Evolution of trust in a hierarchical population with punishing investors,"Trust plays an essential role in the development of human society. According
to the standard trust game, an investor decides whether to keep or transfer a
certain portion of initial stake to a trustee. In the latter case, the stake is
enhanced to signal the value of trust. The trustee then chooses how much to
return to the investor. We here distinguish two types of investors and two
types of trustees who can learn from each other. While a trustee can be
trustworthy or untrustworthy, an investor could be normal or punishing one. The
latter strategy punishes both untrustworthy trustees and normal investors who
are reluctant to control misbehaving trustees. Importantly, we assume a
hierarchical population where the portion of investors and trustees is fixed.
By means of replicator equation approach, we study the $N$-player trust game
and calculate the level of trust and trustworthiness. We find that the
introduction of punishment can induce a stable coexistence state between
punishing investors and trustworthy trustees. Furthermore, an intermediate
fraction of investors can better promote the evolution of trust when the
punishment intensity is low. For more intensive punishment, however, a higher
fraction of investors can be more efficient to elevate the trust level. In
addition, we reveal that appropriate increase of the punishment intensity can
enlarge the attraction domain of the coexistence state.",2209.05179v1,cs.GT,2022-09-12 12:12:06+00:00,"[arxiv.Result.Author('Ketian Sun'), arxiv.Result.Author('Yang Liu'), arxiv.Result.Author('Xiaojie Chen'), arxiv.Result.Author('Attila Szolnoki')]","Chaos, Solitons & Fractals 162 (2022) 112413"
1050,Trusted routing vs. VPN for secured data transfer over IP-networks/Internet,"Though objectives of trusted routing and virtual private networks (VPN) data
transfer methods are to guarantee data transfer securely to from senders to
receivers over public networks like Internet yet there are paramount
differences between the two methods. This paper analyses their differences.",1509.00236v1,cs.NI,2015-09-01 11:33:57+00:00,[arxiv.Result.Author('Osuolale Abdulrahamon Tiamiyu')],"Proceedings of conference "" fundamental and applied science in
  modern world "", Saint-Petersburg, 20-22 June 2013. To-Future, 2013. pp.63-70"
1051,Trust Based Scheme for QoS Assurance in Mobile Ad-Hoc Networks,"A mobile ad-hoc network (MANET) is a peer-to-peer wireless network where
nodes can communicate with each other without the use of infrastructure such as
access points or base stations. These networks are self-configuring, capable of
self-directed operation and hastily deployable. Nodes cooperate to provide
connectivity, operates without centralized administration. Nodes are itinerant,
topology can be very dynamic and nodes must be able to relay traffic since
communicating nodes might be out of range. The dynamic nature of MANET makes
network open to attacks and unreliability. Routing is always the most
significant part for any networks. Each node should not only work for itself,
but should be cooperative with other nodes. Node misbehaviour due to selfish or
malicious intention could significantly degrade the performance of MANET. The
Qos parameters like PDR, throughput and delay are affected directly due to such
misbehaving nodes. We focus on trust management framework, which is intended to
cope with misbehaviour problem of node and increase the performance of MANETs.
A trust-based system can be used to track this misbehaving of nodes, spot them
and isolate them from routing and provide reliability. In this paper a Trust
Based Reliable AODV [TBRAODV] protocol is presented which implements a trust
value for each node. For every node trust value is calculated and based trust
value nodes are allowed to participate in routing or else identified to become
a misbehaving node. This enhances reliability in AODV routing and results in
increase of PDR, decrease in delay and throughput is maintained. This work is
implemented and simulated on NS-2. Based on simulation results, the proposed
protocol provides more consistent and reliable data transfer compared with
general AODV, if there are misbehaving nodes in the MANET",1202.1664v1,cs.NI,2012-02-08 11:38:47+00:00,"[arxiv.Result.Author('Sridhar Subramanian'), arxiv.Result.Author('Baskaran Ramachandran')]",
1052,Quantifying Interpretability and Trust in Machine Learning Systems,"Decisions by Machine Learning (ML) models have become ubiquitous. Trusting
these decisions requires understanding how algorithms take them. Hence
interpretability methods for ML are an active focus of research. A central
problem in this context is that both the quality of interpretability methods as
well as trust in ML predictions are difficult to measure. Yet evaluations,
comparisons and improvements of trust and interpretability require quantifiable
measures. Here we propose a quantitative measure for the quality of
interpretability methods. Based on that we derive a quantitative measure of
trust in ML decisions. Building on previous work we propose to measure
intuitive understanding of algorithmic decisions using the information transfer
rate at which humans replicate ML model predictions. We provide empirical
evidence from crowdsourcing experiments that the proposed metric robustly
differentiates interpretability methods. The proposed metric also demonstrates
the value of interpretability for ML assisted human decision making: in our
experiments providing explanations more than doubled productivity in annotation
tasks. However unbiased human judgement is critical for doctors, judges, policy
makers and others. Here we derive a trust metric that identifies when human
decisions are overly biased towards ML predictions. Our results complement
existing qualitative work on trust and interpretability by quantifiable
measures that can serve as objectives for further improving methods in this
field of research.",1901.08558v1,cs.LG,2019-01-20 18:46:39+00:00,"[arxiv.Result.Author('Philipp Schmidt'), arxiv.Result.Author('Felix Biessmann')]",
1053,Trust Management for Internet of Things: A Systematic Literature Review,"Internet of Things (IoT) is a network of devices that communicate with each
other through the internet and provides intelligence to industry and people.
These devices are running in potentially hostile environments, so the need for
security is critical. Trust Management aims to ensure the reliability of the
network by assigning a trust value in every node indicating its trust level.
This paper presents an exhaustive survey of the current Trust Management
techniques for IoT, a classification based on the methods used in every work
and a discussion of the open challenges and future research directions.",2211.01712v1,cs.NI,2022-11-03 11:06:17+00:00,"[arxiv.Result.Author('Alyzia Maria Konsta'), arxiv.Result.Author('Alberto Lluch Lafuente'), arxiv.Result.Author('Nicola Dragoni')]",
1054,Trust Infrastructures for Virtual Asset Service Providers,"Virtual asset service providers (VASPs) currently face a number of
challenges, both from the technological and the regulatory perspectives. In the
context of virtual asset transfers one key issue is the need for VASPs to
securely exchange customer information to comply to the Travel Rule. We discuss
a VASP information sharing network as one form of a trust infrastructure for
VASP-to-VASP interactions. Related to this is the need for a trusted identity
infrastructure for VASPs that would permit other entities to quickly ascertain
the legal business status of a VASP. For regulated wallets, an attestation
infrastructure may provide VASPs and insurance providers with better visibility
into the state of wallets based on trusted hardware. Finally, for customers of
VASPs there is a need for seamless integration between the VASP services with
the existing consumer identity management infrastructure, providing a
user-friendly experience for transferring virtual assets to other users.",2008.05048v2,cs.CR,2020-08-12 00:55:41+00:00,[arxiv.Result.Author('Thomas Hardjono')],
1055,TRGP: Trust Region Gradient Projection for Continual Learning,"Catastrophic forgetting is one of the major challenges in continual learning.
To address this issue, some existing methods put restrictive constraints on the
optimization space of the new task for minimizing the interference to old
tasks. However, this may lead to unsatisfactory performance for the new task,
especially when the new task is strongly correlated with old tasks. To tackle
this challenge, we propose Trust Region Gradient Projection (TRGP) for
continual learning to facilitate the forward knowledge transfer based on an
efficient characterization of task correlation. Particularly, we introduce a
notion of `trust region' to select the most related old tasks for the new task
in a layer-wise and single-shot manner, using the norm of gradient projection
onto the subspace spanned by task inputs. Then, a scaled weight projection is
proposed to cleverly reuse the frozen weights of the selected old tasks in the
trust region through a layer-wise scaling matrix. By jointly optimizing the
scaling matrices and the model, where the model is updated along the directions
orthogonal to the subspaces of old tasks, TRGP can effectively prompt knowledge
transfer without forgetting. Extensive experiments show that our approach
achieves significant improvement over related state-of-the-art methods.",2202.02931v1,cs.LG,2022-02-07 04:21:54+00:00,"[arxiv.Result.Author('Sen Lin'), arxiv.Result.Author('Li Yang'), arxiv.Result.Author('Deliang Fan'), arxiv.Result.Author('Junshan Zhang')]",
1056,Exploiting Social Trust Assisted Reciprocity (STAR) towards Utility-Optimal Socially-aware Crowdsensing,"Mobile crowdsensing takes advantage of pervasive mobile devices to collect
and process data for a variety of applications (e.g., traffic monitoring,
spectrum sensing). In this study, a socially-aware crowdsensing system is
advocated, in which a cloud-based platform incentivizes mobile users to
participate in sensing tasks} by leveraging social trust among users, upon
receiving sensing requests. For this system, social trust assisted reciprocity
(STAR) - a synergistic marriage of social trust and reciprocity, is exploited
to design an incentive mechanism that stimulates users' participation.
  Given the social trust structure among users, the efficacy of STAR for
satisfying users' sensing requests is thoroughly investigated. Specifically, it
is first shown that all requests can be satisfied if and only if sufficient
social credit can be ""transferred"" from users who request more sensing service
than they can provide to users who can provide more than they request. Then
utility maximization for sensing services under STAR is investigated, and it is
shown that it boils down to maximizing the utility of a circulation flow in the
combined social graph and request graph. Accordingly, an algorithm that
iteratively cancels a cycle of positive weight in the residual graph is
developed, which computes the optimal solution efficiently, for both cases of
divisible and indivisible sensing service. Extensive simulation results
corroborate that STAR can significantly outperform the mechanisms using social
trust only or reciprocity only.",1508.05525v1,cs.NI,2015-08-22 16:39:36+00:00,"[arxiv.Result.Author('Xiaowen Gong'), arxiv.Result.Author('Xu Chen'), arxiv.Result.Author('Junshan Zhang'), arxiv.Result.Author('H. Vincent Poor')]",
1057,How to Tame Multiple Spending in Decentralized Cryptocurrencies,"The last decade has seen a variety of Asset-Transfer systems designed for
decentralized environments. To address the problem of double-spending, these
systems inherently make strong model assumptions and spend a lot of resources.
In this paper, we take a non-orthodox approach to the double-spending problem
that might suit better realistic environments in which these systems are to be
deployed. We consider the decentralized trust setting, where each user may
independently choose who to trust by forming its local quorums. In this
setting, we define $k$-Spending Asset Transfer, a relaxed version of asset
transfer which bounds the number of times the same asset can be spent. We
establish a precise relationship between the decentralized trust assumptions
and $k$, the optimal spending number of the system.",2205.14076v1,cs.DC,2022-05-27 16:15:03+00:00,"[arxiv.Result.Author('João Paulo Bezerra'), arxiv.Result.Author('Petr Kuznetsov')]",
1058,Double spending prevention of digital Euros using a web-of-trust,"In order to provide more security on double-spending, we have implemented a
system allowing for a web-of-trust. In this paper, we explore different
approaches taken against double-spending and implement our own version to avoid
this within TrustChain as part of the ecosystem of EuroToken, the digital
version of the euro. We have used the EVA protocol as a means to transfer data
between users, building on the existing functionality of transferring money
between users. This allows the sender of EuroTokens to leave recommendations of
users based on their previous interactions with other users. This dissemination
of trust through the network allows users to make more trustworthy decisions.
Although this provides an upgrade in terms of usability, the mathematical
details of our implementation can be explored further in other research.",2204.06831v2,cs.CR,2022-04-14 09:01:11+00:00,"[arxiv.Result.Author('Atanas Marinov'), arxiv.Result.Author('Jurriaan Den Toonder'), arxiv.Result.Author('Joep de Jong'), arxiv.Result.Author('Pieter Tolsma'), arxiv.Result.Author('Nils van den Honert'), arxiv.Result.Author('Johan Pouwelse')]",
1059,DeTrust-FL: Privacy-Preserving Federated Learning in Decentralized Trust Setting,"Federated learning has emerged as a privacy-preserving machine learning
approach where multiple parties can train a single model without sharing their
raw training data. Federated learning typically requires the utilization of
multi-party computation techniques to provide strong privacy guarantees by
ensuring that an untrusted or curious aggregator cannot obtain isolated replies
from parties involved in the training process, thereby preventing potential
inference attacks. Until recently, it was thought that some of these secure
aggregation techniques were sufficient to fully protect against inference
attacks coming from a curious aggregator. However, recent research has
demonstrated that a curious aggregator can successfully launch a disaggregation
attack to learn information about model updates of a target party. This paper
presents DeTrust-FL, an efficient privacy-preserving federated learning
framework for addressing the lack of transparency that enables isolation
attacks, such as disaggregation attacks, during secure aggregation by assuring
that parties' model updates are included in the aggregated model in a private
and secure manner. DeTrust-FL proposes a decentralized trust consensus
mechanism and incorporates a recently proposed decentralized functional
encryption (FE) scheme in which all parties agree on a participation matrix
before collaboratively generating decryption key fragments, thereby gaining
control and trust over the secure aggregation process in a decentralized
setting. Our experimental evaluation demonstrates that DeTrust-FL outperforms
state-of-the-art FE-based secure multi-party aggregation solutions in terms of
training time and reduces the volume of data transferred. In contrast to
existing approaches, this is achieved without creating any trust dependency on
external trusted entities.",2207.07779v1,cs.CR,2022-07-15 23:07:20+00:00,"[arxiv.Result.Author('Runhua Xu'), arxiv.Result.Author('Nathalie Baracaldo'), arxiv.Result.Author('Yi Zhou'), arxiv.Result.Author('Ali Anwar'), arxiv.Result.Author('Swanand Kadhe'), arxiv.Result.Author('Heiko Ludwig')]",
1060,Adversary Model: Adaptive Chosen Ciphertext Attack with Timing Attack,"We have introduced a novel adversary model in Chosen-Ciphertext Attack with
Timing Attack (CCA2-TA) and it was a practical model because the model
incorporates the timing attack. This paper is an extended paper for 'A Secure
TFTP Protocol with Security Proofs'.
  Keywords - Timing Attack, Random Oracle Model, Indistinguishabilit, Chosen
Plaintext Attack, CPA, Chosen Ciphertext Attack, IND-CCA1, Adaptive Chosen
Ciphertext Attack, IND-CCA2, Trivial File Transfer Protocol, TFTP, Security,
Trust, Privacy, Trusted Computing, UBOOT, AES, IOT, Lightweight, Asymmetric,
Symmetric, Raspberry Pi, ARM.",1409.6556v1,cs.CR,2014-09-23 14:24:35+00:00,"[arxiv.Result.Author('Mohd Anuar Mat Isa'), arxiv.Result.Author('Habibah Hashim')]",
1061,Enabling Enterprise Blockchain Interoperability with Trusted Data Transfer (industry track),"The adoption of permissioned blockchain networks in enterprise settings has
seen an increase in growth over the past few years. While encouraging, this is
leading to the emergence of new data, asset and process silos limiting the
potential value these networks bring to the broader ecosystem. Mechanisms for
enabling network interoperability help preserve the benefits of independent
sovereign networks, while allowing for the transfer or sharing of data, assets
and processes across network boundaries. However, a naive approach to
interoperability based on traditional point-to-point integration is
insufficient for preserving the underlying trust decentralized networks
provide. In this paper, we lay the foundation for an approach to
interoperability based on a communication protocol that derives trust from the
underlying network consensus protocol. We present an architecture and a set of
building blocks that can be adapted for use in a range of network
implementations and demonstrate a proof-of-concept for trusted data-sharing
between two independent trade finance and supply-chain networks, each running
on Hyperledger Fabric. We show how existing blockchain deployments can be
adapted for interoperation and discuss the security and extensibility of our
architecture and mechanisms.",1911.01064v1,cs.DC,2019-11-04 07:43:28+00:00,"[arxiv.Result.Author('Ermyas Abebe'), arxiv.Result.Author('Dushyant Behl'), arxiv.Result.Author('Chander Govindarajan'), arxiv.Result.Author('Yining Hu'), arxiv.Result.Author('Dileban Karunamoorthy'), arxiv.Result.Author('Petr Novotny'), arxiv.Result.Author('Vinayaka Pandit'), arxiv.Result.Author('Venkatraman Ramakrishna'), arxiv.Result.Author('Christian Vecchiola')]",
1062,TRUFL: Distributed Trust Management framework in SDN,"Software Defined Networking (SDN) has emerged as a revolutionary paradigm to
manage cloud infrastructure. SDN lacks scalable trust setup and verification
mechanism between Data Plane-Control Plane elements, Control Plane elements,
and Control Plane-Application Plane. Trust management schemes like Public Key
Infrastructure (PKI) used currently in SDN are slow for trust establishment in
a larger cloud environment. We propose a distributed trust mechanism - TRUFL to
establish and verify trust in SDN. The distributed framework utilizes
parallelism in trust management, in effect faster transfer rates and reduced
latency compared to centralized trust management. The TRUFL framework scales
well with the number of OpenFlow rules when compared to existing research
works.",1811.00635v2,cs.CR,2018-11-01 21:10:38+00:00,"[arxiv.Result.Author('Ankur Chowdhary'), arxiv.Result.Author('Adel Alshamrani'), arxiv.Result.Author('Dijiang Huang'), arxiv.Result.Author('Myong Kang'), arxiv.Result.Author('Anya Kim'), arxiv.Result.Author('Alexander Velazquez')]",
1063,Long-Distance Trust-Free Quantum Key Distribution,"The feasibility of trust-free long-haul quantum key distribution (QKD)
networks is addressed. We combine measurement-device-independent QKD (MDI-QKD),
as an access technology, with a quantum repeater setup, at the core of future
quantum communication networks. This will provide a quantum link none of whose
intermediary nodes need to be trusted, or, in our terminology, a trust-free QKD
link. As the main figure of merit, we calculate the secret key generation rate
when a particular probabilistic quantum repeater protocol is in use. We assume
the users are equipped with imperfect single photon sources, which can possibly
emit two single photons, or laser sources to implement decoy-state techniques.
We consider apparatus imperfection, such as quantum efficiency and dark count
of photodetectors, path loss of the channel, and writing and reading
efficiencies of quantum memories. By optimizing different system parameters, we
estimate the maximum distance over which users can share secret keys when a
finite number of memories are employed in the repeater setup.",1407.8025v3,quant-ph,2014-07-30 12:51:24+00:00,"[arxiv.Result.Author('Nicoló Lo Piparo'), arxiv.Result.Author('Mohsen Razavi')]","IEEE Journal of Selected Topics in Quantum Electronics 21:6601010,
  May/June 2015"
1064,"""iCub, We Forgive You!"" Investigating Trust in a Game Scenario with Kids","This study presents novel strategies to investigate the mutual influence of
trust and group dynamics in children-robot interaction. We implemented a
game-like experimental activity with the humanoid robot iCub and designed a
questionnaire to assess how the children perceived the interaction. We also aim
to verify if the sensors, setups, and tasks are suitable for studying such
aspects. The questionnaires' results demonstrate that youths perceive iCub as a
friend and, typically, in a positive way. Other preliminary results suggest
that, generally, children trusted iCub during the activity and, after its
mistakes, they tried to reassure it with sentences such as: ""Don't worry iCub,
we forgive you"". Furthermore, trust towards the robot in group cognitive
activity appears to change according to gender: after two consecutive mistakes
by the robot, girls tended to trust iCub more than boys. Finally, no
significant difference has been evidenced between different age groups across
points computed from the game and the self-reported scales. The tool we
proposed is suitable for studying trust in human-robot interaction (HRI) across
different ages and seems appropriate to understand the mechanism of trust in
group interactions.",2209.01694v1,cs.RO,2022-09-04 21:05:28+00:00,"[arxiv.Result.Author('Francesca Cocchella'), arxiv.Result.Author('Giulia Pusceddu'), arxiv.Result.Author('Giulia Belgiovine'), arxiv.Result.Author('Linda Lastrico'), arxiv.Result.Author('Francesco Rea'), arxiv.Result.Author('Alessandra Sciutti')]",
1065,Semi-Device-Independent Random Number Generation with Flexible Assumptions,"Our ability to trust that a random number is truly random is essential for
fields as diverse as cryptography and fundamental tests of quantum mechanics.
Existing solutions both come with drawbacks -- device-independent quantum
random number generators (QRNGs) are highly impractical and standard
semi-device-independent QRNGs are limited to a specific physical implementation
and level of trust. Here we propose a new framework for semi-device-independent
randomness certification, using a source of trusted vacuum in the form of a
signal shutter. It employs a flexible set of assumptions and levels of trust,
allowing it to be applied in a wide range of physical scenarios involving both
quantum and classical entropy sources. We experimentally demonstrate our
protocol with a photonic setup and generate secure random bits under three
different assumptions with varying degrees of security and resulting data
rates.",2002.12295v2,quant-ph,2020-02-27 18:05:17+00:00,"[arxiv.Result.Author('Matej Pivoluska'), arxiv.Result.Author('Martin Plesch'), arxiv.Result.Author('Máté Farkas'), arxiv.Result.Author('Natália Ružičková'), arxiv.Result.Author('Clara Flegel'), arxiv.Result.Author('Natalia Herrera Valencia'), arxiv.Result.Author('Will McCutcheon'), arxiv.Result.Author('Mehul Malik'), arxiv.Result.Author('Edgar A. Aguilar')]","npj Quantum Information volume 7, Article number: 50 (2021)"
1066,Publicly Auditable MPC-as-a-Service with succinct verification and universal setup,"In recent years, multiparty computation as a service (MPCaaS) has gained
popularity as a way to build distributed privacy-preserving systems. We argue
that for many such applications, we should also require that the MPC protocol
is publicly auditable, meaning that anyone can check the given computation is
carried out correctly -- even if the server nodes carrying out the computation
are all corrupt. In a nutshell, the way to make an MPC protocol auditable is to
combine an underlying MPC protocol with verifiable computing proof (in
particular, a SNARK). Building a general-purpose MPCaaS from existing
constructions would require us to perform a costly ""trusted setup"" every time
we wish to run a new or modified application. To address this, we provide the
first efficient construction for auditable MPC that has a one-time universal
setup. Despite improving the trusted setup, we match the state-of-the-art in
asymptotic performance: the server nodes incur a linear computation overhead
and constant round communication overhead compared to the underlying MPC, and
the audit size and verification are logarithmic in the application circuit
size. We also provide an implementation and benchmarks that support our
asymptotic analysis in example applications. Furthermore, compared with
existing auditable MPC protocols, besides offering a universal setup our
construction also has a 3x smaller proof, 3x faster verification time and
comparable prover time.",2107.04248v1,cs.CR,2021-07-09 06:43:35+00:00,"[arxiv.Result.Author('Sanket Kanjalkar'), arxiv.Result.Author('Ye Zhang'), arxiv.Result.Author('Shreyas Gandlur'), arxiv.Result.Author('Andrew Miller')]",
1067,Multi-terminal Secrecy in a Linear Non-coherent Packetized Networks,"We consider a group of m+1 trusted nodes that aim to create a shared secret
key K over a network in the presence of a passive eavesdropper, Eve. We assume
a linear non-coherent network coding broadcast channel (over a finite field
F_q) from one of the honest nodes (i.e., Alice) to the rest of them including
Eve. All of the trusted nodes can also discuss over a cost-free public channel
which is also overheard by Eve.
  For this setup, we propose upper and lower bounds for the secret key
generation capacity assuming that the field size q is very large. For the case
of two trusted terminals (m = 1) our upper and lower bounds match and we have
complete characterization for the secrecy capacity in the large field size
regime.",1206.3133v1,cs.IT,2012-06-14 15:15:32+00:00,"[arxiv.Result.Author('Mahdi Jafari Siavoshani'), arxiv.Result.Author('Christina Fragouli')]",
1068,Blockchain-based Smart-IoT Trust Zone Measurement Architecture,"With a rapid growth in the IT industry, Internet of Things (IoT) has gained a
tremendous attention and become a central aspect of our environment. In IoT the
things (devices) communicate and exchange the data without the act of human
intervention. Such autonomy and proliferation of IoT ecosystem make the devices
more vulnerable to attacks. In this paper, we propose a behavior monitor in
IoT-Blockchain setup which can provide trust-confidence to outside networks.
Behavior monitor extracts the activity of each device and analyzes the behavior
using deep auto-encoders. In addition, we also incorporate Trusted Execution
Technology (Intel SGX) in order to provide a secure execution environment for
applications and data on blockchain. Finally, in evaluation we analyze three
IoT devices data that is infected by mirai attack. The evaluation results
demonstrate the ability of our proposed method in terms of accuracy and time
required for detection.",2001.03002v1,cs.CR,2020-01-08 03:41:27+00:00,"[arxiv.Result.Author('Jawad Ali'), arxiv.Result.Author('Toqeer Ali'), arxiv.Result.Author('Yazed Alsaawy'), arxiv.Result.Author('Ahmad Shahrafidz Khalid'), arxiv.Result.Author('Shahrulniza Musa')]","International Conference on Omni-Layer Intelligent Systems, COINS
  May 2019, Pages 152-157"
1069,The role of successful human-robot interaction on trust -- Findings of an experiment with an autonomous cooperative robot,"The foundation of this paper is an experiment of fifteen participants
interacting directly with an autonomous robot. The task for the participants
was to carry a table, in two different setups, together with a robot, which is
intended to support older people with heavy lifting tasks. By collecting and
analyzing observational, quantitative, and qualitative data the interaction was
investigated with a specific emphasis on trust in the robot. The overall aim
was a better understanding of people's emotional and evaluative reactions when
they engage with a functioning robot in a relatable everyday scenario. This
study shows that successful cooperative task completion has a positive effect
on trust and other related evaluations, like the perceived adaptiveness
regarding the robot's behavior.",2104.06863v1,cs.RO,2021-04-14 13:55:01+00:00,"[arxiv.Result.Author('Nadine Bender'), arxiv.Result.Author('Samir El Faramawy'), arxiv.Result.Author('Johannes Maria Kraus'), arxiv.Result.Author('Martin Baumann')]",
1070,WELES: Policy-driven Runtime Integrity Enforcement of Virtual Machines,"Trust is of paramount concern for tenants to deploy their security-sensitive
services in the cloud. The integrity of VMs in which these services are
deployed needs to be ensured even in the presence of powerful adversaries with
administrative access to the cloud. Traditional approaches for solving this
challenge leverage trusted computing techniques, e.g., vTPM, or hardware CPU
extensions, e.g., AMD SEV. But, they are vulnerable to powerful adversaries, or
they provide only load time (not runtime) integrity measurements of VMs.
  We propose WELES, a protocol allowing tenants to establish and maintain trust
in VM runtime integrity of software and its configuration. WELES is transparent
to the VM configuration and setup. It performs an implicit attestation of VMs
during a secure login and binds the VM integrity state with the secure
connection. Our prototype's evaluation shows that WELES is practical and incurs
low performance overhead.",2104.14862v1,cs.CR,2021-04-30 09:37:14+00:00,"[arxiv.Result.Author('Wojciech Ozga'), arxiv.Result.Author('Do Le Quoc'), arxiv.Result.Author('Christof Fetzer')]","Proceedings of 2021 IEEE International Conference on Cloud
  Computing (IEEE CLOUD'21)"
1071,THEMIS: Decentralized and Trustless Ad Platform with Reporting Integrity,"Online advertising fuels the (seemingly) free internet. However, although
users can access most websites free of charge, they need to pay a heavy cost on
their privacy and blindly trust third parties and intermediaries that absorb
great amounts of adrevenues and user data. This is one of the reasons users opt
out from advertising by resorting ad blockers thatin turn cost publishers
millions of dollars in lost adrevenues. Existing privacy-preserving advertising
approaches(e.g., Adnostic, Privad, Brave Ads) from both industry and academia
cannot guarantee the integrity of the performance analytics they provide to
advertisers, while they also rely on centralized management that users have to
trust without being able to audit. In this paper, we propose THEMIS, a novel
privacy-by-design ad platform that is decentralized and requires zero trust
from users. THEMIS (i) provides auditability to all participants, (ii) rewards
users for viewing ads, and (iii) allows advertisers to verify the performance
and billing reports of their ad campaigns. To demonstrate the feasibility and
practicability of our approach, we implemented a prototype of THEMIS using a
combination of smart contracts and zero-knowledge schemes. Performance
evaluation results show that during adreward payouts, THEMIS can support more
than 51M users on a single-sidechain setup or 153M users ona multi-sidechain
setup, thus proving that THEMIS scales linearly.",2007.05556v2,cs.CR,2020-07-10 18:24:19+00:00,"[arxiv.Result.Author('Gonçalo Pestana'), arxiv.Result.Author('Iñigo Querejeta-Azurmendi'), arxiv.Result.Author('Panagiotis Papadopoulos'), arxiv.Result.Author('Benjamin Livshits')]",
1072,(Universal) Unconditional Verifiability in E-Voting without Trusted Parties,"In traditional e-voting protocols, privacy is often provided by a trusted
authority that learns the votes and computes the tally. Some protocols replace
the trusted authority by a set of authorities, and privacy is guaranteed if
less than a threshold number of authorities are corrupt. For verifiability,
stronger security guarantees are demanded. Typically, corrupt authorities that
try to fake the result of the tally must always be detected.
  To provide verifiability, many e-voting protocols use Non-Interactive
Zero-Knowledge proofs (NIZKs). Thanks to their non-interactive nature, NIZKs
allow anybody, including third parties that do not participate in the protocol,
to verify the correctness of the tally. Therefore, NIZKs can be used to obtain
universal verifiability. Additionally, NIZKs also improve usability because
they allow voters to cast a vote using a non-interactive protocol.
  The disadvantage of NIZKs is that their security is based on setup
assumptions such as the common reference string (CRS) or the random oracle (RO)
model. The former requires a trusted party for the generation of a common
reference string. The latter, though a popular methodology for designing secure
protocols, has been shown to be unsound.
  In this paper, we address the design of an e-voting protocol that provides
verifiability without any trust assumptions, where verifiability here is meant
without eligibility verification. We show that Non-Interactive
Witness-Indistinguishable proofs (NIWI) can be used for this purpose. The
e-voting scheme is private under the Decision Linear assumption, while
verifiability holds unconditionally. To our knowledge, this is the first
private e-voting scheme with perfect universal verifiability, i.e. one in which
the probability of a fake tally not being detected is 0, and with {\em
non-interactive} protocols that does not rely on trust assumptions.",1610.06343v1,cs.CR,2016-10-20 09:57:12+00:00,"[arxiv.Result.Author('Gina Gallegos-Garcia'), arxiv.Result.Author('Vincenzo Iovino'), arxiv.Result.Author('Alfredo Rial'), arxiv.Result.Author('Peter B. Roenne'), arxiv.Result.Author('Peter Y. A. Ryan')]",
1073,Moral-Trust Violation vs Performance-Trust Violation by a Robot: Which Hurts More?,"In recent years a modern conceptualization of trust in human-robot
interaction (HRI) was introduced by Ullman et al.\cite{ullman2018does}. This
new conceptualization of trust suggested that trust between humans and robots
is multidimensional, incorporating both performance aspects (i.e., similar to
the trust in human-automation interaction) and moral aspects (i.e., similar to
the trust in human-human interaction). But how does a robot violating each of
these different aspects of trust affect human trust in a robot? How does trust
in robots change when a robot commits a moral-trust violation compared to a
performance-trust violation? And whether physiological signals have the
potential to be used for assessing gain/loss of each of these two trust aspects
in a human. We aim to design an experiment to study the effects of
performance-trust violation and moral-trust violation separately in a search
and rescue task. We want to see whether two failures of a robot with equal
magnitudes would affect human trust differently if one failure is due to a
performance-trust violation and the other is a moral-trust violation.",2110.04418v1,cs.RO,2021-10-09 00:32:18+00:00,"[arxiv.Result.Author('Zahra Rezaei Khavas'), arxiv.Result.Author('Russell Perkins'), arxiv.Result.Author('S. Reza Ahmadzadeh'), arxiv.Result.Author('Paul Robinette')]",
1074,THEMIS: A Decentralized Privacy-Preserving Ad Platform with Reporting Integrity,"Online advertising fuels the (seemingly) free internet. However, although
users can access most of the web services free of charge, they pay a heavy
coston their privacy. They are forced to trust third parties and
intermediaries, who not only collect behavioral data but also absorb great
amounts of ad revenues. Consequently, more and more users opt out from
advertising by resorting to ad blockers, thus costing publishers millions of
dollars in lost ad revenues. Albeit there are various privacy-preserving
advertising proposals (e.g.,Adnostic, Privad, Brave Ads) from both academia and
industry, they all rely on centralized management that users have to blindly
trust without being able to audit, while they also fail to guarantee the
integrity of the per-formance analytics they provide to advertisers.
  In this paper, we design and deploy THEMIS, a novel, decentralized and
privacy-by-design ad platform that requires zero trust by users. THEMIS (i)
provides auditability to its participants, (ii) rewards users for viewing ads,
and (iii) allows advertisers to verify the performance and billing reports of
their ad campaigns. By leveraging smart contracts and zero-knowledge schemes,
we implement a prototype of THEMIS and early performance evaluation results
show that it can scale linearly on a multi sidechain setup while it supports
more than 51M users on a single-sidechain.",2106.01940v1,cs.CR,2021-06-03 15:44:31+00:00,"[arxiv.Result.Author('Gonçalo Pestana'), arxiv.Result.Author('Iñigo Querejeta-Azurmendi'), arxiv.Result.Author('Panagiotis Papadopoulos'), arxiv.Result.Author('Benjamin Livshits')]",
1075,Trust Enhancement Issues in Program Repair,"Automated program repair is an emerging technology that seeks to
automatically rectify bugs and vulnerabilities using learning, search, and
semantic analysis. Trust in automatically generated patches is necessary for
achieving greater adoption of program repair. Towards this goal, we survey more
than 100 software practitioners to understand the artifacts and setups needed
to enhance trust in automatically generated patches. Based on the feedback from
the survey on developer preferences, we quantitatively evaluate existing
test-suite based program repair tools. We find that they cannot produce
high-quality patches within a top-10 ranking and an acceptable time period of 1
hour. The developer feedback from our qualitative study and the observations
from our quantitative examination of existing repair tools point to actionable
insights to drive program repair research. Specifically, we note that producing
repairs within an acceptable time-bound is very much dependent on leveraging an
abstract search space representation of a rich enough search space. Moreover,
while additional developer inputs are valuable for generating or ranking
patches, developers do not seem to be interested in a significant
human-in-the-loop interaction.",2108.13064v4,cs.SE,2021-08-30 08:53:22+00:00,"[arxiv.Result.Author('Yannic Noller'), arxiv.Result.Author('Ridwan Shariffdeen'), arxiv.Result.Author('Xiang Gao'), arxiv.Result.Author('Abhik Roychoudhury')]",
1076,Network Shuffling: Privacy Amplification via Random Walks,"Recently, it is shown that shuffling can amplify the central differential
privacy guarantees of data randomized with local differential privacy. Within
this setup, a centralized, trusted shuffler is responsible for shuffling by
keeping the identities of data anonymous, which subsequently leads to stronger
privacy guarantees for systems. However, introducing a centralized entity to
the originally local privacy model loses some appeals of not having any
centralized entity as in local differential privacy. Moreover, implementing a
shuffler in a reliable way is not trivial due to known security issues and/or
requirements of advanced hardware or secure computation technology.
  Motivated by these practical considerations, we rethink the shuffle model to
relax the assumption of requiring a centralized, trusted shuffler. We introduce
network shuffling, a decentralized mechanism where users exchange data in a
random-walk fashion on a network/graph, as an alternative of achieving privacy
amplification via anonymity. We analyze the threat model under such a setting,
and propose distributed protocols of network shuffling that is straightforward
to implement in practice. Furthermore, we show that the privacy amplification
rate is similar to other privacy amplification techniques such as uniform
shuffling. To our best knowledge, among the recently studied intermediate trust
models that leverage privacy amplification techniques, our work is the first
that is not relying on any centralized entity to achieve privacy amplification.",2204.03919v1,cs.CR,2022-04-08 08:36:06+00:00,"[arxiv.Result.Author('Seng Pei Liew'), arxiv.Result.Author('Tsubasa Takahashi'), arxiv.Result.Author('Shun Takagi'), arxiv.Result.Author('Fumiyuki Kato'), arxiv.Result.Author('Yang Cao'), arxiv.Result.Author('Masatoshi Yoshikawa')]",
1077,How much can we trust high-resolution spectroscopic stellar chemical abundances?,"To study stellar populations, it is common to combine chemical abundances
from different spectroscopic surveys/studies where different setups were used.
These inhomogeneities can lead us to inaccurate scientific conclusions. In this
work, we studied one aspect of the problem: When deriving chemical abundances
from high-resolution stellar spectra, what differences originate from the use
of different radiative transfer codes?",1609.09071v1,astro-ph.SR,2016-09-28 20:00:01+00:00,"[arxiv.Result.Author('S. Blanco-Cuaresma'), arxiv.Result.Author('T. Nordlander'), arxiv.Result.Author('U. Heiter'), arxiv.Result.Author('P. Jofré'), arxiv.Result.Author('T. Masseron'), arxiv.Result.Author('L. Casamiquela'), arxiv.Result.Author('H. M. Tabernero'), arxiv.Result.Author('S. S. Bhat'), arxiv.Result.Author('A. R. Casey'), arxiv.Result.Author('J. Meléndez'), arxiv.Result.Author('I. Ramírez')]",
1078,Optical scheme for cryptographic commitments with physical unclonable keys,"We investigate the possibility of using multiple-scattering optical media, as
resources of randomness in cryptographic tasks pertaining to commitments and
auctions. The proposed commitment protocol exploits standard wavefront-shaping
and heterodyne-detection techniques, and can be implemented with current
technology. Its security is discussed in the framework of a tamper-resistant
trusted setup.",1909.13094v1,quant-ph,2019-09-28 13:31:39+00:00,[arxiv.Result.Author('Georgios M. Nikolopoulos')],"Optics Express Vol. 27, 29367-29379 (2019)"
1079,Multiple-Access Quantum Key Distribution Networks,"This paper addresses multi-user quantum key distribution networks, in which
any two users can mutually exchange a secret key without trusting any other
nodes. The same network also supports conventional classical communications by
assigning two different wavelength bands to quantum and classical signals. Time
and code division multiple access (CDMA) techniques, within a passive star
network, are considered. In the case of CDMA, it turns out that the optimal
performance is achieved at a unity code weight. A listen-before-send protocol
is then proposed to improve secret key generation rates in this case. Finally,
a hybrid setup with wavelength routers and passive optical networks, which can
support a large number of users, is considered and analyzed.",1112.3218v1,quant-ph,2011-12-14 14:03:34+00:00,[arxiv.Result.Author('Mohsen Razavi')],"IEEE Trans Commun 60, 3071 (2012)"
1080,"Relativity, Anomalies and Objectivity Loophole in Recent Tests of Local Realism","Local realism is in conflict with special quantum Bell-type models. Recently,
several experiments have demonstrated violation of local realism if we trust
their setup assuming special relativity valid. In this paper we question the
assumption of relativity, point out not commented anomalies and show that the
experiments have not closed objectivity loophole because clonability of the
result has not been demonstrated. We propose several improvements in further
experimental tests of local realism make the violation more convincing.",1709.03348v2,quant-ph,2017-09-11 12:08:02+00:00,[arxiv.Result.Author('Adam Bednorz')],"Open Physics 15, 692 (2017)"
1081,Semi-device-independent quantum key distribution based on a coherence equality,"We introduce the first example of a semi-device-independent quantum key
distribution (SDI-QKD) protocol with a classical Alice and Bob. The protocol is
based on the Coherence Equality (CE) game recently introduced by del Santo and
Daki\'c, which verifies a coherent quantum superposition of communication
trajectories in a de-localized way. We show the protocol to be
semi-device-independent since the only trusted operations occur in the users'
labs, and establish security against an adversary with bounded quantum memory.
Finally, we recast the setup of the protocol as a counterfactual test of
nonlocality, and provide additional insight into the CE game.",2103.06829v2,quant-ph,2021-03-11 17:55:34+00:00,"[arxiv.Result.Author('Mário Silva'), arxiv.Result.Author('Ricardo Faleiro'), arxiv.Result.Author('Paulo Mateus')]",
1082,On the Security of Trustee-based Social Authentications,"Recently, authenticating users with the help of their friends (i.e.,
trustee-based social authentication) has been shown to be a promising backup
authentication mechanism. A user in this system is associated with a few
trustees that were selected from the user's friends. When the user wants to
regain access to the account, the service provider sends different verification
codes to the user's trustees. The user must obtain at least k (i.e., recovery
threshold) verification codes from the trustees before being directed to reset
his or her password.
  In this paper, we provide the first systematic study about the security of
trustee-based social authentications. Specifically, we first introduce a novel
framework of attacks, which we call forest fire attacks. In these attacks, an
attacker initially obtains a small number of compromised users, and then the
attacker iteratively attacks the rest of users by exploiting trustee-based
social authentications. Then, we construct a probabilistic model to formalize
the threats of forest fire attacks and their costs for attackers. Moreover, we
introduce various defense strategies. Finally, we apply our framework to
extensively evaluate various concrete attack and defense strategies using three
real-world social network datasets. Our results have strong implications for
the design of more secure trustee-based social authentications.",1402.2699v4,cs.CR,2014-02-12 00:10:59+00:00,"[arxiv.Result.Author('Neil Zhenqiang Gong'), arxiv.Result.Author('Di Wang')]",
1083,Evolution of trust in a hierarchical population with punishing investors,"Trust plays an essential role in the development of human society. According
to the standard trust game, an investor decides whether to keep or transfer a
certain portion of initial stake to a trustee. In the latter case, the stake is
enhanced to signal the value of trust. The trustee then chooses how much to
return to the investor. We here distinguish two types of investors and two
types of trustees who can learn from each other. While a trustee can be
trustworthy or untrustworthy, an investor could be normal or punishing one. The
latter strategy punishes both untrustworthy trustees and normal investors who
are reluctant to control misbehaving trustees. Importantly, we assume a
hierarchical population where the portion of investors and trustees is fixed.
By means of replicator equation approach, we study the $N$-player trust game
and calculate the level of trust and trustworthiness. We find that the
introduction of punishment can induce a stable coexistence state between
punishing investors and trustworthy trustees. Furthermore, an intermediate
fraction of investors can better promote the evolution of trust when the
punishment intensity is low. For more intensive punishment, however, a higher
fraction of investors can be more efficient to elevate the trust level. In
addition, we reveal that appropriate increase of the punishment intensity can
enlarge the attraction domain of the coexistence state.",2209.05179v1,cs.GT,2022-09-12 12:12:06+00:00,"[arxiv.Result.Author('Ketian Sun'), arxiv.Result.Author('Yang Liu'), arxiv.Result.Author('Xiaojie Chen'), arxiv.Result.Author('Attila Szolnoki')]","Chaos, Solitons & Fractals 162 (2022) 112413"
1084,A Probabilistic Graph Model for Trust Opinion Estimation in Online Social Networks,"Trust assessment plays a key role in many online applications, such as online
money lending, product reviewing and active friending. Trust models usually
employ a group of parameters to represent the trust relation between a
trustor-trustee pair. These parameters are originated from the trustor's bias
and opinion on the trustee. Naturally, these parameters can be regarded as a
vector. To address this problem, we propose a framework to accurately convert
the single values to the parameters needed by 3VSL. The framework firstly
employs a probabilistic graph model (PGM) to derive the trustor's opinion and
bias to his rating on the trustee.",1909.10055v1,cs.SI,2019-09-22 18:00:55+00:00,"[arxiv.Result.Author('Luke Liu'), arxiv.Result.Author('Qing Yang')]",
1085,A Value-based Trust Assessment Model for Multi-agent Systems,"An agent's assessment of its trust in another agent is commonly taken to be a
measure of the reliability/predictability of the latter's actions. It is based
on the trustor's past observations of the behaviour of the trustee and requires
no knowledge of the inner-workings of the trustee. However, in situations that
are new or unfamiliar, past observations are of little help in assessing trust.
In such cases, knowledge about the trustee can help. A particular type of
knowledge is that of values - things that are important to the trustor and the
trustee. In this paper, based on the premise that the more values two agents
share, the more they should trust one another, we propose a simple approach to
trust assessment between agents based on values, taking into account if agents
trust cautiously or boldly, and if they depend on others in carrying out a
task.",1905.13380v1,cs.AI,2019-05-31 02:08:20+00:00,"[arxiv.Result.Author('Kinzang Chhogyal'), arxiv.Result.Author('Abhaya Nayak'), arxiv.Result.Author('Aditya Ghose'), arxiv.Result.Author('Hoa Khanh Dam')]",
1086,Trustee: Full Privacy Preserving Vickrey Auction on top of Ethereum,"The wide deployment of tokens for digital assets on top of Ethereum implies
the need for powerful trading platforms. Vickrey auctions have been known to
determine the real market price of items as bidders are motivated to submit
their own monetary valuations without leaking their information to the
competitors. Recent constructions have utilized various cryptographic protocols
such as ZKP and MPC, however, these approaches either are partially
privacy-preserving or require complex computations with several rounds. In this
paper, we overcome these limits by presenting Trustee as a Vickrey auction on
Ethereum which fully preserves bids' privacy at relatively much lower fees.
Trustee consists of three components: a front-end smart contract deployed on
Ethereum, an Intel SGX enclave, and a relay to redirect messages between them.
Initially, the enclave generates an Ethereum account and ECDH key-pair.
Subsequently, the relay publishes the account's address and ECDH public key on
the smart contract. As a prerequisite, bidders are encouraged to verify the
authenticity and security of Trustee by using the SGX remote attestation
service. To participate in the auction, bidders utilize the ECDH public key to
encrypt their bids and submit them to the smart contract. Once the bidding
interval is closed, the relay retrieves the encrypted bids and feeds them to
the enclave that autonomously generates a signed transaction indicating the
auction winner. Finally, the relay submits the transaction to the smart
contract which verifies the transaction's authenticity and the parameters'
consistency before accepting the claimed auction winner. As part of our
contributions, we have made a prototype for Trustee available on Github for the
community to review and inspect it. Additionally, we analyze the security
features of Trustee and report on the transactions' gas cost incurred on
Trustee smart contract.",1905.06280v1,cs.CR,2019-05-15 16:28:54+00:00,"[arxiv.Result.Author('Hisham S. Galal'), arxiv.Result.Author('Amr M. Youssef')]",
1087,Realize General Access Structure Based On Single Share,"Traditional threshold secret sharing cannot realizing all access structures
of secret sharing. So, Ito introduced the concept of Secret sharing scheme
realizing general access structure. But Its scheme has to send multiple shares
to each trustee. In this paper, we proposed two new secret sharing schemes
realizing general access structures by only assigning one share to each
trustee. Our proposed second scheme is a perfect secret sharing scheme.
Furthermore, our schemes can realize any access structures.",1905.02004v3,cs.CR,2019-05-06 12:54:10+00:00,"[arxiv.Result.Author('Yang Xie'), arxiv.Result.Author('Sijjad Ali Khuhro'), arxiv.Result.Author('Fuyou Miao'), arxiv.Result.Author('Keju Meng')]",
1088,A Unified Bi-directional Model for Natural and Artificial Trust in Human-Robot Collaboration,"We introduce a novel capabilities-based bi-directional multi-task trust model
that can be used for trust prediction from either a human or a robotic trustor
agent. Tasks are represented in terms of their capability requirements, while
trustee agents are characterized by their individual capabilities. Trustee
agents' capabilities are not deterministic; they are represented by belief
distributions. For each task to be executed, a higher level of trust is
assigned to trustee agents who have demonstrated that their capabilities exceed
the task's requirements. We report results of an online experiment with 284
participants, revealing that our model outperforms existing models for
multi-task trust prediction from a human trustor. We also present simulations
of the model for determining trust from a robotic trustor. Our model is useful
for control authority allocation applications that involve human-robot teams.",2106.02194v1,cs.RO,2021-06-04 00:52:27+00:00,"[arxiv.Result.Author('Hebert Azevedo-Sa'), arxiv.Result.Author('X. Jessie Yang'), arxiv.Result.Author('Lionel P. Robert Jr.'), arxiv.Result.Author('Dawn M. Tilbury')]",
1089,Building Robust Crowdsourcing Systems with Reputation-aware Decision Support Techniques,"Crowdsourcing refers to the arrangement in which contributions are solicited
from a large group of unrelated people. Due to this nature, crowdsourcers (or
task requesters) often face uncertainty about the workers' capabilities which,
in turn, affects the quality and timeliness of the results obtained. Trust is a
mechanism used by people to facilitate interactions in human societies where
risk and uncertain are common. The crucial challenge to building a robust
crowdsourcing system is how to make trust-aware task delegation decisions to
efficiently utilize the capacities of workers (or trustee agents) to achieve
high social welfare?
  This book presents the research addressing this challenge. It goes beyond the
existing trust management research framework by removing a widespread
assumption implicitly adopted by existing research: that a trustee agent can
process an unlimited number of interaction requests per discrete time unit
without compromising its performance as perceived by the task requesters (or
truster agents). Decision support in crowdsourcing is re-formalized as a
multi-agent trust game based on the principles of the Congestion Game, which is
solved by two trust-aware interaction decision-making approaches: 1) the Social
Welfare Optimizing approach for Reputation-aware Decision-making (SWORD)
approach, and 2) the Distributed Request Acceptance approach for Fair
utilization of Trustee agents (DRAFT). SWORD is designed for centralized
systems, while DRAFT is designed for fully distributed systems. Theoretical
analyses have shown that the social welfare produced by these two approaches
can be made closer to optimal by adjusting only one key parameter. With these
two approaches, the framework of research for crowdsourcing systems can be
enriched to handle more realistic scenarios where workers have varied and
limited capabilities.",1502.02106v2,cs.MA,2015-02-07 07:23:38+00:00,[arxiv.Result.Author('Han Yu')],
1090,Decentralized Privacy-preserving Timed Execution in Blockchain-based Smart Contract Platforms,"In the age of Big Data, enabling task scheduling while protecting users'
privacy is critical for various decentralized applications in blockchain-based
smart contract platforms. Such a privacy-preserving task scheduler requires the
task input data to be secretly maintained until a prescribed task execution
time and be automatically recorded into the blockchain to enabling the
execution of the task at the execution time, even if the user goes offline.
While straight-forward centralized approaches provide a basic solution to the
problem, unfortunately they are limited to a single point of trust and involve
a single point of control. This paper presents decentralized techniques for
supporting privacy-preserving task scheduling using smart contracts in Ethereum
blockchain networks. We design a privacy-preserving task scheduling protocol
that is managed by a manager smart contract. The protocol requires a user to
schedule a task by deploying a proxy smart contract maintaining the
non-sensitive information of the task while creating decentralized secret trust
and selecting trustees from the network to maintain the sensitive information
of the task. With security techniques including secret sharing and layered
encryption as well as security deposit paid by trustees as economic deterrence,
the protocol can protect the sensitive information against possible attacks
including some trustees destroying the sensitive information (drop attack) or
secretly releasing the sensitive information before the execution time
(release-ahead attack). We demonstrate the attack-resilience of the proposed
protocol through rigorous analysis.Our implementation and experimental
evaluation on the Ethereum official test network demonstrate the low monetary
cost and the low time overhead associated with the proposed approach.",1902.05613v1,cs.CR,2019-02-14 21:44:22+00:00,"[arxiv.Result.Author('Chao Li'), arxiv.Result.Author('Balaji Palanisamy')]",
1091,Conditional investment strategy in evolutionary trust games with repeated group interactions,"It has a long tradition to study trust behavior among humans or artificial
agents by investigating the trust game. Although previous studies based on
evolutionary game theory have revealed that trust and trustworthiness can be
promoted if network structure or reputation is considered, they often assume
that interactions among agents are one-shot and investors do not consider the
investment environment before making decisions, which collide with many
realistic situations. In this paper, we introduce the conditional investment
strategy into the repeated N-player trust game, in which conditional investors
decide to invest or not depending on their assessment of the trustworthiness
level of the group. By using the approach of the Markov decision process, we
study the evolutionary dynamics of trust in repeated group interactions with
the conditional investment strategy. We find that conditional investors can
form an effective alliance with trustworthy trustees, hence they can sweep out
untrustworthy trustees. Moreover, we verify that such alliance can exist in a
wide range of model parameters. These results may explain why trusting in
others and reciprocating them with trustworthy actions can be sustained in game
interactions among intelligent agents.",2208.12953v1,math.DS,2022-08-27 07:46:10+00:00,"[arxiv.Result.Author('Linjie Liu'), arxiv.Result.Author('Xiaojie Chen')]",
1092,Clarifying Trust in Social Internet of Things,"A social approach can be exploited for the Internet of Things (IoT) to manage
a large number of connected objects. These objects operate as autonomous agents
to request and provide information and services to users. Establishing
trustworthy relationships among the objects greatly improves the effectiveness
of node interaction in the social IoT and helps nodes overcome perceptions of
uncertainty and risk. However, there are limitations in the existing trust
models. In this paper, a comprehensive model of trust is proposed that is
tailored to the social IoT. The model includes ingredients such as trustor,
trustee, goal, trustworthiness evaluation, decision, action, result, and
context. Building on this trust model, we clarify the concept of trust in the
social IoT in five aspects such as (1) mutuality of trustor and trustee, (2)
inferential transfer of trust, (3) transitivity of trust, (4) trustworthiness
update, and (5) trustworthiness affected by dynamic environment. With network
connectivities that are from real-world social networks, a series of
simulations are conducted to evaluate the performance of the social IoT
operated with the proposed trust model. An experimental IoT network is used to
further validate the proposed trust model.",1704.03554v1,cs.SI,2017-04-11 22:28:52+00:00,"[arxiv.Result.Author('Zhiting Lin'), arxiv.Result.Author('Liang Dong')]","IEEE Transactions on Knowledge and Data Engineering, vol. 30, no.
  2, pp. 234-248, Feb. 2018"
1093,A Correlative Denoising Autoencoder to Model Social Influence for Top-N Recommender System,"In recent years, there are numerous works been proposed to leverage the
techniques of deep learning to improve social-aware recommendation performance.
In most cases, it requires a larger number of data to train a robust deep
learning model, which contains a lot of parameters to fit training data.
However, both data of user ratings and social networks are facing critical
sparse problem, which makes it not easy to train a robust deep neural network
model. Towards this problem, we propose a novel Correlative Denoising
Autoencoder (CoDAE) method by taking correlations between users with multiple
roles into account to learn robust representations from sparse inputs of
ratings and social networks for recommendation. We develop the CoDAE model by
utilizing three separated autoencoders to learn user features with roles of
rater, truster and trustee, respectively. Especially, on account of that each
input unit of user vectors with roles of truster and trustee is corresponding
to a particular user, we propose to utilize shared parameters to learn common
information of the units that corresponding to same users. Moreover, we propose
a related regularization term to learn correlations between user features that
learnt by the three subnetworks of CoDAE model. We further conduct a series of
experiments to evaluate the proposed method on two public datasets for Top-N
recommendation task. The experimental results demonstrate that the proposed
model outperforms state-of-the-art algorithms on rank-sensitive metrics of MAP
and NDCG.",1703.01760v3,cs.IR,2017-03-06 08:35:58+00:00,"[arxiv.Result.Author('Yiteng Pan'), arxiv.Result.Author('Fazhi He'), arxiv.Result.Author('Haiping Yu')]",
1094,Effects of update rules on networked N-player trust game dynamics,"We investigate the effects of update rules on the dynamics of an evolutionary
game-theoretic model - the N-player evolutionary trust game - consisting of
three types of players: investors, trustworthy trustees, and untrustworthy
trustees. Interactions between players are limited to local neighborhoods
determined by predefined spatial or social network topologies. We compare
evolutionary update rules based on the payoffs obtained by their neighbors.
Specifically, we investigate the dynamics generated when players use a
deterministic strategic rule (i.e., unconditional imitation with and without
using a noise process induced by a voter model), a stochastic pairwise
payoff-based strategy (i.e., proportional imitation), and stochastic local
Moran processes. We explore the system dynamics under these update rules based
on different social networks and different levels of game difficulty. We
observe that there are significant differences on the promoted trust and global
net wealth depending on the update rule. If the game is harder, rules based on
unconditional imitation achieve the highest global net wealth in the
population. Besides a global perspective, we also study the spatial and
temporal dynamics induced by the rules and we find important spatio-temporal
correlations in the system for all rules. Indeed, the update rules lead to the
formation of fractal structures on a lattice and, when the rules are
stochastic, also the emergence of low frequencies in the output signal of the
system (i.e., long-term memory).",1712.06875v1,cs.GT,2017-12-19 11:42:59+00:00,"[arxiv.Result.Author('Manuel Chica'), arxiv.Result.Author('Raymond Chiong'), arxiv.Result.Author('Jose Ramasco'), arxiv.Result.Author('Hussein Abbass')]",
1095,Latent Markov modelling applied to grant peer review,"In the grant peer review process we can distinguish various evaluation stages
in which assessors judge applications on a rating scale. Research on this
process that considers its multi-stage character scarcely exists. In this study
we analyze 1954 applications for doctoral and post-doctoral fellowships of the
Boehringer Ingelheim Fonds (B.I.F.), assessed in three stages (first:
evaluation by an external reviewer; second: internal evaluation by a staff
member; third: final decision by the B.I.F. Board of Trustees). The results
show that an application only has a chance of approval if it was recommended
for support in the first evaluation stage. Therefore, a form of triage or
pre-screening seems desirable. We found differences in transition probabilities
from one stage to the other for doctoral applicants submitted by males and
females.",math/0604039v1,math.ST,2006-04-03 14:17:05+00:00,"[arxiv.Result.Author('Lutz Bornmann'), arxiv.Result.Author('Ruediger Mutz'), arxiv.Result.Author('Hans-Dieter Daniel')]",
1096,MaTrust: An Effective Multi-Aspect Trust Inference Model,"Trust is a fundamental concept in many real-world applications such as
e-commerce and peer-to-peer networks. In these applications, users can generate
local opinions about the counterparts based on direct experiences, and these
opinions can then be aggregated to build trust among unknown users. The
mechanism to build new trust relationships based on existing ones is referred
to as trust inference. State-of-the-art trust inference approaches employ the
transitivity property of trust by propagating trust along connected users. In
this paper, we propose a novel trust inference model (MaTrust) by exploring an
equally important property of trust, i.e., the multi-aspect property. MaTrust
directly characterizes multiple latent factors for each trustor and trustee
from the locally-generated trust relationships. Furthermore, it can naturally
incorporate prior knowledge as specified factors. These factors in turn serve
as the basis to infer the unseen trustworthiness scores. Experimental
evaluations on real data sets show that the proposed MaTrust significantly
outperforms several benchmark trust inference models in both effectiveness and
efficiency.",1211.2041v1,cs.DB,2012-11-09 04:46:47+00:00,"[arxiv.Result.Author('Yuan Yao'), arxiv.Result.Author('Hanghang Tong'), arxiv.Result.Author('Xifeng Yan'), arxiv.Result.Author('Feng Xu'), arxiv.Result.Author('Jian Lu')]",
1097,A practical multi-party computation algorithm for a secure distributed online voting system,"We present an online voting architecture based on partitioning the election
in small clusters of voters and using a new Multi-party Computation algorithm
for obtaining voting results from the clusters. This new algorithm has some
practical advantages over other previously known algorithms and isn't bound to
any specific cryptographic concept; so it can be adapted to future
cryptographic exigencies. Compared with other online voting technologies, we
see that this new architecture is less vulnerable to hacker attacks and attacks
from dishonest authorities, given that no sensitive information is stored in
any public server and there is no need for any trustee to safeguard the
legality of the election process. Even in case of an attack succeeding, the
risks associated with the overall election are far lower than with any other
voting system. This architecture can also be combined with any other voting
system, inheriting advantages from both systems.",1603.04228v1,cs.CR,2016-03-14 12:10:47+00:00,[arxiv.Result.Author('Juanjo Bermúdez')],
1098,The N-Player Trust Game and its Replicator Dynamics,"Trust is a fundamental concept that underpins the coherence and resilience of
social systems and shapes human behavior. Despite the importance of trust as a
social and psychological concept, the concept has not gained much attention
from evolutionary game theorists. In this paper, an N-player trust-based social
dilemma game is introduced. While the theory shows that a society with no
untrustworthy individuals would yield maximum wealth to both the society as a
whole and the individuals in the long run, evolutionary dynamics show this
ideal situation is reached only in a special case when the initial population
contains no untrustworthy individuals. When the initial population consists of
even the slightest number of untrustworthy individuals, the society converges
to zero trusters, with many untrustworthy individuals. The promotion of trust
is an uneasy task, despite the fact that a combination of trusters and
trustworthy trustees is the most rational and optimal social state. This paper
presents the game and results of replicator dynamics in a hope that researchers
in evolutionary games see opportunities in filling this critical gap in the
literature.",1803.02443v1,physics.soc-ph,2018-03-02 11:17:16+00:00,"[arxiv.Result.Author('Hussein Abbass'), arxiv.Result.Author('Garrison Greenwood'), arxiv.Result.Author('Eleni Petraki')]","Abbass, H., Greenwood, G., & Petraki, E. (2016). The N-Player
  Trust Game and its Replicator Dynamics. IEEE Transactions on Evolutionary
  Computation, 20(3), 470-474"
1099,Astro2020: Promoting Diversity and Inclusion in Astronomy Graduate Education: an Astro2020 APC White Paper by the AAS Taskforce on Diversity and Inclusion in Astronomy Graduate Education,"The purpose of this white paper is to provide guidance to funding agencies,
leaders in the discipline, and its constituent departments about strategies for
(1) improving access to advanced education for people from populations that
have long been underrepresented and (2) improving the climates of departments
where students enroll. The twin goals of improving access to increase diversity
and improving climate to enhance inclusiveness are mutually reinforcing, and
they are both predicated on a fundamental problem of inequality in
participation. This white paper has been endorsed by the Board of Trustees of
the AAS.",1907.06769v1,astro-ph.IM,2019-07-15 22:06:52+00:00,"[arxiv.Result.Author('Alexander Rudolph'), arxiv.Result.Author('Gibor Basri'), arxiv.Result.Author('Marcel Agüeros'), arxiv.Result.Author('Ed Bertschinger'), arxiv.Result.Author('Kim Coble'), arxiv.Result.Author('Megan Donahue'), arxiv.Result.Author('Jackie Monkiewicz'), arxiv.Result.Author('Angela Speck'), arxiv.Result.Author('Rachel Ivie'), arxiv.Result.Author('Christine Pfund'), arxiv.Result.Author('Julie Posselt')]",
1100,Stochastic modelling of blockchain consensus,"Blockchain and general purpose distributed ledgers are foundational
technologies which bring significant innovation in the infrastructures and
other underpinnings of our socio-economic systems. These P2P technologies are
able to securely diffuse information within and across networks, without need
for trustees or central authorities to enforce consensus. In this contribution,
we propose a minimalistic stochastic model to understand the dynamics of
blockchain-based consensus. By leveraging on random-walk theory, we model block
propagation delay on different network topologies and provide a classification
of blockchain systems in terms of two emergent properties. Firstly, we identify
two performing regimes: a functional regime corresponding to an optimal system
function; and a non-functional regime characterised by a congested or branched
state of sub-optimal blockchains. Secondly, we discover a phase transition
during the emergence of consensus and numerically investigate the corresponding
critical point. Our results provide important insights into the consensus
mechanism and sub-optimal states in decentralised systems.",2106.06465v1,cs.DC,2021-06-11 15:37:32+00:00,"[arxiv.Result.Author('Claudio J. Tessone'), arxiv.Result.Author('Paolo Tasca'), arxiv.Result.Author('Flavio Iannelli')]",
1101,An Owner-managed Indirect-Permission Social Authentication Method for Private Key Recovery,"In this paper, we propose a very secure and reliable owner-self-managed
private key recovery method. In recent years, Public Key Authentication (PKA)
method has been identified as the most feasible online security solution.
However, losing the private key also implies the risk of losing the ownership
of the assets associated with the private key. For key protection, the commonly
adopted something-you-x solutions require a new secret to protect the target
secret and fall into a circular protection issue as the new secret has to be
protected too. To resolve the circular protection issue and provide a truly
secure and reliable solution, we propose separating the permission and
possession of the private key. Then we create secret shares of the permission
using the open public keys of selected trustees while having the owner possess
the permission-encrypted private key. Then by applying the social
authentication method, one may easily retrieve the permission to recover the
private key. Our analysis shows that our proposed indirect-permission method is
six orders of magnitude more secure and reliable than",2209.09388v1,cs.CR,2022-09-19 23:58:43+00:00,"[arxiv.Result.Author('Wei-Hsin Chang'), arxiv.Result.Author('Ren-Song Tsay')]",
1102,It's a Wrap! Reviewing the 1997 Outdoor Season,"The 100m world rankings of the 1997 outdoor track and field competition
season are reviewed, subject to corrections for wind effects and atmospheric
drag. The rankings and times are compared with those of 1996, and the
improvements of each athlete over the course of a year are discussed.
Additionally, the athletes' wind-corrected 50m and 60m splits from the 1997
IAAF World Championships are compared to the 1997 indoor world rankings over
the same distances, as an attempt to predict possible performances for the
coming 1998 indoor season.",physics/9710003v1,physics.pop-ph,1997-10-03 21:10:41+00:00,[arxiv.Result.Author('J. R. Mureika')],"Athletics: Canada's National Track and Field / Running Magazine
  (November/December 1997)"
1103,The Atacama Cosmology Telescope Project: A Progress Report,"The Atacama Cosmology Telescope is a project to map the microwave background
radiation at arcminute angular resolution and high sensitivity in three
frequency bands over substantial sky areas. Cosmological signals driving such
an experiment are reviewed, and current progress in hardware construction is
summarized. Complementary astronomical observations in other wavebands are also
discussed.",astro-ph/0608549v1,astro-ph,2006-08-25 13:54:36+00:00,[arxiv.Result.Author('Arthur Kosowsky')],"New Astron.Rev.50:969-976,2006"
1104,Spread of COVID-19: Adult Detention Facilities in LA County,"We analyze the spread of COVID-19 cases within adult detention facilities in
Los Angeles (LA) county. Throughout the analysis we review the data to explore
the range of positive cases in each center and see the percentage of people who
were positive for COVID-19 against the amount of people who were tested.
Additionally, we see if there is any correlation between the surrounding
community of each detention center and the number of positive cases in each
center and explore the protocols in place at each detention center. We use the
cloud visualization tool SAP Analytics Cloud (SAC) with the data from the
California government website through adult detention facilities in LA County.
We found that (1) the number of confirmed cases at the facilities and the
surrounding communities are not related, (2) the data does not represent all
positive cases at the facility, and (3) there are not enough tests at the
facilities.",2204.12617v1,cs.DC,2022-04-26 22:27:01+00:00,"[arxiv.Result.Author('Maria Barriga Beltran'), arxiv.Result.Author('Wendy Cano'), arxiv.Result.Author('Apichaya Chumsai'), arxiv.Result.Author('Haik Koyosan'), arxiv.Result.Author('Debbie Lemus'), arxiv.Result.Author('Sandra Tenorio'), arxiv.Result.Author('Jongwook Woo')]",
1105,A Spallation Model for the Titanium-rich Supernova Remnant Cassiopeia A,"Titanium-rich subluminous supernovae are rare and challenge current SN
nucleosynthesis models. We present a model in which ejecta from a standard
Supernova is impacted by a second explosion of the neutron star (a Quark-nova),
resulting in spallation reactions that lead to 56Ni destruction and 44Ti
creation under the right conditions. Basic calculations of the spallation
products shows that a delay between the two explosions of ~ 5 days reproduces
the observed abundance of 44Ti in Cas A and explains its low luminosity as a
result of the destruction of 56Ni. Our results could have important
implications for lightcurves of subluminous as well as superluminous
supernovae.",1109.2124v1,astro-ph.HE,2011-09-09 20:09:45+00:00,"[arxiv.Result.Author('Rachid Ouyed'), arxiv.Result.Author('Denis Leahy'), arxiv.Result.Author('Amir Ouyed'), arxiv.Result.Author('Prashanth Jaikumar')]",
1106,Evolutionary Histories of Dwarf Galaxies in the Local Group,"The star formation histories of Local Group (LG) dwarf galaxies and more
distant potential LG members are reviewed. Problems in defining the spatial
extent of the LG and membership are briefly discussed. The morphological types
found in the LG are presented, and it is suggested that we see continuous
evolution from low-mass dwarf irregulars (dIrrs) to dwarf spheroidal galaxies
(dSph) in the LG.
  Star formation histories for LG dwarfs and nearby LG candidates are compiled
using population boxes. No two dwarfs, irrespective of morphological type, show
the same evolutionary history, and all vary widely in ages of their
subpopulations and in their enrichment history. The lack of gas in dSphs and
dEs may be explained by a new photoionization scenario. Old populations, often
spatially very extended, may be a common property of dwarf galaxies, though
their fractions can be very small. Almost all types of dwarf galaxies studied
in detail so far show spatial variations in ages and abundances such as radial
age/metallicity gradients. The observed star formation histories impose
constraints on merger and accretion scenarios.
  Properties of the Milky Way dSphs are compared to the M31 dSphs and discussed
in the framework of the ram pressure/tidal stripping scenario. It is
demonstrated that the newly discovered LG dwarfs follow the same relationship
for central surface brightness, mean metallicity, and absolute magnitude as the
other LG dwarfs. (Shortened)",astro-ph/9812443v1,astro-ph,1998-12-24 06:58:06+00:00,[arxiv.Result.Author('Eva K. Grebel')],"1999, ""The Stellar Content of the Local Group"", IAU Symp. 192,
  eds. P. Whitelock & R. Cannon (Provo: ASP), 17-38"
1107,Experimental implementation of an adiabatic quantum optimization algorithm,"We report the realization of a nuclear magnetic resonance computer with three
quantum bits that simulates an adiabatic quantum optimization algorithm.
Adiabatic quantum algorithms offer new insight into how quantum resources can
be used to solve hard problems. This experiment uses a particularly well suited
three quantum bit molecule and was made possible by introducing a technique
that encodes general instances of the given optimization problem into an easily
applicable Hamiltonian. Our results indicate an optimal run time of the
adiabatic algorithm that agrees well with the prediction of a simple
decoherence model.",quant-ph/0302057v2,quant-ph,2003-02-07 22:06:07+00:00,"[arxiv.Result.Author('Matthias Steffen'), arxiv.Result.Author('Wim van Dam'), arxiv.Result.Author('Tad Hogg'), arxiv.Result.Author('Greg Breyta'), arxiv.Result.Author('Isaac Chuang')]","Physical Review Letters, Volume 90, Number 6, Article 067903
  (2003)"
1108,"Review of Energy Transition Policies in Singapore, London, and California","The paper contains the online supplementary materials for ""Data-Driven
Prediction and Evaluation on Future Impact of Energy Transition Policies in
Smart Regions"". We review the renewable energy development and policies in the
three metropolitan cities/regions over recent decades. Depending on the
geographic variations in the types and quantities of renewable energy resources
and the levels of policymakers' commitment to carbon neutrality, we classify
Singapore, London, and California as case studies at the primary, intermediate,
and advanced stages of the renewable energy transition, respectively.",2208.01433v1,econ.GN,2022-08-02 13:10:10+00:00,"[arxiv.Result.Author('Chunmeng Yang'), arxiv.Result.Author('Siqi Bu'), arxiv.Result.Author('Yi Fan'), arxiv.Result.Author('Wayne Xinwei Wan'), arxiv.Result.Author('Ruoheng Wang'), arxiv.Result.Author('Aoife Foley')]",
1109,Disoriented Chiral Condensate,"The current theoretical understanding of disoriented chiral condensate is
briefly reviewed. I discuss the basic idea, the formation mechanism and
experimental signatures of DCC in high energy collisions.",hep-ph/9501366v1,hep-ph,1995-01-25 01:28:02+00:00,[arxiv.Result.Author('Zheng Huang')],
1110,Radiative Higgs-Sector CP Violation in the MSSM,"We briefly review the phenomenological implications of the minimal
supersymmetric standard model (MSSM) with explicit radiative breaking of CP
invariance in the Higgs sector for the LEP2 and Tevatron colliders.",hep-ph/0003232v1,hep-ph,2000-03-23 14:18:47+00:00,[arxiv.Result.Author('Apostolos Pilaftsis')],
1111,Progress in lattice QCD at finite temperature,"I review current status of lattice QCD calculations of the deconfining
transition at finite temperature and quarkonia spectral functions.",nucl-th/0606013v1,nucl-th,2006-06-09 16:20:37+00:00,[arxiv.Result.Author('Peter Petreczky')],
1112,Charmless three-body decays of b-hadrons,"A review of recent results from LHCb and the B-factories on the charmless
decays of b-hadrons into three-body final states is presented.",1310.0855v1,hep-ex,2013-10-02 21:58:05+00:00,[arxiv.Result.Author('Thomas Latham')],
1113,Interactive Data Integration through Smart Copy & Paste,"In many scenarios, such as emergency response or ad hoc collaboration, it is
critical to reduce the overhead in integrating data. Ideally, one could perform
the entire process interactively under one unified interface: defining
extractors and wrappers for sources, creating a mediated schema, and adding
schema mappings ? while seeing how these impact the integrated view of the
data, and refining the design accordingly.
  We propose a novel smart copy and paste (SCP) model and architecture for
seamlessly combining the design-time and run-time aspects of data integration,
and we describe an initial prototype, the CopyCat system. In CopyCat, the user
does not need special tools for the different stages of integration: instead,
the system watches as the user copies data from applications (including the Web
browser) and pastes them into CopyCat?s spreadsheet-like workspace. CopyCat
generalizes these actions and presents proposed auto-completions, each with an
explanation in the form of provenance. The user provides feedback on these
suggestions ? through either direct interactions or further copy-and-paste
operations ? and the system learns from this feedback. This paper provides an
overview of our prototype system, and identifies key research challenges in
achieving SCP in its full generality.",0909.1769v1,cs.DB,2009-09-09 18:09:41+00:00,"[arxiv.Result.Author('Zachary Ives'), arxiv.Result.Author('Craig Knoblock'), arxiv.Result.Author('Steve Minton'), arxiv.Result.Author('Marie Jacob'), arxiv.Result.Author('Partha Talukdar'), arxiv.Result.Author('Rattapoom Tuchinda'), arxiv.Result.Author('Jose Luis Ambite'), arxiv.Result.Author('Maria Muslea'), arxiv.Result.Author('Cenk Gazen')]",
1114,Astrometry with the Wide-Field InfraRed Space Telescope,"The Wide-Field InfraRed Space Telescope (WFIRST) will be capable of
delivering precise astrometry for faint sources over the enormous field of view
of its main camera, the Wide-Field Imager (WFI). This unprecedented combination
will be transformative for the many scientific questions that require precise
positions, distances, and velocities of stars. We describe the expectations for
the astrometric precision of the WFIRST WFI in different scenarios, illustrate
how a broad range of science cases will see significant advances with such
data, and identify aspects of WFIRST's design where small adjustments could
greatly improve its power as an astrometric instrument.",1712.05420v2,astro-ph.IM,2017-12-14 19:09:33+00:00,"[arxiv.Result.Author('Robyn E. Sanderson'), arxiv.Result.Author('Andrea Bellini'), arxiv.Result.Author('Stefano Casertano'), arxiv.Result.Author('Jessica R. Lu'), arxiv.Result.Author('Peter Melchior'), arxiv.Result.Author('Mattia Libralato'), arxiv.Result.Author('David Bennett'), arxiv.Result.Author('Michael Shao'), arxiv.Result.Author('Jason Rhodes'), arxiv.Result.Author('Sangmo Tony Sohn'), arxiv.Result.Author('Sangeeta Malhotra'), arxiv.Result.Author('Scott Gaudi'), arxiv.Result.Author('S. Michael Fall'), arxiv.Result.Author('Ed Nelan'), arxiv.Result.Author('Puragra Guhathakurta'), arxiv.Result.Author('Jay Anderson'), arxiv.Result.Author('Shirley Ho')]",
1115,Evolution of Gas in Elliptical Galaxies,"We review the origin and structure of hot (cooling flow) gas in elliptical
galaxies. X-ray observations can be used to determine the stellar mass to light
ratio, the mass profiles of dark matter halos, and the interstellar magnetic
field. Interstellar gas cools over a large volume, forming stars with a
bottom-heavy IMF. For consistency with the thin fundamental plane, young stars
must be optically luminous. Circular X-ray isophotes in rotating elliptical
galaxies indicate distributed radiative cooling or strong interstellar
turbulence.",astro-ph/0010040v1,astro-ph,2000-10-02 18:21:58+00:00,"[arxiv.Result.Author('William G. Mathews'), arxiv.Result.Author('Fabrizio Brighenti')]",
1116,Statistical Complexity of Simple 1D Spin Systems,"We present exact results for two complementary measures of spatial structure
generated by 1D spin systems with finite-range interactions. The first, excess
entropy, measures the apparent spatial memory stored in configurations. The
second, statistical complexity, measures the amount of memory needed to
optimally predict the chain of spin values. These statistics capture distinct
properties and are different from existing thermodynamic quantities.",cond-mat/9702191v1,cond-mat.stat-mech,1997-02-21 01:02:16+00:00,"[arxiv.Result.Author('James P. Crutchfield'), arxiv.Result.Author('David P. Feldman')]","Physical Review E, 55:2 (1997) 1239R"
1117,FAIR Metadata: A Community-driven Vocabulary Application,"FAIR metadata is critical to supporting FAIR data overall. Transparency,
community engagement, and flexibility are key aspects of FAIR that apply to
metadata. This paper presents YAMZ (Yet Another Metadata Zoo), a
community-driven vocabulary application that supports FAIR. The history ofYAMZ
and its original features are reviewed, followed by a presentation of recent
innovations and a discussion of how YAMZ supports FAIR principles. The
conclusion identifies next steps and key outputs.",2111.03910v1,cs.DL,2021-11-06 15:53:09+00:00,"[arxiv.Result.Author('Christopher B. Rauch'), arxiv.Result.Author('Mat Kelly'), arxiv.Result.Author('John A. Kunze'), arxiv.Result.Author('Jane Greenberg')]",
1118,An Empirical Evaluation of the Implementation of the California Consumer Privacy Act (CCPA),"On January 1, 2020, California passed the California Consumer Privacy Act
(CCPA) by more than 56% of voters intended to enhance privacy rights and
consumer protection for residents of California, United States. Since then,
more conditions have been added to the Act to support consumers' privacy. In
addition, two years after the first effective day of CCPA, consumers have seen
California organizations apply approaches to adapt to CCPA. Many organizations
quickly upgrade their policy to comply with the legislation and create
effective platforms such as data portals that allow consumers to exercise their
privacy rights. However, on the other hand, we still noticed aspects of CCPA
being absent on some websites. Additionally, we found no prior evaluation of
the CCPA implementation in organizations. Therefore, the convergence of the
regulatory landscape and the organization's privacy policy needs to be studied.
This paper was about an empirical evaluation of the implementation of the
California Consumer Privacy Act. The report includes the evaluations of the
following industries: social media, financial institutions, mortgages,
healthcare providers, and academic institutions. Our approach was to set up a
criteria table constructed from the CCPA Act and then use that table as a
checklist while reviewing a company's privacy notice. Finally, we concluded
this paper with an online tool application design that verifies the CCPA
implementation. Upon completion, the application would be free to use so
consumers can quickly inspect a website for CCPA compliance. Additionally, it
is an advising tool that a website admin can utilize to enhance CCPA compliance
for their website. The conjunction of this empirical report and a practical
application function as a stimulus to promote CCPA implementation in
organizations and deliver awareness to consumers about privacy rights they can
demand.",2205.09897v2,cs.CY,2022-05-19 23:28:41+00:00,[arxiv.Result.Author('Trong Nguyen')],
1119,"Glassy Spin Dynamics in Non-Fermi-Liquid UCu_{5-x}Pd_x, x = 1.0 and 1.5","Local f-electron spin dynamics in the non-Fermi-liquid heavy-fermion alloys
UCu_{5-x}Pd_x, x = 1.0 and 1.5, have been studied using muon spin-lattice
relaxation. The sample-averaged asymmetry function Gbar(t) indicates strongly
inhomogeneous spin fluctuations, and exhibits the scaling Gbar(t,H) =
Gbar(t/H^\gamma) expected from glassy dynamics. At 0.05 K \gamma(x=1.0) = 0.35
\pm 0.1, but \gamma(x=1.5) = 0.7 \pm 0.1. This is in contrast to inelastic
neutron scattering results, which yield \gamma = 0.33 for both concentrations.
There is no sign of static magnetism \gtrsim 10^{-3} \mu_B/U ion in either
material above 0.05 K. Our results strongy suggest that both alloys are quantum
spin glasses.",cond-mat/0012389v2,cond-mat.str-el,2000-12-20 19:58:47+00:00,"[arxiv.Result.Author('D. E. MacLaughlin'), arxiv.Result.Author('O. O. Bernal'), arxiv.Result.Author('R. H. Heffner'), arxiv.Result.Author('G. J. Nieuwenhuys'), arxiv.Result.Author('M. S. Rose'), arxiv.Result.Author('J. E. Sonier'), arxiv.Result.Author('B. Andraka'), arxiv.Result.Author('R. Chau'), arxiv.Result.Author('M. B. Maple')]",
1120,Exchange-induced frustration in Fe/NiO multilayers,"Using spin-polarized low-energy electron microscopy to study magnetization in
epitaxial layered systems, we found that the area vs perimeter relationship of
magnetic domains in the top Fe layers of Fe/NiO/Fe(100) structures follows a
power-law distribution, with very small magnetic domain cutoff radius (about 40
nm) and domain wall thickness. This unusual magnetic microstructure can be
understood as resulting from the competition between antiferromagnetic and
ferromagnetic exchange interactions at the Fe/NiO interfaces, rather than from
mechanisms involving the anisotropy and dipolar forces that govern length
scales in conventional magnetic domain structures. Statistical analysis of our
measurements validates a micromagnetic model that accounts for this interfacial
exchange coupling.",0705.4106v2,cond-mat.mtrl-sci,2007-05-28 20:28:45+00:00,"[arxiv.Result.Author('N. Rougemaille'), arxiv.Result.Author('M. Portalupi'), arxiv.Result.Author('A. Brambilla'), arxiv.Result.Author('P. Biagioni'), arxiv.Result.Author('A. Lanzara'), arxiv.Result.Author('M. Finazzi'), arxiv.Result.Author('A. K. Schmid'), arxiv.Result.Author('L. Duò')]","Physical Review B 76, 214425 (2007)"
1121,Schools on different corners: An investigation into the effects of ethnicity and socioeconomic status on physics offerings in Northern California public high schools,"In the spring of 2018 the Northern California/Nevada section of the American
Association of Physics Teachers was alerted to a local high school's plans to
eliminate physics for the following school year. As part of the campaign to
support the school's efforts to sustain physics in the following year, the
physics offerings from the surrounding schools in that district were compiled.
It appeared that the demographics of the student population in the district
played a role in the number of different physics courses offered within that
district, particularly the percentage of Hispanic students (%Hispanic) and
percentage of socioeconomically disadvantaged (%SED) students at each school.
Concerned that this trend was more widespread, physics course offerings were
reviewed for Northern California public high schools to determine if there were
correlations between the amount of different physics class offerings and these
populations. It was found that %Hispanic and %SED are strongly correlated in
California public schools, and along with number of students, could be used as
statistically significant predictors of a school's physics offerings.",2010.08476v4,physics.ed-ph,2020-10-16 16:23:59+00:00,"[arxiv.Result.Author('David Marasco'), arxiv.Result.Author('Bree Barnett Dreyfuss')]","The Physics Teacher 58, 673 (2020);"
1122,Three quantitative predictions based on past regularities about voter turnout at the French 2009 European election,"The previous twelve turnout rates of French national elections by
municipality show regularities. These regularities do not depend on the
national turnout level, nor on the nature of the election. Based on past
statistical regularities we make three predictions. The first one deals with
the standard deviation of the turnout rate by municipality. The second one
refers to the continuity in time of the heterogeneity of turnout rates in the
vicinity of a municipality. The last one is about the correlation between the
heterogeneity of turnout rates in the vicinity of a municipality and the
population in its surroundings. Details, explanations and discussions will be
given in forthcoming papers.",0905.4578v1,physics.soc-ph,2009-05-28 09:11:39+00:00,[arxiv.Result.Author('Christian Borghesi')],
1123,Results of three quantitative predictions based on past regularities about voter turnout at the French 2009 European election,"Twelve turnout rates of French national elections by municipality have shown
statistical regularities, neither depend on the nature of the election, nor on
the national turnout level. Three quantitative predictions about voter turnout
at the French 2009 European election were made in arXiv:0905.4578. Here, we
give the results of these three predictions. Each one is confirmed by real
measures.",0906.2692v1,physics.soc-ph,2009-06-15 13:56:45+00:00,[arxiv.Result.Author('Christian Borghesi')],
1124,Asymmetric Partisan Voter Turnout Games,"Since Downs proposed that the act of voting is irrational in 1957, myriad
models have been proposed to explain voting and account for observed turnout
patterns. We propose a model in which partisans consider both the instrumental
and expressive benefits of their vote when deciding whether or not to abstain
in an election, introducing an asymmetry that most other models do not
consider. Allowing learning processes within our electorate, we analyze what
turnout states are rationalizable under various conditions. Our model predicts
comparative statics that are consistent with voter behavior. Furthermore,
relaxing some of our preliminary assumptions eliminates some of the
discrepancies between our model and empirical voter behavior.",2003.10313v1,physics.soc-ph,2020-03-23 15:01:26+00:00,"[arxiv.Result.Author('Cameron Guage'), arxiv.Result.Author('Feng Fu')]",
1125,Declination as a Metric to Detect Partisan Gerrymandering,"We explore the Declination, a new metric intended to detect partisan
gerrymandering. We consider instances in which each district has equal turnout,
the maximum turnout to minimum turnout is bounded, and turnout is unrestricted.
For each of these cases, we show exactly which vote-share, seat-share pairs
$(V,S)$ have an election outcome with Declination equal to 0. We also show how
our analyses can be applied to finding vote-share, seat-share pairs that are
possible for nonzero Declination.
  Within our analyses, we show that Declination cannot detect all forms of
packing and cracking, and we compare the Declination to the Efficiency Gap. We
show that these two metrics can behave quite differently, and give explicit
examples of that occurring.",1812.05163v2,physics.soc-ph,2018-12-12 21:34:00+00:00,"[arxiv.Result.Author('Marion Campisi'), arxiv.Result.Author('Andrea Padilla'), arxiv.Result.Author('Thomas C. Ratliff'), arxiv.Result.Author('Ellen Veomett')]",
1126,Identification of Behavioural Models for Railway Turnouts Monitoring,"This study introduces a low-complexity behavioural model to describe the
dynamic response of railway turnouts due to the ballast and railpad components.
The behavioural model should serve as the basis for the future development of a
supervisory system for the continuous monitoring of turnouts. A fourth order
linear model is proposed based on spectral analysis of measured rail vertical
accelerations gathered during a receptance test and it is then identified at
several sections of the turnout applying the Eigensystem Realization Algorithm.
The predictviness and robustness of the behavioural models have been assessed
on a large data set of train passages differing for train type, speed and
loading condition. Last, the need for a novel modeling method is argued in
relation to high-fidelity mechanistic models widely used in the railway
engineering community.",1910.06582v1,eess.SY,2019-10-15 08:12:40+00:00,"[arxiv.Result.Author('Pegah Barkhordari'), arxiv.Result.Author('Roberto Galeazzi'), arxiv.Result.Author('Alejandro de Miguel Tejada'), arxiv.Result.Author('Ilmar F. Santos')]",
1127,"Efficient Choice, Inefficient Democracy? The Implications of Cable and Internet Access for Political Knowledge and Voter Turnout","This paper explains why, despite a marked increase in available political
information on cable television and the Internet, citizens' levels of political
knowledge have, at best, remained stagnant (Delli Carpini & Keeter, 1996).
Since the availability of entertainment content has increased too, the effect
of new media on knowledge and vote likelihood should be determined by people's
relative preferences for entertainment and information. Access to new media
should increase knowledge and vote likelihood among people who prefer news. At
the same time, it is hypothesized to have a negative effect on knowledge and
turnout for people who prefer entertainment content. Hypotheses are tested by
building a measure of Relative Entertainment Preference (REP) from existing NES
and Pew survey data. Results support the predicted interaction effect of media
environment (cable and/or Internet access) and motivation (REP) on political
knowledge and turnout. In particular, people who prefer entertainment to news
and have access to cable television and the Internet are less knowledgeable and
less likely to vote than any other group of people.",cs/0109110v1,cs.CY,2001-09-25 03:35:27+00:00,[arxiv.Result.Author('Markus Prior')],
1128,Spatial correlations in vote statistics: a diffusive field model for decision-making,"We study the statistics of turnout rates and results of the French elections
since 1992. We find that the distribution of turnout rates across towns is
surprisingly stable over time. The spatial correlation of the turnout rates, or
of the fraction of winning votes, is found to decay logarithmically with the
distance between towns. Based on these empirical observations and on the
analogy with a two-dimensional random diffusion equation, we propose that
individual decisions can be rationalised in terms of an underlying ""cultural""
field, that locally biases the decision of the population of a given region, on
top of an idiosyncratic, town-dependent field, with short range correlations.
Using symmetry considerations and a set of plausible assumptions, we suggest
that this cultural field obeys a random diffusion equation.",1003.2807v2,physics.soc-ph,2010-03-14 20:08:51+00:00,"[arxiv.Result.Author('Christian Borghesi'), arxiv.Result.Author('Jean-Philippe Bouchaud')]",
1129,"Election turnout statistics in many countries: similarities, differences, and a diffusive field model for decision-making","We study in details the turnout rate statistics for 77 elections in 11
different countries. We show that the empirical results established in a
previous paper for French elections appear to hold much more generally. We find
in particular that the spatial correlation of turnout rates decay
logarithmically with distance in all cases. This result is quantitatively
reproduced by a decision model that assumes that each voter makes his mind as a
result of three influence terms: one totally idiosyncratic component, one
city-specific term with short-ranged fluctuations in space, and one long-ranged
correlated field which propagates diffusively in space. A detailed analysis
reveals several interesting features: for example, different countries have
different degrees of local heterogeneities and seem to be characterized by a
different propensity for individuals to conform to the cultural norm. We
furthermore find clear signs of herding (i.e. strongly correlated decisions at
the individual level) in some countries, but not in others.",1201.0524v1,physics.soc-ph,2012-01-02 19:46:49+00:00,"[arxiv.Result.Author('Christian Borghesi'), arxiv.Result.Author('Jean-Claude Raynal'), arxiv.Result.Author('Jean-Philippe Bouchaud')]",
1130,"Using auxiliary marginal distributions in imputations for nonresponse while accounting for survey weights, with application to estimating voter turnout","The Current Population Survey is the gold-standard data source for studying
who turns out to vote in elections. However, it suffers from potentially
nonignorable unit and item nonresponse. Fortunately, after elections, the total
number of voters is known from administrative sources and can be used to adjust
for potential nonresponse bias. We present a model-based approach to utilize
this known voter turnout rate, as well as other population marginal
distributions of demographic variables, in multiple imputation for unit and
item nonresponse. In doing so, we ensure that the imputations produce
design-based estimates that are plausible given the known margins. We introduce
and utilize a hybrid missingness model comprising a pattern mixture model for
unit nonresponse and selection models for item nonresponse. Using simulation
studies, we illustrate repeated sampling performance of the model under
different assumptions about the missingness mechanisms. We apply the model to
examine voter turnout by subgroups using the 2018 Current Population Survey for
North Carolina. As a sensitivity analysis, we examine how results change when
we allow for over-reporting, i.e., individuals self-reporting that they voted
when in fact they did not.",2209.05220v2,stat.ME,2022-09-12 13:08:33+00:00,"[arxiv.Result.Author('Jiurui Tang'), arxiv.Result.Author('D. Sunshine Hillygus'), arxiv.Result.Author('Jerome P. Reiter')]",
1131,"The Efficiency Gap, Voter Turnout, and the Efficiency Principle","Recently, scholars from law and political science have introduced metrics
which use only election outcomes (and not district geometry) to assess the
presence of partisan gerrymandering. The most high-profile example of such a
tool is the efficiency gap. Some scholars have suggested that such tools should
be sensitive enough to alert us when two election outcomes have the same
percentage of votes going to political party $A$, but one of the two awards
party $A$ more seats. When a metric is able to distinguish election outcomes in
this way, that metric is said to satisfy the efficiency principle.
  In this article, we show that the efficiency gap fails to satisfy the
efficiency principle. We show precisely how the efficiency principle breaks
down in the presence of unequal voter turnout. To do this, we first present a
construction that, given any rationals $1/4< V<3/4$ and $0<S<1$, constructs an
election outcome with vote share $V$, seat share $S$, and EG = 0. (For
instance, one party can get 26% of the vote and anywhere from 1% to 99% of the
seats while the efficiency gap remains zero.) Then, for any election with vote
share $1/4<V<3/4$, seat share $S$, and EG= 0, we express the ratio $\rho$ of
average turnout in districts party $A$ lost to average turnout in districts
party $A$ won as a function in only $V$ and $S$. It is well known that when all
districts have equal turnout, EG can be expressed as a simple formula in $V$
and $S$; we express the efficiency gap of any election as an equation only in
$V, S,$ and $\rho$. We also report on the values of $\rho$ that can be observed
in actual elections.",1801.05301v2,physics.soc-ph,2018-01-13 16:38:53+00:00,[arxiv.Result.Author('Ellen Veomett')],
1132,Physics peeks into the ballot box,"Electoral results show universal features, such as statistics of candidates'
performance and turnout rates, in different countries and over time. Are voters
as predictable as atoms?",1210.2426v1,physics.soc-ph,2012-10-08 21:35:00+00:00,"[arxiv.Result.Author('Santo Fortunato'), arxiv.Result.Author('Claudio Castellano')]","Physics Today 65, 74-75 (2012)"
1133,A transparent referendum protocol with immutable proceedings and verifiable outcome for trustless networks,"High voter turnout in elections and referendums is very desirable in order to
ensure a robust democracy. Secure electronic voting is a vision for the future
of elections and referendums. Such a system can counteract factors that hinder
strong voter turnout such as the requirement of physical presence during
limited hours at polling stations. However, this vision brings transparency and
confidentiality requirements that render the design of such solutions
challenging. Specifically, the counting must be implemented in a reproducible
way and the ballots of individual voters must remain concealed. In this paper,
we propose and evaluate a referendum protocol that ensures transparency,
confidentiality, and integrity, in trustless networks. The protocol is built by
combining Secure Multi-Party Computation (SMPC) and Distributed Ledger or
Blockchain technology. The persistence and immutability of the protocol
communication allows verifiability of the referendum outcome on the client
side. Voters therefore do not need to trust in third parties. We provide a
formal description and conduct a thorough security evaluation of our proposal.",1909.06462v1,cs.CR,2019-09-13 21:41:05+00:00,"[arxiv.Result.Author('Maximilian Schiedermeier'), arxiv.Result.Author('Omar Hasan'), arxiv.Result.Author('Tobias Mayer'), arxiv.Result.Author('Lionel Brunie'), arxiv.Result.Author('Harald Kosch')]",
1134,Marine Le Pen can breach her glass ceiling: The drastic effect of differentiated abstention,"Ranges of differentiated abstention are shown to reverse an ""exact"" poll
estimate on voting day allowing the minority candidate to win the election. In
a two-candidate competition A and B with voting intentions at $I_a$,
$I_b=1-I_a$ and respective turnout at $x$ and $y$, there exists a critical
value $I_{ac}$ for which $I_{ac}<I_a<\frac{1}{2}$ yields an actual election
outcome $v_a>\frac{1}{2}$. The reversal may occur without any change of
individual choices. Accordingly, for a set of turnouts $x$ and $y$ the minimum
voting intention $I_{ac}$ required for A to win the final vote can be
calculated. The various ranges of $x$ and $y$ for which $I_{Ac}$ is smaller
than the expected 50\% barrier are determined. The calculations are applied to
the coming 2017 French presidential election for a second round scenario
involving the National Front candidate Marine Le Pen against either the Right
candidate Fran\c{c}ois Fillon or the Center candidate Emmanuel Macron. Several
realistic conditions are found to make Marine Le Pen win the election despite
voting intentions about only 40-45\%.",1703.04643v1,physics.soc-ph,2017-03-14 18:16:43+00:00,[arxiv.Result.Author('Serge Galam')],
1135,Monitoring of Railpad Long-term Condition in Turnouts Using Extreme Value Distributions,"The railpad is a key element in railway infrastructures that plays an
essential role in the train-track dynamics. Presence of worn or defective
railpads along railway track may lead to large wheel/rail interaction forces,
and a high rate of deterioration for track components. Despite the importance
of railpad, the track infrastructure managers use no inspection tool for
monitoring in-service railpads over time. In this paper, a novel data-driven
monitoring tool for long-term performance analysis of in-service railpads is
developed based on train-induced vibration data collected by a track-side
measurement system. The monitoring tool consists of a method for track
resonance frequencies estimation, a temperature-frequency model for describing
railpad behavior with respect to ambient temperature, and a generalized
likelihood ratio test based on the generalized extreme value distribution for
detecting changes in the railpad status over time. To evaluate the performance
of the proposed monitoring system, the status of railpads at four different
locations along a railway turnout is monitored over a period of 18 months. It
is shown that the monitoring system can successfully detect changes in railpad
properties over the considered period.",2101.02567v1,eess.SY,2021-01-07 14:45:49+00:00,"[arxiv.Result.Author('Pegah Barkhordari'), arxiv.Result.Author('Roberto Galeazzi'), arxiv.Result.Author('Mogens Blanke')]",
1136,Voting From Jail,"We leverage new data on daily individual-level jail records and exploit the
timing of incarceration to estimate the causal effects of jail incarceration on
voting from jail in 2020. We find that registered voters booked into county
jails for the full duration of 2020 voting days were on average 46% less likely
to vote in 2020, relative to registered voters booked into the same jails
within 7-42 days after Election Day. The estimated negative effect of
incarceration on voting from jail was much larger for Black registered voters,
who were 78% less likely to vote in 2020 if booked into county jails for the
full duration of 2020 voting days, relative to Black registered voters booked
into the same jails just after Election Day. Placebo tests indicate no effects
of 2020 jail incarceration on the 2012 or 2016 turnout of registered voters. We
find inconsistent effects of jail incarceration on voter registration in 2020,
and effect sizes of comparable magnitude for turnout unconditional on
registration status. Our findings reveal the pressing need to enable
voting-eligible incarcerated individuals to exercise their constitutional right
to vote, and to address troubling racial disparities in the effect of jail
incarceration on the exercise of the right to vote.",2210.06542v1,stat.AP,2022-10-12 19:13:53+00:00,"[arxiv.Result.Author('Anna Harvey'), arxiv.Result.Author('Orion Taylor')]",
1137,Une étude de physique sur les élections,"We study spatiotemporal regularities of electoral results and turnout rates
for each municipality (or polling station) concerning French elections between
1992 and 2007. We try to account for the data using models based on a simple
imitation of agents in the vicinity. We also propose a model of an experiment
that shows how choices are modified by knowing the choices of others agents.",0910.4661v2,physics.soc-ph,2009-10-24 16:09:30+00:00,[arxiv.Result.Author('Christian Borghesi')],
1138,Low-Rank Approximations of Nonseparable Panel Models,"We provide estimation methods for nonseparable panel models based on low-rank
factor structure approximations. The factor structures are estimated by
matrix-completion methods to deal with the computational challenges of
principal component analysis in the presence of missing data. We show that the
resulting estimators are consistent in large panels, but suffer from
approximation and shrinkage biases. We correct these biases using matching and
difference-in-differences approaches. Numerical examples and an empirical
application to the effect of election day registration on voter turnout in the
U.S. illustrate the properties and usefulness of our methods.",2010.12439v2,econ.EM,2020-10-23 14:31:41+00:00,"[arxiv.Result.Author('Iván Fernández-Val'), arxiv.Result.Author('Hugo Freeman'), arxiv.Result.Author('Martin Weidner')]",
1139,"Bipartisanship breakdown, functional networks and forensic analysis in Spanish 2015 and 2016 national elections","In this paper we present a social network and forensic analysis of the vote
counts of Spanish national elections that took place in December 2015 and their
sequel in June 2016. Vote counts are extracted at the level of municipalities,
yielding an unusually high resolution dataset with over 8000 samples. We
initially consider the phenomenon of Bipartisanship breakdown by analysing
spatial distributions of several Bipartisanship indices. We find that such
breakdown is more prominent close to cosmopolite and largely populated areas
and less important in rural areas where Bipartisanship still prevails, and its
evolution mildly consolidates in the 2016 round, with some evidence of
Bipartisanship reinforcement which we hypothesize to be due to psychological
mechanisms of risk aversion. On a third step we explore to which extent vote
data are faithful by applying forensic techniques to vote statistics. We first
explore the conformance of first digit distributions to Benford's law for each
of the main political parties. The results and interpretations are mixed and
vary across different levels of aggregation, finding a general good
quantitative agreement at the national scale for both municipalities and
precincts but finding systematic nonconformance at the level of individual
precincts. As a complementary metric, we further explore the co-occurring
statistics of voteshare and turnout, finding a mild tendency in the clusters of
the conservative party to smear out towards the area of high turnout and
voteshare, what has been previously interpreted as a possible sign of
incremental fraud. In every case results are qualitatively similar between 2015
and 2016 elections.",1607.02841v2,physics.soc-ph,2016-07-11 07:18:04+00:00,"[arxiv.Result.Author('Juan Fernández-Gracia'), arxiv.Result.Author('Lucas Lacasa')]",
1140,The price of a vote: diseconomy in proportional elections,"The increasing cost of electoral campaigns raises the need for effective
campaign planning and a precise understanding of the return of such investment.
Interestingly, despite the strong impact of elections on our daily lives, how
this investment is translated into votes is still unknown. By performing data
analysis and modeling, we show that top candidates spend more money \emph{per
vote} than the less successful and poorer candidates, a sublinearity that
discloses a diseconomy of scale. We demonstrate that such electoral diseconomy
arises from the competition between candidates due to inefficient campaign
expenditure. Our approach succeeds in two important tests. First, it reveals
that the statistical pattern in the vote distribution of candidates can be
explained in terms of the independently conceived, but similarly skewed
distribution of money campaign. Second, using a heuristic argument, we are able
to predict a turnout percentage for a given election of approximately 63\%.
This result is in good agreement with the average turnout rate obtained from
real data. Due to its generality, we expect that our approach can be applied to
a wide range of problems concerning the adoption process in marketing
campaigns.",1711.05894v1,physics.soc-ph,2017-11-16 02:19:02+00:00,"[arxiv.Result.Author('Hygor Piaget M. Melo'), arxiv.Result.Author('Saulo D. S. Reis'), arxiv.Result.Author('André A. Moreira'), arxiv.Result.Author('Hernán A. Makse'), arxiv.Result.Author('José S. Andrade Jr')]",
1141,Influencing elections with statistics: Targeting voters with logistic regression trees,"In political campaigning substantial resources are spent on voter
mobilization, that is, on identifying and influencing as many people as
possible to vote. Campaigns use statistical tools for deciding whom to target
(""microtargeting""). In this paper we describe a nonpartisan campaign that aims
at increasing overall turnout using the example of the 2004 US presidential
election. Based on a real data set of 19,634 eligible voters from Ohio, we
introduce a modern statistical framework well suited for carrying out the main
tasks of voter targeting in a single sweep: predicting an individual's turnout
(or support) likelihood for a particular cause, party or candidate as well as
data-driven voter segmentation. Our framework, which we refer to as LORET (for
LOgistic REgression Trees), contains standard methods such as logistic
regression and classification trees as special cases and allows for a synthesis
of both techniques. For our case study, we explore various LORET models with
different regressors in the logistic model components and different
partitioning variables in the tree components; we analyze them in terms of
their predictive accuracy and compare the effect of using the full set of
available variables against using only a limited amount of information. We find
that augmenting a standard set of variables (such as age and voting history)
with additional predictor variables (such as the household composition in terms
of party affiliation) clearly improves predictive accuracy. We also find that
LORET models based on tree induction beat the unpartitioned models.
Furthermore, we illustrate how voter segmentation arises from our framework and
discuss the resulting profiles from a targeting point of view.",1311.7326v1,stat.AP,2013-11-28 14:21:41+00:00,"[arxiv.Result.Author('Thomas Rusch'), arxiv.Result.Author('Ilro Lee'), arxiv.Result.Author('Kurt Hornik'), arxiv.Result.Author('Wolfgang Jank'), arxiv.Result.Author('Achim Zeileis')]","Annals of Applied Statistics 2013, Vol. 7, No. 3, 1612-1639"
1142,Atomistic mechanisms of twin-twin interactions in Cu nanopillars,"Twinning is an important mode of plastic deformation in metallic nanopillars.
When twinning occurs on multiple systems, it is possible that twins belonging
to different twin systems interact and forms a complex twin-twin junctions.
Revealing the atomistic mechanisms of how twin-twin interactions lead to
different twin junctions is crucial for our understanding of mechanical
behaviour of materials. In this paper, we report the atomistic mechanisms
responsible for the formation of two different twin-twin interactions/junctions
in Cu nanopillars using atomistic simulations. One junction contains two twin
boundaries along with one $\Sigma$9 boundary, while the other contains five
twin boundaries (five-fold twin). These junctions were observed during the
tensile deformation of [100] and $[1\bar1 0]$ Cu nanopillars, respectively.",2008.00785v1,cond-mat.mtrl-sci,2020-08-03 11:25:47+00:00,"[arxiv.Result.Author('G. Sainath'), arxiv.Result.Author('Sunil Goyal'), arxiv.Result.Author('A. Nagesha')]",Computational Materials Science 185 (2020) 109950
1143,Digital Twins,"Digital Twins are one of the hottest digital trends. In this contribution we
will shortly review the concept of Digital Twins and the chances for novel
industrial applications. Mathematics are a key enabler and the impact will be
highlighted along four specific examples addressing Digital Product Twins
democratizing Design, Digital Production Twins enabling robots to mill, Digital
Production Twins driving industrialization of additive manufacturing, and
Digital Performance Twins boosting operations. We conclude the article with an
outlook on the next wave of Digital Twins, Executable Digital Twins, and will
review the associated challenges and opportunities for mathematics.",2001.09747v1,cs.CY,2020-01-03 19:20:47+00:00,"[arxiv.Result.Author('Dirk Hartmann'), arxiv.Result.Author('Herman van der Auweraer')]",
1144,Deformation behaviour of body centered cubic iron nanopillars containing coherent twin boundaries,"Molecular dynamics simulations were performed to understand the role of twin
boundaries on deformation behaviour of body-centred cubic (BCC) iron (Fe)
nanopillars. The twin boundaries varying from one to five providing twin
boundary spacing in the range 8.5 - 2.8 nm were introduced perpendicular to the
loading direction. The simulation results indicated that the twin boundaries in
BCC Fe play a contrasting role during deformation under tensile and compressive
loadings. During tensile deformation, a large reduction in yield stress was
observed in twinned nanopillars compared to perfect nanopillar. However, the
yield stress exhibited only marginal variation with respect to twin boundary
spacing. On the contrary, a decrease in yield stress with increase in twin
boundary spacing was obtained during compressive deformation. This contrasting
behaviour originates from difference in operating mechanisms during yielding
and subsequent plastic deformation. It has been observed that the deformation
under tensile loading was dominated mainly by twin growth mechanism, due to
which the twin boundaries offers a negligible resistance to slip of twinning
partials. This is reflected in the negligible variation of yield stress as a
function of twin boundary spacing. On the other hand, the deformation was
dominated by nucleation and slip of full dislocations under compressive
loading. The twin boundaries offer a strong repulsive force on full
dislocations resulting in the yield stress dependence on twin boundary spacing.
Further, it has been observed that the curved twin boundary can acts as a
source for full dislocation. The occurrence of twin-twin interaction during
tensile deformation and dislocation-twin interaction during compressive
deformation were presented and discussed.",1611.05575v1,cond-mat.mtrl-sci,2016-11-17 05:48:19+00:00,"[arxiv.Result.Author('G. Sainath'), arxiv.Result.Author('B. K. Choudhary')]",Philosophical Magazine 96 (2016) 3502-3523
1145,Computation of twin-width of graphs,"Twin-width is a recently introduced graph parameter. In this article, we
compute twin-width of various finite graphs. In particular, we prove that the
twin-widths of finite graphs with 4 and 5 vertices are less than equal to 1 and
2, respectively. We show that the constructions of dual graph and line graph do
not preserve twin-width. Also, we give upper bounds for the twin-width of
King's graph and Rook's graph.",2207.14333v1,math.CO,2022-07-28 18:22:49+00:00,[arxiv.Result.Author('Kajal Das')],
1146,"The (11-22) and (-12-16) twinning modes modelled by obliquity correction of a (58deg, a+2b) prototype stretch twin","The {11-22} and {11-26} twinning modes were recently put in evidence by
Ostapovets et al. (Phil. Mag, 2017)and interpreted as {101-2}-{101-2}
double-twins formed by a simultaneous action of two twinning shears. We propose
another interpretation in which the twinning modes result from a one-step
mechanism based on the same (58deg, a+2b) prototype stretch twin. . The two
twins differ from the prototype twin by their obliquity correction. The results
are compared with the classical theory of twinning and with Westlake-Rosenbaum
model of {11-22} twinning. An unconventional twinning mode recently discovered
in a magnesium single crystal based on the same prototype twin will be the
subject of a separate publication.",1706.08338v1,cond-mat.mtrl-sci,2017-06-26 12:26:38+00:00,[arxiv.Result.Author('Cyril Cayron')],"Acta Crystallographica, 2018, A74, 44-53"
1147,Twin Cogenesis,"We investigate a cogenesis scenario within the twin Higgs setup which can
naturally explain the nature of dark matter, the cosmic coincidence puzzle,
little hierarchy problem, leptogenesis and the tiny neutrino masses. Three
heavy Majorana neutrinos are introduced to the standard model sector and the
twin sector respectively, which explain the tiny neutrino masses and generate
the lepton asymmetry and the twin lepton asymmetry at the same time. The twin
cogenesis scenario is general and applies to any viable twin Higgs model
without hard $\mathbb{Z}_2$ breaking and evading the $\Delta N_{\rm eff}$
constraint. We demonstrate twin cogenesis in two models: fraternal twin Higgs
model, and neutrino-philic twin two Higgs doublet model, a newly proposed model
to lift the twin neutrino masses with spontaneous $\mathbb{Z}_2$ breaking. The
MeV scale dark photon ensures the energy in the twin sector as well as the
symmetric component of twin sector particles can be depleted. The lightest twin
baryons are the dark matter candidates with masses approximately 5.5~GeV, which
explain naturally the amount of dark matter and visible matter in the Universe
are of the same order.",2005.06471v2,hep-ph,2020-05-13 18:00:00+00:00,"[arxiv.Result.Author('Wan-Zhe Feng'), arxiv.Result.Author('Jiang-Hao Yu')]",
1148,Researches on the Twin Prime Problem,"Twin prime number problem is mainly the structure of the twin prime numbers
and whether there are infinitely many prime twins group. In this paper, by
constructing a special cluster number set(see formula(2.3)in the paper), proves
that the number of set number of the first n columns set the intersection of
the minimum number of q is decision of the prime twins (q, q+2), and the
minimum number of series is divergent(see Theorem 2).The main rezults are
Theorem 2,Theorem 3 and Theorem 4.Prime twins so thoroughly proved there must
be infinitely many groups of twin prime conjecture.",1405.2490v2,math.GM,2014-05-11 02:21:05+00:00,[arxiv.Result.Author('Zhang Baoshan')],
1149,The Vector-like Twin Higgs,"We present a version of the twin Higgs mechanism with vector-like top
partners. In this setup all gauge anomalies automatically cancel, even without
twin leptons. The matter content of the most minimal twin sector is therefore
just two twin tops and one twin bottom. The LHC phenomenology, illustrated with
two example models, is dominated by twin glueball decays, possibly in
association with Higgs bosons. We further construct an explicit
four-dimensional UV completion and discuss a variety of UV completions relevant
for both vector-like and fraternal twin Higgs models.",1601.07181v2,hep-ph,2016-01-26 21:00:05+00:00,"[arxiv.Result.Author('Nathaniel Craig'), arxiv.Result.Author('Simon Knapen'), arxiv.Result.Author('Pietro Longhi'), arxiv.Result.Author('Matthew Strassler')]",
1150,On twinning in smectic crystals,"It is shown that mechanical twinning in smectic crystals is possible. The
structure of the boundary of twins for a small disorientation of crystallites
is determined. The periodic twin structure, which should appear at the tension
of the smectic layer, is proposed.",1304.7129v1,cond-mat.soft,2013-04-26 11:23:03+00:00,[arxiv.Result.Author('V. I. Marchenko')],"JETP Lett. 116(4), 587 (2007)"
1151,Disconnection-mediated twin embryo growth in Mg,"While deformation twinning in hexagonal close-packed metals has been widely
studied due to its substantial impact on mechanical properties, an
understanding of the detailed atomic processes associated with twin embryo
growth is still lacking. Conducting molecular dynamics simulations on Mg, we
show that the propagation of twinning disconnections emitted by basal-prismatic
interfaces controls the twin boundary motion and is the rate-limiting mechanism
during the initial growth of the twin embryo. The time needed for disconnection
propagation is related to the distance between the twin tips, with widely
spaced twin tips requiring more time for a unit twin boundary migration event
to be completed. Thus, a phenomenological model, which unifies the two
processes of disconnection and twin tip propagation, is proposed here to
provide a quantitative analysis of twin embryo growth. The model fits the
simulation data well, with two key parameters (twin tip velocity and twinning
disconnection velocity) being extracted. In addition, a linear relationship
between the ratio of twinning disconnection velocity to twin tip velocity and
the applied shear stress is observed. Using an example of twin growth in a
nanoscale single crystal from the recent literature, we find that our molecular
dynamics simulations and analytical model are in good agreement with
experimental data.",1909.11649v2,cond-mat.mtrl-sci,2019-09-25 17:53:57+00:00,"[arxiv.Result.Author('Yang Hu'), arxiv.Result.Author('Vladyslav Turlo'), arxiv.Result.Author('Irene J. Beyerlein'), arxiv.Result.Author('Subhash Mahajan'), arxiv.Result.Author('Enrique J. Lavernia'), arxiv.Result.Author('Julie M. Schoenung'), arxiv.Result.Author('Timothy J. Rupert')]",
1152,"Exceptional Prime Number Twins, Triplets and Multiplets","A classification of twin primes implies special twin primes. When applied to
triplets, it yields exceptional prime number triplets. These generalize
yielding exceptional prime number multiplets.",1102.3075v1,math.NT,2011-02-15 14:03:25+00:00,[arxiv.Result.Author('H. J. Weber')],
1153,New Insights on Stacking Fault Behavior in Twin Induced Plasticity from Meta-Atom Molecular Dynamics Simulations,"There is growing interest in promoting deformation twinning for plasticity in
advanced materials, as highly organized twin boundaries are beneficial to
better strength-ductility combination in contrast to disordered grain
boundaries. Twinning deformation typically involves the kinetics of stacking
faults, its interaction with dislocations, and dislocation - twin boundary
interactions. While the latter has been intensively investigated, the dynamics
of stacking faults has been less known. In this work, we report several new
insights on the stacking fault behavior in twin induced plasticity from our
meta-atom molecular dynamics simulation: The stacking fault interactions are
dominated by dislocation reactions taking place spontaneously, different from
the proposed mechanism in literatures; The competition among generating a
single stacking fault, a twinning partial and a trailing partial dislocation is
dependent on a unique parameter, i.e. stacking fault energy, which in turn
determines deformation twinning behaviors. The complex twin-slip and
twin-dislocation interactions demonstrate the dual role of deformation twins as
both dislocation barrier and storage, potentially contributing to the high
strength and ductility of advanced materials like TWIP steels where deformation
twinning dominated plasticity accounts for the superb strength-ductility
combination.",1604.00579v1,cond-mat.mtrl-sci,2016-04-03 01:03:50+00:00,"[arxiv.Result.Author('Peng Wang'), arxiv.Result.Author('Shaofeng Xu'), arxiv.Result.Author('Jiabin Liu'), arxiv.Result.Author('Xiaoyan Li'), arxiv.Result.Author('Yujie Wei'), arxiv.Result.Author('Hongtao Wang'), arxiv.Result.Author('Huajian Gao'), arxiv.Result.Author('Wei Yang')]",
1154,Deformation twin nucleation and twin variant selection in single crystal magnesium as a function of strain rate,"Deformation twinning is an important deformation mechanism in a variety of
materials, including metals and ceramics. This deformation mechanism is
particularly important in low-symmetry hexagonal close-packed (hcp) metals such
as Magnesium (Mg), Zirconium (Zr) and Titanium (Ti). Extension twins in Mg, Zr
and Ti can accommodate considerable plastic deformation as they grow. Thus, the
rate and the mode of twinning greatly influences the mechanical behavior
including strength and ductility. Herein, we study deformation twinning in
terms of nucleation, twinning mode and variant selection as a function of
strain rate in Mg single crystal (considered as a model material). We show that
twin variant selection is sensitive to the loading rate, with more twin
variants nucleating at the dynamic strain rates. Low Schmid factor twin
variants (one of them being a double extension twin variant) were also found at
the dynamic strain rates. Further at high strain rates, the first twins
generated do not thicken beyond a critical width. Instead, plasticity proceeds
with nucleation of second generation twins from the primary twin boundaries.
The rates of area/volume fraction evolution of both generations of twins are
found to be similar.",1801.10252v2,physics.app-ph,2018-01-30 23:12:03+00:00,"[arxiv.Result.Author('Kavan Hazeli'), arxiv.Result.Author('Vignesh Kannan'), arxiv.Result.Author('Owen Kingstedt'), arxiv.Result.Author('Guruswami Ravichandran'), arxiv.Result.Author('KT Ramesh')]",
1155,Twins: BFT Systems Made Robust,"This paper presents Twins, an automated unit test generator of Byzantine
attacks. Twins implements three types of Byzantine behaviors: (i) leader
equivocation, (ii) double voting, and (iii) losing internal state such as
forgetting 'locks' guarding voted values. To emulate interesting attacks by a
Byzantine node, it instantiates twin copies of the node instead of one, giving
both twins the same identities and network credentials. To the rest of the
system, the twins appear indistinguishable from a single node behaving in a
'questionable' manner. Twins can systematically generate Byzantine attack
scenarios at scale, execute them in a controlled manner, and examine their
behavior. Twins scenarios iterate over protocol rounds and vary the
communication patterns among nodes. Twins runs in a production setting within
DiemBFT where it can execute 44M Twins-generated scenarios daily. Whereas the
system at hand did not manifest errors, subtle safety bugs that were
deliberately injected for the purpose of validating the implementation of Twins
itself were exposed within minutes. Twins can prevent developers from
regressing correctness when updating the codebase, introducing new features, or
performing routine maintenance tasks. Twins only requires a thin wrapper over
DiemBFT, we thus envision other systems using it. Building on this idea, one
new attack and several known attacks against other BFT protocols were
materialized as Twins scenarios. In all cases, the target protocols break
within fewer than a dozen protocol rounds, hence it is realistic for the Twins
approach to expose the problems.",2004.10617v2,cs.CR,2020-04-22 14:59:04+00:00,"[arxiv.Result.Author('Shehar Bano'), arxiv.Result.Author('Alberto Sonnino'), arxiv.Result.Author('Andrey Chursin'), arxiv.Result.Author('Dmitri Perelman'), arxiv.Result.Author('Zekun Li'), arxiv.Result.Author('Avery Ching'), arxiv.Result.Author('Dahlia Malkhi')]",
1156,Graph Learning for Cognitive Digital Twins in Manufacturing Systems,"Future manufacturing requires complex systems that connect simulation
platforms and virtualization with physical data from industrial processes.
Digital twins incorporate a physical twin, a digital twin, and the connection
between the two. Benefits of using digital twins, especially in manufacturing,
are abundant as they can increase efficiency across an entire manufacturing
life-cycle. The digital twin concept has become increasingly sophisticated and
capable over time, enabled by rises in many technologies. In this paper, we
detail the cognitive digital twin as the next stage of advancement of a digital
twin that will help realize the vision of Industry 4.0. Cognitive digital twins
will allow enterprises to creatively, effectively, and efficiently exploit
implicit knowledge drawn from the experience of existing manufacturing systems.
They also enable more autonomous decisions and control, while improving the
performance across the enterprise (at scale). This paper presents graph
learning as one potential pathway towards enabling cognitive functionalities in
manufacturing digital twins. A novel approach to realize cognitive digital
twins in the product design stage of manufacturing that utilizes graph learning
is presented.",2109.08632v1,cs.LG,2021-09-17 16:34:33+00:00,"[arxiv.Result.Author('Trier Mortlock'), arxiv.Result.Author('Deepan Muthirayan'), arxiv.Result.Author('Shih-Yuan Yu'), arxiv.Result.Author('Pramod P. Khargonekar'), arxiv.Result.Author('Mohammad A. Al Faruque')]",
1157,Macroscopic Symmetry Group Describes Josephson Tunneling in Twinned Crystals,"A macroscopic symmetry group describing the superconducting state of an
orthorhombically twinned crystal of YBCO is introduced. This macroscopic
symmetry group is different for different symmetries of twin boundaries.
Josephson tunneling experiments performed on twinned crystals of YBCO determine
this macroscopic symmetry group and hence determine the twin boundary symmetry
(but do not experimentally determine whether the microscopic order parameter is
primarily d- or s-wave). A consequence of the odd-symmetry twin boundaries in
YBCO is the stability of vortices containing one half an elementary flux
quantum at the intersection of a twin boundary and certain grain boundaries.",cond-mat/9608141v1,cond-mat,1996-08-28 14:19:00+00:00,"[arxiv.Result.Author('M. B. Walker'), arxiv.Result.Author('J. Luettmer-Strathmann')]","J. Low Temp. Phys. 105, 483 (1996)"
1158,The twin paradox in relativity revisited,"The accepted resolution of the twin paradox in relativity states that the age
of the inertial twin `jumps' when the traveling twin undergoes his turn-around
acceleration. This resolution is based on the use of the equivalent
gravitational shift in the frame of the accelerating twin. We use the same
analysis to propose a symmetric variant of the problem with the twins
experiencing identical acceleration and deceleration phases, but which predicts
conflicting results for the age of the other twin. We also propose an
unambiguous test of the standard resolution based on the Pound-Rebka
experiment.",1204.5651v2,physics.class-ph,2012-03-20 11:50:21+00:00,[arxiv.Result.Author('Vasant Natarajan')],
1159,Molecular dynamics simulation of twin boundary effect on deformation of Cu nanopillars,"Molecular dynamics simulations performed on <110> Cu nanopillars revealed
significant difference in deformation behavior of nanopillars with and without
twin boundary. The plastic deformation in single crystal Cu nanopillar without
twin boundary was dominated by twinning, whereas the introduction of twin
boundary changed the deformation mode from twinning to slip consisting of
leading partial followed by trailing partial dislocations. This difference in
deformation behavior has been attributed to the formation of stair-rod
dislocation and its dissociation in the twinned nanopillars.",1611.01350v1,cond-mat.mtrl-sci,2016-11-04 12:37:09+00:00,"[arxiv.Result.Author('G. Sainath'), arxiv.Result.Author('B. K. Choudhary')]",Physics Letters A 379 (2015) 1902-1905
1160,Imbalance Parameterized by Twin Cover Revisited,"We study the problem of Imbalance parameterized by the twin cover of a graph.
We show that Imbalance is XP parameterized by twin cover, and FPT when
parameterized by the twin cover and the size of the largest clique outside the
twin cover. In contrast, we introduce a notion of succinct representations of
graphs in terms of their twin cover and demonstrate that Imbalance is NP-hard
in the setting of succinct representations, even for graphs that have a twin
cover of size one.",2005.03800v1,cs.DS,2020-05-07 23:58:21+00:00,"[arxiv.Result.Author('Neeldhara Misra'), arxiv.Result.Author('Harshil Mittal')]",
1161,Deformation behavior of Mg-8.5wt.%Al alloy under reverse loading investigated by in-situ neutron diffraction and elastic viscoplastic self-consistent modeling,"The cyclic deformation behavior of extruded Mg-8.5wt.%Al alloy with a
conventional extrusion texture and a modified texture is systematically
investigated by in-situ neutron diffraction and elastic viscoplastic
self-consistent (EVPSC) modeling incorporating a twinning/de-twinning (TDT)
scheme. The role of twinning and de-twinning on the deformation behavior of
Mg-8.5wt.% Al alloy is investigated in terms of the macroscopic stress-strain
response, the evolution of the activities of various deformation mechanisms,
the texture evolution, the evolution of the internal elastic strains, and the
evolution of the diffraction peak intensities. The alloy with the conventional
extrusion texture undergoes twinning during initial compression and de-twinning
during reverse tension. The same alloy does not favor twinning during initial
tension, but rather during reverse compression. The alloy with a modified
texture undergoes twinning during initial tension followed by detwinning during
reverse compression. The results provide insights into the effect of initial
texture, loading path, slip, twinning, de-twinning on the cyclic behavior of
magnesium.",1507.06384v1,cond-mat.mtrl-sci,2015-07-23 04:51:26+00:00,"[arxiv.Result.Author('Huamiao Wang'), arxiv.Result.Author('Soo Yeol Lee'), arxiv.Result.Author('Michael A Gharghouri'), arxiv.Result.Author('Peidong Wu')]","Acta Materialia 107(1) , 404-414. 2016"
1162,Researches on the Twin Prime Problem,"Twin prime number problem is mainly the structure of the twin prime numbers
and whether there are infinitely many prime twins group. In this paper, by
constructing a special cluster number set(see formula(2.3)in the paper), proves
that the number of set number of the first n columns set the intersection of
the minimum number of q is decision of the prime twins (q, q+2), and the
minimum number of series is divergent(see Theorem 2).The main rezults are
Theorem 2,Theorem 3 and Theorem 4.Prime twins so thoroughly proved there must
be infinitely many groups of twin prime conjecture.",1405.2490v2,math.GM,2014-05-11 02:21:05+00:00,[arxiv.Result.Author('Zhang Baoshan')],
1163,Variations on twins in permutations,"Let $\pi$ be a permutation of the set $[n]=\{1,2,\dots, n\}$. Two disjoint
order-isomorphic subsequences of $\pi$ are called twins. How long twins are
contained in every permutation? The well known Erd\H{o}s-Szekeres theorem
implies that there is always a pair of twins of length $\Omega(\sqrt{n})$. On
the other hand, by a simple probabilistic argument Gawron proved that for every
$n\geqslant 1$ there exist permutations with all twins having length
$O(n^{2/3})$. He conjectured that the latter bound is the correct size of the
longest twins guaranteed in every permutation. We support this conjecture by
showing that almost all permutations contain twins of length
$\Omega(n^{2/3}/\log n^{1/3})$. Recently, Bukh and Rudenko have tweaked our
proof and removed the log-factor. For completeness, we also present our version
of their proof (see Remark 1.2 below on the interrelation between the two
proofs).
  In addition, we study several variants of the problem with diverse
restrictions imposed on the twins. For instance, if we restrict attention to
twins avoiding a fixed permutation $\tau$, then the corresponding extremal
function equals $\Theta(\sqrt{n})$, provided that $\tau$ is not monotone. In
case of block twins (each twin occupies a segment) we prove that it is
$(1+o(1))\frac{\log n}{\log\log n}$, while for random permutations it is twice
as large. For twins that jointly occupy a segment (tight twins), we prove that
for every $n$ there are permutations avoiding them on all segments of length
greater than $24$.",2001.05589v3,math.CO,2020-01-15 22:56:50+00:00,"[arxiv.Result.Author('Andrzej Dudek'), arxiv.Result.Author('Jarosław Grytczuk'), arxiv.Result.Author('Andrzej Ruciński')]",
1164,The twin paradox in compact spaces,"Twins travelling at constant relative velocity will each see the other's time
dilate leading to the apparent paradox that each twin believes the other ages
more slowly. In a finite space, the twins can both be on inertial, periodic
orbits so that they have the opportunity to compare their ages when their paths
cross. As we show, they will agree on their respective ages and avoid the
paradox. The resolution relies on the selection of a preferred frame singled
out by the topology of the space.",gr-qc/0101014v1,gr-qc,2001-01-02 18:58:10+00:00,"[arxiv.Result.Author('John D. Barrow'), arxiv.Result.Author('Janna Levin')]",Phys.Rev. A63 (2001) 044104
1165,Atomistic mechanisms of twin-twin interactions in Cu nanopillars,"Twinning is an important mode of plastic deformation in metallic nanopillars.
When twinning occurs on multiple systems, it is possible that twins belonging
to different twin systems interact and forms a complex twin-twin junctions.
Revealing the atomistic mechanisms of how twin-twin interactions lead to
different twin junctions is crucial for our understanding of mechanical
behaviour of materials. In this paper, we report the atomistic mechanisms
responsible for the formation of two different twin-twin interactions/junctions
in Cu nanopillars using atomistic simulations. One junction contains two twin
boundaries along with one $\Sigma$9 boundary, while the other contains five
twin boundaries (five-fold twin). These junctions were observed during the
tensile deformation of [100] and $[1\bar1 0]$ Cu nanopillars, respectively.",2008.00785v1,cond-mat.mtrl-sci,2020-08-03 11:25:47+00:00,"[arxiv.Result.Author('G. Sainath'), arxiv.Result.Author('Sunil Goyal'), arxiv.Result.Author('A. Nagesha')]",Computational Materials Science 185 (2020) 109950
1166,Some results in the exceptional set of Twin Prime Problem,"In the paper, there are new found methods to determine the range of every
exceptional element in exceptional set, we can solve Twin primes problem and
Goldbach Conjecture problem basically.",math/0612626v1,math.GM,2006-12-21 02:01:38+00:00,"[arxiv.Result.Author('Goldtwe Anihc'), arxiv.Result.Author('Baishi Wang')]",
1167,Inertial Frames and Clock Rates,"This article revisits the historiography of the problem of inertial frames.
Specifically, the case of the twins in the clock paradox is considered to see
that some resolutions implicitly assume inertiality for the non-accelerating
twin. If inertial frames are explicitly identified by motion with respect to
the large scale structure of the universe, it makes it possible to consider the
relative inertiality of different frames.",1202.2885v1,physics.gen-ph,2012-02-13 22:21:29+00:00,[arxiv.Result.Author('Subhash Kak')],
1168,Digital Twins,"Digital Twins are one of the hottest digital trends. In this contribution we
will shortly review the concept of Digital Twins and the chances for novel
industrial applications. Mathematics are a key enabler and the impact will be
highlighted along four specific examples addressing Digital Product Twins
democratizing Design, Digital Production Twins enabling robots to mill, Digital
Production Twins driving industrialization of additive manufacturing, and
Digital Performance Twins boosting operations. We conclude the article with an
outlook on the next wave of Digital Twins, Executable Digital Twins, and will
review the associated challenges and opportunities for mathematics.",2001.09747v1,cs.CY,2020-01-03 19:20:47+00:00,"[arxiv.Result.Author('Dirk Hartmann'), arxiv.Result.Author('Herman van der Auweraer')]",
1169,Neutrinos and Lepton Flavour Violation in the Left-Right Twin Higgs Model,"We analyse the lepton sector of the Left-Right Twin Higgs Model. This model
offers an alternative way to solve the ""little hierarchy"" problem of the
Standard Model. We show that one can achieve an effective see-saw to explain
the origin of neutrino masses and that this model can accommodate the observed
neutrino masses and mixings. We have also studied the lepton flavour violation
process l_1 -> l_2 \gamma and discussed how the experimental bound from these
branching ratios constrains the scale of symmetry breaking of this Twin Higgs
model.",0711.1238v1,hep-ph,2007-11-08 10:31:25+00:00,"[arxiv.Result.Author('Asmaa Abada'), arxiv.Result.Author('Irene Hidalgo')]","Phys.Rev.D77:113013,2008"
1170,Abelian hearts of twin cotorsion pairs on extriangulated categories,"It was shown recently that the heart of a twin cotorsion pair on an
extriangulated category is semi-abelian. In this article, we consider a special
kind of hearts of twin cotorsion pairs induced by $d$-cluster tilting
subcategories in extriangulated categories. We give a necessary and sufficient
condition for such hearts to be abelian. In particular, we also can see that
such hearts are hereditary. As an application, this generalizes the work by Liu
in an exact case, thereby providing new insights in a triangulated case.",2103.08839v1,math.RT,2021-03-16 04:14:12+00:00,"[arxiv.Result.Author('Qiong Huang'), arxiv.Result.Author('Panyue Zhou')]",
1171,Deformation behaviour of body centered cubic iron nanopillars containing coherent twin boundaries,"Molecular dynamics simulations were performed to understand the role of twin
boundaries on deformation behaviour of body-centred cubic (BCC) iron (Fe)
nanopillars. The twin boundaries varying from one to five providing twin
boundary spacing in the range 8.5 - 2.8 nm were introduced perpendicular to the
loading direction. The simulation results indicated that the twin boundaries in
BCC Fe play a contrasting role during deformation under tensile and compressive
loadings. During tensile deformation, a large reduction in yield stress was
observed in twinned nanopillars compared to perfect nanopillar. However, the
yield stress exhibited only marginal variation with respect to twin boundary
spacing. On the contrary, a decrease in yield stress with increase in twin
boundary spacing was obtained during compressive deformation. This contrasting
behaviour originates from difference in operating mechanisms during yielding
and subsequent plastic deformation. It has been observed that the deformation
under tensile loading was dominated mainly by twin growth mechanism, due to
which the twin boundaries offers a negligible resistance to slip of twinning
partials. This is reflected in the negligible variation of yield stress as a
function of twin boundary spacing. On the other hand, the deformation was
dominated by nucleation and slip of full dislocations under compressive
loading. The twin boundaries offer a strong repulsive force on full
dislocations resulting in the yield stress dependence on twin boundary spacing.
Further, it has been observed that the curved twin boundary can acts as a
source for full dislocation. The occurrence of twin-twin interaction during
tensile deformation and dislocation-twin interaction during compressive
deformation were presented and discussed.",1611.05575v1,cond-mat.mtrl-sci,2016-11-17 05:48:19+00:00,"[arxiv.Result.Author('G. Sainath'), arxiv.Result.Author('B. K. Choudhary')]",Philosophical Magazine 96 (2016) 3502-3523
1172,Computation of twin-width of graphs,"Twin-width is a recently introduced graph parameter. In this article, we
compute twin-width of various finite graphs. In particular, we prove that the
twin-widths of finite graphs with 4 and 5 vertices are less than equal to 1 and
2, respectively. We show that the constructions of dual graph and line graph do
not preserve twin-width. Also, we give upper bounds for the twin-width of
King's graph and Rook's graph.",2207.14333v1,math.CO,2022-07-28 18:22:49+00:00,[arxiv.Result.Author('Kajal Das')],
1173,"The (11-22) and (-12-16) twinning modes modelled by obliquity correction of a (58deg, a+2b) prototype stretch twin","The {11-22} and {11-26} twinning modes were recently put in evidence by
Ostapovets et al. (Phil. Mag, 2017)and interpreted as {101-2}-{101-2}
double-twins formed by a simultaneous action of two twinning shears. We propose
another interpretation in which the twinning modes result from a one-step
mechanism based on the same (58deg, a+2b) prototype stretch twin. . The two
twins differ from the prototype twin by their obliquity correction. The results
are compared with the classical theory of twinning and with Westlake-Rosenbaum
model of {11-22} twinning. An unconventional twinning mode recently discovered
in a magnesium single crystal based on the same prototype twin will be the
subject of a separate publication.",1706.08338v1,cond-mat.mtrl-sci,2017-06-26 12:26:38+00:00,[arxiv.Result.Author('Cyril Cayron')],"Acta Crystallographica, 2018, A74, 44-53"
1174,Twin Cogenesis,"We investigate a cogenesis scenario within the twin Higgs setup which can
naturally explain the nature of dark matter, the cosmic coincidence puzzle,
little hierarchy problem, leptogenesis and the tiny neutrino masses. Three
heavy Majorana neutrinos are introduced to the standard model sector and the
twin sector respectively, which explain the tiny neutrino masses and generate
the lepton asymmetry and the twin lepton asymmetry at the same time. The twin
cogenesis scenario is general and applies to any viable twin Higgs model
without hard $\mathbb{Z}_2$ breaking and evading the $\Delta N_{\rm eff}$
constraint. We demonstrate twin cogenesis in two models: fraternal twin Higgs
model, and neutrino-philic twin two Higgs doublet model, a newly proposed model
to lift the twin neutrino masses with spontaneous $\mathbb{Z}_2$ breaking. The
MeV scale dark photon ensures the energy in the twin sector as well as the
symmetric component of twin sector particles can be depleted. The lightest twin
baryons are the dark matter candidates with masses approximately 5.5~GeV, which
explain naturally the amount of dark matter and visible matter in the Universe
are of the same order.",2005.06471v2,hep-ph,2020-05-13 18:00:00+00:00,"[arxiv.Result.Author('Wan-Zhe Feng'), arxiv.Result.Author('Jiang-Hao Yu')]",
1175,The Vector-like Twin Higgs,"We present a version of the twin Higgs mechanism with vector-like top
partners. In this setup all gauge anomalies automatically cancel, even without
twin leptons. The matter content of the most minimal twin sector is therefore
just two twin tops and one twin bottom. The LHC phenomenology, illustrated with
two example models, is dominated by twin glueball decays, possibly in
association with Higgs bosons. We further construct an explicit
four-dimensional UV completion and discuss a variety of UV completions relevant
for both vector-like and fraternal twin Higgs models.",1601.07181v2,hep-ph,2016-01-26 21:00:05+00:00,"[arxiv.Result.Author('Nathaniel Craig'), arxiv.Result.Author('Simon Knapen'), arxiv.Result.Author('Pietro Longhi'), arxiv.Result.Author('Matthew Strassler')]",
1176,On twinning in smectic crystals,"It is shown that mechanical twinning in smectic crystals is possible. The
structure of the boundary of twins for a small disorientation of crystallites
is determined. The periodic twin structure, which should appear at the tension
of the smectic layer, is proposed.",1304.7129v1,cond-mat.soft,2013-04-26 11:23:03+00:00,[arxiv.Result.Author('V. I. Marchenko')],"JETP Lett. 116(4), 587 (2007)"
1177,Disconnection-mediated twin embryo growth in Mg,"While deformation twinning in hexagonal close-packed metals has been widely
studied due to its substantial impact on mechanical properties, an
understanding of the detailed atomic processes associated with twin embryo
growth is still lacking. Conducting molecular dynamics simulations on Mg, we
show that the propagation of twinning disconnections emitted by basal-prismatic
interfaces controls the twin boundary motion and is the rate-limiting mechanism
during the initial growth of the twin embryo. The time needed for disconnection
propagation is related to the distance between the twin tips, with widely
spaced twin tips requiring more time for a unit twin boundary migration event
to be completed. Thus, a phenomenological model, which unifies the two
processes of disconnection and twin tip propagation, is proposed here to
provide a quantitative analysis of twin embryo growth. The model fits the
simulation data well, with two key parameters (twin tip velocity and twinning
disconnection velocity) being extracted. In addition, a linear relationship
between the ratio of twinning disconnection velocity to twin tip velocity and
the applied shear stress is observed. Using an example of twin growth in a
nanoscale single crystal from the recent literature, we find that our molecular
dynamics simulations and analytical model are in good agreement with
experimental data.",1909.11649v2,cond-mat.mtrl-sci,2019-09-25 17:53:57+00:00,"[arxiv.Result.Author('Yang Hu'), arxiv.Result.Author('Vladyslav Turlo'), arxiv.Result.Author('Irene J. Beyerlein'), arxiv.Result.Author('Subhash Mahajan'), arxiv.Result.Author('Enrique J. Lavernia'), arxiv.Result.Author('Julie M. Schoenung'), arxiv.Result.Author('Timothy J. Rupert')]",
1178,"Exceptional Prime Number Twins, Triplets and Multiplets","A classification of twin primes implies special twin primes. When applied to
triplets, it yields exceptional prime number triplets. These generalize
yielding exceptional prime number multiplets.",1102.3075v1,math.NT,2011-02-15 14:03:25+00:00,[arxiv.Result.Author('H. J. Weber')],
1179,New Insights on Stacking Fault Behavior in Twin Induced Plasticity from Meta-Atom Molecular Dynamics Simulations,"There is growing interest in promoting deformation twinning for plasticity in
advanced materials, as highly organized twin boundaries are beneficial to
better strength-ductility combination in contrast to disordered grain
boundaries. Twinning deformation typically involves the kinetics of stacking
faults, its interaction with dislocations, and dislocation - twin boundary
interactions. While the latter has been intensively investigated, the dynamics
of stacking faults has been less known. In this work, we report several new
insights on the stacking fault behavior in twin induced plasticity from our
meta-atom molecular dynamics simulation: The stacking fault interactions are
dominated by dislocation reactions taking place spontaneously, different from
the proposed mechanism in literatures; The competition among generating a
single stacking fault, a twinning partial and a trailing partial dislocation is
dependent on a unique parameter, i.e. stacking fault energy, which in turn
determines deformation twinning behaviors. The complex twin-slip and
twin-dislocation interactions demonstrate the dual role of deformation twins as
both dislocation barrier and storage, potentially contributing to the high
strength and ductility of advanced materials like TWIP steels where deformation
twinning dominated plasticity accounts for the superb strength-ductility
combination.",1604.00579v1,cond-mat.mtrl-sci,2016-04-03 01:03:50+00:00,"[arxiv.Result.Author('Peng Wang'), arxiv.Result.Author('Shaofeng Xu'), arxiv.Result.Author('Jiabin Liu'), arxiv.Result.Author('Xiaoyan Li'), arxiv.Result.Author('Yujie Wei'), arxiv.Result.Author('Hongtao Wang'), arxiv.Result.Author('Huajian Gao'), arxiv.Result.Author('Wei Yang')]",
1180,Deformation twin nucleation and twin variant selection in single crystal magnesium as a function of strain rate,"Deformation twinning is an important deformation mechanism in a variety of
materials, including metals and ceramics. This deformation mechanism is
particularly important in low-symmetry hexagonal close-packed (hcp) metals such
as Magnesium (Mg), Zirconium (Zr) and Titanium (Ti). Extension twins in Mg, Zr
and Ti can accommodate considerable plastic deformation as they grow. Thus, the
rate and the mode of twinning greatly influences the mechanical behavior
including strength and ductility. Herein, we study deformation twinning in
terms of nucleation, twinning mode and variant selection as a function of
strain rate in Mg single crystal (considered as a model material). We show that
twin variant selection is sensitive to the loading rate, with more twin
variants nucleating at the dynamic strain rates. Low Schmid factor twin
variants (one of them being a double extension twin variant) were also found at
the dynamic strain rates. Further at high strain rates, the first twins
generated do not thicken beyond a critical width. Instead, plasticity proceeds
with nucleation of second generation twins from the primary twin boundaries.
The rates of area/volume fraction evolution of both generations of twins are
found to be similar.",1801.10252v2,physics.app-ph,2018-01-30 23:12:03+00:00,"[arxiv.Result.Author('Kavan Hazeli'), arxiv.Result.Author('Vignesh Kannan'), arxiv.Result.Author('Owen Kingstedt'), arxiv.Result.Author('Guruswami Ravichandran'), arxiv.Result.Author('KT Ramesh')]",
1181,Twins: BFT Systems Made Robust,"This paper presents Twins, an automated unit test generator of Byzantine
attacks. Twins implements three types of Byzantine behaviors: (i) leader
equivocation, (ii) double voting, and (iii) losing internal state such as
forgetting 'locks' guarding voted values. To emulate interesting attacks by a
Byzantine node, it instantiates twin copies of the node instead of one, giving
both twins the same identities and network credentials. To the rest of the
system, the twins appear indistinguishable from a single node behaving in a
'questionable' manner. Twins can systematically generate Byzantine attack
scenarios at scale, execute them in a controlled manner, and examine their
behavior. Twins scenarios iterate over protocol rounds and vary the
communication patterns among nodes. Twins runs in a production setting within
DiemBFT where it can execute 44M Twins-generated scenarios daily. Whereas the
system at hand did not manifest errors, subtle safety bugs that were
deliberately injected for the purpose of validating the implementation of Twins
itself were exposed within minutes. Twins can prevent developers from
regressing correctness when updating the codebase, introducing new features, or
performing routine maintenance tasks. Twins only requires a thin wrapper over
DiemBFT, we thus envision other systems using it. Building on this idea, one
new attack and several known attacks against other BFT protocols were
materialized as Twins scenarios. In all cases, the target protocols break
within fewer than a dozen protocol rounds, hence it is realistic for the Twins
approach to expose the problems.",2004.10617v2,cs.CR,2020-04-22 14:59:04+00:00,"[arxiv.Result.Author('Shehar Bano'), arxiv.Result.Author('Alberto Sonnino'), arxiv.Result.Author('Andrey Chursin'), arxiv.Result.Author('Dmitri Perelman'), arxiv.Result.Author('Zekun Li'), arxiv.Result.Author('Avery Ching'), arxiv.Result.Author('Dahlia Malkhi')]",
1182,Compact integral manifolds of differential systems,"The boundedness tests for the number of compact integral manifolds of
autonomous ordinary differential systems, of autonomous total differential
systems, of linear systems of partial differential equations, of Pfaff systems
of equations, and of systems of exterior differential equations are proved.",1009.2998v1,math.DS,2010-09-15 19:06:37+00:00,[arxiv.Result.Author('V. N. Gorbuzov')],
1183,Morphisms of Networks of Hybrid Open Systems,"This thesis (defended 10/07/2019) develops a theory of networks of hybrid
open systems and morphisms. It builds upon a framework of networks of
continuous-time open systems as product and interconnection. We work out
categorical notions for hybrid systems, deterministic hybrid systems, hybrid
open systems, networks of hybrid open systems, and morphisms of networks of
hybrid open systems.
  We also develop categorical notions for abstract systems, abstract open
systems, networks of abstract open systems, and morphisms of networks of
abstract open systems. We show that a collection of relations holding among
pairs of systems induces a relation between interconnected systems. We use this
result for abstract systems to prove a corresponding result for networks of
hybrid systems.
  This result translates as saying that our procedure for building networks
preserves morphisms of open systems: a collection of morphisms of (sub)systems
is sent to a morphism of networked systems. We thus both justify our formalism
and concretize the intuition that a network is a collection of systems pieced
together in a certain way.",1911.09048v2,math.DS,2019-11-20 17:20:41+00:00,[arxiv.Result.Author('James Schmidt')],
1184,First integrals of ordinary linear differential systems,"The spectral method for building first integrals of ordinary linear
differential systems is elaborated. Using this method, we obtain bases of first
integrals for linear differential systems with constant coefficients, for
linear nonautonomous differential systems integrable in closed form (algebraic
reducible systems, triangular systems, the Lappo-Danilevskii systems), and for
reducible ordinary differential systems with respect to various transformation
groups.",1201.4141v1,math.DS,2012-01-19 18:45:08+00:00,"[arxiv.Result.Author('V. N. Gorbuzov'), arxiv.Result.Author('A. F. Pranevich')]",
1185,Complex Systems + Systems Engineering = Complex Systems Engineeri,"One may define a complex system as a system in which phenomena emerge as a
consequence of multiscale interaction among the system's components and their
environments. The field of Complex Systems is the study of such
systems--usually naturally occurring, either bio-logical or social. Systems
Engineering may be understood to include the conceptualising and building of
systems that consist of a large number of concurrently operating and
interacting components--usually including both human and non-human elements. It
has become increasingly apparent that the kinds of systems that systems
engineers build have many of the same multiscale characteristics as those of
naturally occurring complex systems. In other words, systems engineering is the
engineering of complex systems. This paper and the associated panel will
explore some of the connections between the fields of complex systems and
systems engineering.",cs/0603127v1,cs.MA,2006-03-30 22:58:12+00:00,[arxiv.Result.Author('Russ Abbott')],
1186,Systems of quotients of Lie triple systems,"In this paper, we introduce the notion of system of quotients of Lie triple
systems and investigate some properties which can be lifted from a Lie triple
system to its systems of quotients. We relate the notion of Lie triple system
of Martindale-like quotients with respect to a filter of ideals and the notion
of system of quotients, and prove that the system of quotients of a Lie triple
system is equivalent to the algebra of quotients of a Lie algebra in some
sense, and these allow us to construct the maximal system of quotients for
nondegenerate Lie triple systems.",1304.7340v1,math.RA,2013-04-27 07:10:20+00:00,"[arxiv.Result.Author('Yao Ma'), arxiv.Result.Author('Liangyun Chen'), arxiv.Result.Author('Jie Lin')]","Communications in Algebra, 42(2014)(8), 3339-3349"
1187,Equivariant Filter Design for Kinematic Systems on Lie Groups,"It is known that invariance and equivariance properties for systems on Lie
groups can be exploited in the design of high performance and robust observers
and filters for real-world robotic systems. This paper proposes an analysis
framework that allows any kinematic system on a Lie group to be embedded in a
natural manner into an equivariant kinematic system. This framework allows us
to characterise the properties of, and relationships between, invariant
systems, group affine systems, and equivariant systems. We propose a new filter
design, the Equivariant Filter (EqF), that exploits the equivariance properties
of the system embedding and can be applied to any kinematic system on a Lie
group.",2004.00828v2,eess.SY,2020-04-02 05:39:17+00:00,"[arxiv.Result.Author('Robert Mahony'), arxiv.Result.Author('Jochen Trumpf')]",
1188,Linearly repetitive Delone systems have a finite number of non periodic Delone system factors,"We prove linearly repetitive Delone systems have finitely many Delone system
factors up to conjugacy. This result is also applicable to linearly repetitive
tiling systems.",0807.2907v1,math.DS,2008-07-18 14:17:40+00:00,"[arxiv.Result.Author('Maria Isabel Cortez'), arxiv.Result.Author('Fabien Durand'), arxiv.Result.Author('Samuel Petite')]",
1189,Integral equivalence of multidimensional differential systems,"The bases of the theory of integrals for multidimensional differential
systems are stated. The integral equivalence of total differential systems,
linear homogeneous systems of partial differential equations, and Pfaff systems
of equations is established.",0909.3220v1,math.DS,2009-09-17 13:51:38+00:00,[arxiv.Result.Author('V. N. Gorbuzov')],
1190,Fractional Multidimensional System,"The multidimensional ($n$-D) systems described by Roesser model are presented
in this paper. These $n$-D systems consist of discrete systems and continuous
fractional order systems with fractional order $\nu$, $0<\nu<1$. The stability
and Robust stability of such $n$-D systems are investigated.",1704.08427v1,math.OC,2017-04-27 04:05:56+00:00,"[arxiv.Result.Author('Xiaogang Zhu'), arxiv.Result.Author('Junguo Lu')]",
1191,A new type of 4D Hybrid Chaos Systems,"In this paper a new type of chaotic system based on sin and logistic systems
is introduced. Also the behavior of this new system is studied by using various
tests. The results of these tests indicate the appropriate behavior for the
proposed new system.",2101.09493v1,math.DS,2021-01-23 12:39:53+00:00,[arxiv.Result.Author('Reza Parvaz')],
1192,Cubical token systems,"The paper deals with combinatorial and stochastic structures of cubical token
systems. A cubical token system is an instance of a token system, which in turn
is an instance of a transition system. It is shown that some basic results of
combinatorial and stochastic parts of media theory hold almost in identical
form for cubical token systems, although some underlying concepts are quite
different. A representation theorem for a cubical token system is established
asserting that the graph of such a system is cubical.",math/0612696v1,math.CO,2006-12-22 11:36:36+00:00,[arxiv.Result.Author('Sergei Ovchinnikov')],
1193,Separable bi-Hamiltonian systems with quadratic in momenta first integrals,"Geometric separability theory of Gel'fand-Zakharevich bi-Hamiltonian systems
on Riemannian manifolds is reviewed and developed. Particular attention is paid
to the separability of systems generated by the so-called special conformal
Killing tensors, i.e. Benenti systems. Then, infinitely many new classes of
separable systems are constructed by appropriate deformations of Benenti class
systems. All such systems can be lifted to the Gel'fand-Zakharevich
bi-Hamiltonian form.",nlin/0312025v2,nlin.SI,2003-12-11 12:21:56+00:00,[arxiv.Result.Author('Maciej Blaszak')],
1194,A Step towards an Easy Interconversion of Various Number Systems,"Any system that is used for naming or representing numbers is a number
system, also known as numeral system. The modern civilization is familiar with
decimal number system using ten digits. However digital devices and computers
use binary number system instead of decimal number system, using only two
digits namely, 0 and 1 based on the fundamental concept of the decimal number
system. Various other number systems also used this fundamental concept of
decimal number system, for example octal system and hexadecimal number systems
using eight and sixteen digits respectively. The knowledge of number systems
and their inter conversion is essential for understanding of computers. More
over, successful programming for digital devices requires a precise
understanding of data formats, number systems and their inter conversion. The
inter conversion (a process in which things are each converted into the other)
of number system requires allot of time and techniques to expertise. In this
paper the interconversion of four most common number systems is taken under the
consideration in tabulated form. It is a step towards the easy interconversion
of theses number systems to understand as well as memorise it. The four number
systems are binary, octal, decimal and hexadecimal.",1107.1663v1,cs.DM,2011-07-08 15:59:35+00:00,"[arxiv.Result.Author('Shahid Latif'), arxiv.Result.Author('Rahat Ullah'), arxiv.Result.Author('Hamid Jan')]",
1195,Nonlinear Modal Decoupling of Multi-Oscillator Systems with Applications to Power Systems,"Many natural and manmade dynamical systems that are modeled as large
nonlinear multi-oscillator systems like power systems are hard to analyze. For
such a system, we propose a nonlinear modal decoupling (NMD) approach inversely
constructing as many decoupled nonlinear oscillators as the system oscillation
modes so that individual decoupled oscillators can easily be analyzed to infer
dynamics and stability of the original system. The NMD follows a similar idea
to the normal form except that we eliminate inter-modal terms but allow
intra-modal terms of desired nonlinearities in decoupled systems, so decoupled
systems can flexibly be shaped into desired forms of nonlinear oscillators. The
NMD is then applied to power systems towards two types of nonlinear
oscillators, i.e. the single-machine-infinite-bus (SMIB) systems and a proposed
non-SMIB oscillator. Numerical studies on a 3-machine 9-bus system and New
England 10-machine 39-bus system show that (i) decoupled oscillators keep a
majority of the original system modal nonlinearities and the NMD provides a
bigger validity region than the normal form, and (ii) decoupled non-SMIB
oscillators may keep more authentic dynamics of the original system than
decoupled SMIB systems.",1611.04553v1,cs.SY,2016-11-14 20:18:36+00:00,"[arxiv.Result.Author('Bin Wang'), arxiv.Result.Author('Kai Sun'), arxiv.Result.Author('Wei Kang')]",
1196,Variability and Evolution in Systems of Systems,"In this position paper (1) we discuss two particular aspects of Systems of
Systems, i.e., variability and evolution. (2) We argue that concepts from
Product Line Engineering and Software Evolution are relevant to Systems of
Systems Engineering. (3) Conversely, concepts from Systems of Systems
Engineering can be helpful in Product Line Engineering and Software Evolution.
Hence, we argue that an exchange of concepts between the disciplines would be
beneficial.",1311.3627v1,cs.SE,2013-11-14 19:40:33+00:00,[arxiv.Result.Author('Goetz Botterweck')],"EPTCS 133, 2013, pp. 8-23"
1197,An Networked HIL Simulation System for Modeling Large-scale Power Systems,"This paper presents a network hardware-in-the-loop (HIL) simulation system
for modeling large-scale power systems. Researchers have developed many HIL
test systems for power systems in recent years. Those test systems can model
both microsecond-level dynamic responses of power electronic systems and
millisecond-level transients of transmission and distribution grids. By
integrating individual HIL test systems into a network of HIL test systems, we
can create large-scale power grid digital twins with flexible structures at
required modeling resolution that fits for a wide range of system operating
conditions. This will not only significantly reduce the need for field tests
when developing new technologies but also greatly shorten the model development
cycle. In this paper, we present a networked OPAL-RT based HIL test system for
developing transmission-distribution coordinative Volt-VAR regulation
technologies as an example to illustrate system setups, communication
requirements among different HIL simulation systems, and system connection
mechanisms. Impacts of communication delays, information exchange cycles, and
computing delays are illustrated. Simulation results show that the performance
of a networked HIL test system is satisfactory.",2002.07257v1,eess.SY,2020-02-17 21:27:55+00:00,"[arxiv.Result.Author('Fuhong Xie'), arxiv.Result.Author('Catie McEntee'), arxiv.Result.Author('Mingzhi Zhang'), arxiv.Result.Author('Ning Lu'), arxiv.Result.Author('Xinda Ke'), arxiv.Result.Author('Mallikarjuna R. Vallem'), arxiv.Result.Author('Nader Samaan')]",
1198,Using Structure-Behavior Coalescence Method for Systems Definition 2.0,"Systems definition is an artifact created by humans to describe what a system
is. A system has been defined, by systems definition 1.0, hopefully to be an
integrated whole, embodied in its components, their interrelationships with
each other and the environment, and the principles and guidelines governing its
design and evolution. This systems definition 1.0 defining the system possesses
one cardinal deficiency. The deficiency comes from that it does not describe
the integration of systems structure and systems behavior. Structure-behavior
coalescence (SBC) architecture provides an elegant way to integrate the
structure and behavior of a system. A system is therefore redefined, by systems
definition 2.0, truly to be an integrated whole, using the SBC architecture,
embodied in its assembled components, their interactions with each other and
the environment, and the principles and guidelines governing its design and
evolution. Since systems definition 2.0 describes the integration of systems
structure and systems behavior, definitely it is able to form an integrated
whole of a system. In this situation, systems definition 2.0 is fully capable
of defining a system.",2110.08998v4,cs.SE,2021-10-18 03:34:27+00:00,[arxiv.Result.Author('William S. Chao')],
1199,Information-theoretic multi-time-scale partially observable systems with relevance to leukemia treatment,"Inspired by a leukemia treatment challenge, we study a partially observable
non-linear stochastic system with unknown parameters, where the given time
scales of the states and measurements may be distinct. Key words: Stochastic
control; Non-linear systems; Partially observable systems; System
identification; Biomedical systems.",2204.12604v1,eess.SY,2022-04-26 21:35:36+00:00,"[arxiv.Result.Author('Margaret P. Chapman'), arxiv.Result.Author('Emily Jensen'), arxiv.Result.Author('Steven M. Chan'), arxiv.Result.Author('Laurent Lessard')]",
1200,Delocalization of a Dynamic System with Preservation or Self-Resurection of Informational Functionality. Ghost machines or can a system survive its destruction,"We analyzed the problem of a dynamic system delocalization due to changes in
the system environment - universe and system architecture. We developed a
Delocalization of Dynamic Cores model to analyze the migration of functional
properties in open information and dynamic systems undergoing architecture
transition and modifications. Information geometry and topological formalisms
are proposed to analyze informational dynamic systems. Different physical and
holographic models are proposed to construct systems able to conserve their
functional properties under delocalization transition. We found several
constraints for the system environment - universe which conserve the dynamic
core system functionality under transition from localized explicit
implementation of functions to the implicit distributed implementation.",nlin/0701026v1,nlin.AO,2007-01-13 09:42:25+00:00,"[arxiv.Result.Author('Vadim Astakhov'), arxiv.Result.Author('Tamara Astakhova')]",
1201,Non-Hamiltonian systems separable by Hamilton-Jacobi method,"We show that with every separable calssical Stackel system of Benenti type on
a Riemannian space one can associate, by a proper deformation of the metric
tensor, a multi-parameter family of non-Hamiltonian systems on the same space,
sharing the same trajectories and related to the seed system by appropriate
reciprocal transformations. These system are known as bi-cofactor systems and
are integrable in quadratures as the seed Hamiltonian system is. We show that
with each class of bi-cofactor systems a pair of separation curves can be
related. We also investigate conditions under which a given flat bi-cofactor
system can be deformed to a family of geodesically equivalent flat bi-cofactor
systems.",0707.1113v1,nlin.SI,2007-07-07 20:24:28+00:00,"[arxiv.Result.Author('Krzysztof Marciniak'), arxiv.Result.Author('Maciej Blaszak')]",
1202,Limiting Risk by Turning Manifest Phantoms into Evil Zombies,"Drawing a random sample of ballots to conduct a risk-limiting audit generally
requires knowing how the ballots cast in an election are organized into groups,
for instance, how many containers of ballots there are in all and how many
ballots are in each container. A list of the ballot group identifiers along
with number of ballots in each group is called a ballot manifest. What if the
ballot manifest is not accurate? Surprisingly, even if ballots are known to be
missing from the manifest, it is not necessary to make worst-case assumptions
about those ballots--for instance, to adjust the margin by the number of
missing ballots--to ensure that the audit remains conservative. Rather, it
suffices to make worst-case assumptions about the individual randomly selected
ballots that the audit cannot find. This observation provides a simple
modification to some risk-limiting audit procedures that makes them
automatically become more conservative if the ballot manifest has errors. The
modification--phantoms to evil zombies (~2EZ)--requires only an upper bound on
the total number of ballots cast. ~2EZ makes the audit P-value stochastically
larger than it would be had the manifest been accurate, automatically requiring
more than enough ballots to be audited to offset the manifest errors. This
ensures that the true risk limit remains smaller than the nominal risk limit.
On the other hand, if the manifest is in fact accurate and the upper bound on
the total number of ballots equals the total according to the manifest, ~2EZ
has no effect at all on the number of ballots audited nor on the true risk
limit.",1207.3413v1,stat.AP,2012-07-14 11:26:02+00:00,"[arxiv.Result.Author('Jorge H. Banuelos'), arxiv.Result.Author('Philip B. Stark')]",
1203,A Complete Enumeration of Ballot Permutations Avoiding Sets of Small Patterns,"Permutations whose prefixes contain at least as many ascents as descents are
called ballot permutations. Lin, Wang, and Zhao have previously enumerated
ballot permutations avoiding small patterns and have proposed the problem of
enumerating ballot permutations avoiding a pair of permutations of length $3$.
We completely enumerate ballot permutations avoiding two patterns of length $3$
and we relate these avoidance classes with their respective recurrence
relations and formulas, which leads to an interesting bijection between ballot
permutations avoiding $132$ and $312$ with left factors of Dyck paths. In
addition, we also conclude the Wilf-classification of ballot permutations
avoiding sets of two patterns of length $3$, and we then extend our results to
completely enumerate ballot permutations avoiding three patterns of length $3$.",2209.06087v1,math.CO,2022-09-13 15:37:45+00:00,[arxiv.Result.Author('Nathan Sun')],
1204,Can Voters Detect Errors on Their Printed Ballots? Absolutely,"There is still debate on whether voters can detect malicious changes in their
printed ballot after making their selections on a Ballot Marking Device (BMD).
In this study, we altered votes on a voter's ballot after they had made their
selections on a BMD. We then required them to examine their ballots for any
changes from the slate they used to vote. Overall accuracy was exceptionally
high. Participants saw 1440 total contests, and of those 1440, there were a
total of 4 errors, so total accuracy was 99.8%. Participants were able to
perform with near-perfect accuracy regardless of ballot length, ballot type,
number of altered races, and location of altered races. Detection performance
was extremely robust. We conclude that with proper direction and resources,
voters can be near-perfect detectors of ballot changes on printed paper ballots
after voting with a BMD. This finding has significant implications for the
voting community as BMD use continues to grow. Research should now focus on
identifying administrative and behavioral methods that will prompt and
encourage voters to check their BMD-generated ballots before they drop them in
the ballot box.",2204.09780v1,cs.HC,2022-04-20 20:40:32+00:00,"[arxiv.Result.Author('Philip Kortum'), arxiv.Result.Author('Michael D. Byrne'), arxiv.Result.Author('Chidera O. Azubike'), arxiv.Result.Author('Laura E. Roty')]",
1205,Ballot tilings and increasing trees,"We study enumerations of Dyck and ballot tilings, which are tilings of a
region determined by two Dyck or ballot paths. We give bijective proofs to two
formulae of enumerations of Dyck tilings through Hermite histories. We show
that one of the formulae is equal to a certain Kazhdan--Lusztig polynomial. For
a ballot tiling, we establish formulae which are analogues of formulae for Dyck
tilings. Especially, the generating functions have factorized expressions. The
key tool is a planted plane tree and its increasing labellings. We also
introduce a generalized perfect matching which is bijective to an Hermite
history for a ballot tiling. By combining these objects, we obtain various
expressions of a generating function of ballot tilings with a fixed lower path.",1705.06434v1,math-ph,2017-05-18 06:46:09+00:00,[arxiv.Result.Author('Keiichi Shigechi')],
1206,Sophisticated Attacks on Decoy Ballots: The Devil's Menu and the Market for Lemons,"Decoy ballots do not count in election outcomes, but otherwise they are
indistinguishable from real ballots. By means of a game-theoretical model, we
show that decoy ballots may not provide effective protection against a
malevolent adversary trying to buy real ballots. If the citizenry is divided
into subgroups (or districts), the adversary can construct a so-called ""Devil's
Menu"" consisting of several prices. In equilibrium, the adversary can buy the
real ballots of any strict subset of districts at a price corresponding to the
willingness to sell on the part of the citizens holding such ballots. By
contrast, decoy voters are trapped into selling their ballots at a low, or even
negligible, price. Blowing up the adversary's budget by introducing decoy
ballots may thus turn out to be futile. The Devil's Menu can also be applied to
the well-known ""Lemons Problem"".",1712.05477v1,cs.GT,2017-12-14 23:54:58+00:00,"[arxiv.Result.Author('Hans Gersbach'), arxiv.Result.Author('Akaki Mamageishvili'), arxiv.Result.Author('Oriol Tejada')]",
1207,The ATHENA Class of Risk-Limiting Ballot Polling Audits,"The main risk-limiting ballot polling audit in use today, BRAVO, is designed
for use when single ballots are drawn at random and a decision regarding
whether to stop the audit or draw another ballot is taken after each ballot
draw (ballot-by-ballot (B2) audits). On the other hand, real ballot polling
audits draw many ballots in a single round before determining whether to stop
(round-by-round (R2) audits). We show that BRAVO results in significant
inefficiency when directly applied to real R2 audits. We present the ATHENA
class of R2 stopping rules, which we show are risk-limiting if the round
schedule is pre-determined (before the audit begins). We prove that each rule
is at least as efficient as the corresponding BRAVO stopping rule applied at
the end of the round. We have open-source software libraries implementing most
of our results.
  We show that ATHENA halves the number of ballots required, for all state
margins in the 2016 US Presidential election and a first round with $90\%$
stopping probability, when compared to BRAVO (stopping rule applied at the end
of the round). We present simulation results supporting the 90% stopping
probability claims and our claims for the risk accrued in the first round.
Further, ATHENA reduces the number of ballots by more than a quarter for low
margins, when compared to the BRAVO stopping rule applied on ballots in
selection order. This implies that keeping track of the order when drawing
ballots R2 is not beneficial, because ATHENA is more efficient even without
information on selection order. These results are significant because current
approaches to real ballot polling election audits use the B2 BRAVO rules,
requiring about twice as much work on the part of election officials. Applying
the rules in selection order requires fewer ballots, but keeping track of the
order, and entering it into audit software, adds to the effort.",2008.02315v5,cs.CR,2020-08-05 18:47:37+00:00,"[arxiv.Result.Author('Filip Zagórski'), arxiv.Result.Author('Grant McClearn'), arxiv.Result.Author('Sarah Morin'), arxiv.Result.Author('Neal McBurnett'), arxiv.Result.Author('Poorvi L. Vora')]",
1208,$k$-Cut: A Simple Approximately-Uniform Method for Sampling Ballots in Post-Election Audits,"We present an approximate sampling framework and discuss how risk-limiting
audits can compensate for these approximations, while maintaining their
""risk-limiting"" properties. Our framework is general and can compensate for
counting mistakes made during audits.
  Moreover, we present and analyze a simple approximate sampling
method,""$k$-cut"", for picking a ballot randomly from a stack, without counting.
Our method involves doing $k$ ""cuts"", each involving moving a random portion of
ballots from the top to the bottom of the stack, and then picking the ballot on
top. Unlike conventional methods of picking a ballot at random, $k$-cut does
not require identification numbers on the ballots or counting many ballots per
draw. We analyze how close the distribution of chosen ballots is to the uniform
distribution, and design different mitigation procedures. We show that $k=6$
cuts is enough for an risk-limiting election audit, based on empirical data,
which would provide a significant increase in efficiency.",1811.08811v3,cs.DS,2018-11-21 16:26:33+00:00,"[arxiv.Result.Author('Mayuri Sridhar'), arxiv.Result.Author('Ronald L. Rivest')]",
1209,Bernoulli Ballot Polling: A Manifest Improvement for Risk-Limiting Audits,"We present a method and software for ballot-polling risk-limiting audits
(RLAs) based on Bernoulli sampling: ballots are included in the sample with
probability $p$, independently. Bernoulli sampling has several advantages: (1)
it does not require a ballot manifest; (2) it can be conducted independently at
different locations, rather than requiring a central authority to select the
sample from the whole population of cast ballots or requiring stratified
sampling; (3) it can start in polling places on election night, before margins
are known. If the reported margins for the 2016 U.S. Presidential election are
correct, a Bernoulli ballot-polling audit with a risk limit of 5% and a
sampling rate of $p_0 = 1\%$ would have had at least a 99% probability of
confirming the outcome in 42 states. (The other states were more likely to have
needed to examine additional ballots.) Logistical and security advantages that
auditing in the polling place affords may outweigh the cost of examining more
ballots than some other methods might require.",1812.06361v1,stat.AP,2018-12-15 21:57:23+00:00,"[arxiv.Result.Author('Kellie Ottoboni'), arxiv.Result.Author('Matthew Bernhard'), arxiv.Result.Author('J. Alex Halderman'), arxiv.Result.Author('Ronald L. Rivest'), arxiv.Result.Author('Philip B. Stark')]",
1210,"Symmetric Dyck tilings, ballot tableaux and tree-like tableaux of shifted shapes","Symmetric Dyck tilings and ballot tilings are certain tilings in the region
surrounded by two ballot paths. We study the relations of combinatorial objects
which are bijective to symmetric Dyck tilings such as labeled trees, Hermite
histories, and perfect matchings. We also introduce two operations on labeled
trees for symmetric Dyck tilings: symmetric Dyck tiling strip (symDTS) and
symmetric Dyck tiling ribbon (symDTR). We give two definitions of Hermite
histories for symmetric Dyck tilings, and show that they are equivalent by use
of the correspondence between symDTS operation and an Hermite history. Since
ballot tilings form a subset in the set of symmetric Dyck tilings, we construct
an inclusive map from labeled trees for ballot tilings to labeled trees for
symmetric Dyck tilings. By this inclusive map, the results for symmetric Dyck
tilings can be applied to those of ballot tilings. We introduce and study the
notions of ballot tableaux and tree-like tableaux of shifted shapes, which are
generalizations of Dyck tableaux and tree-like tableaux, respectively. The
correspondence between ballot tableaux and tree-like tableaux of shifted shapes
is given by using the symDTR operation and the structure of labeled trees for
symmetric Dyck tilings.",2011.07296v1,math.CO,2020-11-14 13:15:14+00:00,[arxiv.Result.Author('Keiichi Shigechi')],
1211,SOBA: Secrecy-preserving Observable Ballot-level Audit,"SOBA is an approach to election verification that provides observers with
justifiably high confidence that the reported results of an election are
consistent with an audit trail (""ballots""), which can be paper or electronic.
SOBA combines three ideas: (1) publishing cast vote records (CVRs) separately
for each contest, so that anyone can verify that each reported contest outcome
is correct, if the CVRs reflect voters' intentions with sufficient accuracy;
(2) shrouding a mapping between ballots and the CVRs for those ballots to
prevent the loss of privacy that could occur otherwise; (3) assessing the
accuracy with which the CVRs reflect voters' intentions for a collection of
contests while simultaneously assessing the integrity of the shrouded mapping
between ballots and CVRs by comparing randomly selected ballots to the CVRs
that purport to represent them. Step (1) is related to work by the Humboldt
County Election Transparency Project, but publishing CVRs separately for
individual contests rather than images of entire ballots preserves privacy.
Step (2) requires a cryptographic commitment from elections officials.
Observers participate in step (3), which relies on the ""super-simple
simultaneous single-ballot risk-limiting audit."" Step (3) is designed to reveal
relatively few ballots if the shrouded mapping is proper and the CVRs
accurately reflect voter intent. But if the reported outcomes of the contests
differ from the outcomes that a full hand count would show, step (3) is
guaranteed to have a large chance of requiring all the ballots to be counted by
hand, thereby limiting the risk that an incorrect outcome will become official
and final.",1105.5803v2,stat.AP,2011-05-29 17:00:20+00:00,"[arxiv.Result.Author('Josh Benaloh'), arxiv.Result.Author('Douglas Jones'), arxiv.Result.Author('Eric Lazarus'), arxiv.Result.Author('Mark Lindeman'), arxiv.Result.Author('Philip B. Stark')]",
1212,"Voter Verification of BMD Ballots Is a Two-Part Question: Can They? Mostly, They Can. Do They? Mostly, They Don't","The question of whether or not voters actually verify ballots produced by
ballot marking devices (BMDs) is presently the subject of some controversy.
Recent studies (e.g., Bernhard, et al. 2020) suggest the verification rate is
low. What is not clear from previous research is whether this is more a result
of voters being unable to do so accurately or whether this is because voters
simply choose not to attempt verification in the first place. In order to
understand this problem, we conducted an experiment in which 108 participants
participated in a mock election where the BMD displayed the voters' true
choices, but then changed a subset of those choices on the printed ballot. The
design of the printed ballot, the length of the ballot, the number of changes
that were made to the ballot, the location of those changes, and the
instructions provided to the voters were manipulated as part of the experiment.
Results indicated that of those voters who chose to examine the printed ballot,
76% detected anomalies, indicating that voters can reliably detect errors on
their ballot if they will simply review it. This suggests that administrative
remedies, rather than attempts to alter fundamental human perceptual
capabilities, could be employed to encourage voters to check their ballots,
which could prove as an effective countermeasure.",2003.04997v1,cs.HC,2020-03-10 21:06:42+00:00,"[arxiv.Result.Author('Philip Kortum'), arxiv.Result.Author('Michael D. Byrne'), arxiv.Result.Author('Julie Whitmore')]",
1213,Next Steps for the Colorado Risk-Limiting Audit (CORLA) Program,"Colorado conducted risk-limiting tabulation audits (RLAs) across the state in
2017, including both ballot-level comparison audits and ballot-polling audits.
Those audits only covered contests restricted to a single county; methods to
efficiently audit contests that cross county boundaries and combine ballot
polling and ballot-level comparisons have not been available.
  Colorado's current audit software (RLATool) needs to be improved to audit
these contests that cross county lines and to audit small contests efficiently.
  This paper addresses these needs. It presents extremely simple but
inefficient methods, more efficient methods that combine ballot polling and
ballot-level comparisons using stratified samples, and methods that combine
ballot-level comparison and variable-size batch comparison audits in a way that
does not require stratified sampling.
  We conclude with some recommendations, and illustrate our recommended method
using examples that compare them to existing approaches. Exemplar open-source
code and interactive Jupyter notebooks are provided that implement the methods
and allow further exploration.",1803.00698v1,stat.AP,2018-03-02 03:46:37+00:00,"[arxiv.Result.Author('Mark Lindeman'), arxiv.Result.Author('Neal McBurnett'), arxiv.Result.Author('Kellie Ottoboni'), arxiv.Result.Author('Philip B. Stark')]",
1214,RAIRE: Risk-Limiting Audits for IRV Elections,"Risk-limiting post election audits guarantee a high probability of correcting
incorrect election results, independent of why the result was incorrect.
Ballot-polling audits select ballots at random and interpret those ballots as
evidence for and against the reported result, continuing this process until
either they support the recorded result, or they fall back to a full manual
recount. For elections with digitised scanning and counting of ballots, a
comparison audit compares randomly selected digital ballots with their paper
versions. Discrepancies are referred to as errors, and are used to build
evidence against or in support of the recorded result. Risk-limiting audits for
first-past-the-post elections are well understood, and used in some US
elections. We define a number of approaches to ballot-polling and comparison
risk-limiting audits for Instant Runoff Voting (IRV) elections. We show that
for almost all real elections we found, we can perform a risk-limiting audit by
looking at only a small fraction of the total ballots (assuming no errors were
made in the tallying and distribution of votes).",1903.08804v2,cs.DS,2019-03-20 06:19:10+00:00,"[arxiv.Result.Author('Michelle Blom'), arxiv.Result.Author('Peter J. Stuckey'), arxiv.Result.Author('Vanessa Teague')]",
1215,"A decomposition of ballot permutations, pattern avoidance and Gessel walks","A permutation whose any prefix has no more descents than ascents is called a
ballot permutation. In this paper, we present a decomposition of ballot
permutations that enables us to construct a bijection between ballot
permutations and odd order permutations, which proves a set-valued extension of
a conjecture due to Spiro using the statistic of peak values. This bijection
also preserves the neighbors of the largest letter in permutations and thus
resolves a refinement of Spiro' s conjecture proposed by Wang and Zhang. Our
decomposition can be extended to well-labelled positive paths, a class of
generalized ballot permutations arising from polytope theory, that were
enumerated by Bernardi, Duplantier and Nadeau. We will also investigate the
enumerative aspect of ballot permutations avoiding a single pattern of length 3
and establish a connection between 213-avoiding ballot permutations and Gessel
walks.",2103.04599v1,math.CO,2021-03-08 08:37:08+00:00,"[arxiv.Result.Author('Zhicong Lin'), arxiv.Result.Author('David G. L. Wang'), arxiv.Result.Author('Tongyuan Zhao')]",
1216,Ballot Length in Instant Runoff Voting,"Instant runoff voting (IRV) is an increasingly-popular alternative to
traditional plurality voting in which voters submit rankings over the
candidates rather than single votes. In practice, elections using IRV often
restrict the ballot length, the number of candidates a voter is allowed to rank
on their ballot. We theoretically and empirically analyze how ballot length can
influence the outcome of an election, given fixed voter preferences. We show
that there exist preference profiles over $k$ candidates such that up to $k-1$
different candidates win at different ballot lengths. We derive exact lower
bounds on the number of voters required for such profiles and provide a
construction matching the lower bound for unrestricted voter preferences.
Additionally, we characterize which sequences of winners are possible over
ballot lengths and provide explicit profile constructions achieving any
feasible winner sequence. We also examine how classic preference restrictions
influence our results--for instance, single-peakedness makes $k-1$ different
winners impossible but still allows at least $\Omega(\sqrt k)$. Finally, we
analyze a collection of 168 real-world elections, where we truncate rankings to
simulate shorter ballots. We find that shorter ballots could have changed the
outcome in one quarter of these elections. Our results highlight ballot length
as a consequential degree of freedom in the design of IRV elections.",2207.08958v3,cs.MA,2022-07-18 22:01:13+00:00,"[arxiv.Result.Author('Kiran Tomlinson'), arxiv.Result.Author('Johan Ugander'), arxiv.Result.Author('Jon Kleinberg')]",
1217,A modular eballot system - V0.6,"We consider a reasonably simple voting system which can be implemented for
web-based ballots. Simplicity, modularity and the requirement of compatibility
with current web browsers leads to a system which satisfies a set of security
requirements for a ballot system which is not complete but sufficient in many
cases. Due to weak-eligibility and vote-selling, this system cannot be used for
political or similar ballots.",cs/0611066v2,cs.CR,2006-11-15 09:33:58+00:00,[arxiv.Result.Author('Andrea Pasquinucci')],
1218,A quantum secret ballot,"The paper concerns the protection of the secrecy of ballots, so that the
identity of the voters cannot be matched with their vote. To achieve this we
use an entangled quantum state to represent the ballots. Each ballot includes
the identity of the voter, explicitly marked on the ""envelope"" containing it.
Measuring the content of the envelope yields a random number which reveals no
information about the vote. However, the outcome of the elections can be
unambiguously decided after adding the random numbers from all envelopes. We
consider a few versions of the protocol and their complexity of implementation.",quant-ph/0602087v2,quant-ph,2006-02-09 21:03:35+00:00,"[arxiv.Result.Author('Shahar Dolev'), arxiv.Result.Author('Itamar Pitowsky'), arxiv.Result.Author('Boaz Tamir')]",
1219,Ballot Paths Avoiding Depth Zero Patterns,"In a paper by Sapounakis, Tasoulas, and Tsikouras \cite{stt}, the authors
count the number of occurrences of patterns of length four in Dyck paths. In
this paper we specify in one direction and generalize in another. We only count
ballot paths that avoid a given pattern, where a ballot path stays weakly above
the diagonal $y=x$, starts at the origin, and takes steps from the set
$\{\uparrow ,\to \}=\{u,r\}$. A pattern is a finite string made from the same
step set; it is also a path. Notice that a ballot path ending at a point along
the diagonal is a Dyck path.",1004.2710v1,math.CO,2010-04-15 20:23:45+00:00,"[arxiv.Result.Author('Heinrich Niederhausen'), arxiv.Result.Author('Shaun Sullivan')]","Journal OF Combinatorial Mathematics and Combinatorial Computing,
  August 2010"
1220,Exploiting re-voting in the Helios election system,"Election systems must ensure that representatives are chosen by voters.
Moreover, each voter should have equal influence. Traditionally, this has been
achieved by permitting voters to cast at most one ballot. More recently, this
has been achieved by tallying the last ballot cast by each voter. We show this
is not achieved by the Helios election system, because an adversary can cause a
ballot other than a voter's last to be tallied. Moreover, we show how the
adversary can choose the contents of such a ballot, thus the adversary can
unduly influence the selection of representatives.",1612.04099v3,cs.CR,2016-12-13 11:07:22+00:00,"[arxiv.Result.Author('Maxime Meyer'), arxiv.Result.Author('Ben Smyth')]",
1221,A Toeplitz property of ballot permutations and odd order permutations,"We give a new semi-combinatorial proof for the equality of the number of
ballot permutations of length $n$ and the number of odd order permutations of
length $n$, which is due to Bernardi, Duplantier and Nadeau. Spiro conjectures
that the descent number of ballot permutations and certain cyclic weight of odd
order permutations of the same length are equi-distributed. We present a
bijection to establish a Toeplitz property for ballot permutations with any
fixed number of descents, and a Toeplitz property for odd order permutations
with any fixed cyclic weight. This allows us to refine Spiro's conjecture by
tracking the neighbors of the largest letter in permutations.",2001.07143v1,math.CO,2020-01-20 15:28:43+00:00,"[arxiv.Result.Author('David G. L. Wang'), arxiv.Result.Author('Jerry J. R. Zhang')]",
1222,Compact integral manifolds of differential systems,"The boundedness tests for the number of compact integral manifolds of
autonomous ordinary differential systems, of autonomous total differential
systems, of linear systems of partial differential equations, of Pfaff systems
of equations, and of systems of exterior differential equations are proved.",1009.2998v1,math.DS,2010-09-15 19:06:37+00:00,[arxiv.Result.Author('V. N. Gorbuzov')],
1223,Morphisms of Networks of Hybrid Open Systems,"This thesis (defended 10/07/2019) develops a theory of networks of hybrid
open systems and morphisms. It builds upon a framework of networks of
continuous-time open systems as product and interconnection. We work out
categorical notions for hybrid systems, deterministic hybrid systems, hybrid
open systems, networks of hybrid open systems, and morphisms of networks of
hybrid open systems.
  We also develop categorical notions for abstract systems, abstract open
systems, networks of abstract open systems, and morphisms of networks of
abstract open systems. We show that a collection of relations holding among
pairs of systems induces a relation between interconnected systems. We use this
result for abstract systems to prove a corresponding result for networks of
hybrid systems.
  This result translates as saying that our procedure for building networks
preserves morphisms of open systems: a collection of morphisms of (sub)systems
is sent to a morphism of networked systems. We thus both justify our formalism
and concretize the intuition that a network is a collection of systems pieced
together in a certain way.",1911.09048v2,math.DS,2019-11-20 17:20:41+00:00,[arxiv.Result.Author('James Schmidt')],
1224,First integrals of ordinary linear differential systems,"The spectral method for building first integrals of ordinary linear
differential systems is elaborated. Using this method, we obtain bases of first
integrals for linear differential systems with constant coefficients, for
linear nonautonomous differential systems integrable in closed form (algebraic
reducible systems, triangular systems, the Lappo-Danilevskii systems), and for
reducible ordinary differential systems with respect to various transformation
groups.",1201.4141v1,math.DS,2012-01-19 18:45:08+00:00,"[arxiv.Result.Author('V. N. Gorbuzov'), arxiv.Result.Author('A. F. Pranevich')]",
1225,Complex Systems + Systems Engineering = Complex Systems Engineeri,"One may define a complex system as a system in which phenomena emerge as a
consequence of multiscale interaction among the system's components and their
environments. The field of Complex Systems is the study of such
systems--usually naturally occurring, either bio-logical or social. Systems
Engineering may be understood to include the conceptualising and building of
systems that consist of a large number of concurrently operating and
interacting components--usually including both human and non-human elements. It
has become increasingly apparent that the kinds of systems that systems
engineers build have many of the same multiscale characteristics as those of
naturally occurring complex systems. In other words, systems engineering is the
engineering of complex systems. This paper and the associated panel will
explore some of the connections between the fields of complex systems and
systems engineering.",cs/0603127v1,cs.MA,2006-03-30 22:58:12+00:00,[arxiv.Result.Author('Russ Abbott')],
1226,Systems of quotients of Lie triple systems,"In this paper, we introduce the notion of system of quotients of Lie triple
systems and investigate some properties which can be lifted from a Lie triple
system to its systems of quotients. We relate the notion of Lie triple system
of Martindale-like quotients with respect to a filter of ideals and the notion
of system of quotients, and prove that the system of quotients of a Lie triple
system is equivalent to the algebra of quotients of a Lie algebra in some
sense, and these allow us to construct the maximal system of quotients for
nondegenerate Lie triple systems.",1304.7340v1,math.RA,2013-04-27 07:10:20+00:00,"[arxiv.Result.Author('Yao Ma'), arxiv.Result.Author('Liangyun Chen'), arxiv.Result.Author('Jie Lin')]","Communications in Algebra, 42(2014)(8), 3339-3349"
1227,Equivariant Filter Design for Kinematic Systems on Lie Groups,"It is known that invariance and equivariance properties for systems on Lie
groups can be exploited in the design of high performance and robust observers
and filters for real-world robotic systems. This paper proposes an analysis
framework that allows any kinematic system on a Lie group to be embedded in a
natural manner into an equivariant kinematic system. This framework allows us
to characterise the properties of, and relationships between, invariant
systems, group affine systems, and equivariant systems. We propose a new filter
design, the Equivariant Filter (EqF), that exploits the equivariance properties
of the system embedding and can be applied to any kinematic system on a Lie
group.",2004.00828v2,eess.SY,2020-04-02 05:39:17+00:00,"[arxiv.Result.Author('Robert Mahony'), arxiv.Result.Author('Jochen Trumpf')]",
1228,Linearly repetitive Delone systems have a finite number of non periodic Delone system factors,"We prove linearly repetitive Delone systems have finitely many Delone system
factors up to conjugacy. This result is also applicable to linearly repetitive
tiling systems.",0807.2907v1,math.DS,2008-07-18 14:17:40+00:00,"[arxiv.Result.Author('Maria Isabel Cortez'), arxiv.Result.Author('Fabien Durand'), arxiv.Result.Author('Samuel Petite')]",
1229,Integral equivalence of multidimensional differential systems,"The bases of the theory of integrals for multidimensional differential
systems are stated. The integral equivalence of total differential systems,
linear homogeneous systems of partial differential equations, and Pfaff systems
of equations is established.",0909.3220v1,math.DS,2009-09-17 13:51:38+00:00,[arxiv.Result.Author('V. N. Gorbuzov')],
1230,Fractional Multidimensional System,"The multidimensional ($n$-D) systems described by Roesser model are presented
in this paper. These $n$-D systems consist of discrete systems and continuous
fractional order systems with fractional order $\nu$, $0<\nu<1$. The stability
and Robust stability of such $n$-D systems are investigated.",1704.08427v1,math.OC,2017-04-27 04:05:56+00:00,"[arxiv.Result.Author('Xiaogang Zhu'), arxiv.Result.Author('Junguo Lu')]",
1231,A new type of 4D Hybrid Chaos Systems,"In this paper a new type of chaotic system based on sin and logistic systems
is introduced. Also the behavior of this new system is studied by using various
tests. The results of these tests indicate the appropriate behavior for the
proposed new system.",2101.09493v1,math.DS,2021-01-23 12:39:53+00:00,[arxiv.Result.Author('Reza Parvaz')],
1232,Cubical token systems,"The paper deals with combinatorial and stochastic structures of cubical token
systems. A cubical token system is an instance of a token system, which in turn
is an instance of a transition system. It is shown that some basic results of
combinatorial and stochastic parts of media theory hold almost in identical
form for cubical token systems, although some underlying concepts are quite
different. A representation theorem for a cubical token system is established
asserting that the graph of such a system is cubical.",math/0612696v1,math.CO,2006-12-22 11:36:36+00:00,[arxiv.Result.Author('Sergei Ovchinnikov')],
1233,Separable bi-Hamiltonian systems with quadratic in momenta first integrals,"Geometric separability theory of Gel'fand-Zakharevich bi-Hamiltonian systems
on Riemannian manifolds is reviewed and developed. Particular attention is paid
to the separability of systems generated by the so-called special conformal
Killing tensors, i.e. Benenti systems. Then, infinitely many new classes of
separable systems are constructed by appropriate deformations of Benenti class
systems. All such systems can be lifted to the Gel'fand-Zakharevich
bi-Hamiltonian form.",nlin/0312025v2,nlin.SI,2003-12-11 12:21:56+00:00,[arxiv.Result.Author('Maciej Blaszak')],
1234,A Step towards an Easy Interconversion of Various Number Systems,"Any system that is used for naming or representing numbers is a number
system, also known as numeral system. The modern civilization is familiar with
decimal number system using ten digits. However digital devices and computers
use binary number system instead of decimal number system, using only two
digits namely, 0 and 1 based on the fundamental concept of the decimal number
system. Various other number systems also used this fundamental concept of
decimal number system, for example octal system and hexadecimal number systems
using eight and sixteen digits respectively. The knowledge of number systems
and their inter conversion is essential for understanding of computers. More
over, successful programming for digital devices requires a precise
understanding of data formats, number systems and their inter conversion. The
inter conversion (a process in which things are each converted into the other)
of number system requires allot of time and techniques to expertise. In this
paper the interconversion of four most common number systems is taken under the
consideration in tabulated form. It is a step towards the easy interconversion
of theses number systems to understand as well as memorise it. The four number
systems are binary, octal, decimal and hexadecimal.",1107.1663v1,cs.DM,2011-07-08 15:59:35+00:00,"[arxiv.Result.Author('Shahid Latif'), arxiv.Result.Author('Rahat Ullah'), arxiv.Result.Author('Hamid Jan')]",
1235,Nonlinear Modal Decoupling of Multi-Oscillator Systems with Applications to Power Systems,"Many natural and manmade dynamical systems that are modeled as large
nonlinear multi-oscillator systems like power systems are hard to analyze. For
such a system, we propose a nonlinear modal decoupling (NMD) approach inversely
constructing as many decoupled nonlinear oscillators as the system oscillation
modes so that individual decoupled oscillators can easily be analyzed to infer
dynamics and stability of the original system. The NMD follows a similar idea
to the normal form except that we eliminate inter-modal terms but allow
intra-modal terms of desired nonlinearities in decoupled systems, so decoupled
systems can flexibly be shaped into desired forms of nonlinear oscillators. The
NMD is then applied to power systems towards two types of nonlinear
oscillators, i.e. the single-machine-infinite-bus (SMIB) systems and a proposed
non-SMIB oscillator. Numerical studies on a 3-machine 9-bus system and New
England 10-machine 39-bus system show that (i) decoupled oscillators keep a
majority of the original system modal nonlinearities and the NMD provides a
bigger validity region than the normal form, and (ii) decoupled non-SMIB
oscillators may keep more authentic dynamics of the original system than
decoupled SMIB systems.",1611.04553v1,cs.SY,2016-11-14 20:18:36+00:00,"[arxiv.Result.Author('Bin Wang'), arxiv.Result.Author('Kai Sun'), arxiv.Result.Author('Wei Kang')]",
1236,Variability and Evolution in Systems of Systems,"In this position paper (1) we discuss two particular aspects of Systems of
Systems, i.e., variability and evolution. (2) We argue that concepts from
Product Line Engineering and Software Evolution are relevant to Systems of
Systems Engineering. (3) Conversely, concepts from Systems of Systems
Engineering can be helpful in Product Line Engineering and Software Evolution.
Hence, we argue that an exchange of concepts between the disciplines would be
beneficial.",1311.3627v1,cs.SE,2013-11-14 19:40:33+00:00,[arxiv.Result.Author('Goetz Botterweck')],"EPTCS 133, 2013, pp. 8-23"
1237,An Networked HIL Simulation System for Modeling Large-scale Power Systems,"This paper presents a network hardware-in-the-loop (HIL) simulation system
for modeling large-scale power systems. Researchers have developed many HIL
test systems for power systems in recent years. Those test systems can model
both microsecond-level dynamic responses of power electronic systems and
millisecond-level transients of transmission and distribution grids. By
integrating individual HIL test systems into a network of HIL test systems, we
can create large-scale power grid digital twins with flexible structures at
required modeling resolution that fits for a wide range of system operating
conditions. This will not only significantly reduce the need for field tests
when developing new technologies but also greatly shorten the model development
cycle. In this paper, we present a networked OPAL-RT based HIL test system for
developing transmission-distribution coordinative Volt-VAR regulation
technologies as an example to illustrate system setups, communication
requirements among different HIL simulation systems, and system connection
mechanisms. Impacts of communication delays, information exchange cycles, and
computing delays are illustrated. Simulation results show that the performance
of a networked HIL test system is satisfactory.",2002.07257v1,eess.SY,2020-02-17 21:27:55+00:00,"[arxiv.Result.Author('Fuhong Xie'), arxiv.Result.Author('Catie McEntee'), arxiv.Result.Author('Mingzhi Zhang'), arxiv.Result.Author('Ning Lu'), arxiv.Result.Author('Xinda Ke'), arxiv.Result.Author('Mallikarjuna R. Vallem'), arxiv.Result.Author('Nader Samaan')]",
1238,Using Structure-Behavior Coalescence Method for Systems Definition 2.0,"Systems definition is an artifact created by humans to describe what a system
is. A system has been defined, by systems definition 1.0, hopefully to be an
integrated whole, embodied in its components, their interrelationships with
each other and the environment, and the principles and guidelines governing its
design and evolution. This systems definition 1.0 defining the system possesses
one cardinal deficiency. The deficiency comes from that it does not describe
the integration of systems structure and systems behavior. Structure-behavior
coalescence (SBC) architecture provides an elegant way to integrate the
structure and behavior of a system. A system is therefore redefined, by systems
definition 2.0, truly to be an integrated whole, using the SBC architecture,
embodied in its assembled components, their interactions with each other and
the environment, and the principles and guidelines governing its design and
evolution. Since systems definition 2.0 describes the integration of systems
structure and systems behavior, definitely it is able to form an integrated
whole of a system. In this situation, systems definition 2.0 is fully capable
of defining a system.",2110.08998v4,cs.SE,2021-10-18 03:34:27+00:00,[arxiv.Result.Author('William S. Chao')],
1239,Information-theoretic multi-time-scale partially observable systems with relevance to leukemia treatment,"Inspired by a leukemia treatment challenge, we study a partially observable
non-linear stochastic system with unknown parameters, where the given time
scales of the states and measurements may be distinct. Key words: Stochastic
control; Non-linear systems; Partially observable systems; System
identification; Biomedical systems.",2204.12604v1,eess.SY,2022-04-26 21:35:36+00:00,"[arxiv.Result.Author('Margaret P. Chapman'), arxiv.Result.Author('Emily Jensen'), arxiv.Result.Author('Steven M. Chan'), arxiv.Result.Author('Laurent Lessard')]",
1240,Delocalization of a Dynamic System with Preservation or Self-Resurection of Informational Functionality. Ghost machines or can a system survive its destruction,"We analyzed the problem of a dynamic system delocalization due to changes in
the system environment - universe and system architecture. We developed a
Delocalization of Dynamic Cores model to analyze the migration of functional
properties in open information and dynamic systems undergoing architecture
transition and modifications. Information geometry and topological formalisms
are proposed to analyze informational dynamic systems. Different physical and
holographic models are proposed to construct systems able to conserve their
functional properties under delocalization transition. We found several
constraints for the system environment - universe which conserve the dynamic
core system functionality under transition from localized explicit
implementation of functions to the implicit distributed implementation.",nlin/0701026v1,nlin.AO,2007-01-13 09:42:25+00:00,"[arxiv.Result.Author('Vadim Astakhov'), arxiv.Result.Author('Tamara Astakhova')]",
1241,Non-Hamiltonian systems separable by Hamilton-Jacobi method,"We show that with every separable calssical Stackel system of Benenti type on
a Riemannian space one can associate, by a proper deformation of the metric
tensor, a multi-parameter family of non-Hamiltonian systems on the same space,
sharing the same trajectories and related to the seed system by appropriate
reciprocal transformations. These system are known as bi-cofactor systems and
are integrable in quadratures as the seed Hamiltonian system is. We show that
with each class of bi-cofactor systems a pair of separation curves can be
related. We also investigate conditions under which a given flat bi-cofactor
system can be deformed to a family of geodesically equivalent flat bi-cofactor
systems.",0707.1113v1,nlin.SI,2007-07-07 20:24:28+00:00,"[arxiv.Result.Author('Krzysztof Marciniak'), arxiv.Result.Author('Maciej Blaszak')]",
1242,Driving Behavior Analysis through CAN Bus Data in an Uncontrolled Environment,"Cars can nowadays record several thousands of signals through the CAN bus
technology and potentially provide real-time information on the car, the driver
and the surrounding environment. This paper proposes a new method for the
analysis and classification of driver behavior using a selected subset of CAN
bus signals, specifically gas pedal position, brake pedal pressure, steering
wheel angle, steering wheel momentum, velocity, RPM, frontal and lateral
acceleration. Data has been collected in a completely uncontrolled experiment,
where 64 people drove 10 cars for or a total of over 2000 driving trips without
any type of pre-determined driving instruction on a wide variety of road
scenarios. We propose an unsupervised learning technique that clusters drivers
in different groups, and offers a validation method to test the robustness of
clustering in a wide range of experimental settings. The minimal amount of data
needed to preserve robust driver clustering is also computed. The presented
study provides a new methodology for near-real-time classification of driver
behavior in uncontrolled environments.",1710.04133v1,cs.LG,2017-10-09 09:58:23+00:00,"[arxiv.Result.Author('Umberto Fugiglando'), arxiv.Result.Author('Emanuele Massaro'), arxiv.Result.Author('Paolo Santi'), arxiv.Result.Author('Sebastiano Milardo'), arxiv.Result.Author('Kacem Abida'), arxiv.Result.Author('Rainer Stahlmann'), arxiv.Result.Author('Florian Netter'), arxiv.Result.Author('Carlo Ratti')]",
1243,MIAD: A Maintenance Inspection Dataset for Unsupervised Anomaly Detection,"Visual anomaly detection plays a crucial role in not only manufacturing
inspection to find defects of products during manufacturing processes, but also
maintenance inspection to keep equipment in optimum working condition
particularly outdoors. Due to the scarcity of the defective samples,
unsupervised anomaly detection has attracted great attention in recent years.
However, existing datasets for unsupervised anomaly detection are biased
towards manufacturing inspection, not considering maintenance inspection which
is usually conducted under outdoor uncontrolled environment such as varying
camera viewpoints, messy background and degradation of object surface after
long-term working. We focus on outdoor maintenance inspection and contribute a
comprehensive Maintenance Inspection Anomaly Detection (MIAD) dataset which
contains more than 100K high-resolution color images in various outdoor
industrial scenarios. This dataset is generated by a 3D graphics software and
covers both surface and logical anomalies with pixel-precise ground truth.
Extensive evaluations of representative algorithms for unsupervised anomaly
detection are conducted, and we expect MIAD and corresponding experimental
results can inspire research community in outdoor unsupervised anomaly
detection tasks. Worthwhile and related future work can be spawned from our new
dataset.",2211.13968v2,cs.CV,2022-11-25 09:19:36+00:00,"[arxiv.Result.Author('Tianpeng Bao'), arxiv.Result.Author('Jiadong Chen'), arxiv.Result.Author('Wei Li'), arxiv.Result.Author('Xiang Wang'), arxiv.Result.Author('Jingjing Fei'), arxiv.Result.Author('Liwei Wu'), arxiv.Result.Author('Rui Zhao'), arxiv.Result.Author('Ye Zheng')]",
1244,Explore and Control with Adversarial Surprise,"Unsupervised reinforcement learning (RL) studies how to leverage environment
statistics to learn useful behaviors without the cost of reward engineering.
However, a central challenge in unsupervised RL is to extract behaviors that
meaningfully affect the world and cover the range of possible outcomes, without
getting distracted by inherently unpredictable, uncontrollable, and stochastic
elements in the environment. To this end, we propose an unsupervised RL method
designed for high-dimensional, stochastic environments based on an adversarial
game between two policies (which we call Explore and Control) controlling a
single body and competing over the amount of observation entropy the agent
experiences. The Explore agent seeks out states that maximally surprise the
Control agent, which in turn aims to minimize surprise, and thereby manipulate
the environment to return to familiar and predictable states. The competition
between these two policies drives them to seek out increasingly surprising
parts of the environment while learning to gain mastery over them. We show
formally that the resulting algorithm maximizes coverage of the underlying
state in block MDPs with stochastic observations, providing theoretical backing
to our hypothesis that this procedure avoids uncontrollable and stochastic
distractions. Our experiments further demonstrate that Adversarial Surprise
leads to the emergence of complex and meaningful skills, and outperforms
state-of-the-art unsupervised reinforcement learning methods in terms of both
exploration and zero-shot transfer to downstream tasks.",2107.07394v2,cs.LG,2021-07-12 17:58:40+00:00,"[arxiv.Result.Author('Arnaud Fickinger'), arxiv.Result.Author('Natasha Jaques'), arxiv.Result.Author('Samyak Parajuli'), arxiv.Result.Author('Michael Chang'), arxiv.Result.Author('Nicholas Rhinehart'), arxiv.Result.Author('Glen Berseth'), arxiv.Result.Author('Stuart Russell'), arxiv.Result.Author('Sergey Levine')]",
1245,Self-Modifying Morphology Experiments with DyRET: Dynamic Robot for Embodied Testing,"If robots are to become ubiquitous, they will need to be able to adapt to
complex and dynamic environments. Robots that can adapt their bodies while
deployed might be flexible and robust enough to meet this challenge. Previous
work on dynamic robot morphology has focused on simulation, combining simple
modules, or switching between locomotion modes. Here, we present an alternative
approach: a self-reconfigurable morphology that allows a single four-legged
robot to actively adapt the length of its legs to different environments. We
report the design of our robot, as well as the results of a study that verifies
the performance impact of self-reconfiguration. This study compares three
different control and morphology pairs under different levels of servo supply
voltage in the lab. We also performed preliminary tests in different
uncontrolled outdoor environments to see if changes to the external environment
supports our findings in the lab. Our results show better performance with an
adaptable body, lending evidence to the value of self-reconfiguration for
quadruped robots.",1803.05629v4,cs.RO,2018-03-15 08:22:23+00:00,"[arxiv.Result.Author('Tønnes F. Nygaard'), arxiv.Result.Author('Charles P. Martin'), arxiv.Result.Author('Jim Torresen'), arxiv.Result.Author('Kyrre Glette')]",
1246,Joint Material and Illumination Estimation from Photo Sets in the Wild,"Faithful manipulation of shape, material, and illumination in 2D Internet
images would greatly benefit from a reliable factorization of appearance into
material (i.e., diffuse and specular) and illumination (i.e., environment
maps). On the one hand, current methods that produce very high fidelity
results, typically require controlled settings, expensive devices, or
significant manual effort. To the other hand, methods that are automatic and
work on 'in the wild' Internet images, often extract only low-frequency
lighting or diffuse materials. In this work, we propose to make use of a set of
photographs in order to jointly estimate the non-diffuse materials and sharp
lighting in an uncontrolled setting. Our key observation is that seeing
multiple instances of the same material under different illumination (i.e.,
environment), and different materials under the same illumination provide
valuable constraints that can be exploited to yield a high-quality solution
(i.e., specular materials and environment illumination) for all the observed
materials and environments. Similar constraints also arise when observing
multiple materials in a single environment, or a single material across
multiple environments. The core of this approach is an optimization procedure
that uses two neural networks that are trained on synthetic images to predict
good gradients in parametric space given observation of reflected light. We
evaluate our method on a range of synthetic and real examples to generate
high-quality estimates, qualitatively compare our results against
state-of-the-art alternatives via a user study, and demonstrate
photo-consistent image manipulation that is otherwise very challenging to
achieve.",1710.08313v2,cs.GR,2017-10-23 14:48:23+00:00,"[arxiv.Result.Author('Tuanfeng Y. Wang'), arxiv.Result.Author('Tobias Ritschel'), arxiv.Result.Author('Niloy J. Mitra')]",
1247,A Feature Learning and Object Recognition Framework for Underwater Fish Images,"Live fish recognition is one of the most crucial elements of fisheries survey
applications where vast amount of data are rapidly acquired. Different from
general scenarios, challenges to underwater image recognition are posted by
poor image quality, uncontrolled objects and environment, as well as difficulty
in acquiring representative samples. Also, most existing feature extraction
techniques are hindered from automation due to involving human supervision.
Toward this end, we propose an underwater fish recognition framework that
consists of a fully unsupervised feature learning technique and an
error-resilient classifier. Object parts are initialized based on saliency and
relaxation labeling to match object parts correctly. A non-rigid part model is
then learned based on fitness, separation and discrimination criteria. For the
classifier, an unsupervised clustering approach generates a binary class
hierarchy, where each node is a classifier. To exploit information from
ambiguous images, the notion of partial classification is introduced to assign
coarse labels by optimizing the ""benefit"" of indecision made by the classifier.
Experiments show that the proposed framework achieves high accuracy on both
public and self-collected underwater fish images with high uncertainty and
class imbalance.",1603.01696v1,cs.CV,2016-03-05 08:33:18+00:00,"[arxiv.Result.Author('Meng-Che Chuang'), arxiv.Result.Author('Jenq-Neng Hwang'), arxiv.Result.Author('Kresimir Williams')]",
1248,Data-driven Thermal Anomaly Detection for Batteries using Unsupervised Shape Clustering,"For electric vehicles (EV) and energy storage (ES) batteries, thermal runaway
is a critical issue as it can lead to uncontrollable fires or even explosions.
Thermal anomaly detection can identify problematic battery packs that may
eventually undergo thermal runaway. However, there are common challenges like
data unavailability, environment and configuration variations, and battery
aging. We propose a data-driven method to detect battery thermal anomaly based
on comparing shape-similarity between thermal measurements. Based on their
shapes, the measurements are continuously being grouped into different
clusters. Anomaly is detected by monitoring deviations within the clusters.
Unlike model-based or other data-driven methods, the proposed method is robust
to data loss and requires minimal reference data for different pack
configurations. As the initial experimental results show, the method not only
can be more accurate than the onboard BMS and but also can detect unforeseen
anomalies at the early stage.",2103.08796v2,eess.SY,2021-03-16 01:29:41+00:00,"[arxiv.Result.Author('Xiaojun Li'), arxiv.Result.Author('Jianwei Li'), arxiv.Result.Author('Ali Abdollahi'), arxiv.Result.Author('Trevor Jones')]","2021 IEEE 30th International Symposium on Industrial Electronics
  (ISIE), 2021, pp. 1-6"
1249,Controlled Forgetting: Targeted Stimulation and Dopaminergic Plasticity Modulation for Unsupervised Lifelong Learning in Spiking Neural Networks,"Stochastic gradient descent requires that training samples be drawn from a
uniformly random distribution of the data. For a deployed system that must
learn online from an uncontrolled and unknown environment, the ordering of
input samples often fails to meet this criterion, making lifelong learning a
difficult challenge. We exploit the locality of the unsupervised Spike Timing
Dependent Plasticity (STDP) learning rule to target local representations in a
Spiking Neural Network (SNN) to adapt to novel information while protecting
essential information in the remainder of the SNN from catastrophic forgetting.
In our Controlled Forgetting Networks (CFNs), novel information triggers
stimulated firing and heterogeneously modulated plasticity, inspired by
biological dopamine signals, to cause rapid and isolated adaptation in the
synapses of neurons associated with outlier information. This targeting
controls the forgetting process in a way that reduces the degradation of
accuracy for older tasks while learning new tasks. Our experimental results on
the MNIST dataset validate the capability of CFNs to learn successfully over
time from an unknown, changing environment, achieving 95.36% accuracy, which we
believe is the best unsupervised accuracy ever achieved by a fixed-size,
single-layer SNN on a completely disjoint MNIST dataset.",1902.03187v2,cs.NE,2019-02-08 16:50:33+00:00,"[arxiv.Result.Author('Jason M. Allred'), arxiv.Result.Author('Kaushik Roy')]",
1250,Saving the Limping: Fault-tolerant Quadruped Locomotion via Reinforcement Learning,"Quadruped locomotion now has acquired the skill to traverse or even sprint on
uneven terrains in remote uncontrolled environment. However, surviving in the
wild requires not only the maneuverability, but also the ability to handle
unexpected hardware failures. We present the first deep reinforcement learning
based methodology to train fault-tolerant controllers, which can bring an
injured quadruped back home safely and speedily. We adopt the teacher-student
framework to train the controller with close-to-reality joint-locking failure
in the simulation, which can be zero-shot transferred to the physical robot
without any fine-tuning. Extensive simulation and real-world experiments
demonstrate that our fault-tolerant controller can efficiently lead a quadruped
stably when it faces joint failure during locomotion.",2210.00474v1,cs.RO,2022-10-02 09:47:47+00:00,"[arxiv.Result.Author('Dikai Liu'), arxiv.Result.Author('Tianwei Zhang'), arxiv.Result.Author('Jianxiong Yin'), arxiv.Result.Author('Simon See')]",
1251,Effect of Super Resolution on High Dimensional Features for Unsupervised Face Recognition in the Wild,"Majority of the face recognition algorithms use query faces captured from
uncontrolled, in the wild, environment. Often caused by the cameras limited
capabilities, it is common for these captured facial images to be blurred or
low resolution. Super resolution algorithms are therefore crucial in improving
the resolution of such images especially when the image size is small requiring
enlargement. This paper aims to demonstrate the effect of one of the
state-of-the-art algorithms in the field of image super resolution. To
demonstrate the functionality of the algorithm, various before and after 3D
face alignment cases are provided using the images from the Labeled Faces in
the Wild (lfw). Resulting images are subject to testing on a closed set face
recognition protocol using unsupervised algorithms with high dimension
extracted features. The inclusion of super resolution algorithm resulted in
significant improved recognition rate over recently reported results obtained
from unsupervised algorithms.",1704.01464v2,cs.CV,2017-03-23 19:58:27+00:00,"[arxiv.Result.Author('Ahmed ElSayed'), arxiv.Result.Author('Ausif Mahmood'), arxiv.Result.Author('Tarek Sobh')]",
1252,Semi-supervised Federated Learning for Activity Recognition,"Training deep learning models on in-home IoT sensory data is commonly used to
recognise human activities. Recently, federated learning systems that use edge
devices as clients to support local human activity recognition have emerged as
a new paradigm to combine local (individual-level) and global (group-level)
models. This approach provides better scalability and generalisability and also
offers better privacy compared with the traditional centralised analysis and
learning models. The assumption behind federated learning, however, relies on
supervised learning on clients. This requires a large volume of labelled data,
which is difficult to collect in uncontrolled IoT environments such as remote
in-home monitoring.
  In this paper, we propose an activity recognition system that uses
semi-supervised federated learning, wherein clients conduct unsupervised
learning on autoencoders with unlabelled local data to learn general
representations, and a cloud server conducts supervised learning on an activity
classifier with labelled data. Our experimental results show that using a long
short-term memory autoencoder and a Softmax classifier, the accuracy of our
proposed system is higher than that of both centralised systems and
semi-supervised federated learning using data augmentation. The accuracy is
also comparable to that of supervised federated learning systems. Meanwhile, we
demonstrate that our system can reduce the number of needed labels and the size
of local models, and has faster local activity recognition speed than
supervised federated learning does.",2011.00851v3,cs.LG,2020-11-02 09:47:14+00:00,"[arxiv.Result.Author('Yuchen Zhao'), arxiv.Result.Author('Hanyang Liu'), arxiv.Result.Author('Honglin Li'), arxiv.Result.Author('Payam Barnaghi'), arxiv.Result.Author('Hamed Haddadi')]",
1253,A simple model for a minimal environment: the two-atom Tavis-Cummings model revisited,"Individual quantum systems may be interacting with surrounding environments
having a small number of degrees of freedom. It is therefore relevant to
understand the extent to which such small (but uncontrollable) environments
could affect the quantum properties of the system of interest. Here we discuss
a simple system-environment toy model, constituted by a two-level atom (atom 1)
interacting with a single mode cavity field. The field is also assumed to be
(weakly) coupled to an external noisy subsystem, the small environment, modeled
as a second two-level atom (atom 2). We investigate the action of the minimal
environment on the dynamics of the linear entropy (state purity) and the atomic
dipole squeezing of atom 1, as well as the entanglement between atom 1 and the
field. We also obtain the full analytical solution of the two atom
Tavis-Cummings model for both arbitrary coupling strengths and frequency
detunings, necessary to analyze the influence of the field-environment detuning
on the evolution of the above mentioned quantum properties. For
complementarity, we discuss the role of the degree of mixedness of the
environment by analyzing the time-averaged linear entropy of atom 1.",1505.03129v6,quant-ph,2015-05-12 19:32:09+00:00,"[arxiv.Result.Author('G. L. Deçordi'), arxiv.Result.Author('A. Vidiella-Barranco')]",J. Mod. Optics 65 (2018)
1254,Learning to Navigate Intersections with Unsupervised Driver Trait Inference,"Navigation through uncontrolled intersections is one of the key challenges
for autonomous vehicles. Identifying the subtle differences in hidden traits of
other drivers can bring significant benefits when navigating in such
environments. We propose an unsupervised method for inferring driver traits
such as driving styles from observed vehicle trajectories. We use a variational
autoencoder with recurrent neural networks to learn a latent representation of
traits without any ground truth trait labels. Then, we use this trait
representation to learn a policy for an autonomous vehicle to navigate through
a T-intersection with deep reinforcement learning. Our pipeline enables the
autonomous vehicle to adjust its actions when dealing with drivers of different
traits to ensure safety and efficiency. Our method demonstrates promising
performance and outperforms state-of-the-art baselines in the T-intersection
scenario.",2109.06783v2,cs.RO,2021-09-14 15:54:35+00:00,"[arxiv.Result.Author('Shuijing Liu'), arxiv.Result.Author('Peixin Chang'), arxiv.Result.Author('Haonan Chen'), arxiv.Result.Author('Neeloy Chakraborty'), arxiv.Result.Author('Katherine Driggs-Campbell')]",
1255,Shape and Reflectance Reconstruction in Uncontrolled Environments by Differentiable Rendering,"Simultaneous reconstruction of geometry and reflectance properties in
uncontrolled environments remains a challenging problem. In this paper, we
propose an efficient method to reconstruct the scene's 3D geometry and
reflectance from multi-view photography using conventional hand-held cameras.
Our method automatically builds a virtual scene in a differentiable rendering
system that roughly matches the real world's scene parameters, optimized by
minimizing photometric objectives alternatingly and stochastically. With the
optimal scene parameters evaluated, photo-realistic novel views for various
viewing angles and distances can then be generated by our approach. We present
the results of captured scenes with complex geometry and various reflection
types. Our method also shows superior performance compared to state-of-the-art
alternatives in novel view synthesis visually and quantitatively.",2110.12975v2,cs.CV,2021-10-25 14:09:10+00:00,"[arxiv.Result.Author('Rui Li'), arxiv.Result.Author('Guangmin Zang'), arxiv.Result.Author('Miao Qi'), arxiv.Result.Author('Wolfgang Heidrich')]",
1256,Quantum violation of macroscopic realism and the transition to classical physics,"The descriptions of the quantum realm and the macroscopic classical world
differ significantly not only in their mathematical formulations but also in
their foundational concepts and philosophical consequences. When and how
physical systems stop to behave quantum mechanically and begin to behave
classically is still heavily debated in the physics community and subject to
theoretical and experimental research.
  This dissertation puts forward an approach to the quantum-to-classical
transition fully within quantum theory and conceptually different from already
existing models: It neither needs to refer to the uncontrollable environment of
a system (decoherence) nor to change the quantum laws itself (collapse models),
but puts the stress on the limits of observability of quantum phenomena due to
the imprecision of our measurement apparatuses. For a certain class of time
evolutions it is this mere restriction to coarse-grained measurements which is
sufficient to see the natural emergence of macroscopic realism and even the
classical Newtonian laws out of the full quantum formalism. But there also
exist ""non-classical"" Hamiltonians for which a classical spatiotemporal
description of the system's time evolution remains impossible even under fuzzy
measurements or decoherence. It is argued that such Hamiltonians are unlikely
to be spontaneously realized in nature because of their high complexity.
  The last part addresses the question of the origin of quantum randomness and
proposes a link with mathematical undecidability.",0812.0238v1,quant-ph,2008-12-01 08:35:14+00:00,[arxiv.Result.Author('Johannes Kofler')],
1257,Unsupervised Domain Adaptation with Dynamics-Aware Rewards in Reinforcement Learning,"Unsupervised reinforcement learning aims to acquire skills without prior goal
representations, where an agent automatically explores an open-ended
environment to represent goals and learn the goal-conditioned policy. However,
this procedure is often time-consuming, limiting the rollout in some
potentially expensive target environments. The intuitive approach of training
in another interaction-rich environment disrupts the reproducibility of trained
skills in the target environment due to the dynamics shifts and thus inhibits
direct transferring. Assuming free access to a source environment, we propose
an unsupervised domain adaptation method to identify and acquire skills across
dynamics. Particularly, we introduce a KL regularized objective to encourage
emergence of skills, rewarding the agent for both discovering skills and
aligning its behaviors respecting dynamics shifts. This suggests that both
dynamics (source and target) shape the reward to facilitate the learning of
adaptive skills. We also conduct empirical experiments to demonstrate that our
method can effectively learn skills that can be smoothly deployed in target.",2110.12997v2,cs.LG,2021-10-25 14:40:48+00:00,"[arxiv.Result.Author('Jinxin Liu'), arxiv.Result.Author('Hao Shen'), arxiv.Result.Author('Donglin Wang'), arxiv.Result.Author('Yachen Kang'), arxiv.Result.Author('Qiangxing Tian')]",
1258,Unsupervised Model-based Pre-training for Data-efficient Control from Pixels,"Controlling artificial agents from visual sensory data is an arduous task.
Reinforcement learning (RL) algorithms can succeed in this but require large
amounts of interactions between the agent and the environment. To alleviate the
issue, unsupervised RL proposes to employ self-supervised interaction and
learning, for adapting faster to future tasks. Yet, whether current
unsupervised strategies improve generalization capabilities is still unclear,
especially in visual control settings. In this work, we design an effective
unsupervised RL strategy for data-efficient visual control. First, we show that
world models pre-trained with data collected using unsupervised RL can
facilitate adaptation for future tasks. Then, we analyze several design choices
to adapt efficiently, effectively reusing the agents' pre-trained components,
and learning and planning in imagination, with our hybrid planner, which we dub
Dyna-MPC. By combining the findings of a large-scale empirical study, we
establish an approach that strongly improves performance on the Unsupervised RL
Benchmark, requiring 20$\times$ less data to match the performance of
supervised methods. The approach also demonstrates robust performance on the
Real-Word RL benchmark, hinting that the approach generalizes to noisy
environments.",2209.12016v1,cs.AI,2022-09-24 14:22:29+00:00,"[arxiv.Result.Author('Sai Rajeswar'), arxiv.Result.Author('Pietro Mazzaglia'), arxiv.Result.Author('Tim Verbelen'), arxiv.Result.Author('Alexandre Piché'), arxiv.Result.Author('Bart Dhoedt'), arxiv.Result.Author('Aaron Courville'), arxiv.Result.Author('Alexandre Lacoste')]",
1259,Recurrent World Models Facilitate Policy Evolution,"A generative recurrent neural network is quickly trained in an unsupervised
manner to model popular reinforcement learning environments through compressed
spatio-temporal representations. The world model's extracted features are fed
into compact and simple policies trained by evolution, achieving state of the
art results in various environments. We also train our agent entirely inside of
an environment generated by its own internal world model, and transfer this
policy back into the actual environment. Interactive version of paper at
https://worldmodels.github.io",1809.01999v1,cs.LG,2018-09-04 22:25:12+00:00,"[arxiv.Result.Author('David Ha'), arxiv.Result.Author('Jürgen Schmidhuber')]",
1260,Gender and Ethnicity Classification based on Palmprint and Palmar Hand Images from Uncontrolled Environment,"Soft biometric attributes such as gender, ethnicity or age may provide useful
information for biometrics and forensics applications. Researchers used, e.g.,
face, gait, iris, and hand, etc. to classify such attributes. Even though hand
has been widely studied for biometric recognition, relatively less attention
has been given to soft biometrics from hand. Previous studies of soft
biometrics based on hand images focused on gender and well-controlled imaging
environment. In this paper, the gender and ethnicity classification in
uncontrolled environment are considered. Gender and ethnicity labels are
collected and provided for subjects in a publicly available database, which
contains hand images from the Internet. Five deep learning models are
fine-tuned and evaluated in gender and ethnicity classification scenarios based
on palmar 1) full hand, 2) segmented hand and 3) palmprint images. The
experimental results indicate that for gender and ethnicity classification in
uncontrolled environment, full and segmented hand images are more suitable than
palmprint images.",2008.02500v1,cs.CV,2020-08-06 07:50:06+00:00,"[arxiv.Result.Author('Wojciech Michal Matkowski'), arxiv.Result.Author('Adams Wai Kin Kong')]",
1261,"CREATE: Multimodal Dataset for Unsupervised Learning, Generative Modeling and Prediction of Sensory Data from a Mobile Robot in Indoor Environments","The CREATE database is composed of 14 hours of multimodal recordings from a
mobile robotic platform based on the iRobot Create. The various sensors cover
vision, audition, motors and proprioception. The dataset has been designed in
the context of a mobile robot that can learn multimodal representations of its
environment, thanks to its ability to navigate the environment. This ability
can also be used to learn the dependencies and relationships between the
different modalities of the robot (e.g. vision, audition), as they reflect both
the external environment and the internal state of the robot. The provided
multimodal dataset is expected to have multiple usages, such as multimodal
unsupervised object learning, multimodal prediction and egomotion/causality
detection.",1801.10214v1,cs.RO,2018-01-30 20:40:48+00:00,"[arxiv.Result.Author('Simon Brodeur'), arxiv.Result.Author('Simon Carrier'), arxiv.Result.Author('Jean Rouat')]",
1262,Limiting Risk by Turning Manifest Phantoms into Evil Zombies,"Drawing a random sample of ballots to conduct a risk-limiting audit generally
requires knowing how the ballots cast in an election are organized into groups,
for instance, how many containers of ballots there are in all and how many
ballots are in each container. A list of the ballot group identifiers along
with number of ballots in each group is called a ballot manifest. What if the
ballot manifest is not accurate? Surprisingly, even if ballots are known to be
missing from the manifest, it is not necessary to make worst-case assumptions
about those ballots--for instance, to adjust the margin by the number of
missing ballots--to ensure that the audit remains conservative. Rather, it
suffices to make worst-case assumptions about the individual randomly selected
ballots that the audit cannot find. This observation provides a simple
modification to some risk-limiting audit procedures that makes them
automatically become more conservative if the ballot manifest has errors. The
modification--phantoms to evil zombies (~2EZ)--requires only an upper bound on
the total number of ballots cast. ~2EZ makes the audit P-value stochastically
larger than it would be had the manifest been accurate, automatically requiring
more than enough ballots to be audited to offset the manifest errors. This
ensures that the true risk limit remains smaller than the nominal risk limit.
On the other hand, if the manifest is in fact accurate and the upper bound on
the total number of ballots equals the total according to the manifest, ~2EZ
has no effect at all on the number of ballots audited nor on the true risk
limit.",1207.3413v1,stat.AP,2012-07-14 11:26:02+00:00,"[arxiv.Result.Author('Jorge H. Banuelos'), arxiv.Result.Author('Philip B. Stark')]",
1263,A Complete Enumeration of Ballot Permutations Avoiding Sets of Small Patterns,"Permutations whose prefixes contain at least as many ascents as descents are
called ballot permutations. Lin, Wang, and Zhao have previously enumerated
ballot permutations avoiding small patterns and have proposed the problem of
enumerating ballot permutations avoiding a pair of permutations of length $3$.
We completely enumerate ballot permutations avoiding two patterns of length $3$
and we relate these avoidance classes with their respective recurrence
relations and formulas, which leads to an interesting bijection between ballot
permutations avoiding $132$ and $312$ with left factors of Dyck paths. In
addition, we also conclude the Wilf-classification of ballot permutations
avoiding sets of two patterns of length $3$, and we then extend our results to
completely enumerate ballot permutations avoiding three patterns of length $3$.",2209.06087v1,math.CO,2022-09-13 15:37:45+00:00,[arxiv.Result.Author('Nathan Sun')],
1264,Can Voters Detect Errors on Their Printed Ballots? Absolutely,"There is still debate on whether voters can detect malicious changes in their
printed ballot after making their selections on a Ballot Marking Device (BMD).
In this study, we altered votes on a voter's ballot after they had made their
selections on a BMD. We then required them to examine their ballots for any
changes from the slate they used to vote. Overall accuracy was exceptionally
high. Participants saw 1440 total contests, and of those 1440, there were a
total of 4 errors, so total accuracy was 99.8%. Participants were able to
perform with near-perfect accuracy regardless of ballot length, ballot type,
number of altered races, and location of altered races. Detection performance
was extremely robust. We conclude that with proper direction and resources,
voters can be near-perfect detectors of ballot changes on printed paper ballots
after voting with a BMD. This finding has significant implications for the
voting community as BMD use continues to grow. Research should now focus on
identifying administrative and behavioral methods that will prompt and
encourage voters to check their BMD-generated ballots before they drop them in
the ballot box.",2204.09780v1,cs.HC,2022-04-20 20:40:32+00:00,"[arxiv.Result.Author('Philip Kortum'), arxiv.Result.Author('Michael D. Byrne'), arxiv.Result.Author('Chidera O. Azubike'), arxiv.Result.Author('Laura E. Roty')]",
1265,Ballot tilings and increasing trees,"We study enumerations of Dyck and ballot tilings, which are tilings of a
region determined by two Dyck or ballot paths. We give bijective proofs to two
formulae of enumerations of Dyck tilings through Hermite histories. We show
that one of the formulae is equal to a certain Kazhdan--Lusztig polynomial. For
a ballot tiling, we establish formulae which are analogues of formulae for Dyck
tilings. Especially, the generating functions have factorized expressions. The
key tool is a planted plane tree and its increasing labellings. We also
introduce a generalized perfect matching which is bijective to an Hermite
history for a ballot tiling. By combining these objects, we obtain various
expressions of a generating function of ballot tilings with a fixed lower path.",1705.06434v1,math-ph,2017-05-18 06:46:09+00:00,[arxiv.Result.Author('Keiichi Shigechi')],
1266,Sophisticated Attacks on Decoy Ballots: The Devil's Menu and the Market for Lemons,"Decoy ballots do not count in election outcomes, but otherwise they are
indistinguishable from real ballots. By means of a game-theoretical model, we
show that decoy ballots may not provide effective protection against a
malevolent adversary trying to buy real ballots. If the citizenry is divided
into subgroups (or districts), the adversary can construct a so-called ""Devil's
Menu"" consisting of several prices. In equilibrium, the adversary can buy the
real ballots of any strict subset of districts at a price corresponding to the
willingness to sell on the part of the citizens holding such ballots. By
contrast, decoy voters are trapped into selling their ballots at a low, or even
negligible, price. Blowing up the adversary's budget by introducing decoy
ballots may thus turn out to be futile. The Devil's Menu can also be applied to
the well-known ""Lemons Problem"".",1712.05477v1,cs.GT,2017-12-14 23:54:58+00:00,"[arxiv.Result.Author('Hans Gersbach'), arxiv.Result.Author('Akaki Mamageishvili'), arxiv.Result.Author('Oriol Tejada')]",
1267,The ATHENA Class of Risk-Limiting Ballot Polling Audits,"The main risk-limiting ballot polling audit in use today, BRAVO, is designed
for use when single ballots are drawn at random and a decision regarding
whether to stop the audit or draw another ballot is taken after each ballot
draw (ballot-by-ballot (B2) audits). On the other hand, real ballot polling
audits draw many ballots in a single round before determining whether to stop
(round-by-round (R2) audits). We show that BRAVO results in significant
inefficiency when directly applied to real R2 audits. We present the ATHENA
class of R2 stopping rules, which we show are risk-limiting if the round
schedule is pre-determined (before the audit begins). We prove that each rule
is at least as efficient as the corresponding BRAVO stopping rule applied at
the end of the round. We have open-source software libraries implementing most
of our results.
  We show that ATHENA halves the number of ballots required, for all state
margins in the 2016 US Presidential election and a first round with $90\%$
stopping probability, when compared to BRAVO (stopping rule applied at the end
of the round). We present simulation results supporting the 90% stopping
probability claims and our claims for the risk accrued in the first round.
Further, ATHENA reduces the number of ballots by more than a quarter for low
margins, when compared to the BRAVO stopping rule applied on ballots in
selection order. This implies that keeping track of the order when drawing
ballots R2 is not beneficial, because ATHENA is more efficient even without
information on selection order. These results are significant because current
approaches to real ballot polling election audits use the B2 BRAVO rules,
requiring about twice as much work on the part of election officials. Applying
the rules in selection order requires fewer ballots, but keeping track of the
order, and entering it into audit software, adds to the effort.",2008.02315v5,cs.CR,2020-08-05 18:47:37+00:00,"[arxiv.Result.Author('Filip Zagórski'), arxiv.Result.Author('Grant McClearn'), arxiv.Result.Author('Sarah Morin'), arxiv.Result.Author('Neal McBurnett'), arxiv.Result.Author('Poorvi L. Vora')]",
1268,$k$-Cut: A Simple Approximately-Uniform Method for Sampling Ballots in Post-Election Audits,"We present an approximate sampling framework and discuss how risk-limiting
audits can compensate for these approximations, while maintaining their
""risk-limiting"" properties. Our framework is general and can compensate for
counting mistakes made during audits.
  Moreover, we present and analyze a simple approximate sampling
method,""$k$-cut"", for picking a ballot randomly from a stack, without counting.
Our method involves doing $k$ ""cuts"", each involving moving a random portion of
ballots from the top to the bottom of the stack, and then picking the ballot on
top. Unlike conventional methods of picking a ballot at random, $k$-cut does
not require identification numbers on the ballots or counting many ballots per
draw. We analyze how close the distribution of chosen ballots is to the uniform
distribution, and design different mitigation procedures. We show that $k=6$
cuts is enough for an risk-limiting election audit, based on empirical data,
which would provide a significant increase in efficiency.",1811.08811v3,cs.DS,2018-11-21 16:26:33+00:00,"[arxiv.Result.Author('Mayuri Sridhar'), arxiv.Result.Author('Ronald L. Rivest')]",
1269,Bernoulli Ballot Polling: A Manifest Improvement for Risk-Limiting Audits,"We present a method and software for ballot-polling risk-limiting audits
(RLAs) based on Bernoulli sampling: ballots are included in the sample with
probability $p$, independently. Bernoulli sampling has several advantages: (1)
it does not require a ballot manifest; (2) it can be conducted independently at
different locations, rather than requiring a central authority to select the
sample from the whole population of cast ballots or requiring stratified
sampling; (3) it can start in polling places on election night, before margins
are known. If the reported margins for the 2016 U.S. Presidential election are
correct, a Bernoulli ballot-polling audit with a risk limit of 5% and a
sampling rate of $p_0 = 1\%$ would have had at least a 99% probability of
confirming the outcome in 42 states. (The other states were more likely to have
needed to examine additional ballots.) Logistical and security advantages that
auditing in the polling place affords may outweigh the cost of examining more
ballots than some other methods might require.",1812.06361v1,stat.AP,2018-12-15 21:57:23+00:00,"[arxiv.Result.Author('Kellie Ottoboni'), arxiv.Result.Author('Matthew Bernhard'), arxiv.Result.Author('J. Alex Halderman'), arxiv.Result.Author('Ronald L. Rivest'), arxiv.Result.Author('Philip B. Stark')]",
1270,"Symmetric Dyck tilings, ballot tableaux and tree-like tableaux of shifted shapes","Symmetric Dyck tilings and ballot tilings are certain tilings in the region
surrounded by two ballot paths. We study the relations of combinatorial objects
which are bijective to symmetric Dyck tilings such as labeled trees, Hermite
histories, and perfect matchings. We also introduce two operations on labeled
trees for symmetric Dyck tilings: symmetric Dyck tiling strip (symDTS) and
symmetric Dyck tiling ribbon (symDTR). We give two definitions of Hermite
histories for symmetric Dyck tilings, and show that they are equivalent by use
of the correspondence between symDTS operation and an Hermite history. Since
ballot tilings form a subset in the set of symmetric Dyck tilings, we construct
an inclusive map from labeled trees for ballot tilings to labeled trees for
symmetric Dyck tilings. By this inclusive map, the results for symmetric Dyck
tilings can be applied to those of ballot tilings. We introduce and study the
notions of ballot tableaux and tree-like tableaux of shifted shapes, which are
generalizations of Dyck tableaux and tree-like tableaux, respectively. The
correspondence between ballot tableaux and tree-like tableaux of shifted shapes
is given by using the symDTR operation and the structure of labeled trees for
symmetric Dyck tilings.",2011.07296v1,math.CO,2020-11-14 13:15:14+00:00,[arxiv.Result.Author('Keiichi Shigechi')],
1271,SOBA: Secrecy-preserving Observable Ballot-level Audit,"SOBA is an approach to election verification that provides observers with
justifiably high confidence that the reported results of an election are
consistent with an audit trail (""ballots""), which can be paper or electronic.
SOBA combines three ideas: (1) publishing cast vote records (CVRs) separately
for each contest, so that anyone can verify that each reported contest outcome
is correct, if the CVRs reflect voters' intentions with sufficient accuracy;
(2) shrouding a mapping between ballots and the CVRs for those ballots to
prevent the loss of privacy that could occur otherwise; (3) assessing the
accuracy with which the CVRs reflect voters' intentions for a collection of
contests while simultaneously assessing the integrity of the shrouded mapping
between ballots and CVRs by comparing randomly selected ballots to the CVRs
that purport to represent them. Step (1) is related to work by the Humboldt
County Election Transparency Project, but publishing CVRs separately for
individual contests rather than images of entire ballots preserves privacy.
Step (2) requires a cryptographic commitment from elections officials.
Observers participate in step (3), which relies on the ""super-simple
simultaneous single-ballot risk-limiting audit."" Step (3) is designed to reveal
relatively few ballots if the shrouded mapping is proper and the CVRs
accurately reflect voter intent. But if the reported outcomes of the contests
differ from the outcomes that a full hand count would show, step (3) is
guaranteed to have a large chance of requiring all the ballots to be counted by
hand, thereby limiting the risk that an incorrect outcome will become official
and final.",1105.5803v2,stat.AP,2011-05-29 17:00:20+00:00,"[arxiv.Result.Author('Josh Benaloh'), arxiv.Result.Author('Douglas Jones'), arxiv.Result.Author('Eric Lazarus'), arxiv.Result.Author('Mark Lindeman'), arxiv.Result.Author('Philip B. Stark')]",
1272,"Voter Verification of BMD Ballots Is a Two-Part Question: Can They? Mostly, They Can. Do They? Mostly, They Don't","The question of whether or not voters actually verify ballots produced by
ballot marking devices (BMDs) is presently the subject of some controversy.
Recent studies (e.g., Bernhard, et al. 2020) suggest the verification rate is
low. What is not clear from previous research is whether this is more a result
of voters being unable to do so accurately or whether this is because voters
simply choose not to attempt verification in the first place. In order to
understand this problem, we conducted an experiment in which 108 participants
participated in a mock election where the BMD displayed the voters' true
choices, but then changed a subset of those choices on the printed ballot. The
design of the printed ballot, the length of the ballot, the number of changes
that were made to the ballot, the location of those changes, and the
instructions provided to the voters were manipulated as part of the experiment.
Results indicated that of those voters who chose to examine the printed ballot,
76% detected anomalies, indicating that voters can reliably detect errors on
their ballot if they will simply review it. This suggests that administrative
remedies, rather than attempts to alter fundamental human perceptual
capabilities, could be employed to encourage voters to check their ballots,
which could prove as an effective countermeasure.",2003.04997v1,cs.HC,2020-03-10 21:06:42+00:00,"[arxiv.Result.Author('Philip Kortum'), arxiv.Result.Author('Michael D. Byrne'), arxiv.Result.Author('Julie Whitmore')]",
1273,Next Steps for the Colorado Risk-Limiting Audit (CORLA) Program,"Colorado conducted risk-limiting tabulation audits (RLAs) across the state in
2017, including both ballot-level comparison audits and ballot-polling audits.
Those audits only covered contests restricted to a single county; methods to
efficiently audit contests that cross county boundaries and combine ballot
polling and ballot-level comparisons have not been available.
  Colorado's current audit software (RLATool) needs to be improved to audit
these contests that cross county lines and to audit small contests efficiently.
  This paper addresses these needs. It presents extremely simple but
inefficient methods, more efficient methods that combine ballot polling and
ballot-level comparisons using stratified samples, and methods that combine
ballot-level comparison and variable-size batch comparison audits in a way that
does not require stratified sampling.
  We conclude with some recommendations, and illustrate our recommended method
using examples that compare them to existing approaches. Exemplar open-source
code and interactive Jupyter notebooks are provided that implement the methods
and allow further exploration.",1803.00698v1,stat.AP,2018-03-02 03:46:37+00:00,"[arxiv.Result.Author('Mark Lindeman'), arxiv.Result.Author('Neal McBurnett'), arxiv.Result.Author('Kellie Ottoboni'), arxiv.Result.Author('Philip B. Stark')]",
1274,RAIRE: Risk-Limiting Audits for IRV Elections,"Risk-limiting post election audits guarantee a high probability of correcting
incorrect election results, independent of why the result was incorrect.
Ballot-polling audits select ballots at random and interpret those ballots as
evidence for and against the reported result, continuing this process until
either they support the recorded result, or they fall back to a full manual
recount. For elections with digitised scanning and counting of ballots, a
comparison audit compares randomly selected digital ballots with their paper
versions. Discrepancies are referred to as errors, and are used to build
evidence against or in support of the recorded result. Risk-limiting audits for
first-past-the-post elections are well understood, and used in some US
elections. We define a number of approaches to ballot-polling and comparison
risk-limiting audits for Instant Runoff Voting (IRV) elections. We show that
for almost all real elections we found, we can perform a risk-limiting audit by
looking at only a small fraction of the total ballots (assuming no errors were
made in the tallying and distribution of votes).",1903.08804v2,cs.DS,2019-03-20 06:19:10+00:00,"[arxiv.Result.Author('Michelle Blom'), arxiv.Result.Author('Peter J. Stuckey'), arxiv.Result.Author('Vanessa Teague')]",
1275,"A decomposition of ballot permutations, pattern avoidance and Gessel walks","A permutation whose any prefix has no more descents than ascents is called a
ballot permutation. In this paper, we present a decomposition of ballot
permutations that enables us to construct a bijection between ballot
permutations and odd order permutations, which proves a set-valued extension of
a conjecture due to Spiro using the statistic of peak values. This bijection
also preserves the neighbors of the largest letter in permutations and thus
resolves a refinement of Spiro' s conjecture proposed by Wang and Zhang. Our
decomposition can be extended to well-labelled positive paths, a class of
generalized ballot permutations arising from polytope theory, that were
enumerated by Bernardi, Duplantier and Nadeau. We will also investigate the
enumerative aspect of ballot permutations avoiding a single pattern of length 3
and establish a connection between 213-avoiding ballot permutations and Gessel
walks.",2103.04599v1,math.CO,2021-03-08 08:37:08+00:00,"[arxiv.Result.Author('Zhicong Lin'), arxiv.Result.Author('David G. L. Wang'), arxiv.Result.Author('Tongyuan Zhao')]",
1276,Ballot Length in Instant Runoff Voting,"Instant runoff voting (IRV) is an increasingly-popular alternative to
traditional plurality voting in which voters submit rankings over the
candidates rather than single votes. In practice, elections using IRV often
restrict the ballot length, the number of candidates a voter is allowed to rank
on their ballot. We theoretically and empirically analyze how ballot length can
influence the outcome of an election, given fixed voter preferences. We show
that there exist preference profiles over $k$ candidates such that up to $k-1$
different candidates win at different ballot lengths. We derive exact lower
bounds on the number of voters required for such profiles and provide a
construction matching the lower bound for unrestricted voter preferences.
Additionally, we characterize which sequences of winners are possible over
ballot lengths and provide explicit profile constructions achieving any
feasible winner sequence. We also examine how classic preference restrictions
influence our results--for instance, single-peakedness makes $k-1$ different
winners impossible but still allows at least $\Omega(\sqrt k)$. Finally, we
analyze a collection of 168 real-world elections, where we truncate rankings to
simulate shorter ballots. We find that shorter ballots could have changed the
outcome in one quarter of these elections. Our results highlight ballot length
as a consequential degree of freedom in the design of IRV elections.",2207.08958v3,cs.MA,2022-07-18 22:01:13+00:00,"[arxiv.Result.Author('Kiran Tomlinson'), arxiv.Result.Author('Johan Ugander'), arxiv.Result.Author('Jon Kleinberg')]",
1277,A modular eballot system - V0.6,"We consider a reasonably simple voting system which can be implemented for
web-based ballots. Simplicity, modularity and the requirement of compatibility
with current web browsers leads to a system which satisfies a set of security
requirements for a ballot system which is not complete but sufficient in many
cases. Due to weak-eligibility and vote-selling, this system cannot be used for
political or similar ballots.",cs/0611066v2,cs.CR,2006-11-15 09:33:58+00:00,[arxiv.Result.Author('Andrea Pasquinucci')],
1278,A quantum secret ballot,"The paper concerns the protection of the secrecy of ballots, so that the
identity of the voters cannot be matched with their vote. To achieve this we
use an entangled quantum state to represent the ballots. Each ballot includes
the identity of the voter, explicitly marked on the ""envelope"" containing it.
Measuring the content of the envelope yields a random number which reveals no
information about the vote. However, the outcome of the elections can be
unambiguously decided after adding the random numbers from all envelopes. We
consider a few versions of the protocol and their complexity of implementation.",quant-ph/0602087v2,quant-ph,2006-02-09 21:03:35+00:00,"[arxiv.Result.Author('Shahar Dolev'), arxiv.Result.Author('Itamar Pitowsky'), arxiv.Result.Author('Boaz Tamir')]",
1279,Ballot Paths Avoiding Depth Zero Patterns,"In a paper by Sapounakis, Tasoulas, and Tsikouras \cite{stt}, the authors
count the number of occurrences of patterns of length four in Dyck paths. In
this paper we specify in one direction and generalize in another. We only count
ballot paths that avoid a given pattern, where a ballot path stays weakly above
the diagonal $y=x$, starts at the origin, and takes steps from the set
$\{\uparrow ,\to \}=\{u,r\}$. A pattern is a finite string made from the same
step set; it is also a path. Notice that a ballot path ending at a point along
the diagonal is a Dyck path.",1004.2710v1,math.CO,2010-04-15 20:23:45+00:00,"[arxiv.Result.Author('Heinrich Niederhausen'), arxiv.Result.Author('Shaun Sullivan')]","Journal OF Combinatorial Mathematics and Combinatorial Computing,
  August 2010"
1280,Exploiting re-voting in the Helios election system,"Election systems must ensure that representatives are chosen by voters.
Moreover, each voter should have equal influence. Traditionally, this has been
achieved by permitting voters to cast at most one ballot. More recently, this
has been achieved by tallying the last ballot cast by each voter. We show this
is not achieved by the Helios election system, because an adversary can cause a
ballot other than a voter's last to be tallied. Moreover, we show how the
adversary can choose the contents of such a ballot, thus the adversary can
unduly influence the selection of representatives.",1612.04099v3,cs.CR,2016-12-13 11:07:22+00:00,"[arxiv.Result.Author('Maxime Meyer'), arxiv.Result.Author('Ben Smyth')]",
1281,A Toeplitz property of ballot permutations and odd order permutations,"We give a new semi-combinatorial proof for the equality of the number of
ballot permutations of length $n$ and the number of odd order permutations of
length $n$, which is due to Bernardi, Duplantier and Nadeau. Spiro conjectures
that the descent number of ballot permutations and certain cyclic weight of odd
order permutations of the same length are equi-distributed. We present a
bijection to establish a Toeplitz property for ballot permutations with any
fixed number of descents, and a Toeplitz property for odd order permutations
with any fixed cyclic weight. This allows us to refine Spiro's conjecture by
tracking the neighbors of the largest letter in permutations.",2001.07143v1,math.CO,2020-01-20 15:28:43+00:00,"[arxiv.Result.Author('David G. L. Wang'), arxiv.Result.Author('Jerry J. R. Zhang')]",
1282,Automatic Repair and Type Binding of Undeclared Variables using Neural Networks,"Deep learning had been used in program analysis for the prediction of hidden
software defects using software defect datasets, security vulnerabilities using
generative adversarial networks as well as identifying syntax errors by
learning a trained neural machine translation on program codes. However, all
these approaches either require defect datasets or bug-free source codes that
are executable for training the deep learning model. Our neural network model
is neither trained with any defect datasets nor bug-free programming source
codes, instead it is trained using structural semantic details of Abstract
Syntax Tree (AST) where each node represents a construct appearing in the
source code. This model is implemented to fix one of the most common semantic
errors, such as undeclared variable errors as well as infer their type
information before program compilation. By this approach, the model has
achieved in correctly locating and identifying 81% of the programs on prutor
dataset of 1059 programs with only undeclared variable errors and also
inferring their types correctly in 80% of the programs.",1907.06205v1,cs.SE,2019-07-14 11:14:14+00:00,"[arxiv.Result.Author('Venkatesh Theru Mohan'), arxiv.Result.Author('Ali Jannesari')]",
1283,SNIF: A Futuristic Neutrino Probe for Undeclared Nuclear Fission Reactors,"Today reactor neutrino experiments are at the cutting edge of fundamental
research in particle physics. Understanding the neutrino is far from complete,
but thanks to the impressive progress in this field over the last 15 years, a
few research groups are seriously considering that neutrinos could be useful
for society. The International Atomic Energy Agency (IAEA) works with its
Member States to promote safe, secure and peaceful nuclear technologies. In a
context of international tension and nuclear renaissance, neutrino detectors
could help IAEA to enforce the Treaty on the Non-Proliferation of Nuclear
Weapons (NPT). In this article we discuss a futuristic neutrino application to
detect and localize an undeclared nuclear reactor from across borders. The SNIF
(Secret Neutrino Interactions Finder) concept proposes to use a few hundred
thousand tons neutrino detectors to unveil clandestine fission reactors. Beyond
previous studies we provide estimates of all known background sources as a
function of the detector's longitude, latitude and depth, and we discuss how
they impact the detectability.",1011.3850v1,nucl-ex,2010-11-16 22:48:00+00:00,"[arxiv.Result.Author('Thierry Lasserre'), arxiv.Result.Author('Maximilien Fechner'), arxiv.Result.Author('Guillaume Mention'), arxiv.Result.Author('Romain Reboulleau'), arxiv.Result.Author('Michel Cribier'), arxiv.Result.Author('Alain Letourneau'), arxiv.Result.Author('David Lhuillier')]",
1284,"Polarization, Abstention, and the Median Voter Theorem","The median voter theorem has long been the default model of voter behavior
and candidate choice. While contemporary work on the distribution of political
opinion has emphasized polarization and an increasing gap between the ""left""
and the ""right"" in democracies, the median voter theorem presents a model of
anti-polarization: competing candidates move to the center of the ideological
distribution to maximize vote share, regardless of the underlying ideological
distribution of voters. These anti-polar results, however, largely depend on
the ""singled-peakedness"" of voter preferences, an assumption that is rapidly
loosing relevance in the age of polarization. This article presents a model of
voter choice that examines three potential mechanisms that can undermine this
finding: a relative cost of voting that deters voters who are sufficiently
indifferent to both candidates, ideologically motivated third-party
alternatives that attract extreme voters, and a bimodal distribution of voter
ideology. Under reasonable sets of conditions and empirically observed voter
opinion distributions, these mechanisms can be sufficient to cause
strategically-minded candidates to fail to converge to the center, or to even
become more polarized than their electorate.",2103.12847v1,physics.soc-ph,2021-03-23 21:14:22+00:00,"[arxiv.Result.Author('Matthew I. Jones'), arxiv.Result.Author('Antonio D. Sirianni'), arxiv.Result.Author('Feng Fu')]",
1285,A Fault Tolerance Improved Majority Voter for TMR System Architectures,"For digital system designs, triple modular redundancy (TMR), which is a
3-tuple version of N-modular redundancy is widely preferred for many
mission-control and safety-critical applications. The TMR scheme involves
two-times duplication of the simplex system hardware, with a majority voter
ensuring correctness provided at least two out of three copies of the system
remain operational. Thus the majority voter plays a pivotal role in ensuring
the correct operation of the system. The fundamental assumption implicit in the
TMR scheme is that the majority voter does not become faulty, which may not
hold well for implementations based on latest technology nodes with dimensions
of the order of just tens of nanometers. To overcome the drawbacks of the
classical majority voter some new voter designs were put forward in the
literature with the aim of enhancing the fault tolerance. However, these voter
designs generally ensure the correct system operation in the presence of either
a faulty function module or the faulty voter, considered only in isolation.
Since multiple faults may no longer be excluded in the nanoelectronics regime,
simultaneous fault occurrences on both the function module and the voter should
be considered, and the fault tolerance of the voters have to be analyzed under
such a scenario. In this context, this article proposes a new fault-tolerant
majority voter which is found to be more robust to faults than the existing
voters in the presence of faults occurring internally and/or externally to the
voter. Moreover, the proposed voter features less power dissipation, delay, and
area metrics based on the simulation results obtained by using a 32/28nm CMOS
process.",1605.03771v2,cs.AR,2016-05-12 11:54:44+00:00,"[arxiv.Result.Author('P Balasubramanian'), arxiv.Result.Author('K Prasad')]","WSEAS Transactions on Circuits and Systems, vol. 15, Article #14,
  pp. 108-122, 2016"
1286,On the Computational Complexity of Variants of Combinatorial Voter Control in Elections,"Voter control problems model situations in which an external agent tries
toaffect the result of an election by adding or deleting the fewest number of
voters. The goal of the agent is to make a specific candidate either win
(\emph{constructive} control) or lose (\emph{destructive} control) the
election. We study the constructive and destructive voter control problems
whenadding and deleting voters have a \emph{combinatorial flavor}: If we add
(resp.\ delete) a voter~$v$, we also add (resp.\ delete) a bundle~$\kappa(v) $
of voters that are associated with~$v$. While the bundle~$\kappa(v)$ may have
more than one voter, a voter may also be associated with more than one voter.
We analyze the computational complexity of the four voter control problems for
the Plurality rule. We obtain that, in general, making a candidate lose is
computationally easier than making her win. In particular, if the bundling
relation is symmetric (i.e.\ $\forall w\colon w \in \kappa(v) \Leftrightarrow v
\in \kappa(w) $), and if each voter has at most two voters associated with him,
then destructive control is polynomial-time solvable while the constructive
variant remains $\NP$-hard. Even if the bundles are disjoint (i.e.\ $\forall
w\colon w \in \kappa(v) \Leftrightarrow \kappa(v) = \kappa(w) $), the
constructive problem variants remain intractable. Finally, the minimization
variant of constructive control by adding voters does not admit an efficient
approximation algorithm, unless P=NP.",1701.05108v1,cs.MA,2017-01-18 15:36:46+00:00,"[arxiv.Result.Author('Leon Kellerhals'), arxiv.Result.Author('Viatcheslav Korenwein'), arxiv.Result.Author('Philipp Zschoche'), arxiv.Result.Author('Robert Bredereck'), arxiv.Result.Author('Jiehua Chen')]",
1287,Ranking Swing Voters in Congressional Elections,"We present a model for quantitatively identifying swing voters in
congressional elections. This is achieved by predicting an individual voter's
likelihood to vote and an individual voter's likelihood to vote for a given
party, if he votes. We make a rough prediction of these values. We then update
these predictions by incorporating information on a municipality wide basis via
aggregate data to enhance our estimate under the assumption that nearby voters
have similar behavior, which could be due to social interaction or common
external factors. Finally, we use a ranking scheme on these predictions to
identify two key types of voter: 1) Voters who are likely to vote that we can
convince to vote for a given party; and, 2) Voters who are likely to vote for a
given party, if they vote, that we can convince to actually turn out to vote.
Once these voters have been identified, a political campaign can use this
information to micro-target voters and win more votes.",1405.5111v1,physics.soc-ph,2014-05-19 06:30:42+00:00,[arxiv.Result.Author('Steven Ambadjes')],
1288,2-Dimensional Euclidean Preferences,"A preference profile with m alternatives and n voters is 2-dimensional
Euclidean if both the alternatives and the voters can be placed into a
2-dimensional space such that for each pair of alternatives, every voter
prefers the one which has a shorter Euclidean distance to the voter. We study
how 2-dimensional Euclidean preference profiles depend on the values m and n.
We find that any profile with at most two voters or at most three alternatives
is 2-dimensional Euclidean while for three voters, we can show this property
for up to seven alternatives. The results are tight in terms of Bogomolnaia and
Laslier [2, Proposition 15(1)].",2205.14687v1,cs.GT,2022-05-29 15:06:14+00:00,"[arxiv.Result.Author('Laurent Bulteau'), arxiv.Result.Author('Jiehua Chen')]",
1289,TRIP: Trustless Coercion-Resistant In-Person Voter Registration,"Most existing remote electronic voting systems are vulnerable to voter
coercion and vote buying. While coercion-resistant voting systems address this
challenge, current schemes assume that the voter has access to an untappable,
incorruptible device during voter registration. We present TRIP, an in-person
voter registration scheme enabling voters to create verifiable and
indistinguishable real and fake credentials using an untrusted kiosk inside a
privacy booth at a supervised location, e.g., the registrar's office. TRIP
ensures the integrity of the voter's real credential while enabling the
creation of fake credentials using interactive zero-knowledge proofs between
the voter as the verifier and the kiosk as the prover, unbeknownst to the
average voter. TRIP ensures that even voters who are under extreme coercion,
and cannot leave the booth with a real credential, can delegate their vote to a
political party, with the caveat that they must then trust the kiosk. TRIP
optimizes the tallying process by limiting the number of credentials a voter
can receive and capping the number of votes that a credential can cast per
election. We conduct a preliminary usability study among 41 participants at a
university and found that 42.5% of participants rated TRIP a B or higher in
usability, a promising result for a voter registration scheme that
substantially reduces trust in the registrar.",2202.06692v1,cs.CR,2022-02-14 13:35:46+00:00,"[arxiv.Result.Author('Louis-Henri Merino'), arxiv.Result.Author('Simone Colombo'), arxiv.Result.Author('Jeff Allen'), arxiv.Result.Author('Vero Estrada-Galiñanes'), arxiv.Result.Author('Bryan Ford')]",
1290,Combinatorial Voter Control in Elections,"Voter control problems model situations such as an external agent trying to
affect the result of an election by adding voters, for example by convincing
some voters to vote who would otherwise not attend the election. Traditionally,
voters are added one at a time, with the goal of making a distinguished
alternative win by adding a minimum number of voters. In this paper, we
initiate the study of combinatorial variants of control by adding voters: In
our setting, when we choose to add a voter~$v$, we also have to add a whole
bundle $\kappa(v)$ of voters associated with $v$. We study the computational
complexity of this problem for two of the most basic voting rules, namely the
Plurality rule and the Condorcet rule.",1406.6859v1,cs.MA,2014-06-26 11:55:44+00:00,"[arxiv.Result.Author('Laurent Bulteau'), arxiv.Result.Author('Jiehua Chen'), arxiv.Result.Author('Piotr Faliszewski'), arxiv.Result.Author('Rolf Niedermeier'), arxiv.Result.Author('Nimrod Talmon')]",
1291,A Parameterized Perspective on Protecting Elections,"We study the parameterized complexity of the optimal defense and optimal
attack problems in voting. In both the problems, the input is a set of voter
groups (every voter group is a set of votes) and two integers $k_a$ and $k_d$
corresponding to respectively the number of voter groups the attacker can
attack and the number of voter groups the defender can defend. A voter group
gets removed from the election if it is attacked but not defended. In the
optimal defense problem, we want to know if it is possible for the defender to
commit to a strategy of defending at most $k_d$ voter groups such that, no
matter which $k_a$ voter groups the attacker attacks, the outcome of the
election does not change. In the optimal attack problem, we want to know if it
is possible for the attacker to commit to a strategy of attacking $k_a$ voter
groups such that, no matter which $k_d$ voter groups the defender defends, the
outcome of the election is always different from the original (without any
attack) one.",1905.11838v1,cs.MA,2019-05-28 14:20:33+00:00,"[arxiv.Result.Author('Palash Dey'), arxiv.Result.Author('Neeldhara Misra'), arxiv.Result.Author('Swaprava Nath'), arxiv.Result.Author('Garima Shakya')]",
1292,Wisdom of the Crowd Voting: Truthful Aggregation of Voter Information and Preferences,"We consider two-alternative elections where voters' preferences depend on a
state variable that is not directly observable. Each voter receives a private
signal that is correlated to the state variable. Voters may be ""contingent""
with different preferences in different states; or predetermined with the same
preference in every state. In this setting, even if every voter is a contingent
voter, agents voting according to their private information need not result in
the adoption of the universally preferred alternative, because the signals can
be systematically biased.
  We present an easy-to-deploy mechanism that elicits and aggregates the
private signals from the voters, and outputs the alternative that is favored by
the majority. In particular, voters truthfully reporting their signals forms a
strong Bayes Nash equilibrium (where no coalition of voters can deviate and
receive a better outcome).",2108.03749v1,cs.GT,2021-08-08 22:20:15+00:00,"[arxiv.Result.Author('Grant Schoenebeck'), arxiv.Result.Author('Biaoshuai Tao')]","Advances in Neural Information Processing Systems 2021, Vol. 34,
  Page 1872--1883"
1293,Remote detection of undeclared nuclear reactors using the WATCHMAN detector,"Remote detection of undeclared nuclear reactors remains one of the key goals
concerning global nuclear security. To meet this goal the WATCHMAN
collaboration has proposed the construction of a water based antineutrino
detector, sited 13 to 25 kilometres from a nuclear reactor complex.
Antineutrinos from the reactor interact in the water of the detector via an
inverse beta decay interaction resulting in two distinct cones of Cherenkov
light tens of milliseconds apart. Using this interaction WATCHMAN (WATer
Cherenkov Monitor for ANtineutrinos) will be the first detector to determine
the active/inactive status of a reactor complex at a stand-off greater than 10
kilometres. The water used in the detector will be doped with gadolinium,
providing the first demonstration of the potential of gadolinium doped
detectors for reactor monitoring and will confirm the potential of the
technology for use in larger multi-kiloton neutrino experiments. The proposed
WATCHMAN design will be a kiloton scale water based detector, constructed of a
16 metre diameter tank with a height of 16 metres and will comprise
approximately 3000 photomultiplier tubes.
  An overview of the remote monitoring goals of the WATCHMAN collaboration will
be given, with a detailed description of the proposed detector. An outline of
the two proposed WATCHMAN sites will also be detailed with a prediction of the
expected antineutrino rate and the time taken to determine the switch between
the associated reactor on and off state at each site. A brief summary of the
project and the future goals non-proliferation goals of the collaboration will
also be presented.",1804.00655v1,physics.ins-det,2018-04-01 19:59:54+00:00,[arxiv.Result.Author('Jonathan Burns')],
1294,Prompt-tuned Code Language Model as a Neural Knowledge Base for Type Inference in Statically-Typed Partial Code,"Partial code usually involves non-fully-qualified type names (non-FQNs) and
undeclared receiving objects. Resolving the FQNs of these non-FQN types and
undeclared receiving objects (referred to as type inference) is the
prerequisite to effective search and reuse of partial code. Existing
dictionary-lookup based methods build a symbolic knowledge base of API names
and code contexts, which involve significant compilation overhead and are
sensitive to unseen API names and code context variations. In this paper, we
formulate type inference as a cloze-style fill-in-blank language task. Built on
source code naturalness, our approach fine-tunes a code masked language model
(MLM) as a neural knowledge base of code elements with a novel ""pre-train,
prompt and predict"" paradigm from raw source code. Our approach is lightweight
and has minimum requirements on code compilation. Unlike existing symbolic name
and context matching for type inference, our prompt-tuned code MLM packs FQN
syntax and usage in its parameters and supports fuzzy neural type inference. We
systematically evaluate our approach on a large amount of source code from
GitHub and Stack Overflow. Our results confirm the effectiveness of our
approach design and the practicality for partial code type inference. As the
first of its kind, our neural type inference method opens the door to many
innovative ways of using partial code.",2208.05361v2,cs.SE,2022-08-10 14:16:45+00:00,"[arxiv.Result.Author('Qing Huang'), arxiv.Result.Author('Zhiqiang Yuan'), arxiv.Result.Author('Zhenchang Xing'), arxiv.Result.Author('Xiwei Xu'), arxiv.Result.Author('Liming Zhu'), arxiv.Result.Author('Qinghua Lu')]",
1295,k-Majority Digraphs and the Hardness of Voting with a Constant Number of Voters,"Many hardness results in computational social choice make use of the fact
that every directed graph may be induced as the pairwise majority relation of
some preference profile. However, this fact requires a number of voters that is
almost linear in the number of alternatives. It is therefore unclear whether
these results remain intact when the number of voters is bounded, as is, for
example, typically the case in search engine aggregation settings. In this
paper, we provide a systematic study of majority digraphs for a constant number
of voters resulting in analytical, experimental, and complexity-theoretic
insights. First, we characterize the set of digraphs that can be induced by two
and three voters, respectively, and give sufficient conditions for larger
numbers of voters. Second, we present a surprisingly efficient implementation
via SAT solving for computing the minimal number of voters that is required to
induce a given digraph and experimentally evaluate how many voters are required
to induce the majority digraphs of real-world and generated preference
profiles. Finally, we leverage our sufficient conditions to show that the
winner determination problem of various well-known voting rules remains hard
even when there is only a small constant number of voters. In particular, we
show that Kemeny's rule is hard to evaluate for 7 voters, while previous
methods could only establish such a result for constant even numbers of voters.",1704.06304v1,cs.GT,2017-04-20 19:04:28+00:00,"[arxiv.Result.Author('Georg Bachmeier'), arxiv.Result.Author('Felix Brandt'), arxiv.Result.Author('Christian Geist'), arxiv.Result.Author('Paul Harrenstein'), arxiv.Result.Author('Keyvan Kardel'), arxiv.Result.Author('Dominik Peters'), arxiv.Result.Author('Hans Georg Seedig')]",
1296,Reputation-Driven Voting Dynamics,"We introduce the reputational voter model (RVM) to account for the
time-varying abilities of individuals to influence their neighbors. To
understand of the RVM, we first discuss the fitness voter model (FVM), in which
each voter has a fixed and distinct fitness. In a voting event where voter $i$
is fitter than voter $j$, only $j$ changes opinion. We show that the dynamics
of the FVM and the voter model are identical. We next discuss the adaptive
voter model (AVM), in which the influencing voter in a voting event increases
its fitness by a fixed amount. The dynamics of the AVM is non-stationary and
slowly crosses over to that of FVM because of the gradual broadening of the
fitness distribution of the population. Finally, we treat the RVM, in which the
voter $i$ is endowed with a reputational rank $r_i$ that ranges from 1 (highest
rank) to $N$ (lowest), where $N$ is the population size. In a voting event in
which voter $i$ outranks $j$, only the opinion of $j$ changes. Concomitantly,
the rank of $i$ increases, while that of $j$ does not change. The rank
distribution remains uniform on the integers $1,2,3,\ldots,N$, leading to
stationary dynamics. For equal number of voters in the two voting states with
these two subpopulations having the same average rand, the time to reach
consensus in the mean-field limit scales as $\exp(\sqrt{N})$. This long
consensus time arises because the average rank of the minority population is
typically higher than that of the majority. Thus whenever consensus is
approached, this highly ranked minority tends to drive the population away from
consensus.",1902.09371v2,physics.soc-ph,2019-02-22 18:19:16+00:00,"[arxiv.Result.Author('D. Bhat'), arxiv.Result.Author('S. Redner')]",J. Stat. Mech. (2019) 063208
1297,Slower is faster: Fostering consensus formation by heterogeneous intertia,"We investigate an extension of the voter model in which voters are equipped
with an individual inertia to change their opinion. This inertia depends on the
persistence time of a voter's current opinion (ageing). We focus on the case of
only two different inertia values: zero if a voter just changed towards a new
opinion and $\nu$ otherwise. We are interested in the average time to reach
consensus, i.e. the state in which all voters have adopted the same opinion.
Adding inertia to the system means to slow down the dynamics at the voter's
level, which should presumably lead to a slower consensus formation. As an
unexpected outcome of our inertial voter dynamics, there is a parameter region
of $\nu$ where an increasing inertia leads to a faster consensus formation.
These results rest on the heterogeneity of voters which evolves through the
described ageing. In a control setting of homogeneous inertia values, we only
find monotonously increasing consensus times. In the paper, we present
dynamical equations for the mean-field case which allow for analytical insight
into the observed slower-is-faster effect.",0904.0765v1,physics.soc-ph,2009-04-05 12:22:31+00:00,"[arxiv.Result.Author('Hans-Ulrich Stark'), arxiv.Result.Author('Claudio J. Tessone'), arxiv.Result.Author('Frank Schweitzer')]","ACS - Advances in Complex Systems, vol 11, no 4 (2008) pp. 87-116"
1298,On the Number of Single-Peaked Narcissistic or Single-Crossing Narcissistic Preference Profiles,"We investigate preference profiles for a set $\mathcal{V}$ of voters, where
each voter $i$ has a preference order $\succ_i$ on a finite set $A$ of
alternatives (that is, a linear order on $A$) such that for each two
alternatives $a,b\in A$, voter $i$ prefers $a$ to $b$ if $a\succ_i b$. Such a
profile is narcissistic if each alternative $a$ is preferred the most by at
least one voter. It is single-peaked if there is a linear order
$\triangleright^{\text{sp}}$ on the alternatives such that each voter's
preferences on the alternatives along the order $\triangleright^{\text{sp}}$
are either strictly increasing, or strictly decreasing, or first strictly
increasing and then strictly decreasing. It is single-crossing if there is a
linear order $\triangleright^{\text{sc}}$ on the voters such that each pair of
alternatives divides the order $\triangleright^{\text{sc}}$ into at most two
suborders, where in each suborder, all voters have the same linear order on
this pair.
  We show that for $n$ voters and $n$ alternatives,the number of single-peaked
narcissistic profiles is $\prod_{i=2}^{n-1} \binom{n-1}{i-1}$ while the number
of single-crossing narcissistic profiles is $2^{\binom{n-1}{2}}$.",1701.08652v2,math.CO,2017-01-25 16:45:43+00:00,"[arxiv.Result.Author('Jiehua Chen'), arxiv.Result.Author('Ugo P. Finnendahl')]",
1299,Multidimensional Manhattan Preferences,"A preference profile with $m$ alternatives and $n$ voters is $d$-Manhattan
(resp. $d$-Euclidean) if both the alternatives and the voters can be placed
into the $d$-dimensional space such that between each pair of alternatives,
every voter prefers the one which has a shorter Manhattan (resp. Euclidean)
distance to the voter. Following Bogomolnaia and Laslier [Journal of
Mathematical Economics, 2007] and Chen and Grottke [Social Choice and Welfare,
2021] who look at $d$-Euclidean preference profiles, we study which preference
profiles are $d$-Manhattan depending on the values $m$ and $n$.
  First, we show that each preference profile with $m$ alternatives and $n$
voters is $d$-Manhattan whenever $d$ $\geq$ min($n$, $m$-$1$). Second, for $d =
2$, we show that the smallest non $d$-Manhattan preference profile has either
three voters and six alternatives, or four voters and five alternatives, or
five voters and four alternatives. This is more complex than the case with
$d$-Euclidean preferences (see [Bogomolnaia and Laslier, 2007] and [Bulteau and
Chen, 2020].",2201.09691v1,cs.MA,2022-01-24 13:52:38+00:00,"[arxiv.Result.Author('Jiehua Chen'), arxiv.Result.Author('Martin Nöllenburg'), arxiv.Result.Author('Sofia Simola'), arxiv.Result.Author('Anaïs Villedieu'), arxiv.Result.Author('Markus Wallinger')]",
1300,Fault Masking By Probabilistic Voting,"In this study, we introduced a probabilistic voter, regarding symbol
probabilities in decision process besides majority consensus. Conventional
majority voter is independent of functionality of redundant modules. In our
study, proposed probabilistic voter is designed corresponding to functionality
of the redundant module. We tested probabilistic voter for 3 and 5 redundant
modules with random transient errors inserted the wires and it was seen from
simulation results that Multi-Modular Redundancy (M-MR) with Probabilistic
Voting (PV) had been shown better availability performance than conventional
majority voter.",0901.1181v2,cs.OH,2009-01-09 13:55:57+00:00,[arxiv.Result.Author('B. Baykant Alagoz')],"OncuBilim Algorithm And Systems Labs. Vol.09, Art.No:01,(2009)"
1301,Quantum anonymous voting with anonymity check,"We propose a new protocol for quantum anonymous voting having serious
advantages over the existing protocols: it protects both the voters from a
curious tallyman and all the participants from a dishonest voter in
unconditional way. The central idea of the protocol is that the ballots are
given back to the voters after the voting process, which gives a possibility
for two voters to check the anonymity of the vote counting process by preparing
a special entangled state of two ballots. Any attempt of cheating from the side
of the tallyman results in destroying the entanglement, which can be detected
by the voters.",0911.5605v1,quant-ph,2009-11-30 10:39:14+00:00,"[arxiv.Result.Author('Dmitri Horoshko'), arxiv.Result.Author('Sergei Kilin')]","Physics Letters A 375, 1172-1175 (2011)"
1302,Geometric vulnerability of democratic institutions against lobbying: a sociophysics approach,"An alternative voting scheme is proposed to fill the democratic gap between a
president elected democratically via universal suffrage (deterministic outcome,
the actual majority decides), and a president elected by one person randomly
selected from the population (probabilistic outcome depending on respective
supports). Moving from one voting agent to a group of r randomly selected
voting agents reduces the probabilistic character of the outcome. Building r
such groups, each one electing its president, to constitute a group of the
groups with the r local presidents electing a higher-level president, does
reduce further the outcome probabilistic aspect. Repeating the process n times
leads to a n-level bottom-up pyramidal structure. The hierarchy top president
is still elected with a probability but the distance from a deterministic
outcome reduces quickly with increasing n. At a critical value n_{c,r} the
outcome turns deterministic recovering the same result a universal suffrage
would yield. The scheme yields several social advantages like the distribution
of local power to the competing minority making the structure more resilient,
yet preserving the presidency allocation to the actual majority. An area is
produced around fifty percent for which the president is elected with an almost
equiprobability slightly biased in favor of the actual majority. However, our
results reveal the existence of a severe geometric vulnerability to lobbying. A
tiny lobbying group is able to kill the democratic balance by seizing the
presidency democratically. It is sufficient to complete a correlated
distribution of a few agents at the hierarchy bottom. Moreover, at the present
stage, identifying an actual killing distribution is not feasible, which sheds
a disturbing light on the devastating effect geometric lobbying can have on
democratic hierarchical institutions.",1701.02621v1,physics.soc-ph,2017-01-10 14:52:19+00:00,[arxiv.Result.Author('Serge Galam')],
1303,Abolitionist Networks: Modeling Language Change in Nineteenth-Century Activist Newspapers,"The abolitionist movement of the nineteenth-century United States remains
among the most significant social and political movements in US history.
Abolitionist newspapers played a crucial role in spreading information and
shaping public opinion around a range of issues relating to the abolition of
slavery. These newspapers also serve as a primary source of information about
the movement for scholars today, resulting in powerful new accounts of the
movement and its leaders. This paper supplements recent qualitative work on the
role of women in abolition's vanguard, as well as the role of the Black press,
with a quantitative text modeling approach. Using diachronic word embeddings,
we identify which newspapers tended to lead lexical semantic innovations -- the
introduction of new usages of specific words -- and which newspapers tended to
follow. We then aggregate the evidence across hundreds of changes into a
weighted network with the newspapers as nodes; directed edge weights represent
the frequency with which each newspaper led the other in the adoption of a
lexical semantic change. Analysis of this network reveals pathways of lexical
semantic influence, distinguishing leaders from followers, as well as others
who stood apart from the semantic changes that swept through this period. More
specifically, we find that two newspapers edited by women -- THE PROVINCIAL
FREEMAN and THE LILY -- led a large number of semantic changes in our corpus,
lending additional credence to the argument that a multiracial coalition of
women led the abolitionist movement in terms of both thought and action. It
also contributes additional complexity to the scholarship that has sought to
tease apart the relation of the abolitionist movement to the women's suffrage
movement, and the vexed racial politics that characterized their relation.",2103.07538v1,cs.CL,2021-03-12 21:26:30+00:00,"[arxiv.Result.Author('Sandeep Soni'), arxiv.Result.Author('Lauren Klein'), arxiv.Result.Author('Jacob Eisenstein')]",Journal of Cultural Analytics (2021)
1304,SoK: Blockchain Governance,"Blockchain systems come with a promise of decentralization that often
stumbles on a roadblock when key decisions about modifying the software
codebase need to be made. This is attested by the fact that both of the two
major cryptocurrencies, Bitcoin and Ethereum, have undergone hard forks that
resulted in the creation of alternative systems, creating confusion and
opportunities for fraudulent activities. These events, and numerous others,
underscore the importance of Blockchain governance, namely the set of processes
that blockchain platforms utilize in order to perform decision-making and
converge to a widely accepted direction for the system to evolve. While a rich
topic of study in other areas, governance of blockchain platforms is lacking a
well established set of methods and practices that are adopted industry wide.
This makes the topic of blockchain governance a fertile domain for a thorough
systematization that we undertake in this work.
  We start by distilling a comprehensive array of properties for sound
governance systems drawn from academic sources as well as grey literature of
election systems and blockchain white papers. These are divided into seven
categories, confidentiality, verifiability, accountability, sustainability,
Pareto efficiency, suffrage and liveness that capture the whole spectrum of
desiderata of governance systems. We proceed to classify ten well-documented
blockchain systems. While all properties are satisfied, even partially, by at
least one system, no system that satisfies most of them. Our work lays out a
foundation for assessing blockchain governance processes. While it highlights
shortcomings and deficiencies in currently deployed systems, it can also be a
catalyst for improving these processes to the highest possible standard with
appropriate trade-offs, something direly needed for blockchain platforms to
operate effectively in the long term.",2201.07188v3,cs.CR,2022-01-18 18:38:26+00:00,"[arxiv.Result.Author('Aggelos Kiayias'), arxiv.Result.Author('Philip Lazos')]",
1305,On universal operators and universal pairs,"We study some basic properties of the class of universal operators on Hilbert
space, and provide new examples of universal operators and universal pairs.",1702.05276v1,math.FA,2017-02-17 09:43:20+00:00,"[arxiv.Result.Author('Riikka Schroderus'), arxiv.Result.Author('Hans-Olav Tylli')]",
1306,Deep exclusive electroproduction of $π^0$ at high $Q^2$ in the quark valence regime,"We report measurements of the exclusive neutral pion electroproduction cross
section off protons at large values of $x_B$ (0.36, 0.48 and 0.60) and $Q^2$
(3.1 to 8.4 GeV$^2$) obtained from Jefferson Lab Hall A experiment E12-06-014.
The corresponding structure functions $d\sigma_L/dt+\epsilon d\sigma_T/dt$,
$d\sigma_{TT}/dt$, $d\sigma_{LT}/dt$ and $d\sigma_{LT'}/dt$ are extracted as a
function of the proton momentum transfer $t-t_{min}$. The results suggest the
amplitude for transversely polarized virtual photons continues to dominate the
cross-section throughout this kinematic range. The data are well described by
calculations based on transversity Generalized Parton Distributions coupled to
a helicity flip Distribution Amplitude of the pion, thus providing a unique way
to probe the structure of the nucleon.",2011.11125v2,hep-ex,2020-11-22 22:20:34+00:00,"[arxiv.Result.Author('The Jefferson Lab Hall A Collaboration'), arxiv.Result.Author('M. Dlamini'), arxiv.Result.Author('B. Karki'), arxiv.Result.Author('S. F. Ali'), arxiv.Result.Author('P-J. Lin'), arxiv.Result.Author('F. Georges'), arxiv.Result.Author('H-S Ko'), arxiv.Result.Author('N. Israel'), arxiv.Result.Author('M. N. H. Rashad'), arxiv.Result.Author('A. Stefanko'), arxiv.Result.Author('D. Adikaram'), arxiv.Result.Author('Z. Ahmed'), arxiv.Result.Author('H. Albataineh'), arxiv.Result.Author('B. Aljawrneh'), arxiv.Result.Author('K. Allada'), arxiv.Result.Author('S. Allison'), arxiv.Result.Author('S. Alsalmi'), arxiv.Result.Author('D. Androic'), arxiv.Result.Author('K. Aniol'), arxiv.Result.Author('J. Annand'), arxiv.Result.Author('H. Atac'), arxiv.Result.Author('T. Averett'), arxiv.Result.Author('C. Ayerbe Gayoso'), arxiv.Result.Author('X. Bai'), arxiv.Result.Author('J. Bane'), arxiv.Result.Author('S. Barcus'), arxiv.Result.Author('K. Bartlett'), arxiv.Result.Author('V. Bellini'), arxiv.Result.Author('R. Beminiwattha'), arxiv.Result.Author('J. Bericic'), arxiv.Result.Author('D. Biswas'), arxiv.Result.Author('E. Brash'), arxiv.Result.Author('D. Bulumulla'), arxiv.Result.Author('J. Campbell'), arxiv.Result.Author('A. Camsonne'), arxiv.Result.Author('M. Carmignotto'), arxiv.Result.Author('J. Castellano'), arxiv.Result.Author('C. Chen'), arxiv.Result.Author('J-P. Chen'), arxiv.Result.Author('T. Chetry'), arxiv.Result.Author('M. E. Christy'), arxiv.Result.Author('E. Cisbani'), arxiv.Result.Author('B. Clary'), arxiv.Result.Author('E. Cohen'), arxiv.Result.Author('N. Compton'), arxiv.Result.Author('J. C. Cornejo'), arxiv.Result.Author('S. Covrig Dusa'), arxiv.Result.Author('B. Crowe'), arxiv.Result.Author('S. Danagoulian'), arxiv.Result.Author('T. Danley'), arxiv.Result.Author('F. De Persio'), arxiv.Result.Author('W. Deconinck'), arxiv.Result.Author('M. Defurne'), arxiv.Result.Author('C. Desnault'), arxiv.Result.Author('D. Di'), arxiv.Result.Author('M. Duer'), arxiv.Result.Author('B. Duran'), arxiv.Result.Author('R. Ent'), arxiv.Result.Author('C. Fanelli'), arxiv.Result.Author('G. Franklin'), arxiv.Result.Author('E. Fuchey'), arxiv.Result.Author('C. Gal'), arxiv.Result.Author('D. Gaskell'), arxiv.Result.Author('T. Gautam'), arxiv.Result.Author('O. Glamazdin'), arxiv.Result.Author('K. Gnanvo'), arxiv.Result.Author('V. M. Gray'), arxiv.Result.Author('C. Gu'), arxiv.Result.Author('T. Hague'), arxiv.Result.Author('G. Hamad'), arxiv.Result.Author('D. Hamilton'), arxiv.Result.Author('K. Hamilton'), arxiv.Result.Author('O. Hansen'), arxiv.Result.Author('F. Hauenstein'), arxiv.Result.Author('W. Henry'), arxiv.Result.Author('D. W. Higinbotham'), arxiv.Result.Author('T. Holmstrom'), arxiv.Result.Author('T. Horn'), arxiv.Result.Author('Y. Huang'), arxiv.Result.Author('G. M. Huber'), arxiv.Result.Author('C. Hyde'), arxiv.Result.Author('H. Ibrahim'), arxiv.Result.Author('C-M. Jen'), arxiv.Result.Author('K. Jin'), arxiv.Result.Author('M. Jones'), arxiv.Result.Author('A. Kabir'), arxiv.Result.Author('C. Keppel'), arxiv.Result.Author('V. Khachatryan'), arxiv.Result.Author('P. M. King'), arxiv.Result.Author('S. Li'), arxiv.Result.Author('W. Li'), arxiv.Result.Author('J. Liu'), arxiv.Result.Author('H. Liu'), arxiv.Result.Author('A. Liyanage'), arxiv.Result.Author('J. Magee'), arxiv.Result.Author('S. Malace'), arxiv.Result.Author('J. Mammei'), arxiv.Result.Author('P. Markowitz'), arxiv.Result.Author('E. McClellan'), arxiv.Result.Author('F. Meddi'), arxiv.Result.Author('D. Meekins'), arxiv.Result.Author('K. Mesik'), arxiv.Result.Author('R. Michaels'), arxiv.Result.Author('A. Mkrtchyan'), arxiv.Result.Author('R. Montgomery'), arxiv.Result.Author('C. Munoz Camacho'), arxiv.Result.Author('L. S. Myers'), arxiv.Result.Author('P. Nadel-Turonski'), arxiv.Result.Author('S. J. Nazeer'), arxiv.Result.Author('V. Nelyubin'), arxiv.Result.Author('D. Nguyen'), arxiv.Result.Author('N. Nuruzzaman'), arxiv.Result.Author('M. Nycz'), arxiv.Result.Author('O. F. Obretch'), arxiv.Result.Author('L. Ou'), arxiv.Result.Author('C. Palatchi'), arxiv.Result.Author('B. Pandey'), arxiv.Result.Author('S. Park'), arxiv.Result.Author('K. Park'), arxiv.Result.Author('C. Peng'), arxiv.Result.Author('R. Pomatsalyuk'), arxiv.Result.Author('E. Pooser'), arxiv.Result.Author('A. J. R. Puckett'), arxiv.Result.Author('V. Punjabi'), arxiv.Result.Author('B. Quinn'), arxiv.Result.Author('S. Rahman'), arxiv.Result.Author('P. E. Reimer'), arxiv.Result.Author('J. Roche'), arxiv.Result.Author('I. Sapkota'), arxiv.Result.Author('A. Sarty'), arxiv.Result.Author('B. Sawatzky'), arxiv.Result.Author('N. H. Saylor'), arxiv.Result.Author('B. Schmookler'), arxiv.Result.Author('M. H. Shabestari'), arxiv.Result.Author('A. Shahinyan'), arxiv.Result.Author('S. Sirca'), arxiv.Result.Author('G. R. Smith'), arxiv.Result.Author('S. Sooriyaarachchilage'), arxiv.Result.Author('N. Sparveris'), arxiv.Result.Author('R. Spies'), arxiv.Result.Author('T. Su'), arxiv.Result.Author('A. Subedi'), arxiv.Result.Author('V. Sulkosky'), arxiv.Result.Author('A. Sun'), arxiv.Result.Author('L. Thorne'), arxiv.Result.Author('Y. Tian'), arxiv.Result.Author('N. Ton'), arxiv.Result.Author('F. Tortorici'), arxiv.Result.Author('R. Trotta'), arxiv.Result.Author('G. M. Urciuoli'), arxiv.Result.Author('E. Voutier'), arxiv.Result.Author('B. Waidyawansa'), arxiv.Result.Author('Y. Wang'), arxiv.Result.Author('B. Wojtsekhowski'), arxiv.Result.Author('S. Wood'), arxiv.Result.Author('X. Yan'), arxiv.Result.Author('L. Ye'), arxiv.Result.Author('Z. Ye'), arxiv.Result.Author('C. Yero'), arxiv.Result.Author('J. Zhang'), arxiv.Result.Author('Y. Zhao'), arxiv.Result.Author('P. Zhu')]","Phys. Rev. Lett. 127, 152301 (2021)"
1307,The Mirror Universes,"In this paper we investigate the structure of the Mirror Universes. The two
universes are coupled with transformation t to -t. It is shown that for Planck
scale the oscillations of temperature of the universes are observed. For the
Mirror Universes the temperature fields are shifted in phase.
  Key words: Gravity; Universe temperature; Oscillation of temperature.",gr-qc/0505116v1,gr-qc,2005-05-23 13:27:42+00:00,"[arxiv.Result.Author('M. Kozlowski'), arxiv.Result.Author('J. Marciak-Kozlowska')]",
1308,On the universal norm distribution,"We introduce and study the universal norm distribution in this paper, which
generalizes the concepts of universal ordinary distribution and the universal
Euler system. We study the Anderson type resolution of the universal norm
distribution and then use this resolution to study the group cohomology of the
universal norm distribution.",math/0210297v2,math.NT,2002-10-18 21:15:01+00:00,[arxiv.Result.Author('Yi Ouyang')],
1309,Intrinsically Universal Cellular Automata,"This talk advocates intrinsic universality as a notion to identify simple
cellular automata with complex computational behavior. After an historical
introduction and proper definitions of intrinsic universality, which is
discussed with respect to Turing and circuit universality, we discuss
construction methods for small intrinsically universal cellular automata before
discussing techniques for proving non universality.",0906.3213v1,cs.CC,2009-06-17 15:24:44+00:00,[arxiv.Result.Author('Nicolas Ollinger')],"EPTCS 1, 2009, pp. 199-204"
1310,A Conversation with Seymour Geisser,"Seymour Geisser received his bachelor's degree in Mathematics from the City
College of New York in 1950, and his M.A. and Ph.D. degrees in Mathematical
Statistics at the University of North Carolina in 1952 and 1955, respectively.
He then held positions at the National Bureau of Standards and the National
Institute of Mental Health until 1961. From 1961 until 1965, he was Chief of
the Biometry Section at the National Institute of Arthritis and Metabolic
Diseases, and also held the position of Professorial Lecturer at the George
Washington University from 1960 to 1965. From 1965 to 1970, he was the founding
Chair of the Department of Statistics at the State University of New York,
Buffalo, and in 1971, he became the founding Director of the School of
Statistics at the University of Minnesota, remaining in that position until
2001. He held visiting professorships at Iowa State University, 1960;
University of Wisconsin, 1964; University of Tel-Aviv (Israel), 1971;
University of Waterloo (Canada), 1972; Stanford University, 1976, 1977, 1988;
Carnegie Mellon University, 1976; University of the Orange Free State (South
Africa), 1978, 1993; Harvard University, 1981; University of Chicago, 1985;
University of Warwick (England), 1986; University of Modena (Italy), 1996; and
National Chiao Tung University (Taiwan), 1998. He was the Lady Davis Visiting
Professor, Hebrew University of Jerusalem, 1991, 1994, 1999, and the Schor
Scholar, Merck Research Laboratories, 2002-2003. He was a Fellow of the
Institute of Mathematical Statistics and the American Statistical Association.",0804.3243v1,stat.ME,2008-04-21 07:06:30+00:00,"[arxiv.Result.Author('Ronald Christensen'), arxiv.Result.Author('Wesley Johnson')]","Statistical Science 2007, Vol. 22, No. 4, 621-636"
1311,"Comparing Production Cross Sections for QCD Matter, Higgs Boson, Neutrino with Dark Energy in Accelerating Universe","In this research, the production cross sections for QCD matter, neutrino and
dark energy due to acceleration of Universe is calculated. To obtain these
cross sections, the Universe production cross section is multiplied by the
particle or dark energy distribution in accelerating Universe. Also missing
cross section for each matter and dark energy due to formation of event
horizon, is calculated. It is clear that the cross section of particles
produced near event horizon of Universe is much larger for higher acceleration
of Universe. This is because as the acceleration of Universe becomes larger,
the Unruh temperature becomes larger and the thermal radiations of particles
are enhanced. There are different channels for producing Higgs boson in
accelerating Universe. Universe maybe decay to quark and gluons, and then these
particles interact with each other and Higgs boson is produced. Also, some
Higgs boson are emitted directly from event horizon of Universe. Comparing
Higgs boson cross sections via different channels, it is observed that at lower
acceleration, a_Universe<2.5 a_(early Universe), the Universe will not be able
to emit Higgs, but is still able to produce a quark and eventually for
a_Universe<1.5 a_(early Universe) the Universe can only emit massless gluons.
As the acceleration of Universe at the LHC increases, a_Universe>2.5 a_(early
Universe), most of Higgs boson production will be due to Unruh effect near
event horizon of Universe. Finally comparing the production cross section for
dark energy with particle cross sections, it is found that the cross section
for dark energy is dominated by QCD matter, Higgs boson and neutrino. This
result is consistent with previous predictions for dark energy cross section.",1610.04410v2,hep-ph,2016-10-14 11:18:41+00:00,[arxiv.Result.Author('Tooraj Ghaffary')],
1312,Validation of the HERA Phase I Epoch of Reionization 21 cm Power Spectrum Software Pipeline,"We describe the validation of the HERA Phase I software pipeline by a series
of modular tests, building up to an end-to-end simulation. The philosophy of
this approach is to validate the software and algorithms used in the Phase I
upper limit analysis on wholly synthetic data satisfying the assumptions of
that analysis, not addressing whether the actual data meet these assumptions.
We discuss the organization of this validation approach, the specific modular
tests performed, and the construction of the end-to-end simulations. We
explicitly discuss the limitations in scope of the current simulation effort.
With mock visibility data generated from a known analytic power spectrum and a
wide range of realistic instrumental effects and foregrounds, we demonstrate
that the current pipeline produces power spectrum estimates that are consistent
with known analytic inputs to within thermal noise levels (at the 2 sigma
level) for k > 0.2 h/Mpc for both bands and fields considered. Our input
spectrum is intentionally amplified to enable a strong `detection' at k ~0.2
h/Mpc -- at the level of ~25 sigma -- with foregrounds dominating on larger
scales, and thermal noise dominating at smaller scales. Our pipeline is able to
detect this amplified input signal after suppressing foregrounds with a dynamic
range (foreground to noise ratio) of > 10^7. Our validation test suite
uncovered several sources of scale-independent signal loss throughout the
pipeline, whose amplitude is well-characterized and accounted for in the final
estimates. We conclude with a discussion of the steps required for the next
round of data analysis.",2104.09547v1,astro-ph.IM,2021-04-19 18:16:33+00:00,"[arxiv.Result.Author('James E. Aguirre'), arxiv.Result.Author('Steven G. Murray'), arxiv.Result.Author('Robert Pascua'), arxiv.Result.Author('Zachary E. Martinot'), arxiv.Result.Author('Jacob Burba'), arxiv.Result.Author('Joshua S. Dillon'), arxiv.Result.Author('Daniel C. Jacobs'), arxiv.Result.Author('Nicholas S. Kern'), arxiv.Result.Author('Piyanat Kittiwisit'), arxiv.Result.Author('Matthew Kolopanis'), arxiv.Result.Author('Adam Lanman'), arxiv.Result.Author('Adrian Liu'), arxiv.Result.Author('Lily Whitler'), arxiv.Result.Author('Zara Abdurashidova'), arxiv.Result.Author('Paul Alexander'), arxiv.Result.Author('Zaki S. Ali'), arxiv.Result.Author('Yanga Balfour'), arxiv.Result.Author('Adam P. Beardsley'), arxiv.Result.Author('Gianni Bernardi'), arxiv.Result.Author('Tashalee S. Billings'), arxiv.Result.Author('Judd D. Bowman'), arxiv.Result.Author('Richard F. Bradley'), arxiv.Result.Author('Philip Bull'), arxiv.Result.Author('Steve Carey'), arxiv.Result.Author('Chris L. Carilli'), arxiv.Result.Author('Carina Cheng'), arxiv.Result.Author('David R. DeBoer'), arxiv.Result.Author('Matt Dexter'), arxiv.Result.Author('Eloy de Lera Acedo'), arxiv.Result.Author('John Ely'), arxiv.Result.Author('Aaron Ewall-Wice'), arxiv.Result.Author('Nicolas Fagnoni'), arxiv.Result.Author('Randall Fritz'), arxiv.Result.Author('Steven R. Furlanetto'), arxiv.Result.Author('Kingsley Gale-Sides'), arxiv.Result.Author('Brian Glendenning'), arxiv.Result.Author('Deepthi Gorthi'), arxiv.Result.Author('Bradley Greig'), arxiv.Result.Author('Jasper Grobbelaar'), arxiv.Result.Author('Ziyaad Halday'), arxiv.Result.Author('Bryna J. Hazelton'), arxiv.Result.Author('Jacqueline N. Hewitt'), arxiv.Result.Author('Jack Hickish'), arxiv.Result.Author('Austin Julius'), arxiv.Result.Author('Joshua Kerrigan'), arxiv.Result.Author('Saul A. Kohn'), arxiv.Result.Author('Paul La Plante'), arxiv.Result.Author('Telalo Lekalake'), arxiv.Result.Author('David Lewis'), arxiv.Result.Author('David MacMahon'), arxiv.Result.Author('Lourence Malan'), arxiv.Result.Author('Cresshim Malgas'), arxiv.Result.Author('Matthys Maree'), arxiv.Result.Author('Eunice Matsetela'), arxiv.Result.Author('Andrei Mesinger'), arxiv.Result.Author('Mathakane Molewa'), arxiv.Result.Author('Miguel F. Morales'), arxiv.Result.Author('Tshegofalang Mosiane'), arxiv.Result.Author('Abraham R. Neben'), arxiv.Result.Author('Bojan Nikolic'), arxiv.Result.Author('Aaron R. Parsons'), arxiv.Result.Author('Nipanjana Patra'), arxiv.Result.Author('Samantha Pieterse'), arxiv.Result.Author('Jonathan C. Pober'), arxiv.Result.Author('Nima Razavi-Ghods'), arxiv.Result.Author('Jon Ringuette'), arxiv.Result.Author('James Robnett'), arxiv.Result.Author('Kathryn Rosie'), arxiv.Result.Author('Mario G. Santos'), arxiv.Result.Author('Peter Sims'), arxiv.Result.Author('Saurabh Singh'), arxiv.Result.Author('Craig Smith'), arxiv.Result.Author('Angelo Syce'), arxiv.Result.Author('Nithyanandan Thyagarajan'), arxiv.Result.Author('Peter K. G. Williams'), arxiv.Result.Author('Haoxuan Zheng')]",
1313,Graph Universal Cycles: Compression and Connections to Universal Cycles,"Universal cycles, such as De Bruijn cycles, are cyclic sequences of symbols
that represent every combinatorial object from some family exactly once as a
consecutive subsequence. Graph universal cycles are a graph analogue of
universal cycles introduced in 2010. We introduce graph universal partial
cycles, a more compact representation of graph classes, which use ""do not know""
edges. We show how to construct graph universal partial cycles for labeled
graphs, threshold graphs, and permutation graphs. For threshold graphs and
permutation graphs, we demonstrate that the graph universal cycles and graph
universal partial cycles are closely related to universal cycles and compressed
universal cycles, respectively. Using the same connection, for permutation
graphs, we define and prove the existence of an $s$-overlap form of graph
universal cycles. We also prove the existence of a generalized form of graph
universal cycles for unlabeled graphs.",2209.14198v1,math.CO,2022-09-28 16:11:42+00:00,"[arxiv.Result.Author('Rachel Kirsch'), arxiv.Result.Author('Clare Sibley'), arxiv.Result.Author('Elizabeth Sprangel')]",
1314,Symmetries and Universality Classes in Conservative Sandpile Models,"The symmetry properties which determine the critical exponents and
universality classes in conservative sandpile models are identified. This is
done by introducing a set of models, including all possible combinations of
abelian vs. non-abelian, deterministic vs. stochastic and isotropic vs.
anisotropic toppling rules. The universality classes are determined by an
extended set of critical exponents, scaling functions and geometrical features.
Two universality classes are clearly identified: (a) the universality class of
abelian models and (b) the universality class of stochastic models. In
addition, it is found that non-abelian models with deterministic toppling rules
exhibit non-universal behavior.",cond-mat/9805206v1,cond-mat,1998-05-18 12:42:30+00:00,"[arxiv.Result.Author('O. Biham'), arxiv.Result.Author('E. Milshtein'), arxiv.Result.Author('S. Solomon')]",
1315,The model of the universe with two spaces,"The model of the homogenous and isotropic universe with two spaces is
considered. The background space is a coordinate system of reference and
defines the behaviour of the universe. The other space characterizes the
gravity of the matter of the universe. In the presented model, the first
derivative of the scale factor of the universe with respect to time is equal to
the velocity of light. The density of the matter of the universe changes from
the Planckian value at the Planck time to the modern value at the modern time.
The model under consideration describes the universe from the Planck time to
the modern time and avoids the problems of the Friedman universe such as the
flatness problem and the horizon problem.",gr-qc/9802037v1,gr-qc,1998-02-16 15:31:20+00:00,[arxiv.Result.Author('Dmitri Khokhlov')],
1316,"Cosmological Constant, Quintessence and Expansive Nondecelerative Universe","Recent observations of the Universe have led to a conclusion suppressing an
up-to-now supposed deceleration of the Universe caused by attractive
gravitational forces. Contrary, there is a renaissance of the cosmological
member lambda and introduction of enigmatic repulsive dark energy in attempts
to rationalize a would-be acceleration of the Universe expansion. It is
documented that the model of Expansive Nondecelerative Universe is capable to
offer acceptable answers to the questions on the Universe expansion, state
equations of the Universe, the parameter omega, the cosmological member lambda
without any necessity to introduce new strange kinds of matter or energy being
in accord with the fundamental conservation laws and generally accepted
parameters of the Universe.",gr-qc/0105090v1,gr-qc,2001-05-25 06:49:14+00:00,"[arxiv.Result.Author('Jozef Sima'), arxiv.Result.Author('Miroslav Sukenik')]",
1317,Lectures notes in universal algebraic geometry,Lectures notes in universal algebraic geometry for beginners,1601.02743v1,math.AG,2016-01-12 06:26:37+00:00,[arxiv.Result.Author('A. Shevlyakov')],
1318,"Emergent Universe Scenario, Bouncing and Cyclic Universes in Degenerate Massive Gravity","We consider alternative inflationary cosmologies in massive gravity with
degenerate reference metrics and study the feasibilities of the emergent
universe scenario, bouncing and cyclic universes. We focus on the construction
of the Einstein static universe, classes of exact solutions of bouncing and
cyclic universes in degenerate massive gravity. We further study the
stabilities of the Einstein static universe against both homogeneous and
inhomogeneous scalar perturbations and give the parameters region for a stable
Einstein static universe.",1903.03940v2,gr-qc,2019-03-10 06:51:23+00:00,"[arxiv.Result.Author('Shou-Long Li'), arxiv.Result.Author('H. Lü'), arxiv.Result.Author('Hao Wei'), arxiv.Result.Author('Puxun Wu'), arxiv.Result.Author('Hongwei Yu')]","Phys. Rev. D 99, 104057 (2019)"
1319,What future does the universe have?,"We discuss the future evolution of the universe in the light of recent
observations. The apparent luminosity vs. redshift of supernovae favor an
accelerating universe. However an Einstein-de Sitter critical universe should
not be ruled out yet.",astro-ph/0210526v1,astro-ph,2002-10-23 23:15:54+00:00,[arxiv.Result.Author('B. Hoeneisen')],
1320,On hierarchies of universal predicates,"We investigate a hierarchy of arithmetical structures obtained by a
transfinite addition of a canonic universal predicate, where the canonic
universal predicate for M is defined as a minimum universal predicate for M in
terms of definability. We determine the upper bound of the hierarchy and give a
characterisation for the sets definable in the hierarchy.",math/0703720v1,math.LO,2007-03-24 11:41:16+00:00,[arxiv.Result.Author('Pavel Hrubes')],
1321,Multiply Connected Universes,"It is now generally believed that our observable universe is one amongst a
very large number - may be $10^{500}$ - of parallel universes. Following the
author's own model in this context, we argue that this conglomeration of
universes defines a multiply connected super space.",physics/0606245v1,physics.gen-ph,2006-06-28 13:57:57+00:00,[arxiv.Result.Author('B. G. Sidharth')],
1322,Verifying Parallel Loops with Separation Logic,"This paper proposes a technique to specify and verify whether a loop can be
parallelised. Our approach can be used as an additional step in a parallelising
compiler to verify user annotations about loop dependences. Essentially, our
technique requires each loop iteration to be specified with the locations it
will read and write. From the loop iteration specifications, the loop
(in)dependences can be derived. Moreover, the loop iteration specifications
also reveal where synchronisation is needed in the parallelised program. The
loop iteration specifications can be verified using permission-based separation
logic.",1406.3484v1,cs.SE,2014-06-13 10:17:34+00:00,"[arxiv.Result.Author('Stefan Blom'), arxiv.Result.Author('Saeed Darabi'), arxiv.Result.Author('Marieke Huisman')]","EPTCS 155, 2014, pp. 47-53"
1323,How to create a universe,"The purpose of this paper is (i) to expound the specification of a universe,
according to those parts of mathematical physics which have been experimentally
and observationally verified in our own universe; and (ii) to expound the
possible means of creating a universe in the laboratory.",physics/0702239v1,physics.gen-ph,2007-02-27 17:10:56+00:00,[arxiv.Result.Author('Gordon McCabe')],
1324,Measurement-only verifiable blind quantum computing with quantum input verification,"Verifiable blind quantum computing is a secure delegated quantum computing
where a client with a limited quantum technology delegates her quantum
computing to a server who has a universal quantum computer. The client's
privacy is protected (blindness) and the correctness of the computation is
verifiable by the client in spite of her limited quantum technology
(verifiability). There are mainly two types of protocols for verifiable blind
quantum computing: the protocol where the client has only to generate
single-qubit states, and the protocol where the client needs only the ability
of single-qubit measurements. The latter is called the measurement-only
verifiable blind quantum computing. If the input of the client's quantum
computing is a quantum state whose classical efficient description is not known
to the client, there was no way for the measurement-only client to verify the
correctness of the input. Here we introduce a new protocol of measurement-only
verifiable blind quantum computing where the correctness of the quantum input
is also verifiable.",1606.06467v1,quant-ph,2016-06-21 08:09:05+00:00,[arxiv.Result.Author('Tomoyuki Morimae')],"Phys. Rev. A 94, 042301 (2016)"
1325,Quantum state and circuit distinguishability with single-qubit measurements,"We show that the Quantum State Distinguishability (QSD), which is a
QSZK-complete problem, and the Quantum Circuit Distinguishability (QCD), which
is a QIP-complete problem, can be solved by the verifier who can perform only
single-qubit measurements. To show these results, we use measurement-based
quantum computing: the honest prover sends a graph state to the verifier, and
the verifier can perform universal quantum computing on it with only
single-qubit measurements. If the prover is malicious, he does not necessarily
generate the correct graph state, but the verifier can verify the correctness
of the graph state by measuring the stabilizer operators.",1607.00574v1,quant-ph,2016-07-03 01:18:09+00:00,[arxiv.Result.Author('Tomoyuki Morimae')],
1326,End-to-end verifiability,"This pamphlet describes end-to-end election verifiability (E2E-V) for a
nontechnical audience: election officials, public policymakers, and anyone else
interested in secure, transparent, evidence-based electronic elections.
  This work is part of the Overseas Vote Foundation's End-to-End Verifiable
Internet Voting: Specification and Feasibility Assessment Study (E2E VIV
Project), funded by the Democracy Fund.",1504.03778v1,cs.CR,2015-04-15 03:52:45+00:00,"[arxiv.Result.Author('Josh Benaloh'), arxiv.Result.Author('Ronald Rivest'), arxiv.Result.Author('Peter Y. A. Ryan'), arxiv.Result.Author('Philip Stark'), arxiv.Result.Author('Vanessa Teague'), arxiv.Result.Author('Poorvi Vora')]",
1327,Verifying the Smallest Interesting Colour Code with Quantomatic,"In this paper we present a Quantomatic case study, verifying the basic
properties of the Smallest Interesting Colour Code error detecting code.",1706.02717v2,quant-ph,2017-06-08 18:02:57+00:00,"[arxiv.Result.Author('Liam Garvie'), arxiv.Result.Author('Ross Duncan')]","EPTCS 266, 2018, pp. 147-163"
1328,On optimising quantum communication in verifiable quantum computing,"In the absence of any efficient classical schemes for verifying a universal
quantum computer, the importance of limiting the required quantum resources for
this task has been highlighted recently. Currently, most of efficient quantum
verification protocols are based on cryptographic techniques where an almost
classical verifier executes her desired encrypted quantum computation remotely
on an untrusted quantum prover. In this work we present a new protocol for
quantum verification by incorporating existing techniques in a non-standard
composition to reduce the required quantum communications between the verifier
and the prover.",1506.06943v1,quant-ph,2015-06-23 11:09:59+00:00,"[arxiv.Result.Author('Theodoros Kapourniotis'), arxiv.Result.Author('Vedran Dunjko'), arxiv.Result.Author('Elham Kashefi')]",
1329,Finite state verifiers with constant randomness,"We give a new characterization of $\mathsf{NL}$ as the class of languages
whose members have certificates that can be verified with small error in
polynomial time by finite state machines that use a constant number of random
bits, as opposed to its conventional description in terms of deterministic
logarithmic-space verifiers. It turns out that allowing two-way interaction
with the prover does not change the class of verifiable languages, and that no
polynomially bounded amount of randomness is useful for constant-memory
computers when used as language recognizers, or public-coin verifiers. A
corollary of our main result is that the class of outcome problems
corresponding to O(log n)-space bounded games of incomplete information where
the universal player is allowed a constant number of moves equals NL.",1102.2719v4,cs.CC,2011-02-14 10:17:49+00:00,"[arxiv.Result.Author('Cem Say'), arxiv.Result.Author('Abuzer Yakaryilmaz')]","Logical Methods in Computer Science, Volume 10, Issue 3 (August
  19, 2014) lmcs:724"
1330,Proof of All: Verifiable Computation in a Nutshell,"Recent advances in the cryptographic field of ""Zero-Knowledge Proofs"" have
sparked a new wave of research, giving birth to many exciting theoretical
approaches in the last few years. Such research has often overlapped with the
need for private and scalable solutions of Blockchain-based communities,
resulting in the first practical implementations of such systems. Many of these
innovative constructions have developed in parallel, using different
terminologies and evolving into a fragmented ecosystem, calling for their
consolidation into the more stable domain of ""Verifiable Computation"". In this
master thesis I propose a unifying Verifiable Computation model for the
simplification and efficient comparison of all cryptographic proof systems. I
take advantage of this model to analyse innovative technologies (Homomorphic
Authenticators, Verifiable Delay Functions) which developed into their own
specialised domains, and I attempt to make them more accessible for newcomers
to the field. Furthermore, I expand on the future of Verifiable Computation,
Universal proof compilers and ""Proofs of All"", by approaching the
state-of-the-art zk-STARK construction from a more accessible and informal
design perspective.",1908.02327v2,cs.CR,2019-08-06 19:00:06+00:00,[arxiv.Result.Author('Mario Alessandro Barbara')],
1331,Universal Parametric Correlations of Eigenfunctions in Chaotic and Disordered Systems,"This paper establishes the universality of parametric correlations of
eigenfunctions in chaotic and weakly disordered systems. We demonstrate this
universality in the framework of the gaussian random matrix process and obtain
predictions for a number of parametric correlators, one of them analytically.
We present numerical evidence from different models that verifies our
predictions.",cond-mat/9502019v1,cond-mat,1995-02-04 01:38:06+00:00,"[arxiv.Result.Author('Y. Alhassid'), arxiv.Result.Author('H. Attias')]",
1332,"Electryo, In-person Voting with Transparent Voter Verifiability and Eligibility Verifiability","Selene is an e-voting protocol that allows voters to directly check their
individual vote, in cleartext, in the final tally via a tracker system, while
providing good coercion mitigation. This is in contrast to conventional,
end-to-end verifiable schemes in which the voter verifies the presence of an
encryption of her vote on the bulletin board. The Selene mechanism can be
applied to many e-voting schemes, but here we present an application to the
polling station context, resulting in a voter-verifiable electronic tally with
a paper audit trail. The system uses a smartcard-based public key system to
provide the individual verification and universal eligibility verifiability.
The paper record contains an encrypted link to the voter's identity, requiring
stronger assumptions on ballot privacy than normal paper voting, but with the
benefit of providing good auditability and dispute resolution as well as
supporting (comparison) risk limiting audits.",2105.14783v1,cs.CR,2021-05-31 08:22:29+00:00,"[arxiv.Result.Author('Peter B. Roenne'), arxiv.Result.Author('Peter Y. A Ryan'), arxiv.Result.Author('Marie-Laure Zollinger')]",
1333,New Extensions of Pairing-based Signatures into Universal (Multi) Designated Verifier Signatures,"The concept of universal designated verifier signatures was introduced by
Steinfeld, Bull, Wang and Pieprzyk at Asiacrypt 2003. These signatures can be
used as standard publicly verifiable digital signatures but have an additional
functionality which allows any holder of a signature to designate the signature
to any desired verifier. This designated verifier can check that the message
was indeed signed, but is unable to convince anyone else of this fact. We
propose new efficient constructions for pairing-based short signatures. Our
first scheme is based on Boneh-Boyen signatures and its security can be
analyzed in the standard security model. We prove its resistance to forgery
assuming the hardness of the so-called strong Diffie-Hellman problem, under the
knowledge-of-exponent assumption. The second scheme is compatible with the
Boneh-Lynn-Shacham signatures and is proven unforgeable, in the random oracle
model, under the assumption that the computational bilinear Diffie-Hellman
problem is untractable. Both schemes are designed for devices with constrained
computation capabilities since the signing and the designation procedure are
pairing-free. Finally, we present extensions of these schemes in the multi-user
setting proposed by Desmedt in 2003.",0802.1076v1,cs.CR,2008-02-07 23:35:41+00:00,[arxiv.Result.Author('Damien Vergnaud')],
1334,(Universal) Unconditional Verifiability in E-Voting without Trusted Parties,"In traditional e-voting protocols, privacy is often provided by a trusted
authority that learns the votes and computes the tally. Some protocols replace
the trusted authority by a set of authorities, and privacy is guaranteed if
less than a threshold number of authorities are corrupt. For verifiability,
stronger security guarantees are demanded. Typically, corrupt authorities that
try to fake the result of the tally must always be detected.
  To provide verifiability, many e-voting protocols use Non-Interactive
Zero-Knowledge proofs (NIZKs). Thanks to their non-interactive nature, NIZKs
allow anybody, including third parties that do not participate in the protocol,
to verify the correctness of the tally. Therefore, NIZKs can be used to obtain
universal verifiability. Additionally, NIZKs also improve usability because
they allow voters to cast a vote using a non-interactive protocol.
  The disadvantage of NIZKs is that their security is based on setup
assumptions such as the common reference string (CRS) or the random oracle (RO)
model. The former requires a trusted party for the generation of a common
reference string. The latter, though a popular methodology for designing secure
protocols, has been shown to be unsound.
  In this paper, we address the design of an e-voting protocol that provides
verifiability without any trust assumptions, where verifiability here is meant
without eligibility verification. We show that Non-Interactive
Witness-Indistinguishable proofs (NIWI) can be used for this purpose. The
e-voting scheme is private under the Decision Linear assumption, while
verifiability holds unconditionally. To our knowledge, this is the first
private e-voting scheme with perfect universal verifiability, i.e. one in which
the probability of a fake tally not being detected is 0, and with {\em
non-interactive} protocols that does not rely on trust assumptions.",1610.06343v1,cs.CR,2016-10-20 09:57:12+00:00,"[arxiv.Result.Author('Gina Gallegos-Garcia'), arxiv.Result.Author('Vincenzo Iovino'), arxiv.Result.Author('Alfredo Rial'), arxiv.Result.Author('Peter B. Roenne'), arxiv.Result.Author('Peter Y. A. Ryan')]",
1335,Natural Deduction and the Isabelle Proof Assistant,"We describe our Natural Deduction Assistant (NaDeA) and the interfaces
between the Isabelle proof assistant and NaDeA. In particular, we explain how
NaDeA, using a generated prover that has been verified in Isabelle, provides
feedback to the student, and also how NaDeA, for each formula proved by the
student, provides a generated theorem that can be verified in Isabelle.",1803.01473v1,cs.LO,2018-03-05 02:47:59+00:00,"[arxiv.Result.Author('Jørgen Villadsen'), arxiv.Result.Author('Andreas Halkjær From'), arxiv.Result.Author('Anders Schlichtkrull')]","EPTCS 267, 2018, pp. 140-155"
1336,A Program Logic for Verifying Secure Routing Protocols,"The Internet, as it stands today, is highly vulnerable to attacks. However,
little has been done to understand and verify the formal security guarantees of
proposed secure inter-domain routing protocols, such as Secure BGP (S-BGP). In
this paper, we develop a sound program logic for SANDLog-a declarative
specification language for secure routing protocols for verifying properties of
these protocols. We prove invariant properties of SANDLog programs that run in
an adversarial environment. As a step towards automated verification, we
implement a verification condition generator (VCGen) to automatically extract
proof obligations. VCGen is integrated into a compiler for SANDLog that can
generate executable protocol implementations; and thus, both verification and
empirical evaluation of secure routing protocols can be carried out in this
unified framework. To validate our framework, we encoded several proposed
secure routing mechanisms in SANDLog, verified variants of path authenticity
properties by manually discharging the generated verification conditions in
Coq, and generated executable code based on SANDLog specification and ran the
code in simulation.",1510.03531v2,cs.LO,2015-10-13 05:07:19+00:00,"[arxiv.Result.Author('Chen Chen'), arxiv.Result.Author('Limin Jia'), arxiv.Result.Author('Hao Xu'), arxiv.Result.Author('Cheng Luo'), arxiv.Result.Author('Wenchao Zhou'), arxiv.Result.Author('Boon Thau Loo')]","Logical Methods in Computer Science, Volume 11, Issue 4 (December
  29, 2015) lmcs:1620"
1337,Determinism and the Theory of Every Thing,"Recently Gerard 't Hooft proposed a structure for a universe overwhelmed with
a control by a Theory of Everything (arXiv:1709.02874). He concludes, among
many other things, that such a universe could be fully deterministic and that,
accordingly, the divine intervention will be eliminated. Here I discuss such a
possibility and show that a fully deterministic universe will turn out to
become the divine himself, thus verifying the consistency of Einstein's belief.",1802.03767v1,quant-ph,2018-02-11 16:49:03+00:00,[arxiv.Result.Author('M. B. Altaie')],
1338,The Auslander bijections and universal extensions,"Universal extensions arise naturally in the Auslander bijections. For an
abelian category having Auslander-Reiten duality, we exploit a bijection
triangle, which involves the Auslander bijections, universal extensions and the
Auslander-Reiten duality. Some consequences are given, in particular, a
conjecture by Ringel is verified.",1312.6560v2,math.RT,2013-12-23 14:44:58+00:00,[arxiv.Result.Author('Xiao-Wu Chen')],"Arkiv foer Matematik 55 (2017), 41-59"
1339,Numerical search for universal entanglers in C3xC4 and C4xC4,"A universal entangler is quantum gate able to transform any disentangled
state in an entangled state. Although universal entanglers are abundant in
arbitrary high dimensional spaces, to verify if a quantum gate is a universal
entangler is a hard task since it is not known which property of the unitary
matrix is responsible for such behavior. In this direction, the present work
shows the results of an algorithm based on differential evolution that tests
universal entanglers in C3xC4 and C4xC4. We present two good candidates for
each cited space and we show that a candidate found in the literature is not a
universal entangler.",1408.3701v1,quant-ph,2014-08-16 04:28:54+00:00,"[arxiv.Result.Author('F. V. Mendes'), arxiv.Result.Author('R. V. Ramos')]",Physics Letters A 379 (2015) 289
1340,Phrase-Verified Voting: Verifiable Low-Tech Remote Boardroom Voting,"We present Phrase-Verified Voting, a voter-verifiable remote voting system
assembled from commercial off-the-shelf software for small private elections.
The system is transparent and enables each voter to verify that the tally
includes their ballot selection without requiring any understanding of
cryptography. This paper describes the system and its use in fall 2020, to vote
remotely in promotion committees in a university. Each voter fills out a form
in the cloud with their vote V (YES, NO, ABSTAIN) and a passphrase P-two words
entered by the voter. The system generates a verification prompt of the (P,V)
pairs and a tally of the votes, organized to help visualize how the votes add
up. After the polls close, each voter verifies that this table lists their
(P,V) pair and that the tally is computed correctly. The system is especially
appropriate for any small group making sensitive decisions. Because the system
would not prevent a coercer from demanding that their victim use a specified
passphrase, it is not designed for applications where such malfeasance would be
likely or go undetected. Results from 43 voters show that the system was
well-accepted, performed effectively for its intended purpose, and introduced
users to the concept of voter-verified elections. Compared to the commonly-used
alternatives of paper ballots or voting by email, voters found the system
easier to use, and that it provided greater privacy and outcome integrity.",2103.07180v1,cs.CR,2021-03-12 09:59:55+00:00,"[arxiv.Result.Author('Enka Blanchard'), arxiv.Result.Author('Ryan Robucci'), arxiv.Result.Author('Ted Selker'), arxiv.Result.Author('Alan Sherman')]",
1341,Formal Reasoning Using an Iterative Approach with an Integrated Web IDE,"This paper summarizes our experience in communicating the elements of
reasoning about correctness, and the central role of formal specifications in
reasoning about modular, component-based software using a language and an
integrated Web IDE designed for the purpose. Our experience in using such an
IDE, supported by a 'push-button' verifying compiler in a classroom setting,
reveals the highly iterative process learners use to arrive at suitably
specified, automatically provable code. We explain how the IDE facilitates
reasoning at each step of this process by providing human readable verification
conditions (VCs) and feedback from an integrated prover that clearly indicates
unprovable VCs to help identify obstacles to completing proofs. The paper
discusses the IDE's usage in verified software development using several
examples drawn from actual classroom lectures and student assignments to
illustrate principles of design-by-contract and the iterative process of
creating and subsequently refining assertions, such as loop invariants in
object-based code.",1508.03896v1,cs.SE,2015-08-17 01:37:08+00:00,"[arxiv.Result.Author('Nabil M. Kabbani'), arxiv.Result.Author('Daniel Welch'), arxiv.Result.Author('Caleb Priester'), arxiv.Result.Author('Stephen Schaub'), arxiv.Result.Author('Blair Durkee'), arxiv.Result.Author('Yu-Shan Sun'), arxiv.Result.Author('Murali Sitaraman')]","EPTCS 187, 2015, pp. 56-71"
1342,Limiting Risk by Turning Manifest Phantoms into Evil Zombies,"Drawing a random sample of ballots to conduct a risk-limiting audit generally
requires knowing how the ballots cast in an election are organized into groups,
for instance, how many containers of ballots there are in all and how many
ballots are in each container. A list of the ballot group identifiers along
with number of ballots in each group is called a ballot manifest. What if the
ballot manifest is not accurate? Surprisingly, even if ballots are known to be
missing from the manifest, it is not necessary to make worst-case assumptions
about those ballots--for instance, to adjust the margin by the number of
missing ballots--to ensure that the audit remains conservative. Rather, it
suffices to make worst-case assumptions about the individual randomly selected
ballots that the audit cannot find. This observation provides a simple
modification to some risk-limiting audit procedures that makes them
automatically become more conservative if the ballot manifest has errors. The
modification--phantoms to evil zombies (~2EZ)--requires only an upper bound on
the total number of ballots cast. ~2EZ makes the audit P-value stochastically
larger than it would be had the manifest been accurate, automatically requiring
more than enough ballots to be audited to offset the manifest errors. This
ensures that the true risk limit remains smaller than the nominal risk limit.
On the other hand, if the manifest is in fact accurate and the upper bound on
the total number of ballots equals the total according to the manifest, ~2EZ
has no effect at all on the number of ballots audited nor on the true risk
limit.",1207.3413v1,stat.AP,2012-07-14 11:26:02+00:00,"[arxiv.Result.Author('Jorge H. Banuelos'), arxiv.Result.Author('Philip B. Stark')]",
1343,A Complete Enumeration of Ballot Permutations Avoiding Sets of Small Patterns,"Permutations whose prefixes contain at least as many ascents as descents are
called ballot permutations. Lin, Wang, and Zhao have previously enumerated
ballot permutations avoiding small patterns and have proposed the problem of
enumerating ballot permutations avoiding a pair of permutations of length $3$.
We completely enumerate ballot permutations avoiding two patterns of length $3$
and we relate these avoidance classes with their respective recurrence
relations and formulas, which leads to an interesting bijection between ballot
permutations avoiding $132$ and $312$ with left factors of Dyck paths. In
addition, we also conclude the Wilf-classification of ballot permutations
avoiding sets of two patterns of length $3$, and we then extend our results to
completely enumerate ballot permutations avoiding three patterns of length $3$.",2209.06087v1,math.CO,2022-09-13 15:37:45+00:00,[arxiv.Result.Author('Nathan Sun')],
1344,Can Voters Detect Errors on Their Printed Ballots? Absolutely,"There is still debate on whether voters can detect malicious changes in their
printed ballot after making their selections on a Ballot Marking Device (BMD).
In this study, we altered votes on a voter's ballot after they had made their
selections on a BMD. We then required them to examine their ballots for any
changes from the slate they used to vote. Overall accuracy was exceptionally
high. Participants saw 1440 total contests, and of those 1440, there were a
total of 4 errors, so total accuracy was 99.8%. Participants were able to
perform with near-perfect accuracy regardless of ballot length, ballot type,
number of altered races, and location of altered races. Detection performance
was extremely robust. We conclude that with proper direction and resources,
voters can be near-perfect detectors of ballot changes on printed paper ballots
after voting with a BMD. This finding has significant implications for the
voting community as BMD use continues to grow. Research should now focus on
identifying administrative and behavioral methods that will prompt and
encourage voters to check their BMD-generated ballots before they drop them in
the ballot box.",2204.09780v1,cs.HC,2022-04-20 20:40:32+00:00,"[arxiv.Result.Author('Philip Kortum'), arxiv.Result.Author('Michael D. Byrne'), arxiv.Result.Author('Chidera O. Azubike'), arxiv.Result.Author('Laura E. Roty')]",
1345,Ballot tilings and increasing trees,"We study enumerations of Dyck and ballot tilings, which are tilings of a
region determined by two Dyck or ballot paths. We give bijective proofs to two
formulae of enumerations of Dyck tilings through Hermite histories. We show
that one of the formulae is equal to a certain Kazhdan--Lusztig polynomial. For
a ballot tiling, we establish formulae which are analogues of formulae for Dyck
tilings. Especially, the generating functions have factorized expressions. The
key tool is a planted plane tree and its increasing labellings. We also
introduce a generalized perfect matching which is bijective to an Hermite
history for a ballot tiling. By combining these objects, we obtain various
expressions of a generating function of ballot tilings with a fixed lower path.",1705.06434v1,math-ph,2017-05-18 06:46:09+00:00,[arxiv.Result.Author('Keiichi Shigechi')],
1346,Sophisticated Attacks on Decoy Ballots: The Devil's Menu and the Market for Lemons,"Decoy ballots do not count in election outcomes, but otherwise they are
indistinguishable from real ballots. By means of a game-theoretical model, we
show that decoy ballots may not provide effective protection against a
malevolent adversary trying to buy real ballots. If the citizenry is divided
into subgroups (or districts), the adversary can construct a so-called ""Devil's
Menu"" consisting of several prices. In equilibrium, the adversary can buy the
real ballots of any strict subset of districts at a price corresponding to the
willingness to sell on the part of the citizens holding such ballots. By
contrast, decoy voters are trapped into selling their ballots at a low, or even
negligible, price. Blowing up the adversary's budget by introducing decoy
ballots may thus turn out to be futile. The Devil's Menu can also be applied to
the well-known ""Lemons Problem"".",1712.05477v1,cs.GT,2017-12-14 23:54:58+00:00,"[arxiv.Result.Author('Hans Gersbach'), arxiv.Result.Author('Akaki Mamageishvili'), arxiv.Result.Author('Oriol Tejada')]",
1347,The ATHENA Class of Risk-Limiting Ballot Polling Audits,"The main risk-limiting ballot polling audit in use today, BRAVO, is designed
for use when single ballots are drawn at random and a decision regarding
whether to stop the audit or draw another ballot is taken after each ballot
draw (ballot-by-ballot (B2) audits). On the other hand, real ballot polling
audits draw many ballots in a single round before determining whether to stop
(round-by-round (R2) audits). We show that BRAVO results in significant
inefficiency when directly applied to real R2 audits. We present the ATHENA
class of R2 stopping rules, which we show are risk-limiting if the round
schedule is pre-determined (before the audit begins). We prove that each rule
is at least as efficient as the corresponding BRAVO stopping rule applied at
the end of the round. We have open-source software libraries implementing most
of our results.
  We show that ATHENA halves the number of ballots required, for all state
margins in the 2016 US Presidential election and a first round with $90\%$
stopping probability, when compared to BRAVO (stopping rule applied at the end
of the round). We present simulation results supporting the 90% stopping
probability claims and our claims for the risk accrued in the first round.
Further, ATHENA reduces the number of ballots by more than a quarter for low
margins, when compared to the BRAVO stopping rule applied on ballots in
selection order. This implies that keeping track of the order when drawing
ballots R2 is not beneficial, because ATHENA is more efficient even without
information on selection order. These results are significant because current
approaches to real ballot polling election audits use the B2 BRAVO rules,
requiring about twice as much work on the part of election officials. Applying
the rules in selection order requires fewer ballots, but keeping track of the
order, and entering it into audit software, adds to the effort.",2008.02315v5,cs.CR,2020-08-05 18:47:37+00:00,"[arxiv.Result.Author('Filip Zagórski'), arxiv.Result.Author('Grant McClearn'), arxiv.Result.Author('Sarah Morin'), arxiv.Result.Author('Neal McBurnett'), arxiv.Result.Author('Poorvi L. Vora')]",
1348,The curious moduli spaces of unmarked Kleinian surface groups,"Fixing a closed hyperbolic surface S, we define a moduli space AI(S) of
unmarked hyperbolic 3-manifolds homotopy equivalent to S. This 3-dimensional
analogue of the moduli space M(S) of unmarked hyperbolic surfaces homeomorphic
to S has bizarre local topology, possessing many points that are not closed.
There is, however, a natural embedding of M(S) into AI(S) and a
compactification of AI(S) such that this embedding extends to an embedding of
the Deligne-Mumford compactification of M(S) into the compactification of
AI(S).",0906.5601v2,math.GT,2009-06-30 18:28:48+00:00,"[arxiv.Result.Author('Richard Canary'), arxiv.Result.Author('Peter Storm')]",
1349,$k$-Cut: A Simple Approximately-Uniform Method for Sampling Ballots in Post-Election Audits,"We present an approximate sampling framework and discuss how risk-limiting
audits can compensate for these approximations, while maintaining their
""risk-limiting"" properties. Our framework is general and can compensate for
counting mistakes made during audits.
  Moreover, we present and analyze a simple approximate sampling
method,""$k$-cut"", for picking a ballot randomly from a stack, without counting.
Our method involves doing $k$ ""cuts"", each involving moving a random portion of
ballots from the top to the bottom of the stack, and then picking the ballot on
top. Unlike conventional methods of picking a ballot at random, $k$-cut does
not require identification numbers on the ballots or counting many ballots per
draw. We analyze how close the distribution of chosen ballots is to the uniform
distribution, and design different mitigation procedures. We show that $k=6$
cuts is enough for an risk-limiting election audit, based on empirical data,
which would provide a significant increase in efficiency.",1811.08811v3,cs.DS,2018-11-21 16:26:33+00:00,"[arxiv.Result.Author('Mayuri Sridhar'), arxiv.Result.Author('Ronald L. Rivest')]",
1350,Bernoulli Ballot Polling: A Manifest Improvement for Risk-Limiting Audits,"We present a method and software for ballot-polling risk-limiting audits
(RLAs) based on Bernoulli sampling: ballots are included in the sample with
probability $p$, independently. Bernoulli sampling has several advantages: (1)
it does not require a ballot manifest; (2) it can be conducted independently at
different locations, rather than requiring a central authority to select the
sample from the whole population of cast ballots or requiring stratified
sampling; (3) it can start in polling places on election night, before margins
are known. If the reported margins for the 2016 U.S. Presidential election are
correct, a Bernoulli ballot-polling audit with a risk limit of 5% and a
sampling rate of $p_0 = 1\%$ would have had at least a 99% probability of
confirming the outcome in 42 states. (The other states were more likely to have
needed to examine additional ballots.) Logistical and security advantages that
auditing in the polling place affords may outweigh the cost of examining more
ballots than some other methods might require.",1812.06361v1,stat.AP,2018-12-15 21:57:23+00:00,"[arxiv.Result.Author('Kellie Ottoboni'), arxiv.Result.Author('Matthew Bernhard'), arxiv.Result.Author('J. Alex Halderman'), arxiv.Result.Author('Ronald L. Rivest'), arxiv.Result.Author('Philip B. Stark')]",
1351,"Symmetric Dyck tilings, ballot tableaux and tree-like tableaux of shifted shapes","Symmetric Dyck tilings and ballot tilings are certain tilings in the region
surrounded by two ballot paths. We study the relations of combinatorial objects
which are bijective to symmetric Dyck tilings such as labeled trees, Hermite
histories, and perfect matchings. We also introduce two operations on labeled
trees for symmetric Dyck tilings: symmetric Dyck tiling strip (symDTS) and
symmetric Dyck tiling ribbon (symDTR). We give two definitions of Hermite
histories for symmetric Dyck tilings, and show that they are equivalent by use
of the correspondence between symDTS operation and an Hermite history. Since
ballot tilings form a subset in the set of symmetric Dyck tilings, we construct
an inclusive map from labeled trees for ballot tilings to labeled trees for
symmetric Dyck tilings. By this inclusive map, the results for symmetric Dyck
tilings can be applied to those of ballot tilings. We introduce and study the
notions of ballot tableaux and tree-like tableaux of shifted shapes, which are
generalizations of Dyck tableaux and tree-like tableaux, respectively. The
correspondence between ballot tableaux and tree-like tableaux of shifted shapes
is given by using the symDTR operation and the structure of labeled trees for
symmetric Dyck tilings.",2011.07296v1,math.CO,2020-11-14 13:15:14+00:00,[arxiv.Result.Author('Keiichi Shigechi')],
1352,SOBA: Secrecy-preserving Observable Ballot-level Audit,"SOBA is an approach to election verification that provides observers with
justifiably high confidence that the reported results of an election are
consistent with an audit trail (""ballots""), which can be paper or electronic.
SOBA combines three ideas: (1) publishing cast vote records (CVRs) separately
for each contest, so that anyone can verify that each reported contest outcome
is correct, if the CVRs reflect voters' intentions with sufficient accuracy;
(2) shrouding a mapping between ballots and the CVRs for those ballots to
prevent the loss of privacy that could occur otherwise; (3) assessing the
accuracy with which the CVRs reflect voters' intentions for a collection of
contests while simultaneously assessing the integrity of the shrouded mapping
between ballots and CVRs by comparing randomly selected ballots to the CVRs
that purport to represent them. Step (1) is related to work by the Humboldt
County Election Transparency Project, but publishing CVRs separately for
individual contests rather than images of entire ballots preserves privacy.
Step (2) requires a cryptographic commitment from elections officials.
Observers participate in step (3), which relies on the ""super-simple
simultaneous single-ballot risk-limiting audit."" Step (3) is designed to reveal
relatively few ballots if the shrouded mapping is proper and the CVRs
accurately reflect voter intent. But if the reported outcomes of the contests
differ from the outcomes that a full hand count would show, step (3) is
guaranteed to have a large chance of requiring all the ballots to be counted by
hand, thereby limiting the risk that an incorrect outcome will become official
and final.",1105.5803v2,stat.AP,2011-05-29 17:00:20+00:00,"[arxiv.Result.Author('Josh Benaloh'), arxiv.Result.Author('Douglas Jones'), arxiv.Result.Author('Eric Lazarus'), arxiv.Result.Author('Mark Lindeman'), arxiv.Result.Author('Philip B. Stark')]",
1353,"Voter Verification of BMD Ballots Is a Two-Part Question: Can They? Mostly, They Can. Do They? Mostly, They Don't","The question of whether or not voters actually verify ballots produced by
ballot marking devices (BMDs) is presently the subject of some controversy.
Recent studies (e.g., Bernhard, et al. 2020) suggest the verification rate is
low. What is not clear from previous research is whether this is more a result
of voters being unable to do so accurately or whether this is because voters
simply choose not to attempt verification in the first place. In order to
understand this problem, we conducted an experiment in which 108 participants
participated in a mock election where the BMD displayed the voters' true
choices, but then changed a subset of those choices on the printed ballot. The
design of the printed ballot, the length of the ballot, the number of changes
that were made to the ballot, the location of those changes, and the
instructions provided to the voters were manipulated as part of the experiment.
Results indicated that of those voters who chose to examine the printed ballot,
76% detected anomalies, indicating that voters can reliably detect errors on
their ballot if they will simply review it. This suggests that administrative
remedies, rather than attempts to alter fundamental human perceptual
capabilities, could be employed to encourage voters to check their ballots,
which could prove as an effective countermeasure.",2003.04997v1,cs.HC,2020-03-10 21:06:42+00:00,"[arxiv.Result.Author('Philip Kortum'), arxiv.Result.Author('Michael D. Byrne'), arxiv.Result.Author('Julie Whitmore')]",
1354,Next Steps for the Colorado Risk-Limiting Audit (CORLA) Program,"Colorado conducted risk-limiting tabulation audits (RLAs) across the state in
2017, including both ballot-level comparison audits and ballot-polling audits.
Those audits only covered contests restricted to a single county; methods to
efficiently audit contests that cross county boundaries and combine ballot
polling and ballot-level comparisons have not been available.
  Colorado's current audit software (RLATool) needs to be improved to audit
these contests that cross county lines and to audit small contests efficiently.
  This paper addresses these needs. It presents extremely simple but
inefficient methods, more efficient methods that combine ballot polling and
ballot-level comparisons using stratified samples, and methods that combine
ballot-level comparison and variable-size batch comparison audits in a way that
does not require stratified sampling.
  We conclude with some recommendations, and illustrate our recommended method
using examples that compare them to existing approaches. Exemplar open-source
code and interactive Jupyter notebooks are provided that implement the methods
and allow further exploration.",1803.00698v1,stat.AP,2018-03-02 03:46:37+00:00,"[arxiv.Result.Author('Mark Lindeman'), arxiv.Result.Author('Neal McBurnett'), arxiv.Result.Author('Kellie Ottoboni'), arxiv.Result.Author('Philip B. Stark')]",
1355,RAIRE: Risk-Limiting Audits for IRV Elections,"Risk-limiting post election audits guarantee a high probability of correcting
incorrect election results, independent of why the result was incorrect.
Ballot-polling audits select ballots at random and interpret those ballots as
evidence for and against the reported result, continuing this process until
either they support the recorded result, or they fall back to a full manual
recount. For elections with digitised scanning and counting of ballots, a
comparison audit compares randomly selected digital ballots with their paper
versions. Discrepancies are referred to as errors, and are used to build
evidence against or in support of the recorded result. Risk-limiting audits for
first-past-the-post elections are well understood, and used in some US
elections. We define a number of approaches to ballot-polling and comparison
risk-limiting audits for Instant Runoff Voting (IRV) elections. We show that
for almost all real elections we found, we can perform a risk-limiting audit by
looking at only a small fraction of the total ballots (assuming no errors were
made in the tallying and distribution of votes).",1903.08804v2,cs.DS,2019-03-20 06:19:10+00:00,"[arxiv.Result.Author('Michelle Blom'), arxiv.Result.Author('Peter J. Stuckey'), arxiv.Result.Author('Vanessa Teague')]",
1356,"A decomposition of ballot permutations, pattern avoidance and Gessel walks","A permutation whose any prefix has no more descents than ascents is called a
ballot permutation. In this paper, we present a decomposition of ballot
permutations that enables us to construct a bijection between ballot
permutations and odd order permutations, which proves a set-valued extension of
a conjecture due to Spiro using the statistic of peak values. This bijection
also preserves the neighbors of the largest letter in permutations and thus
resolves a refinement of Spiro' s conjecture proposed by Wang and Zhang. Our
decomposition can be extended to well-labelled positive paths, a class of
generalized ballot permutations arising from polytope theory, that were
enumerated by Bernardi, Duplantier and Nadeau. We will also investigate the
enumerative aspect of ballot permutations avoiding a single pattern of length 3
and establish a connection between 213-avoiding ballot permutations and Gessel
walks.",2103.04599v1,math.CO,2021-03-08 08:37:08+00:00,"[arxiv.Result.Author('Zhicong Lin'), arxiv.Result.Author('David G. L. Wang'), arxiv.Result.Author('Tongyuan Zhao')]",
1357,Ballot Length in Instant Runoff Voting,"Instant runoff voting (IRV) is an increasingly-popular alternative to
traditional plurality voting in which voters submit rankings over the
candidates rather than single votes. In practice, elections using IRV often
restrict the ballot length, the number of candidates a voter is allowed to rank
on their ballot. We theoretically and empirically analyze how ballot length can
influence the outcome of an election, given fixed voter preferences. We show
that there exist preference profiles over $k$ candidates such that up to $k-1$
different candidates win at different ballot lengths. We derive exact lower
bounds on the number of voters required for such profiles and provide a
construction matching the lower bound for unrestricted voter preferences.
Additionally, we characterize which sequences of winners are possible over
ballot lengths and provide explicit profile constructions achieving any
feasible winner sequence. We also examine how classic preference restrictions
influence our results--for instance, single-peakedness makes $k-1$ different
winners impossible but still allows at least $\Omega(\sqrt k)$. Finally, we
analyze a collection of 168 real-world elections, where we truncate rankings to
simulate shorter ballots. We find that shorter ballots could have changed the
outcome in one quarter of these elections. Our results highlight ballot length
as a consequential degree of freedom in the design of IRV elections.",2207.08958v3,cs.MA,2022-07-18 22:01:13+00:00,"[arxiv.Result.Author('Kiran Tomlinson'), arxiv.Result.Author('Johan Ugander'), arxiv.Result.Author('Jon Kleinberg')]",
1358,A modular eballot system - V0.6,"We consider a reasonably simple voting system which can be implemented for
web-based ballots. Simplicity, modularity and the requirement of compatibility
with current web browsers leads to a system which satisfies a set of security
requirements for a ballot system which is not complete but sufficient in many
cases. Due to weak-eligibility and vote-selling, this system cannot be used for
political or similar ballots.",cs/0611066v2,cs.CR,2006-11-15 09:33:58+00:00,[arxiv.Result.Author('Andrea Pasquinucci')],
1359,A quantum secret ballot,"The paper concerns the protection of the secrecy of ballots, so that the
identity of the voters cannot be matched with their vote. To achieve this we
use an entangled quantum state to represent the ballots. Each ballot includes
the identity of the voter, explicitly marked on the ""envelope"" containing it.
Measuring the content of the envelope yields a random number which reveals no
information about the vote. However, the outcome of the elections can be
unambiguously decided after adding the random numbers from all envelopes. We
consider a few versions of the protocol and their complexity of implementation.",quant-ph/0602087v2,quant-ph,2006-02-09 21:03:35+00:00,"[arxiv.Result.Author('Shahar Dolev'), arxiv.Result.Author('Itamar Pitowsky'), arxiv.Result.Author('Boaz Tamir')]",
1360,Ballot Paths Avoiding Depth Zero Patterns,"In a paper by Sapounakis, Tasoulas, and Tsikouras \cite{stt}, the authors
count the number of occurrences of patterns of length four in Dyck paths. In
this paper we specify in one direction and generalize in another. We only count
ballot paths that avoid a given pattern, where a ballot path stays weakly above
the diagonal $y=x$, starts at the origin, and takes steps from the set
$\{\uparrow ,\to \}=\{u,r\}$. A pattern is a finite string made from the same
step set; it is also a path. Notice that a ballot path ending at a point along
the diagonal is a Dyck path.",1004.2710v1,math.CO,2010-04-15 20:23:45+00:00,"[arxiv.Result.Author('Heinrich Niederhausen'), arxiv.Result.Author('Shaun Sullivan')]","Journal OF Combinatorial Mathematics and Combinatorial Computing,
  August 2010"
1361,Exploiting re-voting in the Helios election system,"Election systems must ensure that representatives are chosen by voters.
Moreover, each voter should have equal influence. Traditionally, this has been
achieved by permitting voters to cast at most one ballot. More recently, this
has been achieved by tallying the last ballot cast by each voter. We show this
is not achieved by the Helios election system, because an adversary can cause a
ballot other than a voter's last to be tallied. Moreover, we show how the
adversary can choose the contents of such a ballot, thus the adversary can
unduly influence the selection of representatives.",1612.04099v3,cs.CR,2016-12-13 11:07:22+00:00,"[arxiv.Result.Author('Maxime Meyer'), arxiv.Result.Author('Ben Smyth')]",
1362,ClipAudit: A Simple Risk-Limiting Post-Election Audit,"We propose a simple risk-limiting audit for elections, ClipAudit. To
determine whether candidate A (the reported winner) actually beat candidate B
in a plurality election, ClipAudit draws ballots at random, without
replacement, until either all cast ballots have been drawn, or until \[ a - b
\ge \beta \sqrt{a+b}
  \] where $a$ is the number of ballots in the sample for the reported winner
A, and $b$ is the number of ballots in the sample for opponent B, and where
$\beta$ is a constant determined a priori as a function of the number $n$ of
ballots cast and the risk-limit $\alpha$. ClipAudit doesn't depend on the
unofficial margin (as does Bravo). We show how to extend ClipAudit to contests
with multiple winners or losers, or to multiple contests.",1701.08312v1,cs.CR,2017-01-28 18:51:10+00:00,[arxiv.Result.Author('Ronald L. Rivest')],
1363,Limiting Risk by Turning Manifest Phantoms into Evil Zombies,"Drawing a random sample of ballots to conduct a risk-limiting audit generally
requires knowing how the ballots cast in an election are organized into groups,
for instance, how many containers of ballots there are in all and how many
ballots are in each container. A list of the ballot group identifiers along
with number of ballots in each group is called a ballot manifest. What if the
ballot manifest is not accurate? Surprisingly, even if ballots are known to be
missing from the manifest, it is not necessary to make worst-case assumptions
about those ballots--for instance, to adjust the margin by the number of
missing ballots--to ensure that the audit remains conservative. Rather, it
suffices to make worst-case assumptions about the individual randomly selected
ballots that the audit cannot find. This observation provides a simple
modification to some risk-limiting audit procedures that makes them
automatically become more conservative if the ballot manifest has errors. The
modification--phantoms to evil zombies (~2EZ)--requires only an upper bound on
the total number of ballots cast. ~2EZ makes the audit P-value stochastically
larger than it would be had the manifest been accurate, automatically requiring
more than enough ballots to be audited to offset the manifest errors. This
ensures that the true risk limit remains smaller than the nominal risk limit.
On the other hand, if the manifest is in fact accurate and the upper bound on
the total number of ballots equals the total according to the manifest, ~2EZ
has no effect at all on the number of ballots audited nor on the true risk
limit.",1207.3413v1,stat.AP,2012-07-14 11:26:02+00:00,"[arxiv.Result.Author('Jorge H. Banuelos'), arxiv.Result.Author('Philip B. Stark')]",
1364,A Complete Enumeration of Ballot Permutations Avoiding Sets of Small Patterns,"Permutations whose prefixes contain at least as many ascents as descents are
called ballot permutations. Lin, Wang, and Zhao have previously enumerated
ballot permutations avoiding small patterns and have proposed the problem of
enumerating ballot permutations avoiding a pair of permutations of length $3$.
We completely enumerate ballot permutations avoiding two patterns of length $3$
and we relate these avoidance classes with their respective recurrence
relations and formulas, which leads to an interesting bijection between ballot
permutations avoiding $132$ and $312$ with left factors of Dyck paths. In
addition, we also conclude the Wilf-classification of ballot permutations
avoiding sets of two patterns of length $3$, and we then extend our results to
completely enumerate ballot permutations avoiding three patterns of length $3$.",2209.06087v1,math.CO,2022-09-13 15:37:45+00:00,[arxiv.Result.Author('Nathan Sun')],
1365,Can Voters Detect Errors on Their Printed Ballots? Absolutely,"There is still debate on whether voters can detect malicious changes in their
printed ballot after making their selections on a Ballot Marking Device (BMD).
In this study, we altered votes on a voter's ballot after they had made their
selections on a BMD. We then required them to examine their ballots for any
changes from the slate they used to vote. Overall accuracy was exceptionally
high. Participants saw 1440 total contests, and of those 1440, there were a
total of 4 errors, so total accuracy was 99.8%. Participants were able to
perform with near-perfect accuracy regardless of ballot length, ballot type,
number of altered races, and location of altered races. Detection performance
was extremely robust. We conclude that with proper direction and resources,
voters can be near-perfect detectors of ballot changes on printed paper ballots
after voting with a BMD. This finding has significant implications for the
voting community as BMD use continues to grow. Research should now focus on
identifying administrative and behavioral methods that will prompt and
encourage voters to check their BMD-generated ballots before they drop them in
the ballot box.",2204.09780v1,cs.HC,2022-04-20 20:40:32+00:00,"[arxiv.Result.Author('Philip Kortum'), arxiv.Result.Author('Michael D. Byrne'), arxiv.Result.Author('Chidera O. Azubike'), arxiv.Result.Author('Laura E. Roty')]",
1366,Ballot tilings and increasing trees,"We study enumerations of Dyck and ballot tilings, which are tilings of a
region determined by two Dyck or ballot paths. We give bijective proofs to two
formulae of enumerations of Dyck tilings through Hermite histories. We show
that one of the formulae is equal to a certain Kazhdan--Lusztig polynomial. For
a ballot tiling, we establish formulae which are analogues of formulae for Dyck
tilings. Especially, the generating functions have factorized expressions. The
key tool is a planted plane tree and its increasing labellings. We also
introduce a generalized perfect matching which is bijective to an Hermite
history for a ballot tiling. By combining these objects, we obtain various
expressions of a generating function of ballot tilings with a fixed lower path.",1705.06434v1,math-ph,2017-05-18 06:46:09+00:00,[arxiv.Result.Author('Keiichi Shigechi')],
1367,Sophisticated Attacks on Decoy Ballots: The Devil's Menu and the Market for Lemons,"Decoy ballots do not count in election outcomes, but otherwise they are
indistinguishable from real ballots. By means of a game-theoretical model, we
show that decoy ballots may not provide effective protection against a
malevolent adversary trying to buy real ballots. If the citizenry is divided
into subgroups (or districts), the adversary can construct a so-called ""Devil's
Menu"" consisting of several prices. In equilibrium, the adversary can buy the
real ballots of any strict subset of districts at a price corresponding to the
willingness to sell on the part of the citizens holding such ballots. By
contrast, decoy voters are trapped into selling their ballots at a low, or even
negligible, price. Blowing up the adversary's budget by introducing decoy
ballots may thus turn out to be futile. The Devil's Menu can also be applied to
the well-known ""Lemons Problem"".",1712.05477v1,cs.GT,2017-12-14 23:54:58+00:00,"[arxiv.Result.Author('Hans Gersbach'), arxiv.Result.Author('Akaki Mamageishvili'), arxiv.Result.Author('Oriol Tejada')]",
1368,The ATHENA Class of Risk-Limiting Ballot Polling Audits,"The main risk-limiting ballot polling audit in use today, BRAVO, is designed
for use when single ballots are drawn at random and a decision regarding
whether to stop the audit or draw another ballot is taken after each ballot
draw (ballot-by-ballot (B2) audits). On the other hand, real ballot polling
audits draw many ballots in a single round before determining whether to stop
(round-by-round (R2) audits). We show that BRAVO results in significant
inefficiency when directly applied to real R2 audits. We present the ATHENA
class of R2 stopping rules, which we show are risk-limiting if the round
schedule is pre-determined (before the audit begins). We prove that each rule
is at least as efficient as the corresponding BRAVO stopping rule applied at
the end of the round. We have open-source software libraries implementing most
of our results.
  We show that ATHENA halves the number of ballots required, for all state
margins in the 2016 US Presidential election and a first round with $90\%$
stopping probability, when compared to BRAVO (stopping rule applied at the end
of the round). We present simulation results supporting the 90% stopping
probability claims and our claims for the risk accrued in the first round.
Further, ATHENA reduces the number of ballots by more than a quarter for low
margins, when compared to the BRAVO stopping rule applied on ballots in
selection order. This implies that keeping track of the order when drawing
ballots R2 is not beneficial, because ATHENA is more efficient even without
information on selection order. These results are significant because current
approaches to real ballot polling election audits use the B2 BRAVO rules,
requiring about twice as much work on the part of election officials. Applying
the rules in selection order requires fewer ballots, but keeping track of the
order, and entering it into audit software, adds to the effort.",2008.02315v5,cs.CR,2020-08-05 18:47:37+00:00,"[arxiv.Result.Author('Filip Zagórski'), arxiv.Result.Author('Grant McClearn'), arxiv.Result.Author('Sarah Morin'), arxiv.Result.Author('Neal McBurnett'), arxiv.Result.Author('Poorvi L. Vora')]",
1369,$k$-Cut: A Simple Approximately-Uniform Method for Sampling Ballots in Post-Election Audits,"We present an approximate sampling framework and discuss how risk-limiting
audits can compensate for these approximations, while maintaining their
""risk-limiting"" properties. Our framework is general and can compensate for
counting mistakes made during audits.
  Moreover, we present and analyze a simple approximate sampling
method,""$k$-cut"", for picking a ballot randomly from a stack, without counting.
Our method involves doing $k$ ""cuts"", each involving moving a random portion of
ballots from the top to the bottom of the stack, and then picking the ballot on
top. Unlike conventional methods of picking a ballot at random, $k$-cut does
not require identification numbers on the ballots or counting many ballots per
draw. We analyze how close the distribution of chosen ballots is to the uniform
distribution, and design different mitigation procedures. We show that $k=6$
cuts is enough for an risk-limiting election audit, based on empirical data,
which would provide a significant increase in efficiency.",1811.08811v3,cs.DS,2018-11-21 16:26:33+00:00,"[arxiv.Result.Author('Mayuri Sridhar'), arxiv.Result.Author('Ronald L. Rivest')]",
1370,Bernoulli Ballot Polling: A Manifest Improvement for Risk-Limiting Audits,"We present a method and software for ballot-polling risk-limiting audits
(RLAs) based on Bernoulli sampling: ballots are included in the sample with
probability $p$, independently. Bernoulli sampling has several advantages: (1)
it does not require a ballot manifest; (2) it can be conducted independently at
different locations, rather than requiring a central authority to select the
sample from the whole population of cast ballots or requiring stratified
sampling; (3) it can start in polling places on election night, before margins
are known. If the reported margins for the 2016 U.S. Presidential election are
correct, a Bernoulli ballot-polling audit with a risk limit of 5% and a
sampling rate of $p_0 = 1\%$ would have had at least a 99% probability of
confirming the outcome in 42 states. (The other states were more likely to have
needed to examine additional ballots.) Logistical and security advantages that
auditing in the polling place affords may outweigh the cost of examining more
ballots than some other methods might require.",1812.06361v1,stat.AP,2018-12-15 21:57:23+00:00,"[arxiv.Result.Author('Kellie Ottoboni'), arxiv.Result.Author('Matthew Bernhard'), arxiv.Result.Author('J. Alex Halderman'), arxiv.Result.Author('Ronald L. Rivest'), arxiv.Result.Author('Philip B. Stark')]",
1371,"Symmetric Dyck tilings, ballot tableaux and tree-like tableaux of shifted shapes","Symmetric Dyck tilings and ballot tilings are certain tilings in the region
surrounded by two ballot paths. We study the relations of combinatorial objects
which are bijective to symmetric Dyck tilings such as labeled trees, Hermite
histories, and perfect matchings. We also introduce two operations on labeled
trees for symmetric Dyck tilings: symmetric Dyck tiling strip (symDTS) and
symmetric Dyck tiling ribbon (symDTR). We give two definitions of Hermite
histories for symmetric Dyck tilings, and show that they are equivalent by use
of the correspondence between symDTS operation and an Hermite history. Since
ballot tilings form a subset in the set of symmetric Dyck tilings, we construct
an inclusive map from labeled trees for ballot tilings to labeled trees for
symmetric Dyck tilings. By this inclusive map, the results for symmetric Dyck
tilings can be applied to those of ballot tilings. We introduce and study the
notions of ballot tableaux and tree-like tableaux of shifted shapes, which are
generalizations of Dyck tableaux and tree-like tableaux, respectively. The
correspondence between ballot tableaux and tree-like tableaux of shifted shapes
is given by using the symDTR operation and the structure of labeled trees for
symmetric Dyck tilings.",2011.07296v1,math.CO,2020-11-14 13:15:14+00:00,[arxiv.Result.Author('Keiichi Shigechi')],
1372,SOBA: Secrecy-preserving Observable Ballot-level Audit,"SOBA is an approach to election verification that provides observers with
justifiably high confidence that the reported results of an election are
consistent with an audit trail (""ballots""), which can be paper or electronic.
SOBA combines three ideas: (1) publishing cast vote records (CVRs) separately
for each contest, so that anyone can verify that each reported contest outcome
is correct, if the CVRs reflect voters' intentions with sufficient accuracy;
(2) shrouding a mapping between ballots and the CVRs for those ballots to
prevent the loss of privacy that could occur otherwise; (3) assessing the
accuracy with which the CVRs reflect voters' intentions for a collection of
contests while simultaneously assessing the integrity of the shrouded mapping
between ballots and CVRs by comparing randomly selected ballots to the CVRs
that purport to represent them. Step (1) is related to work by the Humboldt
County Election Transparency Project, but publishing CVRs separately for
individual contests rather than images of entire ballots preserves privacy.
Step (2) requires a cryptographic commitment from elections officials.
Observers participate in step (3), which relies on the ""super-simple
simultaneous single-ballot risk-limiting audit."" Step (3) is designed to reveal
relatively few ballots if the shrouded mapping is proper and the CVRs
accurately reflect voter intent. But if the reported outcomes of the contests
differ from the outcomes that a full hand count would show, step (3) is
guaranteed to have a large chance of requiring all the ballots to be counted by
hand, thereby limiting the risk that an incorrect outcome will become official
and final.",1105.5803v2,stat.AP,2011-05-29 17:00:20+00:00,"[arxiv.Result.Author('Josh Benaloh'), arxiv.Result.Author('Douglas Jones'), arxiv.Result.Author('Eric Lazarus'), arxiv.Result.Author('Mark Lindeman'), arxiv.Result.Author('Philip B. Stark')]",
1373,"Voter Verification of BMD Ballots Is a Two-Part Question: Can They? Mostly, They Can. Do They? Mostly, They Don't","The question of whether or not voters actually verify ballots produced by
ballot marking devices (BMDs) is presently the subject of some controversy.
Recent studies (e.g., Bernhard, et al. 2020) suggest the verification rate is
low. What is not clear from previous research is whether this is more a result
of voters being unable to do so accurately or whether this is because voters
simply choose not to attempt verification in the first place. In order to
understand this problem, we conducted an experiment in which 108 participants
participated in a mock election where the BMD displayed the voters' true
choices, but then changed a subset of those choices on the printed ballot. The
design of the printed ballot, the length of the ballot, the number of changes
that were made to the ballot, the location of those changes, and the
instructions provided to the voters were manipulated as part of the experiment.
Results indicated that of those voters who chose to examine the printed ballot,
76% detected anomalies, indicating that voters can reliably detect errors on
their ballot if they will simply review it. This suggests that administrative
remedies, rather than attempts to alter fundamental human perceptual
capabilities, could be employed to encourage voters to check their ballots,
which could prove as an effective countermeasure.",2003.04997v1,cs.HC,2020-03-10 21:06:42+00:00,"[arxiv.Result.Author('Philip Kortum'), arxiv.Result.Author('Michael D. Byrne'), arxiv.Result.Author('Julie Whitmore')]",
1374,A personal survey on recent and less recent results on tilting theory,"This note is the written version of conversations with young colleagues on
unofficial history, general ideas, unexpected facts and open problems
concerning tilting theory.",1411.4418v1,math.RT,2014-11-17 10:20:00+00:00,"[arxiv.Result.Author(""Gabriella D'Este"")]",
1375,Unofficial history of a joint work with Dieter Happel and of two unexpected quotations,"This survey contains a recollection of results, problems and conversations
which go back to the early years of Representation Theory and Tilting Theory.",1401.2085v1,math.RT,2014-01-09 17:21:47+00:00,"[arxiv.Result.Author(""Gabriella D'Este"")]",
1376,Next Steps for the Colorado Risk-Limiting Audit (CORLA) Program,"Colorado conducted risk-limiting tabulation audits (RLAs) across the state in
2017, including both ballot-level comparison audits and ballot-polling audits.
Those audits only covered contests restricted to a single county; methods to
efficiently audit contests that cross county boundaries and combine ballot
polling and ballot-level comparisons have not been available.
  Colorado's current audit software (RLATool) needs to be improved to audit
these contests that cross county lines and to audit small contests efficiently.
  This paper addresses these needs. It presents extremely simple but
inefficient methods, more efficient methods that combine ballot polling and
ballot-level comparisons using stratified samples, and methods that combine
ballot-level comparison and variable-size batch comparison audits in a way that
does not require stratified sampling.
  We conclude with some recommendations, and illustrate our recommended method
using examples that compare them to existing approaches. Exemplar open-source
code and interactive Jupyter notebooks are provided that implement the methods
and allow further exploration.",1803.00698v1,stat.AP,2018-03-02 03:46:37+00:00,"[arxiv.Result.Author('Mark Lindeman'), arxiv.Result.Author('Neal McBurnett'), arxiv.Result.Author('Kellie Ottoboni'), arxiv.Result.Author('Philip B. Stark')]",
1377,RAIRE: Risk-Limiting Audits for IRV Elections,"Risk-limiting post election audits guarantee a high probability of correcting
incorrect election results, independent of why the result was incorrect.
Ballot-polling audits select ballots at random and interpret those ballots as
evidence for and against the reported result, continuing this process until
either they support the recorded result, or they fall back to a full manual
recount. For elections with digitised scanning and counting of ballots, a
comparison audit compares randomly selected digital ballots with their paper
versions. Discrepancies are referred to as errors, and are used to build
evidence against or in support of the recorded result. Risk-limiting audits for
first-past-the-post elections are well understood, and used in some US
elections. We define a number of approaches to ballot-polling and comparison
risk-limiting audits for Instant Runoff Voting (IRV) elections. We show that
for almost all real elections we found, we can perform a risk-limiting audit by
looking at only a small fraction of the total ballots (assuming no errors were
made in the tallying and distribution of votes).",1903.08804v2,cs.DS,2019-03-20 06:19:10+00:00,"[arxiv.Result.Author('Michelle Blom'), arxiv.Result.Author('Peter J. Stuckey'), arxiv.Result.Author('Vanessa Teague')]",
1378,"A decomposition of ballot permutations, pattern avoidance and Gessel walks","A permutation whose any prefix has no more descents than ascents is called a
ballot permutation. In this paper, we present a decomposition of ballot
permutations that enables us to construct a bijection between ballot
permutations and odd order permutations, which proves a set-valued extension of
a conjecture due to Spiro using the statistic of peak values. This bijection
also preserves the neighbors of the largest letter in permutations and thus
resolves a refinement of Spiro' s conjecture proposed by Wang and Zhang. Our
decomposition can be extended to well-labelled positive paths, a class of
generalized ballot permutations arising from polytope theory, that were
enumerated by Bernardi, Duplantier and Nadeau. We will also investigate the
enumerative aspect of ballot permutations avoiding a single pattern of length 3
and establish a connection between 213-avoiding ballot permutations and Gessel
walks.",2103.04599v1,math.CO,2021-03-08 08:37:08+00:00,"[arxiv.Result.Author('Zhicong Lin'), arxiv.Result.Author('David G. L. Wang'), arxiv.Result.Author('Tongyuan Zhao')]",
1379,Ballot Length in Instant Runoff Voting,"Instant runoff voting (IRV) is an increasingly-popular alternative to
traditional plurality voting in which voters submit rankings over the
candidates rather than single votes. In practice, elections using IRV often
restrict the ballot length, the number of candidates a voter is allowed to rank
on their ballot. We theoretically and empirically analyze how ballot length can
influence the outcome of an election, given fixed voter preferences. We show
that there exist preference profiles over $k$ candidates such that up to $k-1$
different candidates win at different ballot lengths. We derive exact lower
bounds on the number of voters required for such profiles and provide a
construction matching the lower bound for unrestricted voter preferences.
Additionally, we characterize which sequences of winners are possible over
ballot lengths and provide explicit profile constructions achieving any
feasible winner sequence. We also examine how classic preference restrictions
influence our results--for instance, single-peakedness makes $k-1$ different
winners impossible but still allows at least $\Omega(\sqrt k)$. Finally, we
analyze a collection of 168 real-world elections, where we truncate rankings to
simulate shorter ballots. We find that shorter ballots could have changed the
outcome in one quarter of these elections. Our results highlight ballot length
as a consequential degree of freedom in the design of IRV elections.",2207.08958v3,cs.MA,2022-07-18 22:01:13+00:00,"[arxiv.Result.Author('Kiran Tomlinson'), arxiv.Result.Author('Johan Ugander'), arxiv.Result.Author('Jon Kleinberg')]",
1380,A modular eballot system - V0.6,"We consider a reasonably simple voting system which can be implemented for
web-based ballots. Simplicity, modularity and the requirement of compatibility
with current web browsers leads to a system which satisfies a set of security
requirements for a ballot system which is not complete but sufficient in many
cases. Due to weak-eligibility and vote-selling, this system cannot be used for
political or similar ballots.",cs/0611066v2,cs.CR,2006-11-15 09:33:58+00:00,[arxiv.Result.Author('Andrea Pasquinucci')],
1381,A quantum secret ballot,"The paper concerns the protection of the secrecy of ballots, so that the
identity of the voters cannot be matched with their vote. To achieve this we
use an entangled quantum state to represent the ballots. Each ballot includes
the identity of the voter, explicitly marked on the ""envelope"" containing it.
Measuring the content of the envelope yields a random number which reveals no
information about the vote. However, the outcome of the elections can be
unambiguously decided after adding the random numbers from all envelopes. We
consider a few versions of the protocol and their complexity of implementation.",quant-ph/0602087v2,quant-ph,2006-02-09 21:03:35+00:00,"[arxiv.Result.Author('Shahar Dolev'), arxiv.Result.Author('Itamar Pitowsky'), arxiv.Result.Author('Boaz Tamir')]",
1382,Generalizing the Sharp Threshold Phenomenon for the Distributed Complexity of the Lovász Local Lemma,"Recently, Brandt, Maus and Uitto [PODC'19] showed that, in a restricted
setting, the dependency of the complexity of the distributed Lov\'asz Local
Lemma (LLL) on the chosen LLL criterion exhibits a sharp threshold phenomenon:
They proved that, under the LLL criterion $p2^d < 1$, if each random variable
affects at most $3$ events, the deterministic complexity of the LLL in the
LOCAL model is $O(d^2 + \log^* n)$. In stark contrast, under the criterion
$p2^d \leq 1$, there is a randomized lower bound of $\Omega(\log \log n)$ by
Brandt et al. [STOC'16] and a deterministic lower bound of $\Omega(\log n)$ by
Chang, Kopelowitz and Pettie [FOCS'16]. Brandt, Maus and Uitto conjectured that
the same behavior holds for the unrestricted setting where each random variable
affects arbitrarily many events.
  We prove their conjecture, by providing an algorithm that solves the LLL in
time $O(d^2 + \log^* n)$ under the LLL criterion $p2^d < 1$, which is tight in
bounded-degree graphs due to an $\Omega(\log^* n)$ lower bound by Chung, Pettie
and Su [PODC'14]. By the work of Brandt, Maus and Uitto, obtaining such an
algorithm can be reduced to proving that all members in a certain family of
functions in arbitrarily high dimensions are convex on some specific domain.
Unfortunately, an analytical description of these functions is known only for
dimension at most $3$, which led to the aforementioned restriction of their
result. While obtaining those descriptions for functions of (substantially)
higher dimension seems out of the reach of current techniques, we show that
their convexity can be inferred by combinatorial means.",2006.04625v1,cs.DS,2020-06-08 14:24:36+00:00,"[arxiv.Result.Author('Sebastian Brandt'), arxiv.Result.Author('Christoph Grunau'), arxiv.Result.Author('Václav Rozhoň')]",
1383,Multi-adversarial Faster-RCNN for Unrestricted Object Detection,"Conventional object detection methods essentially suppose that the training
and testing data are collected from a restricted target domain with expensive
labeling cost. For alleviating the problem of domain dependency and cumbersome
labeling, this paper proposes to detect objects in an unrestricted environment
by leveraging domain knowledge trained from an auxiliary source domain with
sufficient labels. Specifically, we propose a multi-adversarial Faster-RCNN
(MAF) framework for unrestricted object detection, which inherently addresses
domain disparity minimization for domain adaptation in feature representation.
The paper merits are in three-fold: 1) With the idea that object detectors
often becomes domain incompatible when image distribution resulted domain
disparity appears, we propose a hierarchical domain feature alignment module,
in which multiple adversarial domain classifier submodules for layer-wise
domain feature confusion are designed; 2) An information invariant scale
reduction module (SRM) for hierarchical feature map resizing is proposed for
promoting the training efficiency of adversarial domain adaptation; 3) In order
to improve the domain adaptability, the aggregated proposal features with
detection results are feed into a proposed weighted gradient reversal layer
(WGRL) for characterizing hard confused domain samples. We evaluate our MAF on
unrestricted tasks, including Cityscapes, KITTI, Sim10k, etc. and the
experiments show the state-of-the-art performance over the existing detectors.",1907.10343v2,cs.CV,2019-07-24 10:12:36+00:00,"[arxiv.Result.Author('Zhenwei He'), arxiv.Result.Author('Lei Zhang')]",
1384,Crossing Numbers of Beyond-Planar Graphs Revisited,"Graph drawing beyond planarity focuses on drawings of high visual quality for
non-planar graphs which are characterized by certain forbidden edge
configurations. A natural criterion for the quality of a drawing is the number
of edge crossings. The question then arises whether beyond-planar drawings have
a significantly larger crossing number than unrestricted drawings. Chimani et
al. [GD'19] gave bounds for the ratio between the crossing number of three
classes of beyond-planar graphs and the unrestricted crossing number. In this
paper we extend their results to the main currently known classes of
beyond-planar graphs characterized by forbidden edge configurations and answer
several of their open questions.",2105.12452v1,cs.CG,2021-05-26 10:24:21+00:00,"[arxiv.Result.Author('Nathan van Beusekom'), arxiv.Result.Author('Irene Parada'), arxiv.Result.Author('Bettina Speckmann')]",
1385,Minimum-Link Paths Revisited,"A path or a polygonal domain is C-oriented if the orientations of its edges
belong to a set of C given orientations; this is a generalization of the
notable rectilinear case (C = 2). We study exact and approximation algorithms
for minimum-link C-oriented paths and paths with unrestricted orientations,
both in C-oriented and in general domains. Our two main algorithms are as
follows:
  A subquadratic-time algorithm with a non-trivial approximation guarantee for
general (unrestricted-orientation) minimum-link paths in general domains.
  An algorithm to find a minimum-link C-oriented path in a C-oriented domain.
Our algorithm is simpler and more time-space efficient than the prior
algorithm.
  We also obtain several related results:
  - 3SUM-hardness of determining the link distance with unrestricted
orientations (even in a rectilinear domain).
  - An optimal algorithm for finding a minimum-link rectilinear path in a
rectilinear domain. The algorithm and its analysis are simpler than the
existing ones.
  - An extension of our methods to find a C-oriented minimum-link path in a
general (not necessarily C-oriented) domain.
  - A more efficient algorithm to compute a 2-approximate C-oriented
minimum-link path.
  - A notion of ""robust"" paths. We show how minimum-link C-oriented paths
approximate the robust paths with unrestricted orientations to within an
additive error of 1.",1302.3091v1,cs.CG,2013-02-13 13:54:19+00:00,"[arxiv.Result.Author('Joseph S. B. Mitchell'), arxiv.Result.Author('Valentin Polishchuk'), arxiv.Result.Author('Mikko Sysikaski')]",
1386,A unified study for estimation of order restricted location/scale parameters under the generalized Pitman nearness criterion,"We consider component-wise estimation of order restricted location/scale
parameters of a general bivariate location/scale distribution under the
generalized Pitman nearness criterion (GPN). We develop some general results
that, in many situations, are useful in finding improvements over
location/scale equivariant estimators. In particular, under certain conditions,
these general results provide improvements over the unrestricted Pitman nearest
location/scale equivariant estimators and restricted maximum likelihood
estimators. The usefulness of the obtained results is illustrated through their
applications to specific probability models. A simulation study has been
considered to compare how well different estimators perform under the GPN
criterion with a specific loss function.",2209.10803v1,math.ST,2022-09-22 06:11:30+00:00,"[arxiv.Result.Author('Naresh Garg'), arxiv.Result.Author('Neeraj Misra')]",
1387,Unrestricted slave-boson mean-field approximation for the two-dimensional Hubbard model,"The Kotliar-Ruckenstein slave-boson scheme is used to allow for an
unrestricted variation of the bosonic and fermionic fields on the saddle-point
level. Various inhomogeneous solutions, such as spin polarons and domain walls
are discussed within the two-dimensional Hubbard model and compared with
results of unrestricted Hartree-Fock (HF) calculations. We find that the
present approach drastically reduces the polarization of these states and leads
to increased delocalized wave functions as compared to the HF model. The
interaction between two spin polarons turns out to be attractive over a wide
range of the on-site repulsion U. In addition we obtain the crossover from
vertical to diagonal domain walls at a higher value of U than predicted by HF.",cond-mat/9801135v1,cond-mat.str-el,1998-01-14 13:01:48+00:00,"[arxiv.Result.Author('G. Seibold'), arxiv.Result.Author('E. Sigmund'), arxiv.Result.Author('V. Hizhnyakov')]",
1388,Informationally complete measurements on bipartite quantum systems: comparing local with global measurements,"Informationally complete measurements allow the estimation of expectation
values of any operator on a quantum system, by changing only the
data-processing of the measurement outcomes. In particular, an informationally
complete measurement can be used to perform quantum tomography, namely to
estimate the density matrix of the quantum state. The data-processing is
generally nonunique, and can be optimized according to a given criterion. In
this paper we provide the solution of the optimization problem which minimizes
the variance in the estimation. We then consider informationally complete
measurements performed over bipartite quantum systems focusing attention on
universally covariant measurements, and compare their statistical efficiency
when performed either locally or globally on the two systems. Among global
measurements we consider the special case of Bell measurements, which allow to
estimate the expectation of a restricted class of operators. We compare the
variance in the three cases: local, Bell, and unrestricted global--and derive
conditions for the operators to be estimated such that one type of measurement
is more efficient than the other. In particular, we find that for factorized
operators and Bell projectors the Bell measurement always performs better than
the unrestricted global measurement, which in turn outperforms the local one.
For estimation of the matrix elements of the density operator, the relative
performances depend on the basis on which the state is represented, and on the
matrix element being diagonal or off-diagonal, however, with the global
unrestricted measurement generally performing better than the local one.",quant-ph/0507104v2,quant-ph,2005-07-11 17:49:49+00:00,"[arxiv.Result.Author(""G. M. D'Ariano""), arxiv.Result.Author('P. Perinotti'), arxiv.Result.Author('M. F. Sacchi')]",Phys. Rev. A 72 042108 (2005)
1389,Probabilistic Fixed Ballot Rules and Hybrid Domains,"We study a class of preference domains that satisfies the familiar properties
of minimal richness, diversity and no-restoration. We show that a specific
preference restriction, hybridness, has been embedded in these domains so that
the preferences are single-peaked at the ""extremes"" and unrestricted in the
""middle"". We also study the structure of strategy-proof and unanimous Random
Social Choice Functions on these domains. We show them to be special cases of
probabilistic fixed ballot rules (introduced by Ehlers, Peters, and Storcken
(2002)).",2105.10677v2,econ.TH,2021-05-22 10:12:17+00:00,"[arxiv.Result.Author('Shurojit Chatterji'), arxiv.Result.Author('Souvik Roy'), arxiv.Result.Author('Soumyarup Sadhukhan'), arxiv.Result.Author('Arunava Sen'), arxiv.Result.Author('Huaxia Zeng')]",
1390,Elicitation for Preferences Single Peaked on Trees,"In multiagent systems, we often have a set of agents each of which have a
preference ordering over a set of items and one would like to know these
preference orderings for various tasks, for example, data analysis, preference
aggregation, voting etc. However, we often have a large number of items which
makes it impractical to ask the agents for their complete preference ordering.
In such scenarios, we usually elicit these agents' preferences by asking (a
hopefully small number of) comparison queries --- asking an agent to compare
two items. Prior works on preference elicitation focus on unrestricted domain
and the domain of single peaked preferences and show that the preferences in
single peaked domain can be elicited by much less number of queries compared to
unrestricted domain. We extend this line of research and study preference
elicitation for single peaked preferences on trees which is a strict superset
of the domain of single peaked preferences. We show that the query complexity
crucially depends on the number of leaves, the path cover number, and the
distance from path of the underlying single peaked tree, whereas the other
natural parameters like maximum degree, diameter, pathwidth do not play any
direct role in determining query complexity. We then investigate the query
complexity for finding a weak Condorcet winner for preferences single peaked on
a tree and show that this task has much less query complexity than preference
elicitation. Here again we observe that the number of leaves in the underlying
single peaked tree and the path cover number of the tree influence the query
complexity of the problem.",1604.04403v1,cs.GT,2016-04-15 08:40:39+00:00,"[arxiv.Result.Author('Palash Dey'), arxiv.Result.Author('Neeldhara Misra')]",
1391,The Euclidean criterion for irreducibles,"We recast Euclid's proof of the infinitude of prime numbers as a Euclidean
Criterion for a domain to have infinitely many atoms. We make connections with
Furstenberg's ""topological"" proof of the infinitude of prime numbers and show
that our criterion applies even in certain domains in which not all nonzero
nonunits factor into products of irreducibles.",1605.01298v1,math.AC,2016-05-04 14:42:36+00:00,[arxiv.Result.Author('Pete L. Clark')],
1392,An $L^2_T$-error bound for time-limited balanced truncation,"Model order reduction (MOR) is often applied to spatially-discretized partial
differential equations to reduce their order and hence decrease computational
complexity. A reduced system can be obtained, e.g., by time-limited balanced
truncation, a method that aims to construct an accurate reduced order model on
a given finite time interval $[0, T]$. This particular balancing related MOR
technique is studied in this paper. An $L^2_T$-error bound based on the
truncated time-limited singular values is proved and is the main result of this
paper. The derived error bound converges (as $T\rightarrow \infty$) to the
well-known $\mathcal H_\infty$-error bound of unrestricted balanced truncation,
a scheme that is used to construct a good reduced system on the entire time
line. The techniques within the proofs of this paper can also be applied to
unrestricted balanced truncation so that a relatively short time domain proof
of the $\mathcal H_\infty$-error bound is found here.",1907.05478v1,math.OC,2019-07-11 20:19:28+00:00,[arxiv.Result.Author('Martin Redmann')],
1393,Dichotomy Theorems for Alternation-Bounded Quantified Boolean Formulas,"In 1978, Schaefer proved his famous dichotomy theorem for generalized
satisfiability problems. He defined an infinite number of propositional
satisfiability problems, showed that all these problems are either in P or
NP-complete, and gave a simple criterion to determine which of the two cases
holds. This result is surprising in light of Ladner's theorem, which implies
that there are an infinite number of complexity classes between P and
NP-complete (under the assumption that P is not equal to NP).
  Schaefer also stated a dichotomy theorem for quantified generalized Boolean
formulas, but this theorem was only recently proven by Creignou, Khanna, and
Sudan, and independently by Dalmau: Determining truth of quantified Boolean
formulas is either PSPACE-complete or in P.
  This paper looks at alternation-bounded quantified generalized Boolean
formulas. In their unrestricted forms, these problems are the canonical
problems complete for the levels of the polynomial hierarchy. In this paper, we
prove dichotomy theorems for alternation-bounded quantified generalized Boolean
formulas, by showing that these problems are either $\Sigma_i^p$-complete or in
P, and we give a simple criterion to determine which of the two cases holds.
This is the first result that obtains dichotomy for an infinite number of
classes at once.",cs/0406006v1,cs.CC,2004-06-02 23:17:20+00:00,[arxiv.Result.Author('Edith Hemaspaandra')],
1394,Braiding of edge states in narrow zigzag graphene nanoribbons: effect of the third neighbors hopping,"We study narrow zigzag graphene nanoribbons (ZGNRs), employing density
functional theory (DFT) simulations and the tight-binding (TB) method. The main
result of these calculations is the braiding of the conduction and valence
bands, generating Dirac cones for non-commensurate wave vectors $\vec{k}$.
Employing a TB Hamiltonian, we show that the braiding is generated by the
third-neighbor hopping (N3). We calculate the band structure, the density of
states and the conductance, new conductance channels are opened, and the
conductance at the Fermi energy assumes integer multiples of the quantum
conductance unit $G_{o} = 2e^{2}/h$. We also investigate the satisfaction of
the Stoner criterion by these ZGNRs. We calculate the magnetic properties of
the fundamental state employing LSDA (spin-unrestricted DFT) and we confirm
that ZGNRs with $N=(2,3)$ do not satisfy the Stoner criterion and as such the
magnetic order could not be developed at their edges. These results are
confirmed by both tight-binding and LSDA calculations.",1711.10027v2,cond-mat.mes-hall,2017-11-27 22:38:59+00:00,"[arxiv.Result.Author('J. H. Correa'), arxiv.Result.Author('A. Pezo'), arxiv.Result.Author('M. S. Figueira')]","Phys. Rev. B 98, 045419 (2018)"
1395,Sensitivity of the Rayleigh criterion in thermoacoustics,"Thermoacoustic instabilities are one of the most challenging problems faced
by gas turbine and rocket motor manufacturers. The key instability mechanism is
described by the {\it Rayleigh criterion}. The Rayleigh criterion does not
directly show how to alter a system to make it more stable. This is the
objective of sensitivity analysis. Because thermoacoustic systems have many
design parameters, adjoint sensitivity analysis has been proposed to obtain all
the sensitivities with one extra calculation. Although adjoint sensitivity
analysis can be carried out in both the time and the frequency domain, the
frequency domain is more natural for a linear analysis. Perhaps surprisingly,
the Rayleigh criterion has not yet been rigorously derived and comprehensively
interpreted in the frequency domain. The contribution of this theoretical paper
is threefold. First, the Rayleigh criterion is interpreted in the frequency
domain with integral formulae for the complex eigenvalue. Second, the first
variation of the Rayleigh criterion is calculated both in the time and
frequency domain, both with and without Lagrange multipliers (adjoint
variables). The Lagrange multipliers are physically related to the system's
observables. Third, an adjoint Rayleigh criterion is proposed. The paper also
points out that the conclusions of {\it Juniper, M. P. (2018), Phys. Rev.
Fluids, vol. 3, 110509} apply to the first variation of the Rayleigh criterion,
not to the Rayleigh criterion itself. The mathematical relations of this paper
can be used to compute sensitivities directly from measurable quantities to
enable optimal design.",1910.08040v2,physics.flu-dyn,2019-10-17 17:09:14+00:00,"[arxiv.Result.Author('Luca Magri'), arxiv.Result.Author('Matthew P. Juniper'), arxiv.Result.Author('Jonas P. Moeck')]",J. Fluid Mech. 882 (2020) R1
1396,Bundled fragments of first-order modal logic: (un)decidability,"Quantified modal logic provides a natural logical language for reasoning
about modal attitudes even while retaining the richness of quantification for
referring to predicates over domains. But then most fragments of the logic are
undecidable, over many model classes. Over the years, only a few fragments
(such as the monodic) have been shown to be decidable. In this paper, we study
fragments that bundle quantifiers and modalities together, inspired by earlier
work on epistemic logics of know-how/why/what. As always with quantified modal
logics, it makes a significant difference whether the domain stays the same
across worlds, or not. In particular, we show that the bundle $\forall \Box$ is
undecidable over constant domain interpretations, even with only monadic
predicates, whereas $\exists \Box$ bundle is decidable. On the other hand, over
increasing domain interpretations, we get decidability with both $\forall \Box$
and $\exists \Box$ bundles with unrestricted predicates. In these cases, we
also obtain tableau based procedures that run in \PSPACE. We further show that
the $\exists \Box$ bundle cannot distinguish between constant domain and
increasing domain interpretations.",1803.10508v1,cs.LO,2018-03-28 10:20:13+00:00,"[arxiv.Result.Author('Anantha Padmanabha'), arxiv.Result.Author('R. Ramanujam'), arxiv.Result.Author('Yanjing Wang')]",
1397,Developing and Evaluating a Probabilistic LR Parser of Part-of-Speech and Punctuation Labels,"We describe an approach to robust domain-independent syntactic parsing of
unrestricted naturally-occurring (English) input. The technique involves
parsing sequences of part-of-speech and punctuation labels using a
unification-based grammar coupled with a probabilistic LR parser. We describe
the coverage of several corpora using this grammar and report the results of a
parsing experiment using probabilities derived from bracketed training data. We
report the first substantial experiments to assess the contribution of
punctuation to deriving an accurate syntactic analysis, by parsing identical
texts both with and without naturally-occurring punctuation marks.",cmp-lg/9510005v1,cmp-lg,1995-10-09 16:27:17+00:00,"[arxiv.Result.Author('Ted Briscoe'), arxiv.Result.Author('John Carroll')]","4th International Workshop on Parsing Technologies (IWPT-95),
  48-58"
1398,Word Sense Disambiguation using Optimised Combinations of Knowledge Sources,"Word sense disambiguation algorithms, with few exceptions, have made use of
only one lexical knowledge source. We describe a system which performs
unrestricted word sense disambiguation (on all content words in free text) by
combining different knowledge sources: semantic preferences, dictionary
definitions and subject/domain codes along with part-of-speech tags. The
usefulness of these sources is optimised by means of a learning algorithm. We
also describe the creation of a new sense tagged corpus by combining existing
resources. Tested accuracy of our approach on this corpus exceeds 92%,
demonstrating the viability of all-word disambiguation rather than restricting
oneself to a small sample.",cmp-lg/9806014v1,cmp-lg,1998-06-22 16:20:22+00:00,"[arxiv.Result.Author('Yorick Wilks'), arxiv.Result.Author('Mark Stevenson')]",
1399,Stripe formation in electron-doped cuprates,"We investigate the formation of charge domain walls in an electron-doped
extended Hubbard model for the superconducting cuprates. Within an unrestricted
Hartree-Fock approach, extended by the introduction of slave-bosons to obtain a
more proper treatment of strong correlations, we demonstrate the occurrence of
stripes in the (1,1) and (1,-1) directions having one doped electron per stripe
site. The different filling, direction and width of these electron-doped
stripes with respect to those obtained in the hole-doped systems have
interesting observable consequences, which are discussed.",cond-mat/9907447v3,cond-mat.supr-con,1999-07-28 16:02:59+00:00,"[arxiv.Result.Author('A. Sadori'), arxiv.Result.Author('M. Grilli')]",
1400,Arrow's Impossibility Theorem Without Unanimity,"Arrow's Impossibility Theorem states that any constitution which satisfies
Transitivity, Independence of Irrelevant Alternatives (IIA) and Unanimity is a
dictatorship. Wilson derived properties of constitutions satisfying
Transitivity and IIA for unrestricted domains where ties are allowed. In this
paper we consider the case where only strict preferences are allowed. In this
case we derive a new short proof of Arrow theorem and further obtain a new and
complete characterization of all functions satisfying Transitivity and IIA.",0901.4727v5,cs.GT,2009-01-29 17:32:26+00:00,[arxiv.Result.Author('Elchanan Mossel')],
1401,Model Complete Expansions of the Real Field by Modular Functions and Forms,"We prove a strong form of model completenes for expansions of the field of
real numbers by (the real and imaginary parts of) the modular function J, by
the modular forms $E_4$ and $E_6$ and quasimodular form $E_2$ defined in the
usual fundamental domain, and the restricted sine function and the
(unrestricted) exponential function. This is done using ideas of Peterzil and
Starchenko's paper \cite{peterzil-starchenko-wp2004} on the uniform
definability of $\wp$ function in $\mathbb{R}_{\mathit{an}}$ (and of the
modular function $J$). In the conclusion we pose some open problems related to
this work.",1406.7158v1,math.LO,2014-06-27 12:06:02+00:00,[arxiv.Result.Author('Ricardo Bianconi')],"South American Journal of Logic, Vol. 1, n. 1, pp. 321-335, 2015"
1402,Phase Transition in Unrestricted Random SAT,"For random CNF formulae with m clauses, n variables and an unrestricted
number of literals per clause the transition from high to low satisfiability
can be determined exactly for large n. The critical density m/n turns out to be
strongly n-dependent, ccr = ln(2)/(1-p)^^n, where pn is the mean number of
positive literals per clause.This is in contrast to restricted random SAT
problems (random K-SAT), where the critical ratio m/n is a constant. All
transition lines are calculated by the second moment method applied to the
number of solutions N of a formula. In contrast to random K-SAT, the method
does not fail for the unrestricted model, because long range interactions
between solutions are not cut off by disorder.",1204.1656v1,cs.CC,2012-04-07 16:50:46+00:00,[arxiv.Result.Author('Bernd R. Schuh')],
1403,Spin-unrestricted random-phase approximation with range separation: Benchmark on atomization energies and reaction barrier heights,"We consider several spin-unrestricted random-phase approximation (RPA)
variants for calculating correlation energies, with and without range
separation, and test them on datasets of atomization energies and reaction
barrier heights. We show that range separation greatly improves the accuracy of
all RPA variants for these properties. Moreover, we show that a RPA variant
with exchange, hereafter referred to as RPAx-SO2, first proposed by Sz-abo and
Ostlund [A. Szabo and N. S. Ostlund, J. Chem. Phys. 67, 4351 (1977)] in a
spin-restricted closed-shell formalism, and extended here to a
spin-unrestricted formalism , provides on average the most accurate
range-separated RPA variant for atomization energies and reaction barrier
heights. Since this range-separated RPAx-SO2 method had already been shown to
be among the most accurate range-separated RPA variants for weak intermolecular
interactions [J. Toulouse, W. Zhu, A. Savin, G. Jansen, and J. G.
{\'A}ngy{\'a}n, J. Chem. Phys. 135, 084119 (2011)], this works confirms
range-separated RPAx-SO2 as a promising method for general chemical
applications.",1506.05907v3,physics.chem-ph,2015-06-19 08:27:25+00:00,"[arxiv.Result.Author('Bastien Mussard'), arxiv.Result.Author('Peter Reinhardt'), arxiv.Result.Author('Janos Angyan'), arxiv.Result.Author('Julien Toulouse')]","Journal of Chemical Physics, American Institute of Physics, 2015,
  pp.00"
1404,Unrestricted slave-boson mean-field approximation for the two-dimensional Hubbard model,"The Kotliar-Ruckenstein slave-boson scheme is used to allow for an
unrestricted variation of the bosonic and fermionic fields on the saddle-point
level. Various inhomogeneous solutions, such as spin polarons and domain walls
are discussed within the two-dimensional Hubbard model and compared with
results of unrestricted Hartree-Fock (HF) calculations. We find that the
present approach drastically reduces the polarization of these states and leads
to increased delocalized wave functions as compared to the HF model. The
interaction between two spin polarons turns out to be attractive over a wide
range of the on-site repulsion U. In addition we obtain the crossover from
vertical to diagonal domain walls at a higher value of U than predicted by HF.",cond-mat/9801135v1,cond-mat.str-el,1998-01-14 13:01:48+00:00,"[arxiv.Result.Author('G. Seibold'), arxiv.Result.Author('E. Sigmund'), arxiv.Result.Author('V. Hizhnyakov')]",
1405,ColorFool: Semantic Adversarial Colorization,"Adversarial attacks that generate small L_p-norm perturbations to mislead
classifiers have limited success in black-box settings and with unseen
classifiers. These attacks are also not robust to defenses that use denoising
filters and to adversarial training procedures. Instead, adversarial attacks
that generate unrestricted perturbations are more robust to defenses, are
generally more successful in black-box settings and are more transferable to
unseen classifiers. However, unrestricted perturbations may be noticeable to
humans. In this paper, we propose a content-based black-box adversarial attack
that generates unrestricted perturbations by exploiting image semantics to
selectively modify colors within chosen ranges that are perceived as natural by
humans. We show that the proposed approach, ColorFool, outperforms in terms of
success rate, robustness to defense frameworks and transferability, five
state-of-the-art adversarial attacks on two different tasks, scene and object
classification, when attacking three state-of-the-art deep neural networks
using three standard datasets. The source code is available at
https://github.com/smartcameras/ColorFool.",1911.10891v2,cs.CV,2019-11-25 13:10:29+00:00,"[arxiv.Result.Author('Ali Shahin Shamsabadi'), arxiv.Result.Author('Ricardo Sanchez-Matilla'), arxiv.Result.Author('Andrea Cavallaro')]",
1406,Adversarial Color Enhancement: Generating Unrestricted Adversarial Images by Optimizing a Color Filter,"We introduce an approach that enhances images using a color filter in order
to create adversarial effects, which fool neural networks into
misclassification. Our approach, Adversarial Color Enhancement (ACE), generates
unrestricted adversarial images by optimizing the color filter via gradient
descent. The novelty of ACE is its incorporation of established practice for
image enhancement in a transparent manner. Experimental results validate the
white-box adversarial strength and black-box transferability of ACE. A range of
examples demonstrates the perceptual quality of images that ACE produces. ACE
makes an important contribution to recent work that moves beyond $L_p$
imperceptibility and focuses on unrestricted adversarial modifications that
yield large perceptible perturbations, but remain non-suspicious, to the human
eye. The future potential of filter-based adversaries is also explored in two
directions: guiding ACE with common enhancement practices (e.g., Instagram
filters) towards specific attractive image styles and adapting ACE to image
semantics. Code is available at https://github.com/ZhengyuZhao/ACE.",2002.01008v3,cs.CV,2020-02-03 20:44:29+00:00,"[arxiv.Result.Author('Zhengyu Zhao'), arxiv.Result.Author('Zhuoran Liu'), arxiv.Result.Author('Martha Larson')]",
1407,Generating Unrestricted Adversarial Examples via Three Parameters,"Deep neural networks have been shown to be vulnerable to adversarial examples
deliberately constructed to misclassify victim models. As most adversarial
examples have restricted their perturbations to $L_{p}$-norm, existing defense
methods have focused on these types of perturbations and less attention has
been paid to unrestricted adversarial examples; which can create more realistic
attacks, able to deceive models without affecting human predictions. To address
this problem, the proposed adversarial attack generates an unrestricted
adversarial example with a limited number of parameters. The attack selects
three points on the input image and based on their locations transforms the
image into an adversarial example. By limiting the range of movement and
location of these three points and using a discriminatory network, the proposed
unrestricted adversarial example preserves the image appearance. Experimental
results show that the proposed adversarial examples obtain an average success
rate of 93.5% in terms of human evaluation on the MNIST and SVHN datasets. It
also reduces the model accuracy by an average of 73% on six datasets MNIST,
FMNIST, SVHN, CIFAR10, CIFAR100, and ImageNet. It should be noted that, in the
case of attacks, lower accuracy in the victim model denotes a more successful
attack. The adversarial train of the attack also improves model robustness
against a randomly transformed image.",2103.07640v1,cs.CV,2021-03-13 07:20:14+00:00,"[arxiv.Result.Author('Hanieh Naderi'), arxiv.Result.Author('Leili Goli'), arxiv.Result.Author('Shohreh Kasaei')]",
1408,On Technical Trading and Social Media Indicators in Cryptocurrencies' Price Classification Through Deep Learning,"This work aims to analyse the predictability of price movements of
cryptocurrencies on both hourly and daily data observed from January 2017 to
January 2021, using deep learning algorithms. For our experiments, we used
three sets of features: technical, trading and social media indicators,
considering a restricted model of only technical indicators and an unrestricted
model with technical, trading and social media indicators. We verified whether
the consideration of trading and social media indicators, along with the
classic technical variables (such as price's returns), leads to a significative
improvement in the prediction of cryptocurrencies price's changes. We conducted
the study on the two highest cryptocurrencies in volume and value (at the time
of the study): Bitcoin and Ethereum. We implemented four different machine
learning algorithms typically used in time-series classification problems:
Multi Layers Perceptron (MLP), Convolutional Neural Network (CNN), Long Short
Term Memory (LSTM) neural network and Attention Long Short Term Memory (ALSTM).
We devised the experiments using the advanced bootstrap technique to consider
the variance problem on test samples, which allowed us to evaluate a more
reliable estimate of the model's performance. Furthermore, the Grid Search
technique was used to find the best hyperparameters values for each implemented
algorithm. The study shows that, based on the hourly frequency results, the
unrestricted model outperforms the restricted one. The addition of the trading
indicators to the classic technical indicators improves the accuracy of Bitcoin
and Ethereum price's changes prediction, with an increase of accuracy from a
range of 51-55% for the restricted model, to 67-84% for the unrestricted model.",2102.08189v2,q-fin.ST,2021-02-13 13:18:36+00:00,"[arxiv.Result.Author('Marco Ortu'), arxiv.Result.Author('Nicola Uras'), arxiv.Result.Author('Claudio Conversano'), arxiv.Result.Author('Giuseppe Destefanis'), arxiv.Result.Author('Silvia Bartolucci')]",
1409,Ground state of two electrons on concentric spheres,"We extend our analysis of two electrons on a sphere [Phys. Rev. A {\bf 79},
062517 (2009); Phys. Rev. Lett. {\bf 103}, 123008 (2009)] to electrons on
concentric spheres with different radii. The strengths and weaknesses of
several electronic structure models are analyzed, ranging from the mean-field
approximation (restricted and unrestricted Hartree-Fock solutions) to
configuration interaction expansion, leading to near-exact wave functions and
energies. The M{\o}ller-Plesset energy corrections (up to third-order) and the
asymptotic expansion for the large-spheres regime are also considered. We also
study the position intracules derived from approximate and exact wave
functions. We find evidence for the existence of a long-range Coulomb hole in
the large-spheres regime, and infer that unrestricted Hartree-Fock theory
over-localizes the electrons.",1004.2097v3,cond-mat.other,2010-04-13 02:50:47+00:00,"[arxiv.Result.Author('Pierre-François Loos'), arxiv.Result.Author('Peter M. W. Gill')]","Phys. Rev. A 81, 052510 (2010)"
1410,Blocking and Other Enhancements for Bottom-Up Model Generation Methods,"Model generation is a problem complementary to theorem proving and is
important for fault analysis and debugging of formal specifications of security
protocols, programs and terminological definitions. This paper discusses
several ways of enhancing the paradigm of bottom-up model generation. The two
main contributions are new, generalized blocking techniques and a new
range-restriction transformation. The blocking techniques are based on simple
transformations of the input set together with standard equality reasoning and
redundancy elimination techniques. These provide general methods for finding
small, finite models. The range-restriction transformation refines existing
transformations to range-restricted clauses by carefully limiting the creation
of domain terms. All possible combinations of the introduced techniques and
classical range-restriction were tested on the clausal problems of the TPTP
Version 6.0.0 with an implementation based on the SPASS theorem prover using a
hyperresolution-like refinement. Unrestricted domain blocking gave best results
for satisfiable problems showing it is a powerful technique indispensable for
bottom-up model generation methods. Both in combination with the new
range-restricting transformation, and the classical range-restricting
transformation, good results have been obtained. Limiting the creation of terms
during the inference process by using the new range restricting transformation
has paid off, especially when using it together with a shifting transformation.
The experimental results also show that classical range restriction with
unrestricted blocking provides a useful complementary method. Overall, the
results showed bottom-up model generation methods were good for disproving
theorems and generating models for satisfiable problems, but less efficient
than SPASS in auto mode for unsatisfiable problems.",1611.09014v2,cs.AI,2016-11-28 07:54:50+00:00,"[arxiv.Result.Author('Peter Baumgartner'), arxiv.Result.Author('Renate A. Schmidt')]",
1411,Unrestricted Hartree-Fock for Quantum Dots,"We present detailed results of Unrestricted Hartree-Fock (UHF) calculations
for up to eight electrons in a parabolic quantum dot. The UHF energies are
shown to provide rather accurate estimates of the ground-state energy in the
entire range of parameters from high densities with shell model characteristics
to low densities with Wigner molecule features. To elucidate the significance
of breaking the rotational symmetry, we compare Restricted Hartree-Fock (RHF)
and UHF. While UHF symmetry breaking admits lower ground-state energies,
misconceptions in the interpretation of UHF densities are pointed out. An
analysis of the orbital energies shows that for very strong interaction the UHF
Hamiltonian is equivalent to a tight-binding Hamiltonian. This explains why the
UHF energies become nearly spin independent in this regime while the RHF
energies do not. The UHF densities display an even-odd effect which is related
to the angular momentum of the Wigner molecule. In a weak transversal magnetic
field this even-odd effect disappears.",cond-mat/0305623v1,cond-mat.str-el,2003-05-27 16:06:45+00:00,"[arxiv.Result.Author('Boris Reusch'), arxiv.Result.Author('Hermann Grabert')]","Phys. Rev. B 68, 045309 (2003)"
1412,Blind Adversarial Training: Balance Accuracy and Robustness,"Adversarial training (AT) aims to improve the robustness of deep learning
models by mixing clean data and adversarial examples (AEs). Most existing AT
approaches can be grouped into restricted and unrestricted approaches.
Restricted AT requires a prescribed uniform budget to constrain the magnitude
of the AE perturbations during training, with the obtained results showing high
sensitivity to the budget. On the other hand, unrestricted AT uses
unconstrained AEs, resulting in the use of AEs located beyond the decision
boundary; these overestimated AEs significantly lower the accuracy on clean
data. These limitations mean that the existing AT approaches have difficulty in
obtaining a comprehensively robust model with high accuracy and robustness when
confronting attacks with varying strengths. Considering this problem, this
paper proposes a novel AT approach named blind adversarial training (BAT) to
better balance the accuracy and robustness. The main idea of this approach is
to use a cutoff-scale strategy to adaptively estimate a nonuniform budget to
modify the AEs used in the training, ensuring that the strengths of the AEs are
dynamically located in a reasonable range and ultimately improving the overall
robustness of the AT model. The experimental results obtained using BAT for
training classification models on several benchmarks demonstrate the
competitive performance of this method.",2004.05914v1,cs.LG,2020-04-10 02:16:01+00:00,"[arxiv.Result.Author('Haidong Xie'), arxiv.Result.Author('Xueshuang Xiang'), arxiv.Result.Author('Naijin Liu'), arxiv.Result.Author('Bin Dong')]",
1413,Study of a toy model and its relation to the Hubbard model with infinite range hopping,"A toy model of strongly correlated fermions is studied using Green function
and functional integration methods. The model exhibits a metal-insulator
transition as the interaction is varied. In the case of unrestricted hopping is
established the equivalence of the model with the Hubbard model with infinite
range hopping. The generalization to the case with $N$ components is made.",cond-mat/9511050v1,cond-mat,1995-11-11 00:47:29+00:00,"[arxiv.Result.Author('Flavio S. Nogueira'), arxiv.Result.Author('Enrique V. Anda')]",
1414,"Nonlocal potentials for short-range electronic correlation in atoms, molecules, and solids","Extending density functional theory (DFT) to an {\it ab initio} orbital
functional theory (OFT) requires new methodology for nonlocal exchange and
correlation potentials. This paper describes such modifications to a standard
Dirac-Slater atomic program. Unrestricted Hartree-Fock (UHF) theory is extended
by a modified Colle-Salvetti Ansatz for short-range electronic correlation.
Results are reported for atoms He-Ne. Values of parameters needed for similar
calculations on molecules and solids are reported. Implementation of nonlocal
exchange and correlation for such extended systems, using multiple scattering
theory to connect independent calculations in space-filling atomic cells, is
discussed.",cond-mat/0310117v1,cond-mat,2003-10-06 15:56:03+00:00,[arxiv.Result.Author('R. K. Nesbet')],
1415,Superconductivity in the Kondo lattice: a mean-field approach,"We calculate the superconducting critical temperature T_c and the Kondo
temperature T_K of the Kondo lattice, decoupling the Kondo exchange interaction
in the unrestricted Hartree-Fock (HF) Bardeen-Cooper-Schrieffer (BCS)
approximation. We obtain that both T_K and T_c have an exponential dependence
in the Kondo coupling J_K. For optimum doping and realistic parameters, both
temperatures fall in the experimentally observed range.",cond-mat/0011383v1,cond-mat.str-el,2000-11-22 11:51:51+00:00,"[arxiv.Result.Author('M. A. Gusmao'), arxiv.Result.Author('A. A. Aligia')]",
1416,Percolation-like behavior of some optimal coalition formation models,"The ground-state of an infinite-range Potts glass-type model with +/- J bonds
and unrestricted number of states is used to investigate coalition formation.
As a function of the q probability of +J bonds in the system it is found that
the r relative size of the largest cluster (a cluster being the group of
elements in the same state) shows a percolation like behavior. By a simple
renormalization approach and several optimization methods we investigate the
r(q) curves for finite systems sizes. Non-trivial consequences for social
percolation problems are discussed.",cond-mat/0209041v1,cond-mat.stat-mech,2002-09-02 18:05:27+00:00,"[arxiv.Result.Author('Z. Neda'), arxiv.Result.Author('R. Florian'), arxiv.Result.Author('M. Ravasz'), arxiv.Result.Author('A. Libal'), arxiv.Result.Author('G. Gyorgyi')]",
1417,Checkerboard and stripe inhomogeneities in cuprates,"We systematically investigate charge-ordering phases by means of a restricted
and unrestricted Gutzwiller approximation to the single-band Hubbard model with
nearest ($t$) and next-nearest neighbor hopping ($t'$). When $|t'/t|$ is small,
as appropriate for ${\rm La_{2-x}Sr_xCuO_4}$, stripes are found, whereas in
compounds with larger $|t'/t|$ (such as ${\rm Ca_{2-x}Na_x CuO_2Cl_2}$ and
${\rm Bi_2Sr_2CaCu_2O_{8+\delta}}$) checkerboard structures are favored. In
contrast to the linear doping dependence found for stripes the charge
periodicity of checkerboard textures is locked to 4 unit cells over a wide
doping range. In addition we find that checkerboard structures are favored at
surfaces.",cond-mat/0606010v1,cond-mat.str-el,2006-05-31 21:04:39+00:00,"[arxiv.Result.Author('G. Seibold'), arxiv.Result.Author('J. Lorenzana'), arxiv.Result.Author('M. Grilli')]","Phys. Rev. B 75, 100505 (2007)"
1418,Numerically exact and approximate determination of energy eigenvalues for antiferromagnetic molecules using irreducible tensor operators and general point-group symmetries,"Numerical exact diagonalization is the ultimate method of choice in order to
discuss static, dynamic, and thermodynamic properties of quantum systems. In
this article we consider Heisenberg spin-systems and extend the range of
applicability of the exact diagonalization method by showing how the
irreducible tensor operator technique can be combined with an unrestricted use
of general point-group symmetries. We also present ideas how to use
spin-rotational and point-group symmetries in order to obtain approximate
spectra.",0812.4126v1,cond-mat.str-el,2008-12-22 09:06:53+00:00,"[arxiv.Result.Author('R. Schnalle'), arxiv.Result.Author('J. Schnack')]",Phys. Rev. B 79 (2009) 104419
1419,Ground state of two electrons on a sphere,"We have performed a comprehensive study of the singlet ground state of two
electrons on the surface of a sphere of radius $R$. We have used electronic
structure models ranging from restricted and unrestricted Hartree-Fock theory
to explicitly correlated treatments, the last of which lead to near-exact
wavefunctions and energies for any value of $R$. M{\o}ller-Plesset energy
corrections (up to fifth-order) are also considered, as well as the asymptotic
solution in the large-$R$ regime.",1002.3398v1,cond-mat.other,2010-02-17 23:32:00+00:00,"[arxiv.Result.Author('Pierre-François Loos'), arxiv.Result.Author('Peter M. W. Gill')]","Phys. Rev. A 79, 062517 (2009)"
1420,Charge-transfer in time-dependent density-functional theory via spin-symmetry-breaking,"Long-range charge-transfer excitations pose a major challenge for
time-dependent density functional approximations. We show that
spin-symmetry-breaking offers a simple solution for molecules composed of
open-shell fragments, yielding accurate excitations at large separations when
the acceptor effectively contains one active electron. Unrestricted
exact-exchange and self-interaction-corrected functionals are performed on
one-dimensional models and the real LiH molecule within the pseudopotential
approximation to demonstrate our results.",1101.1378v1,physics.chem-ph,2011-01-07 08:41:31+00:00,"[arxiv.Result.Author('Johanna I. Fuks'), arxiv.Result.Author('Angel Rubio'), arxiv.Result.Author('Neepa T. Maitra')]","Physical Review A 83, 042501 (2011)"
1421,Magnetic ordering of three-component ultracold fermionic mixtures in optical lattices,"We study finite-temperature magnetic phases of three-component mixtures of
ultracold fermions with repulsive interactions in optical lattices with simple
cubic or square geometry by means of dynamical mean-field theory (DMFT). We
focus on the case of one particle per site (1/3 band filling) at moderate
interaction strength, where we observe a sequence of thermal phase transitions
into two- and three-sublattice ordered states by means of the unrestricted
real-space generalization of DMFT. From our quantitative analysis we conclude
that long-range ordering in three-component mixtures should be observable at
comparable temperatures as in two-component mixtures.",1402.3397v2,cond-mat.quant-gas,2014-02-14 08:55:04+00:00,"[arxiv.Result.Author('Andrii Sotnikov'), arxiv.Result.Author('Walter Hofstetter')]","Phys. Rev. A 89, 063601 (2014)"
1422,Multiple Private Key Generation for Continuous Memoryless Sources with A Helper,"We propose a method to study the secrecy constraints in key generation
problems where side information might be present at untrusted users. Our method
is inspired by a recent work of Hayashi and Tan who used the R\'enyi divergence
as the secrecy measure to study the output statistics of applying hash
functions to a random sequence. By generalizing the achievability result of
Hayashi and Tan to the multi-terminal case, we obtain the output statistics of
applying hash functions to multiple random sequences, which turn out to be an
important tool in the achievability proof of strong secrecy capacity regions of
key generation problems with side information at untrusted users. To illustrate
the power of our method, we derive the capacity region of the multiple private
key generation problem with an untrusted helper for continuous memoryless
sources under Markov conditions. The converse proof of our result follows by
generalizing a result of Nitinawarat and Narayan to the case with side
information at untrusted users.",2009.02852v1,cs.IT,2020-09-07 01:45:08+00:00,[arxiv.Result.Author('Lin Zhou')],
1423,Revisiting Definitional Foundations of Oblivious RAM for Secure Processor Implementations,"Oblivious RAM (ORAM) is a renowned technique to hide the access patterns of
an application to an untrusted memory. According to the standard ORAM
definition presented by Goldreich and Ostrovsky, two ORAM access sequences must
be computationally indistinguishable if the lengths of these sequences are
identically distributed. An artifact of this definition is that it does not
apply to modern ORAM implementations adapted in current secure processors
technology because of their arbitrary lengths of memory access sequences
depending on programs' behaviors (their termination times). As a result, the
ORAM definition does not directly apply; the theoretical foundations of ORAM do
not clearly argue about the timing and termination channels.
  This paper conducts a first rigorous study of the standard
Goldreich-Ostrovsky ORAM definition in view of modern practical ORAMs (e.g.,
Path ORAM) and demonstrates the gap between theoretical foundations and real
implementations. A new ORAM formulation which clearly separates out termination
channel leakage is proposed. It is shown how this definition implies the
standard ORAM definition (for finite length input access sequences) and better
fits the modern practical ORAM implementations. The proposed definition relaxes
the constraints around the stash size and overflow probability for Path ORAM,
and essentially transforms its security argument into a performance
consideration problem.
  Finally, a `strong' ORAM formulation which clearly includes obfuscation of
termination leakage is shown to imply our new ORAM formulation and applies to
ORAM for outsourced disk storage. In this strong formulation constraints are
not relaxed and the security argument for Path ORAM remains complex as one
needs to prove that the stash overflows with negligible probability.",1706.03852v3,cs.CR,2017-06-12 20:58:01+00:00,"[arxiv.Result.Author('Syed Kamran Haider'), arxiv.Result.Author('Omer Khan'), arxiv.Result.Author('Marten van Dijk')]",
1424,Secure transmission with covert requirement in untrusted relaying networks,"In this paper, we study the problem of secure transmission with covert
requirement in untrusted relaying networks. Our considered system model
consists of one source, one destination, one untrusted relay, and one Willie.
The untrusted relay tries to extract the information signal, while the goal of
Willie is to detect the presence of the information signal transmitted by the
source, in the current time slot. To overcome these two attacks, we illustrate
that the destination and the source should inject jamming signal to the network
in phase I and phase II, respectively. Accordingly, the communication in our
proposed system model is accomplished in two phases. In the first phase, when
the source transmits its data to the untrusted relay the destination broadcasts
its jamming signal. In the second phase, when the relay retransmits the
received signal, the source transmits a jamming signal with one of its
antennas. For this system model, we propose a power allocation strategy to
maximize the instantaneous secrecy rate subject to satisfying the covert
requirements in both of the phases. Since the proposed optimization problem is
non-convex, we adopt the Successive Convex Approximation (SCA) approach to
convert it to a convex optimization problem. Next, we extend our system model
to a practical system model where there are multiple untrusted relays and
multiple Willies under two scenarios of noncolluding Willies and colluding
Willies. Our findings highlight that unlike the direct transmission scheme, the
achievable secrecy rate of the proposed secure transmission scheme improve as
the number of untrusted relays increases.",1809.00312v1,cs.CR,2018-09-02 08:26:41+00:00,"[arxiv.Result.Author('Moslem Forouzesh'), arxiv.Result.Author('Paeiz Azmi'), arxiv.Result.Author('Ali Kuhestani')]",
1425,Information Flow Control in WebKit's JavaScript Bytecode,"Websites today routinely combine JavaScript from multiple sources, both
trusted and untrusted. Hence, JavaScript security is of paramount importance. A
specific interesting problem is information flow control (IFC) for JavaScript.
In this paper, we develop, formalize and implement a dynamic IFC mechanism for
the JavaScript engine of a production Web browser (specifically, Safari's
WebKit engine). Our IFC mechanism works at the level of JavaScript bytecode and
hence leverages years of industrial effort on optimizing both the source to
bytecode compiler and the bytecode interpreter. We track both explicit and
implicit flows and observe only moderate overhead. Working with bytecode
results in new challenges including the extensive use of unstructured control
flow in bytecode (which complicates lowering of program context taints),
unstructured exceptions (which complicate the matter further) and the need to
make IFC analysis permissive. We explain how we address these challenges,
formally model the JavaScript bytecode semantics and our instrumentation, prove
the standard property of termination-insensitive non-interference, and present
experimental results on an optimized prototype.",1401.4339v2,cs.CR,2014-01-17 13:38:08+00:00,"[arxiv.Result.Author('Abhishek Bichhawat'), arxiv.Result.Author('Vineet Rajani'), arxiv.Result.Author('Deepak Garg'), arxiv.Result.Author('Christian Hammer')]",
1426,Verifying the quantumness of a channel with an untrusted device,"Suppose one wants to certify that a quantum channel is not
entanglement-breaking. I consider all four combinations of trusted and
untrusted devices at the input and output of the channel, finding that the most
interesting is a trusted preparation device at the input and an untrusted
measurement device at the output. This provides a time-like analogue of
EPR-steering, which turns out to reduce to the problem of joint measurability,
connecting these concepts in a different way to other recent work. I suggest a
few applications of this connection, such as a resource theory of
incompatibility. This perspective also sheds light on why the BB84 key
distribution protocol can be secure even with an untrusted measuring device,
leading to an uncertainty relation for arbitrary pairs of ensembles.",1502.03010v2,quant-ph,2015-02-10 17:43:15+00:00,[arxiv.Result.Author('Matthew F. Pusey')],"J. Opt. Soc. Am. B 32, A56 (2015)"
1427,A Cryptographic Test of Quantumness and Certifiable Randomness from a Single Quantum Device,"We consider a new model for the testing of untrusted quantum devices,
consisting of a single polynomial-time bounded quantum device interacting with
a classical polynomial-time verifier. In this model we propose solutions to two
tasks - a protocol for efficient classical verification that the untrusted
device is ""truly quantum,"" and a protocol for producing certifiable randomness
from a single untrusted quantum device. Our solution relies on the existence of
a new cryptographic primitive for constraining the power of an untrusted
quantum device: post-quantum secure trapdoor claw-free functions which must
satisfy an adaptive hardcore bit property. We show how to construct this
primitive based on the hardness of the learning with errors (LWE) problem.",1804.00640v4,quant-ph,2018-04-02 17:39:37+00:00,"[arxiv.Result.Author('Zvika Brakerski'), arxiv.Result.Author('Paul Christiano'), arxiv.Result.Author('Urmila Mahadev'), arxiv.Result.Author('Umesh Vazirani'), arxiv.Result.Author('Thomas Vidick')]",
1428,Reconciling progress-insensitive noninterference and declassification,"Practitioners of secure information flow often face a design challenge: what
is the right semantic treatment of leaks via termination? On the one hand, the
potential harm of untrusted code calls for strong progress-sensitive security.
On the other hand, when the code is trusted to not aggressively exploit
termination channels, practical concerns, such as permissiveness of the
enforcement, make a case for settling for weaker, progress-insensitive
security. This binary situation, however, provides no suitable middle point for
systems that mix trusted and untrusted code. This paper connects the two
extremes by reframing progress-insensitivity as a particular form of
declassification. Our novel semantic condition reconciles progress-insensitive
security as a declassification bound on the so-called progress knowledge in an
otherwise progress or timing sensitive setting. We show how the new condition
can be soundly enforced using a mostly standard information-flow monitor. We
believe that the connection established in this work will enable other
applications of ideas from the literature on declassification to progress
insensitivity.",2005.01977v2,cs.PL,2020-05-05 07:28:57+00:00,"[arxiv.Result.Author('Johan Bay'), arxiv.Result.Author('Aslan Askarov')]",
1429,Quantization-Aided Secrecy: FD C-RAN Communications with Untrusted Radios,"In this work, we study a full-duplex (FD) cloud radio access network (C-RAN)
from the aspects of infrastructure sharing and information secrecy, where the
central unit utilizes FD remote radio units (RU)s belonging to the same
operator, i.e., the trusted RUs, as well as the RUs belonging to other
operators or private owners, i.e., the untrusted RUs. Furthermore, the
communication takes place in the presence of untrusted external receivers,
i.e., eavesdropper nodes. The communicated uplink (UL) and downlink (DL)
waveforms are quantized in order to comply with the limited capacity of the
fronthaul links. In order to provide information secrecy, we propose a novel
utilization of the quantization noise shaping in the DL, such that it is
simultaneously used to comply with the limited capacity of the fronthaul links,
as well as to degrade decoding capability of the individual eavesdropper and
the untrusted RUs for both the UL and DL communications. In this regard,
expressions describing the achievable secrecy rates are obtained. An
optimization problem for jointly designing the DL and UL quantization and
precoding strategies are then formulated, with the purpose of maximizing the
overall system weighted sum secrecy rate. Due to the intractability of the
formulated problem, an iterative solution is proposed, following the successive
inner approximation and semi-definite relaxation frameworks, with convergence
to a stationary point. Numerical evaluations indicate a promising gain of the
proposed approaches for providing information secrecy against the untrusted
infrastructure nodes and/or external eavesdroppers in the context of FD C-RAN
communications.",2107.08495v1,cs.IT,2021-07-18 17:12:48+00:00,"[arxiv.Result.Author('Omid Taghizadeh'), arxiv.Result.Author('Tianyu Yang'), arxiv.Result.Author('Hiroki Iimori'), arxiv.Result.Author('Giuseppe Abreu'), arxiv.Result.Author('Ali Cagatay Cirik'), arxiv.Result.Author('Rudolf Mathar')]",
1430,NxWLAN: Neighborhood eXtensible WLAN,"The increased usage of IEEE 802.11 Wireless LAN (WLAN) in residential
environments by unexperienced users leads to dense, unplanned and chaotic
residential WLAN deployments. Often WLAN Access Points (APs) are deployed
unprofitable in terms of radio coverage and interference conditions. In many
cases the usage of the neighbor's AP would be beneficial as it would provide
better radio coverage in some parts of the residential user's apartment.
Moreover, the network performance can be dramatically improved by balancing the
network load over spatially co-located APs.
  We address this problem by presenting Neighborhood extensible WLAN (NxWLAN)
which enables the secure extension of user's home WLANs through usage of
neighboring APs in residential environments with zero configuration efforts and
without revealing WPA2 encryption keys to untrusted neighbor APs. NxWLAN makes
use of virtualization techniques utilizing neighboring AP by deploying
on-demand a Wireless Termination Point (WTP) on the neighboring AP and by
tunneling encrypted 802.11 traffic to the Virtual Access Point (VAP) residing
on the home AP. This allows the client devices to always authenticate against
the home AP using the WPA2-PSK passphrase already stored in the device without
any additional registration process.
  We implemented NxWLAN prototypically using off-the-shelf hardware and open
source software. As the OpenFlow is not suited for forwarding native 802.11
frames, we built software switch using P4 language. The performance evaluation
in a small 802.11 indoor testbed showed the feasibility of our approach. NxWLAN
is provided to the community as open source.",1607.03254v1,cs.NI,2016-07-12 08:15:05+00:00,"[arxiv.Result.Author('Piotr Gawłowicz'), arxiv.Result.Author('Sven Zehl'), arxiv.Result.Author('Anatolij Zubow'), arxiv.Result.Author('Adam Wolisz')]",
1431,The Supervisionary proof-checking kernel (or: a work-in-progress towards proof generating code),"Interactive theorem proving software is typically designed around a trusted
proof-checking kernel, the sole system component capable of authenticating
theorems. Untrusted automation procedures reside outside of the kernel, and
drive it to deduce new theorems via an API. Kernel and untrusted automation are
typically implemented in the same programming language -- the ""meta-language""
-- usually some functional programming language in the ML family. This strategy
-- introduced by Milner in his LCF proof assistant -- is a reliability
mechanism, aiming to ensure that any purported theorem produced by the system
is indeed entailed by the theory within the logic.
  Changing tack, operating systems are also typically designed around a trusted
kernel, a privileged component responsible for -- amongst other things --
mediating interaction betwixt user-space software and hardware. Untrusted
processes interact with the system by issuing kernel system calls across a
hardware privilege boundary. In this way, the operating system kernel
supervises user-space processes.
  Though ostensibly very different, squinting, we see that the two kinds of
kernel are tasked with solving the same task: enforcing system invariants in
the face of unbounded interaction with untrusted code. Yet, the two solutions
to solving this problem, employed by the respective kinds of kernel, are very
different.
  In this abstract, we explore designing proof-checking kernels as supervisory
software, where separation between kernel and untrusted code is enforced by
privilege, not programming language module boundaries and type abstraction. We
describe work on the Supervisionary proof-checking kernel, and briefly sketch
its unique system interface. We then describe some potential uses of the
Supervisionary kernel.",2205.03332v1,cs.CR,2022-05-06 16:10:22+00:00,"[arxiv.Result.Author('Dominic P. Mulligan'), arxiv.Result.Author('Nick Spinale')]",
1432,OFDMA-based DF Secure Cooperative Communication with Untrusted Users,"In this letter we consider resource allocation for OFDMA-based secure
cooperative communication by employing a trusted Decode and Forward (DF) relay
among the untrusted users. We formulate two optimization problems, namely, (i)
sum rate maximization subject to individual power constraints on source and
relay, and (ii) sum power minimization subject to a fairness constraint in
terms of per-user minimum support secure rate requirement. The optimization
problems are solved utilizing the optimality of KKT conditions for pseudolinear
functions.",1901.03585v1,cs.IT,2019-01-11 14:15:30+00:00,"[arxiv.Result.Author('Ravikant Saini'), arxiv.Result.Author('Deepak Mishra'), arxiv.Result.Author('Swades De')]",
1433,Measurement-device-independent quantum key distribution for nonstandalone networks,"Untrusted node networks initially implemented by
measurement-device-independent quantum key distribution (MDI-QKD) protocol are
a crucial step on the roadmap of the quantum Internet. Considering extensive
QKD implementations of trusted node networks, a workable upgrading tactic of
existing networks toward MDI networks needs to be explicit. Here, referring to
the nonstandalone (NSA) network of 5G, we propose an NSA-MDI scheme as an
evolutionary selection for existing phase-encoding BB84 networks. Our solution
can upgrade the BB84 networks and terminals that employ various phase-encoding
schemes to immediately support MDI without hardware changes. This
cost-effective upgrade effectively promotes the deployment of MDI networks as a
step of untrusted node networks while taking full advantage of existing
networks. In addition, the diversified demands on security and bandwidth are
satisfied, and network survivability is improved.",2109.01294v2,quant-ph,2021-09-03 03:38:18+00:00,"[arxiv.Result.Author('Guan-Jie Fan-Yuan'), arxiv.Result.Author('Feng-Yu Lu'), arxiv.Result.Author('Shuang Wang'), arxiv.Result.Author('Zhen-Qiang Yin'), arxiv.Result.Author('De-Yong He'), arxiv.Result.Author('Zheng Zhou'), arxiv.Result.Author('Jun Teng'), arxiv.Result.Author('Wei Chen'), arxiv.Result.Author('Guang-Can Guo'), arxiv.Result.Author('Zheng-Fu Han')]","Photon. Res. 9, 1881-1891 (2021)"
1434,Passive-scheme analysis for solving untrusted source problem in quantum key distribution,"As a practical method, the passive scheme is useful to monitor the photon
statistics of an untrusted source in a ""Plug & Play"" quantum key distribution
(QKD) system. In a passive scheme, three kinds of monitor mode can be adopted:
average photon number (APN) monitor, photon number analyzer (PNA) and photon
number distribution (PND) monitor. In this paper, the security analysis is
rigorously given for APN monitor, while for PNA, the analysis including
statistical fluctuation and random noise, is addressed with a confidence level.
The results show that the PNA can achieve better performance than the APN
monitor and can asymptotically approach the theoretical limit of the PND
monitor. Also, the passive scheme with the PNA works efficiently when the
signal-to-noise ratio ($R^{SN}$) is not too low and so is highly applicable to
solve the untrusted source problem in the QKD system.",0908.1641v4,quant-ph,2009-08-12 08:41:49+00:00,"[arxiv.Result.Author('Xiang Peng'), arxiv.Result.Author('Bingjie Xu'), arxiv.Result.Author('Hong Guo')]","Phys. Rev. A, 81, 042320 (2010)"
1435,Multiterminal Secret Key Agreement with Nearly No Discussion,"We consider the secret key agreement problem under the multiterminal source
model proposed by Csisz\'ar and Narayan. A single-letter characterization of
the secrecy capacity is desired but remains unknown except in the extreme case
with unlimited public discussion and without wiretapper's side information.
Taking the problem to the opposite extreme by requiring the public discussion
rate to be zero asymptotically, we obtain the desired characterization under
surprisingly general setting with wiretapper's side information, silent users,
trusted and untrusted helpers. An immediate consequence of the result is that
the capacity with nearly no discussion is the same as the capacity with no
discussion, resolving a previous conjecture in the affirmative. The idea of the
proof is to characterize the capacity in the special case with neither
wiretapper's side information nor untrusted helpers using a multivariate
extension of G\'acs-K\""orner common information, and then extend the result to
the general setting by a change of scenario that turns untrusted helpers into
trusted helpers. We further show how to evaluate the capacity explicitly for
finite linear sources and discuss how the current result can be extended to
improve and unify existing bounds on the capacity for strictly positive
discussion rates.",1904.11383v1,cs.IT,2019-04-25 14:36:32+00:00,"[arxiv.Result.Author('Chung Chan'), arxiv.Result.Author('Manuj Mukherjee'), arxiv.Result.Author('Praneeth Kumar Vippathalla'), arxiv.Result.Author('Qiaoqiao Zhou')]",
1436,Secure Video Streaming in Heterogeneous Small Cell Networks with Untrusted Cache Helpers,"This paper studies secure video streaming in cache-enabled small cell
networks, where some of the cache-enabled small cell base stations (BSs)
helping in video delivery are untrusted. Unfavorably, caching improves the
eavesdropping capability of these untrusted helpers as they may intercept both
the cached and the delivered video files. To address this issue, we propose
joint caching and scalable video coding (SVC) of video files to enable secure
cooperative multiple-input multiple-output (MIMO) transmission and, at the same
time, exploit the cache memory of both the trusted and untrusted BSs for
improving the system performance. Considering imperfect channel state
information (CSI) at the transmitters, we formulate a two-timescale non-convex
mixed-integer robust optimization problem to minimize the total transmit power
required for guaranteeing the quality of service (QoS) and secrecy during video
streaming. We develop an iterative algorithm based on a modified generalized
Benders decomposition (GBD) to solve the problem optimally, where the caching
and the cooperative transmission policies are determined via offline
(long-timescale) and online (short-timescale) optimization, respectively.
Furthermore, inspired by the optimal algorithm, a low-complexity suboptimal
algorithm based on a greedy heuristic is proposed. Simulation results show that
the proposed schemes achieve significant gains in power efficiency and secrecy
performance compared to several baseline schemes.",1707.08050v3,cs.IT,2017-07-25 15:36:37+00:00,"[arxiv.Result.Author('Lin Xiang'), arxiv.Result.Author('Derrick Wing Kwan Ng'), arxiv.Result.Author('Robert Schober'), arxiv.Result.Author('Vincent W. S. Wong')]",
1437,Computation Offloading in the Untrusted MEC-aided Mobile Blockchain IoT System,"Deploying mobile edge computing (MEC) server in the mobile blockchain-enabled
Internet of things (IoT) system is a promising approach to improve the system
performance, however, it imposes a significant challenge on the trust of MEC
server. To address this problem, we first propose an untrusted MEC proof of
work scheme in mobile blockchain network where plenty of nonce hash computing
demands can be offloaded to MEC server. Then, we design a nonce ordering
algorithm for this scheme to provide fairer computing resource allocation for
all mobile IoT devices/users. Specifically, we formulate the user's nonce
selection strategy as a non-cooperative game, where the utilities of individual
user are maximized in the untrusted MEC-aided mobile blockchain network. We
also prove the existence of Nash equilibrium and analyze that the cooperation
behavior is unsuitable for the blockchain-enabled IoT devices by using the
repeated game. Finally, we design the blockchain's difficulty adjustment
mechanism to ensure stable block times during a long period of time.",1911.08255v1,cs.IT,2019-11-19 13:32:52+00:00,"[arxiv.Result.Author('Yiping Zuo'), arxiv.Result.Author('Shi Jin'), arxiv.Result.Author('Shengli Zhang')]",
1438,On the Security of Offloading Post-Processing for Quantum Key Distribution,"Quantum key distribution (QKD) has been researched for almost four decades
and is currently making its way to commercial applications. However, deployment
of the technology at scale is challenging, because of the very particular
nature of QKD and its physical limitations. Among others, QKD is
computationally intensive in the post-processing phase and devices are
therefore complex and power hungry, which leads to problems in certain
application scenarios. In this work we study the possibility to offload
computationally intensive parts in the QKD post-processing stack in a secure
way to untrusted hardware. We show how error correction can be securely
offloaded for discrete-variable QKD to a single untrusted server and that the
same method cannot be used for long distance continuous-variable QKD.
Furthermore, we analyze possibilities for multi-server protocols to be used for
error correction and privacy amplification. Even in cases where it is not
possible to offload to an external server, being able to delegate computation
to untrusted hardware components on the device could improve the cost and
certification effort for device manufacturers.",2210.08977v1,quant-ph,2022-10-17 12:08:10+00:00,"[arxiv.Result.Author('Thomas Loruenser'), arxiv.Result.Author('Stephan Krenn'), arxiv.Result.Author('Christoph Pacher'), arxiv.Result.Author('Bernhard Schrenk')]",
1439,Termination Analysis Without the Tears,"Determining whether a given program terminates is the quintessential
undecidable problem. Algorithms for termination analysis are divided into two
groups: (1) algorithms with strong behavioral guarantees that work in limited
circumstances (e.g., complete synthesis of linear ranking functions for
polyhedral loops [Podelski and Rybalchenko, 2004]), and (2) algorithms that are
widely applicable, but have weak behavioral guarantees (e.g., Terminator [Cook
et al., 2006]). This paper investigates the space in between: how can we design
practical termination analyzers with useful behavioral guarantees?
  This paper presents a termination analysis that is both compositional (the
result of analyzing a composite program is a function of the analysis results
of its components) and monotone (""more information into the analysis yields
more information out""). The paper has two key contributions. The first is an
extension of Tarjan's method for solving path problems in graphs to solve
infinite path problems. This provides a foundation upon which to build
compositional termination analyses. The second is a collection of monotone
conditional termination analyses based on this framework. We demonstrate that
our tool ComPACT (Compositional and Predictable Analysis for Conditional
Termination) is competitive with state-of-the-art termination tools while
providing stronger behavioral guarantees.",2101.09783v2,cs.PL,2021-01-24 19:53:16+00:00,"[arxiv.Result.Author('Shaowei Zhu'), arxiv.Result.Author('Zachary Kincaid')]",
1440,On Chase Termination Beyond Stratification,"We study the termination problem of the chase algorithm, a central tool in
various database problems such as the constraint implication problem,
Conjunctive Query optimization, rewriting queries using views, data exchange,
and data integration. The basic idea of the chase is, given a database instance
and a set of constraints as input, to fix constraint violations in the database
instance. It is well-known that, for an arbitrary set of constraints, the chase
does not necessarily terminate (in general, it is even undecidable if it does
or not). Addressing this issue, we review the limitations of existing
sufficient termination conditions for the chase and develop new techniques that
allow us to establish weaker sufficient conditions. In particular, we introduce
two novel termination conditions called safety and inductive restriction, and
use them to define the so-called T-hierarchy of termination conditions. We then
study the interrelations of our termination conditions with previous conditions
and the complexity of checking our conditions. This analysis leads to an
algorithm that checks membership in a level of the T-hierarchy and accounts for
the complexity of termination conditions. As another contribution, we study the
problem of data-dependent chase termination and present sufficient termination
conditions w.r.t. fixed instances. They might guarantee termination although
the chase does not terminate in the general case. As an application of our
techniques beyond those already mentioned, we transfer our results into the
field of query answering over knowledge bases where the chase on the underlying
database may not terminate, making existing algorithms applicable to broader
classes of constraints.",0906.4228v2,cs.DB,2009-06-23 11:46:43+00:00,"[arxiv.Result.Author('Michael Meier'), arxiv.Result.Author('Michael Schmidt'), arxiv.Result.Author('Georg Lausen')]",
1441,Termination Prediction for General Logic Programs,"We present a heuristic framework for attacking the undecidable termination
problem of logic programs, as an alternative to current
termination/non-termination proof approaches. We introduce an idea of
termination prediction, which predicts termination of a logic program in case
that neither a termination nor a non-termination proof is applicable. We
establish a necessary and sufficient characterization of infinite (generalized)
SLDNF-derivations with arbitrary (concrete or moded) queries, and develop an
algorithm that predicts termination of general logic programs with arbitrary
non-floundering queries. We have implemented a termination prediction tool and
obtained quite satisfactory experimental results. Except for five programs
which break the experiment time limit, our prediction is 100% correct for all
296 benchmark programs of the Termination Competition 2007, of which eighteen
programs cannot be proved by any of the existing state-of-the-art analyzers
like AProVE07, NTI, Polytool and TALP.",0905.2004v1,cs.PL,2009-05-13 02:47:06+00:00,"[arxiv.Result.Author('Yi-Dong Shen'), arxiv.Result.Author('Danny De Schreye'), arxiv.Result.Author('Dean Voets')]",
1442,Usability Inspection: Novice Crowd Inspectors versus Expert,"Objective: This research study aims to investigate the use of novice crowd
inspectors for usability inspection with respect to time spent and the cost
incurred. This study compares the results of the novice crowd usability
inspection guided by a single expert's heuristic usability inspection (novice
crowd usability inspection henceforth) with the expert heuristic usability
inspection. Background: Traditional usability evaluation methods are time
consuming and expensive. Crowdsourcing has emerged as a cost effective and
quick means of software usability evaluation. Method: In this regard, we
designed an experiment to evaluate the usability of two websites and a web
dashboard. Results: The results of the experiment show that novice crowd
usability inspection guided by a single expert's heuristic usability
inspection: a). Finds the same usability issues (w.r.t. content & quantity) as
expert heuristic usability inspection. b). Is cost effective than expert
heuristic usability inspection employing less time duration. Conclusion: Based
on the findings of this research study, we can conclude that the novice crowd
usability inspection guided by a single expert's heuristic usability inspection
and expert heuristic usability inspection, on average, gives the same results
in terms of issues identified.",2110.14228v1,cs.SE,2021-10-27 07:24:50+00:00,"[arxiv.Result.Author('Muhammad Nasir'), arxiv.Result.Author('Naveed Ikram'), arxiv.Result.Author('Zakia Jalil')]",
1443,From Playability to a Hierarchical Game Usability Model,"This paper presents a brief review of current game usability models. This
leads to the conception of a high-level game development-centered usability
model that integrates current usability approaches in game industry and game
research.",1004.0256v1,cs.HC,2010-04-01 23:42:11+00:00,[arxiv.Result.Author('Lennart E. Nacke')],
1444,Crowdsourcing for Usability Testing,"While usability evaluation is critical to designing usable websites,
traditional usability testing can be both expensive and time consuming. The
advent of crowdsourcing platforms such as Amazon Mechanical Turk and
CrowdFlower offer an intriguing new avenue for performing remote usability
testing with potentially many users, quick turn-around, and significant cost
savings. To investigate the potential of such crowdsourced usability testing,
we conducted two similar (though not completely parallel) usability studies
which evaluated a graduate school's website: one via a traditional usability
lab setting, and the other using crowdsourcing. While we find crowdsourcing
exhibits some notable limitations in comparison to the traditional lab
environment, its applicability and value for usability testing is clearly
evidenced. We discuss both methodological differences for crowdsourced
usability testing, as well as empirical contrasts to results from more
traditional, face-to-face usability testing.",1203.1468v2,cs.HC,2012-03-07 13:46:32+00:00,"[arxiv.Result.Author('Di Liu'), arxiv.Result.Author('Matthew Lease'), arxiv.Result.Author('Rebecca Kuipers'), arxiv.Result.Author('Randolph Bias')]",
1445,Automated Usability Testing: Analysing Asia Web Sites,"Web usability is continuing to be a pressing problem. For number of years
researchers have been developed tools for doing automatic web usability
testing. This study uses our own PHP, and MySQL based tool AWebHUT: Automated
Web Homepage Usability Tester to evaluate web usability of full Dmoz
(www.dmoz.org) Asia web sites (45126 on time stamp 2011-12-03 04:12:46 GMT).
The tool uses an extensive automated quantitative analysis of XHTML source code
of homepages against seventeen organised web usability guidelines. The
automated quantitative approach is effective on large scale to achieve better
usability. The AWebHUT uses four web usability levels such as N: Neutral, V:
Violate, R: Respect, and E: Error to evaluate web usability. The main objective
of the study is to produce data which is used to answer research questions, (1)
Are there any categories of web sites which have usability problems? Which
ones? and (2) Are there any categories in which the usability is typically
higher? Why? The findings were indicated that all Asia categories have
usability problems. Furthermore, there are four web sites which have highest
web usability problem with violation percentage 71. One step further, the Asia
category: Weather has highest usability problems with 42.2819 as the average of
the violation percentage. The category Weather uses tables and images,
considerable amount of those were not satisfying web usability guidelines which
relates to tables and images. One step further, the Asia wants to get the same
level of usability as North America, Europe, and Australia therefore it is
essential to have an automated web usability evaluation in Asia web sites to
identify web usability problems which are important for improving Asia web
sites.",1212.1849v1,cs.HC,2012-12-09 02:20:00+00:00,"[arxiv.Result.Author('A. Rukshan'), arxiv.Result.Author('A. Baravalle')]","International Conference on Business and Information 2012 (ICBI
  2012), Faculty of Commerce and Management Studies of University of Kelaniya,
  Sri Lanka"
1446,What is Usability? A Characterization based on ISO 9241-11 and ISO/IEC 25010,"According to Brooke [1] ""Usability does not exist in any absolute sense; it
can only be defined with reference to particular contexts."" That is, one cannot
speak of usability without specifying what that particular usability is
characterized by. Driven by the feedback of a reviewer at an international
conference, I explore in which way one can precisely specify the kind of
usability they are investigating in a given setting. Finally, I come up with a
formalism that defines usability as a quintuple comprising the elements level
of usability metrics, product, users, goals and context of use. Providing
concrete values for these elements then constitutes the investigated type of
usability. The use of this formalism is demonstrated in two case studies.
  [1] J. Brooke. SUS: A ""quick and dirty"" usability scale. In P. W. Jordan, B.
Thomas, B. A. Weerdmeester, and A. L. McClelland, editors, Usability Evaluation
in Industry. Taylor and Francis, 1996.",1502.06792v2,cs.HC,2015-02-24 13:06:28+00:00,[arxiv.Result.Author('Maximilian Speicher')],
1447,A Generic Cognitive Dimensions Questionnaire to Evaluate the Usability of Security APIs,"Programmers use security APIs to embed security into the applications they
develop. Security vulnerabilities get introduced into those applications, due
to the usability issues that exist in the security APIs. Improving usability of
security APIs would contribute to improve the security of applications that
programmers develop. However, currently there is no methodology to evaluate the
usability of security APIs. In this study, we attempt to improve the Cognitive
Dimensions framework based API usability evaluation methodology, to evaluate
the usability of security APIs.",1703.09846v1,cs.CR,2017-03-29 00:25:44+00:00,"[arxiv.Result.Author('Chamila Wijayarathna'), arxiv.Result.Author('Nalin A. G. Arachchilage'), arxiv.Result.Author('Jill Slay')]",
1448,Towards Enhanced Usability of IT Security Mechanisms - How to Design Usable IT Security Mechanisms Using the Example of Email Encryption,"Nowadays, advanced security mechanisms exist to protect data, systems, and
networks. Most of these mechanisms are effective, and security experts can
handle them to achieve a sufficient level of security for any given system.
However, most of these systems have not been designed with focus on good
usability for the average end user. Today, the average end user often struggles
with understanding and using security mecha-nisms. Other security mechanisms
are simply annoying for end users. As the overall security of any system is
only as strong as the weakest link in this system, bad usability of IT security
mechanisms may result in operating errors, resulting in inse-cure systems.
Buying decisions of end users may be affected by the usability of security
mechanisms. Hence, software provid-ers may decide to better have no security
mechanism then one with a bad usability. Usability of IT security mechanisms is
one of the most underestimated properties of applications and sys-tems. Even IT
security itself is often only an afterthought. Hence, usability of security
mechanisms is often the after-thought of an afterthought. This paper presents
some guide-lines that should help software developers to improve end user
usability of security-related mechanisms, and analyzes com-mon applications
based on these guidelines. Based on these guidelines, the usability of email
encryption is analyzed and an email encryption solution with increased
usability is presented. The approach is based on an automated key and trust
man-agement. The compliance of the proposed email encryption solution with the
presented guidelines for usable security mechanisms is evaluated.",1506.06987v1,cs.CR,2015-06-23 13:34:36+00:00,[arxiv.Result.Author('Hans-Joachim Hof')],"International Journal On Advances in Security, volume 6, number
  1&2, pp. 78-87 ISSN 1942-2636, 2013"
1449,Role of context in usability evaluations: A review,"Usability is often defined as the ability of a system to carry out specific
tasks by specific users in a specific context. Usability evaluation involves
testing the system for its expected usability. Usability testing is performed
in natural environment (field) or artificial environment (laboratory). The
result of usability evaluation is affected by the environment in which it is
carried out. Previous studies have focused only on the physical environment
(lab and field) effect on the results but rarely focused on the effect of
social environment (people present during testing). Therefore, this study aims
to review how important it is to take context into account during usability
evaluation. Context is explored through the theory of behaviour settings,
according to which behaviour of individuals is strongly influenced by the
physical as well as the social environment in which they function. The result
of this review indicates that the physical and social context plays a
substantial role in usability evaluations. Further, it also suggests that the
usability evaluation model should encompass context as an important component
in the framework.",1204.2138v1,cs.HC,2012-04-10 13:18:51+00:00,"[arxiv.Result.Author('Munesh Chandra Trivedi'), arxiv.Result.Author('Mohammadi Akheela Khanum')]",
1450,Usability Investigation on the Localization of Text CAPTCHAs: Take Chinese Characters as a Case Study,"Text CAPTCHA has been an effective means to protect online systems from spams
and abuses caused by automatic scripts which pretend to be human beings.
However, nearly all the Text CAPTCHA designs in nowadays are based on English
characters, which may not be the most user-friendly option for non-English
speakers. Therefore, under the background of globalization, there is an
increasing interest in designing local-language CAPTCHA, which is expected to
be more usable for native speakers. However, systematic studies on the
usability of localized CAPTCHAs are rare, and a general procedure for the
design of usable localized CAPTCHA is still unavailable. Here, we
comprehensively explored the design of CAPTCHAs based on Chinese characters
from a usability perspective: cognitive processes of solving alphanumeric and
Chinese CAPTCHAs are analyzed, followed by a usability comparison of those two
types of CAPTCHAs and the evaluation of intrinsic design factors of Chinese
CAPTCHAs. It was found that Chinese CAPTCHAs could be equally usable comparing
with alphanumeric ones. Meanwhile, guidelines for the design of usable Chinese
CAPTCHAs were also presented. Moreover, those design practices were also
summarized as a general procedure which is expected to be applicable for the
design of CAPTCHAs based on other languages.",1612.01070v1,cs.HC,2016-12-04 05:34:58+00:00,"[arxiv.Result.Author('Junnan Yu'), arxiv.Result.Author('Xuna Ma'), arxiv.Result.Author('Ting Han')]",
1451,Using Cognitive Dimensions Questionnaire to Evaluate the Usability of Security APIs,"Usability issues that exist in security APIs cause programmers to embed those
security APIs incorrectly to the applications they develop. This results in
introduction of security vulnerabilities to those applications. One of the main
reasons for security APIs to be not usable is currently there is no proper
method by which the usability issues of security APIs can be identified. We
conducted a study to assess the effectiveness of the cognitive dimensions
questionnaire based usability evaluation methodology in evaluating the
usability of security APIs. We used a cognitive dimensions based generic
questionnaire to collect feedback from programmers who participated in the
study. Results revealed interesting facts about the prevailing usability issues
in four commonly used security APIs and the capability of the methodology to
identify those issues.",1706.00138v2,cs.CR,2017-06-01 00:56:52+00:00,"[arxiv.Result.Author('Chamila Wijayarathna'), arxiv.Result.Author('Nalin Asanka Gamagedara Arachchilage'), arxiv.Result.Author('Jill Slay')]",
1452,The AutoProof Verifier: Usability by Non-Experts and on Standard Code,"Formal verification tools are often developed by experts for experts; as a
result, their usability by programmers with little formal methods experience
may be severely limited. In this paper, we discuss this general phenomenon with
reference to AutoProof: a tool that can verify the full functional correctness
of object-oriented software. In particular, we present our experiences of using
AutoProof in two contrasting contexts representative of non-expert usage.
First, we discuss its usability by students in a graduate course on software
verification, who were tasked with verifying implementations of various sorting
algorithms. Second, we evaluate its usability in verifying code developed for
programming assignments of an undergraduate course. The first scenario
represents usability by serious non-experts; the second represents usability on
""standard code"", developed without full functional verification in mind. We
report our experiences and lessons learnt, from which we derive some general
suggestions for furthering the development of verification tools with respect
to improving their usability.",1508.03895v1,cs.SE,2015-08-17 01:36:56+00:00,"[arxiv.Result.Author('Carlo A. Furia'), arxiv.Result.Author('Christopher M. Poskitt'), arxiv.Result.Author('Julian Tschannen')]","EPTCS 187, 2015, pp. 42-55"
1453,A Novel Multifactor Authentication System Ensuring Usability and Security,"User authentication is one of the most important part of information
security. Computer security most commonly depends on passwords to authenticate
human users. Password authentication systems will be either been usable but not
secure, or secure but not usable. While there are different types of
authentication systems available alphanumeric password is the most commonly
used authentication mechanism. But this method has significant drawbacks. An
alternative solution to the text based authentication is Graphical User
Authentication based on the fact that humans tends to remember images better
than text. Graphical password authentication systems provide passwords which
are easy to be created and remembered by the user. However, the main issues of
simple graphical password techniques are shoulder surfing attack and image
gallery attack. Studies reveals that most of the graphical passwords are either
secure but not usable or usable but not secure. In this paper, a new technique
that uses cued click point graphical password method along with the one-time
session key is proposed. The goal is to propose a new authentication mechanism
using graphical password to achieve higher security and better usability
levels. The result of the system testing is evaluated and it reveals that the
proposed system ensures security and usability to a great extent.",1311.4037v1,cs.CR,2013-11-16 09:26:00+00:00,"[arxiv.Result.Author('Gloriya Mathew'), arxiv.Result.Author('Shiney Thomas')]",
1454,An Empirical Study of Open Source Software Usability: The Industrial Perspective,"Recent years have seen a sharp increase in the use of open source projects by
common novice users; Open Source Software (OSS) is thus no longer a reserved
arena for software developers and computer gurus. Although user-centered
designs are gaining popularity in OSS, usability is still not considered as one
of the prime objectives in many design scenarios. In this paper, we analyze
industry users perception of usability factors, including understandability,
learnability, operability and attractiveness, on OSS usability. The research
model of this empirical study establishes the relationship between the key
usability factors and OSS usability from industrial perspective. In order to
conduct the study, a data set of 105 industry users is included. The results of
the empirical investigation indicate the significance of the key factors for
OSS usability.",1511.08844v1,cs.HC,2015-11-27 22:35:53+00:00,"[arxiv.Result.Author('Arif Raza'), arxiv.Result.Author('Luiz Fernando Capretz'), arxiv.Result.Author('Faheem Ahmed')]","International Journal of Open Source Software and Processes,
  3(1):1-16, 2011"
1455,A methodology to Evaluate the Usability of Security APIs,"Increasing number of cyber-attacks demotivate people to use Information and
Communication Technology (ICT) for industrial as well as day to day work. A
main reason for the increasing number of cyber-attacks is mistakes that
programmers make while developing software applications that are caused by
usability issues exist in security Application Programming Interfaces (APIs).
These mistakes make software vulnerable to cyber-attacks. In this paper, we
attempt to take a step closer to solve this problem by proposing a methodology
to evaluate the usability and identify usability issues exist in security APIs.
By conducting a review of previous research, we identified 5 usability
evaluation methodologies that have been proposed to evaluate the usability of
general APIs and characteristics of those methodologies that would affect when
using these methodologies to evaluate security APIs. Based on the findings, we
propose a methodology to evaluate the usability of security APIs.",1810.05100v1,cs.CR,2018-10-11 16:04:51+00:00,"[arxiv.Result.Author('Chamila Wijayarathna'), arxiv.Result.Author('Nalin Asanka Gamagedara Arachchilage')]","IEEE International Conference on Information and Automation for
  Sustainability (ICIAfS), 2019"
1456,Testing the Usability and Accessibility of Smart TV Applications Using an Automated Model-based Approach,"As the popularity of Smart Televisions (TVs) and interactive Smart TV
applications (apps) has recently grown, the usability of these apps has become
an important quality characteristic. Previous studies examined Smart TV apps
from a usability perspective. However, these methods are mainly manual, and the
potential of automated model-based testing methods for usability testing
purposes has not yet been fully explored. In this paper, we propose an approach
to test the usability of Smart TV apps based on the automated generation of a
Smart TV user interaction model from an existing app by a specialized automated
crawler. By means of this model, defined user tasks in the Smart TV app can be
evaluated automatically in terms of their feasibility and estimated user
effort, which reflects the usability of the analyzed app. This analysis can be
applied in the context of regular users and users with various specific needs.
The findings from this model-based automated analysis approach can be used to
optimize the user interface of a Smart TV app to increase its usability,
accessibility, and quality.",2004.01478v1,cs.SE,2020-04-03 11:36:36+00:00,"[arxiv.Result.Author('Miroslav Bures'), arxiv.Result.Author('Miroslav Macik'), arxiv.Result.Author('Bestoun S. Ahmed'), arxiv.Result.Author('Vaclav Rechtberger'), arxiv.Result.Author('Pavel Slavik')]",
1457,Don't forget your classics: Systematizing 45 years of Ancestry for Security API Usability Recommendations,"Producing secure software is challenging. The poor usability of security APIs
makes this even harder. Many recommendations have been proposed to support
developers by improving the usability of cryptography libraries and APIs;
rooted in wider best practice guidance in software engineering and API design.
In this SLR, we systematize knowledge regarding these recommendations.
  We identify and analyze 65 papers spanning 45 years, offering a total of 883
recommendations.We undertake a thematic analysis to identify 7 core ways to
improve usability of APIs. We find that most of the recommendations focus on
helping API developers to construct and structure their code and make it more
usable and easier for programmers to understand. There is less focus, however,
on documentation, writing requirements, code quality assessment and the impact
of organizational software development practices. By tracing and analyzing
paper ancestry, we map how this knowledge becomes validated and translated over
time.We find evidence that less than a quarter of all API usability
recommendations are empirically validated, and that recommendations specific to
usable security APIs lag even further behind in this regard.",2105.02031v1,cs.CR,2021-05-05 13:00:32+00:00,"[arxiv.Result.Author('Nikhil Patnaik'), arxiv.Result.Author('Andrew C. Dwyer'), arxiv.Result.Author('Joseph Hallett'), arxiv.Result.Author('Awais Rashid')]",
1458,User-Centric IT Security - How to Design Usable Security Mechanisms,"Nowadays, advanced security mechanisms exist to protect data, systems, and
networks. Most of these mechanisms are effective, and security experts can
handle them to achieve a sufficient level of security for any given system.
However, most of these systems have not been designed with focus on good
usability for the average end user. Today, the average end user often struggles
with understanding and using security mechanisms. Other security mechanisms are
simply annoying for end users. As the overall security of any system is only as
strong as the weakest link in this system, bad usability of IT security
mechanisms may result in operating errors, resulting in insecure systems.
Buying decisions of end users may be affected by the usability of security
mechanisms. Hence software providers may decide to better have no security
mechanism then one with a bad usability. Usability of IT security mechanisms is
one of the most underestimated properties of applications and systems. Even IT
security itself is often only an afterthought. Hence, usability of security
mechanisms is often the afterthought of an afterthought. Software developers
are missing guidelines on how to build security mechanisms with good usability
for end users. This paper presents some guidelines that should help software
developers to improve end user usability of security-related mechanisms, and
analyzes common applications based on these guidelines.",1506.07167v1,cs.CR,2015-06-23 13:43:23+00:00,[arxiv.Result.Author('Hans-Joachim Hof')],"The Fifth International Conference on Advances in Human-oriented
  and Personalized Mechanisms, Technologies, and Services (CENTRIC 2012), pp.
  7-12, November 2012"
1459,GENIUS: Generating Usable User Interfaces,"In this report we describe the implementation and approach developed during
the GENIUS Project. The GENIUS project is about the generation of usable user
interfaces. It tries to cope with issues related to automatic generation where,
usually end-user complain about the poor quality (in term of usability) of
generated UI. To solve this issue GENIUS relies on Model-Driven Engineering
principles and several MDE tools. Notably, it consists in a set of metamodels
specific to the interaction, a set of model transformation embedding usability
criteria and an environment for model execution/ interpretation.",1310.1758v1,cs.HC,2013-10-07 12:45:48+00:00,"[arxiv.Result.Author('Jean-Sebastien Sottet'), arxiv.Result.Author('Alain Vagner')]",
1460,"MessageGuard: A Browser-based Platform for Usable, Content-Based Encryption Research","This paper describes MessageGuard, a browser-based platform for research into
usable content-based encryption. MessageGuard is designed to enable
collaboration between security and usability researchers on long-standing
research questions in this area. It significantly simplifies the effort
required to work in this space and provides a place for research results to be
shared, replicated, and compared with minimal confounding factors. MessageGuard
provides ubiquitous encryption and secure cryptographic operations, enabling
research on any existing web application, with realistic usability studies on a
secure platform. We validate MessageGuard's compatibility and performance, and
we illustrate its utility with case studies for Gmail and Facebook Chat.",1510.08943v2,cs.CR,2015-10-30 00:33:52+00:00,"[arxiv.Result.Author('Scott Ruoti'), arxiv.Result.Author('Jeff Andersen'), arxiv.Result.Author('Tyler Monson'), arxiv.Result.Author('Daniel Zappala'), arxiv.Result.Author('Kent Seamons')]",
1461,Usability of AutoProof: a case study of software verification,"Many verification tools come out of academic projects, whose natural
constraints do not typically lead to a strong focus on usability. For
widespread use, however, usability is essential. Using a well-known benchmark,
the Tokeneer problem, we evaluate the usability of a recent and promising
verification tool: AutoProof. The results show the efficacy of the tool in
verifying a real piece of software and automatically discharging nearly two
thirds of verification conditions. At the same time, the case study shows the
demand for improved documentation and emphasizes the need for improvement in
the tool itself and in the Eiffel IDE.",1605.01663v1,cs.SE,2016-05-05 17:43:29+00:00,"[arxiv.Result.Author('Mansur Khazeev'), arxiv.Result.Author('Victor Rivera'), arxiv.Result.Author('Manuel Mazzara'), arxiv.Result.Author('Alexander Tchitchigin')]",
1462,Vote Delegation and Misbehavior,"We study vote delegation with ""well-behaving"" and ""misbehaving"" agents and
compare it with conventional voting. Typical examples for vote delegation are
validation or governance tasks on blockchains. There is a majority of
well-behaving agents, but they may abstain or delegate their vote to other
agents since voting is costly. Misbehaving agents always vote. We compare
conventional voting allowing for abstention with vote delegation. Preferences
of voters are private information and a positive outcome is achieved if
well-behaving agents win. We illustrate that vote delegation leads to quite
different outcomes than conventional voting with abstention. In particular, we
obtain three insights: First, if the number of misbehaving voters, denoted by f
, is high, both voting methods fail to deliver a positive outcome. Second, if f
takes an intermediate value, conventional voting delivers a positive outcome,
while vote delegation fails with probability one. Third, if f is low,
delegation delivers a positive outcome with higher probability than
conventional voting. Finally, our results characterize worst-case outcomes that
can happen in a liquid democracy.",2102.08823v2,cs.GT,2021-02-17 15:32:32+00:00,"[arxiv.Result.Author('Hans Gersbach'), arxiv.Result.Author('Akaki Mamageishvili'), arxiv.Result.Author('Manvir Schneider')]",
1463,Weighted Voting on the Blockchain: Improving Consensus in Proof of Stake Protocols,"Proof of Stake (PoS) protocols rely on voting mechanisms to reach consensus
on the current state. If an enhanced majority of staking nodes, also called
validators, agree on a proposed block, then this block is appended to the
blockchain. Yet, these protocols remain vulnerable to faults caused by
validators who abstain either accidentally or maliciously. To protect against
such faults while retaining the PoS selection and reward allocation schemes, we
study weighted voting in validator committees. We formalize the block creation
process and introduce validators' voting profiles which we update by a
multiplicative weights algorithm relative to validators' voting behavior and
aggregate blockchain rewards. Using this framework, we leverage weighted
majority voting rules that optimize collective decision making to show, both
numerically and analytically, that the consensus mechanism is more robust if
validators' votes are appropriately scaled. We raise potential issues and
limitations of weighted voting in trustless, decentralized networks and relate
our results to the design of current PoS protocols.",1903.04213v4,cs.GT,2019-03-11 10:59:43+00:00,"[arxiv.Result.Author('Stefanos Leonardos'), arxiv.Result.Author('Daniel Reijsbergen'), arxiv.Result.Author('Georgios Piliouras')]","International Journal of Network Management, Vol. 30(5), pp:
  e2093, (2020)"
1464,Power-Efficient Direct-Voting Assurance for Data Fusion in Wireless Sensor Networks,"Wireless sensor networks place sensors into an area to collect data and send
them back to a base station. Data fusion, which fuses the collected data before
they are sent to the base station, is usually implemented over the network.
Since the sensor is typically placed in locations accessible to malicious
attackers, information assurance of the data fusion process is very important.
A witness-based approach has been proposed to validate the fusion data. In this
approach, the base station receives the fusion data and ""votes"" on the data
from a randomly chosen sensor node. The vote comes from other sensor nodes,
called ""witnesses,"" to verify the correctness of the fusion data. Because the
base station obtains the vote through the chosen node, the chosen node could
forge the vote if it is compromised. Thus, the witness node must encrypt the
vote to prevent this forgery. Compared with the vote, the encryption requires
more bits, increasing transmission burden from the chosen node to the base
station. The chosen node consumes more power. This work improves the
witness-based approach using direct voting mechanism such that the proposed
scheme has better performance in terms of assurance, overhead, and delay. The
witness node transmits the vote directly to the base station. Forgery is not a
problem in this scheme. Moreover, fewer bits are necessary to represent the
vote, significantly reducing the power consumption. Performance analysis and
simulation results indicate that the proposed approach can achieve a 40 times
better overhead than the witness-based approach.",0705.3683v1,cs.CR,2007-05-25 02:56:47+00:00,"[arxiv.Result.Author('H. -T. Pai'), arxiv.Result.Author('Y. S. Han')]",
1465,Making Code Voting Secure against Insider Threats using Unconditionally Secure MIX Schemes and Human PSMT Protocols,"Code voting was introduced by Chaum as a solution for using a possibly
infected-by-malware device to cast a vote in an electronic voting application.
Chaum's work on code voting assumed voting codes are physically delivered to
voters using the mail system, implicitly requiring to trust the mail system.
This is not necessarily a valid assumption to make - especially if the mail
system cannot be trusted. When conspiring with the recipient of the cast
ballots, privacy is broken.
  It is clear to the public that when it comes to privacy, computers and
""secure"" communication over the Internet cannot fully be trusted. This
emphasizes the importance of using: (1) Unconditional security for secure
network communication. (2) Reduce reliance on untrusted computers.
  In this paper we explore how to remove the mail system trust assumption in
code voting. We use PSMT protocols (SCN 2012) where with the help of visual
aids, humans can carry out $\mod 10$ addition correctly with a 99\% degree of
accuracy. We introduce an unconditionally secure MIX based on the combinatorics
of set systems.
  Given that end users of our proposed voting scheme construction are humans we
\emph{cannot use} classical Secure Multi Party Computation protocols.
  Our solutions are for both single and multi-seat elections achieving:
\begin{enumerate}[i)]
  \item An anonymous and perfectly secure communication network secure against
a $t$-bounded passive adversary used to deliver voting,
  \item The end step of the protocol can be handled by a human to evade the
threat of malware. \end{enumerate} We do not focus on active adversaries.",1506.04429v1,cs.CR,2015-06-14 19:07:51+00:00,"[arxiv.Result.Author('Yvo Desmedt'), arxiv.Result.Author('Stelios Erotokritou')]",
1466,On Penrose's square-root law and beyond,"In certain bodies, like the Council of the EU, the member states have a
voting weight which depends on the population of the re- spective state. In
this article we ask the question which voting weight guarantees a `fair'
representation of the citizens in the union. The tra- ditional answer, the
square-root law by Penrose, is that the weight of a state (more precisely: the
voting power) should be proportional to the square-root of the population of
this state. The square root law is based on the assumption that the voters in
every state cast their vote inde- pendently of each other. In this paper we
concentrate on cases where the independence assumption is not valid.",math/0611418v1,math.PR,2006-11-14 10:53:27+00:00,[arxiv.Result.Author('Werner Kirsch')],
1467,Dancing with Donald: Polarity in the 2016 Presidential Election,"In almost every election cycle, the validity of the United States Electoral
College is brought into question. The 2016 Presidential Election again brought
up the issue of a candidate winning the popular vote but not winning the
Electoral College, with Hillary Clinton receiving close to three million more
votes than Donald Trump. However, did the popular vote actually determine the
most liked candidate in the election? In this paper, we demonstrate that
different voting policies can alter which candidate is elected. Additionally,
we explore the trade-offs between each of these mechanisms. Finally, we
introduce two novel mechanisms with the intent of electing the least polarizing
candidate.",1901.07542v1,econ.GN,2019-01-22 02:43:28+00:00,"[arxiv.Result.Author('Robert Chuchro'), arxiv.Result.Author(""Kyle D'Souza""), arxiv.Result.Author('Darren Mei')]",
1468,Theoretical Analyses of Cross-Validation Error and Voting in Instance-Based Learning,"This paper begins with a general theory of error in cross-validation testing
of algorithms for supervised learning from examples. It is assumed that the
examples are described by attribute-value pairs, where the values are symbolic.
Cross-validation requires a set of training examples and a set of testing
examples. The value of the attribute that is to be predicted is known to the
learner in the training set, but unknown in the testing set. The theory
demonstrates that cross-validation error has two components: error on the
training set (inaccuracy) and sensitivity to noise (instability). This general
theory is then applied to voting in instance-based learning. Given an example
in the testing set, a typical instance-based learning algorithm predicts the
designated attribute by voting among the k nearest neighbors (the k most
similar examples) to the testing example in the training set. Voting is
intended to increase the stability (resistance to noise) of instance-based
learning, but a theoretical analysis shows that there are circumstances in
which voting can be destabilizing. The theory suggests ways to minimize
cross-validation error, by insuring that voting is stable and does not
adversely affect accuracy.",cs/0212030v1,cs.LG,2002-12-11 17:36:00+00:00,[arxiv.Result.Author('Peter D. Turney')],"Journal of Experimental and Theoretical Artificial Intelligence,
  (1994), 6, 331-360"
1469,Random errors are not necessarily politically neutral,"Errors are inevitable in the implementation of any complex process. Here we
examine the effect of random errors on Single Transferable Vote (STV)
elections, a common approach to deciding multi-seat elections. It is usually
expected that random errors should have nearly equal effects on all candidates,
and thus be fair. We find to the contrary that random errors can introduce
systematic bias into election results. This is because, even if the errors are
random, votes for different candidates occur in different patterns that are
affected differently by random errors. In the STV context, the most important
effect of random errors is to invalidate the ballot. This removes far more
votes for those candidates whose supporters tend to list a lot of preferences,
because their ballots are much more likely to be invalidated by random error.
Different validity rules for different voting styles mean that errors are much
more likely to penalise some types of votes than others. For close elections
this systematic bias can change the result of the election.",2007.00854v3,cs.CY,2020-07-02 03:37:48+00:00,"[arxiv.Result.Author('Michelle Blom'), arxiv.Result.Author('Andrew Conway'), arxiv.Result.Author('Peter J. Stuckey'), arxiv.Result.Author('Vanessa Teague'), arxiv.Result.Author('Damjan Vukcevic')]","Electronic Voting, E-Vote-ID 2020, Lecture Notes in Computer
  Science 12455 (2020) 19-35"
1470,HoughNet: Integrating near and long-range evidence for bottom-up object detection,"This paper presents HoughNet, a one-stage, anchor-free, voting-based,
bottom-up object detection method. Inspired by the Generalized Hough Transform,
HoughNet determines the presence of an object at a certain location by the sum
of the votes cast on that location. Votes are collected from both near and
long-distance locations based on a log-polar vote field. Thanks to this voting
mechanism, HoughNet is able to integrate both near and long-range,
class-conditional evidence for visual recognition, thereby generalizing and
enhancing current object detection methodology, which typically relies on only
local evidence. On the COCO dataset, HoughNet's best model achieves 46.4 $AP$
(and 65.1 $AP_{50}$), performing on par with the state-of-the-art in bottom-up
object detection and outperforming most major one-stage and two-stage methods.
We further validate the effectiveness of our proposal in another task, namely,
""labels to photo"" image generation by integrating the voting module of HoughNet
to two different GAN models and showing that the accuracy is significantly
improved in both cases. Code is available at
https://github.com/nerminsamet/houghnet.",2007.02355v3,cs.CV,2020-07-05 14:45:01+00:00,"[arxiv.Result.Author('Nermin Samet'), arxiv.Result.Author('Samet Hicsonmez'), arxiv.Result.Author('Emre Akbas')]",
1471,Enhancing Engagement in Token-Curated Registries via an Inflationary Mechanism,"Token Curated Registries (TCR) are decentralized recommendation systems that
can be implemented using Blockchain smart contracts. They allow participants to
vote for or against adding items to a list through a process that involves
staking tokens intrinsic to the registry, with winners receiving the staked
tokens for each vote. A TCR aims to provide incentives to create a well-curated
list. In this work, we consider a challenge for these systems - incentivizing
token-holders to actually engage and participate in the voting process. We
propose a novel token-inflation mechanism for enhancing engagement, whereby
only voting participants see their token supply increased by a pre-defined
multiple after each round of voting. To evaluate this proposal, we propose a
simple 4-class model of voters that captures all possible combinations of two
key dimensions: whether they are engaged (likely to vote at all for a given
item) or disengaged, and whether they are informed (likely to vote in a way
that increases the quality of the list) or uninformed, and a simple metric to
evaluate the quality of the list as a function of the vote outcomes. We conduct
simulations using this model of voters and show that implementing
token-inflation results in greater wealth accumulation for engaged voters. In
particular, when the number of informed voters is sufficiently high, our
simulations show that voters that are both informed and engaged see the
greatest benefits from participating in the registry when our proposed
token-inflation mechanism is employed. We further validate this finding using a
simplified mathematical analysis.",1811.09680v1,cs.GT,2018-11-23 20:51:13+00:00,"[arxiv.Result.Author('Yi Lucy Wang'), arxiv.Result.Author('Bhaskar Krishnamachari')]",
1472,Quantifying Voter Biases in Online Platforms: An Instrumental Variable Approach,"In content-based online platforms, use of aggregate user feedback (say, the
sum of votes) is commonplace as the ""gold standard"" for measuring content
quality. Use of vote aggregates, however, is at odds with the existing
empirical literature, which suggests that voters are susceptible to different
biases -- reputation (e.g., of the poster), social influence (e.g., votes thus
far), and position (e.g., answer position). Our goal is to quantify, in an
observational setting, the degree of these biases in online platforms.
Specifically, what are the causal effects of different impression signals --
such as the reputation of the contributing user, aggregate vote thus far, and
position of content -- on a participant's vote on content? We adopt an
instrumental variable (IV) framework to answer this question. We identify a set
of candidate instruments, carefully analyze their validity, and then use the
valid instruments to reveal the effects of the impression signals on votes. Our
empirical study using log data from Stack Exchange websites shows that the bias
estimates from our IV approach differ from the bias estimates from the ordinary
least squares (OLS) method. In particular, OLS underestimates reputation bias
(1.6--2.2x for gold badges) and position bias (up to 1.9x for the initial
position) and overestimates social influence bias (1.8--2.3x for initial
votes). The implications of our work include: redesigning user interface to
avoid voter biases; making changes to platforms' policy to mitigate voter
biases; detecting other forms of biases in online platforms.",1910.00757v1,cs.SI,2019-10-02 03:00:36+00:00,"[arxiv.Result.Author('Himel Dev'), arxiv.Result.Author('Karrie Karahalios'), arxiv.Result.Author('Hari Sundaram')]","Proceedings of the ACM on Human Computer Interaction, Vol. 3, No.
  CSCW, Article 120. Publication date: November 2019"
1473,Modeling peer and external influence in online social networks,"Opinion polls mediated through a social network can give us, in addition to
usual demographics data like age, gender and geographic location, a friendship
structure between voters and the temporal dynamics of their activity during the
voting process. Using a Facebook application we collected friendship
relationships, demographics and votes of over ten thousand users on the
referendum on the definition of marriage in Croatia held on 1st of December
2013. We also collected data on online news articles mentioning our
application. Publication of these articles align closely with large peaks of
voting activity, indicating that these external events have a crucial influence
in engaging the voters. Also, existence of strongly connected friendship
communities where majority of users vote during short time period, and the fact
that majority of users in general tend to friend users that voted the same
suggest that peer influence also has its role in engaging the voters. As we are
not able to track activity of our users at all times, and we do not know their
motivations for expressing their votes through our application, the question is
whether we can infer peer and external influence using friendship network of
users and the times of their voting. We propose a new method for estimation of
magnitude of peer and external influence in friendship network and demonstrate
its validity on both simulated and actual data.",1610.08262v1,cs.SI,2016-10-26 10:03:07+00:00,"[arxiv.Result.Author('Matija Piškorec'), arxiv.Result.Author('Nino Antulov-Fantulin'), arxiv.Result.Author('Iva Miholić'), arxiv.Result.Author('Tomislav Šmuc'), arxiv.Result.Author('Mile Šikić')]",
1474,Voting-based Opinion Maximization,"We investigate the novel problem of voting-based opinion maximization in a
social network: Find a given number of seed nodes for a target campaigner, in
the presence of other competing campaigns, so as to maximize a voting-based
score for the target campaigner at a given time horizon.
  The bulk of the influence maximization literature assumes that social network
users can switch between only two discrete states, inactive and active, and the
choice to switch is frozen upon one-time activation. In reality, even when
having a preferred opinion, a user may not completely despise the other
opinions, and the preference level may vary over time due to social influence.
To this end, we employ models rooted in opinion formation and diffusion, and
use several voting-based scores to determine a user's vote for each of the
multiple campaigners at a given time horizon.
  Our problem is NP-hard and non-submodular for various scores. We design
greedy seed selection algorithms with quality guarantees for our scoring
functions via sandwich approximation. To improve the efficiency, we develop
random walk and sketch-based opinion computation, with quality guarantees.
Empirical results validate our effectiveness, efficiency, and scalability.",2209.06756v1,cs.SI,2022-09-14 16:17:58+00:00,"[arxiv.Result.Author('Arkaprava Saha'), arxiv.Result.Author('Xiangyu Ke'), arxiv.Result.Author('Arijit Khan'), arxiv.Result.Author('Laks V. S. Lakshmanan')]",
1475,The quest for scaling BFT Consensus through Tree-Based Vote Aggregation,"With the growing commercial interest in blockchain, permissioned
implementations have received increasing attention. Unfortunately, existing BFT
consensus protocols that are the backbone of permissioned blockchains, either
scale poorly or offer limited throughput. Most of these algorithms require at
least one process to receive and validate the votes from all other processes
and then broadcast the result, which is inherently non-scalable. Some
algorithms avoid this bottleneck by using aggregation trees to collect and
validate votes. However, to the best of our knowledge, such algorithms offer
limited throughput and degrade quickly in the presence of faults. In this paper
we propose \thesystem, the first BFT communication abstraction that organizes
participants in a tree to perform scalable vote aggregation and that, in faulty
runs, is able to terminate the protocol within an optimal number of
reconfigurations ($f+1$). We define precisely which aggregation trees allow for
optimal reconfiguration and show that, unlike previous protocols, when using
these configurations, \thesystem scales to large number of processes and
outperforms HotStuff's throughput by up to 38x.",2103.12112v1,cs.DC,2021-03-22 18:15:04+00:00,"[arxiv.Result.Author('Ray Neiheiser'), arxiv.Result.Author('Miguel Matos'), arxiv.Result.Author('Luís Rodrigues')]",
1476,Confidence Intervals for Causal Effects with Invalid Instruments using Two-Stage Hard Thresholding with Voting,"A major challenge in instrumental variables (IV) analysis is to find
instruments that are valid, or have no direct effect on the outcome and are
ignorable. Typically one is unsure whether all of the putative IVs are in fact
valid. We propose a general inference procedure in the presence of invalid IVs,
called Two-Stage Hard Thresholding (TSHT) with voting. TSHT uses two hard
thresholding steps to select strong instruments and generate candidate sets of
valid IVs. Voting takes the candidate sets and uses majority and plurality
rules to determine the true set of valid IVs. In low dimensions, if the
sufficient and necessary identification condition under invalid instruments is
met, which is more general than the so-called 50% rule or the majority rule,
our proposal (i) correctly selects valid IVs, (ii) consistently estimates the
causal effect, (iii) produces valid confidence intervals for the causal effect,
and (iv) has oracle-optimal width. In high dimensions, we establish nearly
identical results without oracle-optimality. In simulations, our proposal
outperforms traditional and recent methods in the invalid IV literature. We
also apply our method to re-analyze the causal effect of education on earnings.",1603.05224v3,math.ST,2016-03-16 19:21:45+00:00,"[arxiv.Result.Author('Zijian Guo'), arxiv.Result.Author('Hyunseung Kang'), arxiv.Result.Author('T. Tony Cai'), arxiv.Result.Author('Dylan S. Small')]",
1477,"Quick Anomaly Detection by the Newcomb--Benford Law, with Applications to Electoral Processes Data from the USA, Puerto Rico and Venezuela","A simple and quick general test to screen for numerical anomalies is
presented. It can be applied, for example, to electoral processes, both
electronic and manual. It uses vote counts in officially published voting
units, which are typically widely available and institutionally backed. The
test examines the frequencies of digits on voting counts and rests on the First
(NBL1) and Second Digit Newcomb--Benford Law (NBL2), and in a novel
generalization of the law under restrictions of the maximum number of voters
per unit (RNBL2). We apply the test to the 2004 USA presidential elections, the
Puerto Rico (1996, 2000 and 2004) governor elections, the 2004 Venezuelan
presidential recall referendum (RRP) and the previous 2000 Venezuelan
Presidential election. The NBL2 is compellingly rejected only in the Venezuelan
referendum and only for electronic voting units. Our original suggestion on the
RRP (Pericchi and Torres, 2004) was criticized by The Carter Center report
(2005). Acknowledging this, Mebane (2006) and The Economist (US) (2007)
presented voting models and case studies in favor of NBL2. Further evidence is
presented here. Moreover, under the RNBL2, Mebane's voting models are valid
under wider conditions. The adequacy of the law is assessed through Bayes
Factors (and corrections of $p$-values) instead of significance testing, since
for large sample sizes and fixed $\alpha$ levels the null hypothesis is over
rejected. Our tests are extremely simple and can become a standard screening
that a fair electoral process should pass.",1205.3290v1,stat.ME,2012-05-15 08:35:27+00:00,"[arxiv.Result.Author('Luis Pericchi'), arxiv.Result.Author('David Torres')]","Statistical Science 2011, Vol. 26, No. 4, 502-516"
1478,HoughNet: Integrating near and long-range evidence for visual detection,"This paper presents HoughNet, a one-stage, anchor-free, voting-based,
bottom-up object detection method. Inspired by the Generalized Hough Transform,
HoughNet determines the presence of an object at a certain location by the sum
of the votes cast on that location. Votes are collected from both near and
long-distance locations based on a log-polar vote field. Thanks to this voting
mechanism, HoughNet is able to integrate both near and long-range,
class-conditional evidence for visual recognition, thereby generalizing and
enhancing current object detection methodology, which typically relies on only
local evidence. On the COCO dataset, HoughNet's best model achieves $46.4$ $AP$
(and $65.1$ $AP_{50}$), performing on par with the state-of-the-art in
bottom-up object detection and outperforming most major one-stage and two-stage
methods. We further validate the effectiveness of our proposal in other visual
detection tasks, namely, video object detection, instance segmentation, 3D
object detection and keypoint detection for human pose estimation, and an
additional ""labels to photo"" image generation task, where the integration of
our voting module consistently improves performance in all cases. Code is
available at https://github.com/nerminsamet/houghnet.",2104.06773v2,cs.CV,2021-04-14 11:05:29+00:00,"[arxiv.Result.Author('Nermin Samet'), arxiv.Result.Author('Samet Hicsonmez'), arxiv.Result.Author('Emre Akbas')]",
1479,Anchoring Bias in Online Voting,"Voting online with explicit ratings could largely reflect people's
preferences and objects' qualities, but ratings are always irrational, because
they may be affected by many unpredictable factors like mood, weather, as well
as other people's votes. By analyzing two real systems, this paper reveals a
systematic bias embedding in the individual decision-making processes, namely
people tend to give a low rating after a low rating, as well as a high rating
following a high rating. This so-called \emph{anchoring bias} is validated via
extensive comparisons with null models, and numerically speaking, the extent of
bias decays with interval voting number in a logarithmic form. Our findings
could be applied in the design of recommender systems and considered as
important complementary materials to previous knowledge about anchoring effects
on financial trades, performance judgements, auctions, and so on.",1209.0057v1,physics.data-an,2012-09-01 05:20:00+00:00,"[arxiv.Result.Author('Zimo Yang'), arxiv.Result.Author('Zi-Ke Zhang'), arxiv.Result.Author('Tao Zhou')]",EPL 100 (2012) 68002
1480,"In elections, irrelevant alternatives provide relevant data","The electoral criterion of independence of irrelevant alternatives, or IIA,
states that a voting system is unacceptable if it would choose a different
winner if votes were recounted after one of the losers had dropped out. But IIA
confuses the candidate who withdrew with the data which was generated by that
candidate. This paper reports a wide variety of simulation studies which
consistently show that data from dropout candidates can be very useful in
choosing the best of the remaining candidates. These studies use well-validated
spatial models in which the most centrist candidates are considered to be the
best candidates. Thus IIA should be abandoned. The majority judgment or MJ
voting system was created specifically to satisfy IIA. Some of these studies
also show the substantial inferiority of MJ to other voting systems.
Discussions of IIA have usually treated dropouts as strictly hypothetical, but
our conclusions about the usefulness of dropout data may apply even to real
dropouts.",1706.01083v1,stat.ME,2017-06-04 14:43:52+00:00,[arxiv.Result.Author('Richard B. Darlington')],
1481,Gerrymandering and the net number of US House seats won due to vote-distribution asymmetries,"Using the recently introduced declination function, we estimate the net
number of seats won in the US House of Representatives due to asymmetries in
vote distributions. Such asymmetries can arise from combinations of partisan
gerrymandering and inherent geographic advantage. Our estimates show
significant biases in favor of the Democrats prior to the mid 1990s and
significant biases in favor of Republicans since then. We find net differences
of 28, 20 and 25 seats in favor of the Republicans in the years 2012, 2014 and
2016, respectively. The validity of our results is supported by the technique
of simulated packing and cracking. We also use this technique to show that the
presidential-vote logistic regression model is insensitive to the packing and
cracking by which partisan gerrymanders are achieved.",1707.08681v2,stat.AP,2017-07-27 01:46:28+00:00,"[arxiv.Result.Author('Jeffrey S. Buzas'), arxiv.Result.Author('Gregory S. Warrington')]",
1482,Probabilistic Evaluation of Candidates and Symptom Clustering for Multidisorder Diagnosis,"This paper derives a formula for computing the conditional probability of a
set of candidates, where a candidate is a set of disorders that explain a given
set of positive findings. Such candidate sets are produced by a recent method
for multidisorder diagnosis called symptom clustering. A symptom clustering
represents a set of candidates compactly as a cartesian product of differential
diagnoses. By evaluating the probability of a candidate set, then, a large set
of candidates can be validated or pruned simultaneously. The probability of a
candidate set is then specialized to obtain the probability of a single
candidate. Unlike earlier results, the equation derived here allows the
specification of positive, negative, and unknown symptoms and does not make
assumptions about disorders not in the candidate.",1304.1136v1,cs.AI,2013-03-27 13:59:43+00:00,[arxiv.Result.Author('Thomas D. Wu')],
1483,Recovering Accurate Labeling Information from Partially Valid Data for Effective Multi-Label Learning,"Partial Multi-label Learning (PML) aims to induce the multi-label predictor
from datasets with noisy supervision, where each training instance is
associated with several candidate labels but only partially valid. To address
the noisy issue, the existing PML methods basically recover the ground-truth
labels by leveraging the ground-truth confidence of the candidate label, \ie
the likelihood of a candidate label being a ground-truth one. However, they
neglect the information from non-candidate labels, which potentially
contributes to the ground-truth label recovery. In this paper, we propose to
recover the ground-truth labels, \ie estimating the ground-truth confidences,
from the label enrichment, composed of the relevance degrees of candidate
labels and irrelevance degrees of non-candidate labels. Upon this observation,
we further develop a novel two-stage PML method, namely
\emph{\underline{P}artial \underline{M}ulti-\underline{L}abel
\underline{L}earning with \underline{L}abel
\underline{E}nrichment-\underline{R}ecovery} (\baby), where in the first stage,
it estimates the label enrichment with unconstrained label propagation, then
jointly learns the ground-truth confidence and multi-label predictor given the
label enrichment. Experimental results validate that \baby outperforms the
state-of-the-art PML methods.",2006.11488v1,cs.LG,2020-06-20 04:13:24+00:00,"[arxiv.Result.Author('Ximing Li'), arxiv.Result.Author('Yang Wang')]",
1484,Multicolour photometry for exoplanet candidate validation,"Context. The TESS and PLATO missions are expected to find vast numbers of new
transiting planet candidates. However, only a fraction of these candidates will
be legitimate planets, and the candidate validation will require a significant
amount of follow-up resources. Radial velocity follow-up can be carried out
only for the most promising candidates around bright, slowly rotating, stars.
Thus, before devoting RV resources to candidates, they need to be vetted using
cheaper methods, and, in the cases for which an RV confirmation is not
feasible, the candidate's true nature needs to be determined based on these
alternative methods alone.
  Aims. We study the applicability of multicolour transit photometry in the
validation of transiting planet candidates when the candidate signal arises
from a real astrophysical source. We seek to answer how securely can we
estimate the true uncontaminated star-planet radius ratio when the light curve
may contain contamination from unresolved light sources inside the photometry
aperture when combining multicolour transit observations with a physics-based
contamination model.
  Methods. The study is based on simulations and ground-based transit
observations. The analyses are carried out with a contamination model
integrated into the PyTransit v2 transit modelling package, and the
observations are carried out with the MuSCAT2 multicolour imager installed in
the 1.5 m TCS in the Teide Observatory.
  Results. We show that multicolour transit photometry can be used to estimate
the amount of flux contamination and the true radius ratio. Combining the true
radius ratio with an estimate for the stellar radius yields the true absolute
radius of the transiting object, which is a valuable quantity in statistical
candidate validation, and enough in itself to validate a candidate whose radius
falls below the theoretical lower limit for a brown dwarf.",1907.09776v1,astro-ph.EP,2019-07-23 09:14:02+00:00,"[arxiv.Result.Author('Hannu Parviainen'), arxiv.Result.Author('Brandon Tingley'), arxiv.Result.Author('Hans. J. Deeg'), arxiv.Result.Author('Enric Palle'), arxiv.Result.Author('Roi Alonso'), arxiv.Result.Author('Pilar Montanes Rodriguez'), arxiv.Result.Author('Felipe Murgas'), arxiv.Result.Author('Norio Narita'), arxiv.Result.Author('Akihiko Fukui'), arxiv.Result.Author('Nobuhiko Kusakabe'), arxiv.Result.Author('Motohide Tamura'), arxiv.Result.Author('Taku Nishiumi'), arxiv.Result.Author('Jorge Prieto-Arranz'), arxiv.Result.Author('Peter Klagyivik'), arxiv.Result.Author('Victor J. S. Béjar'), arxiv.Result.Author('Nicolas Crouzet'), arxiv.Result.Author('Mayuko Mori'), arxiv.Result.Author('Diego Hidalgo Soto'), arxiv.Result.Author('Núria Casasayas Barris'), arxiv.Result.Author('Rafael Luque')]","A&A 630, A89 (2019)"
1485,Large-Scale Validation of Hypothesis Generation Systems via Candidate Ranking,"The first step of many research projects is to define and rank a short list
of candidates for study. In the modern rapidity of scientific progress, some
turn to automated hypothesis generation (HG) systems to aid this process. These
systems can identify implicit or overlooked connections within a large
scientific corpus, and while their importance grows alongside the pace of
science, they lack thorough validation. Without any standard numerical
evaluation method, many validate general-purpose HG systems by rediscovering a
handful of historical findings, and some wishing to be more thorough may run
laboratory experiments based on automatic suggestions. These methods are
expensive, time consuming, and cannot scale. Thus, we present a numerical
evaluation framework for the purpose of validating HG systems that leverages
thousands of validation hypotheses. This method evaluates a HG system by its
ability to rank hypotheses by plausibility; a process reminiscent of human
candidate selection. Because HG systems do not produce a ranking criteria,
specifically those that produce topic models, we additionally present novel
metrics to quantify the plausibility of hypotheses given topic model system
output. Finally, we demonstrate that our proposed validation method aligns with
real-world research goals by deploying our method within Moliere, our recent
topic-driven HG system, in order to automatically generate a set of candidate
genes related to HIV-associated neurodegenerative disease (HAND). By performing
laboratory experiments based on this candidate set, we discover a new
connection between HAND and Dead Box RNA Helicase 3 (DDX3). Reproducibility:
code, validation data, and results can be found at
sybrandt.com/2018/validation.",1802.03793v4,cs.IR,2018-02-11 19:04:49+00:00,"[arxiv.Result.Author('Justin Sybrandt'), arxiv.Result.Author('Michael Shtutman'), arxiv.Result.Author('Ilya Safro')]",
1486,Validation of TESS exoplanet candidates orbiting solar analogues in the all-sky PLATO input catalogue,"The Transiting Exoplanet Survey Satellite (TESS) is focusing on relatively
bright stars and has found thousands of planet candidates. However, mainly
because of the low spatial resolution of its cameras ($\approx$ 21
arcsec/pixel), TESS is expected to detect several false positives (FPs); hence,
vetting needs to be done. Here, we present a follow-up program of TESS
candidates orbiting solar-analogue stars that are in the all-sky PLATO input
catalogue. Using Gaia photometry and astrometry we built an absolute
colour-magnitude diagram and isolated solar-analogue candidates' hosts. We
performed a probabilistic validation of each candidate using the VESPA software
and produced a prioritized list of objects that have the highest probability of
being genuine transiting planets. Following this procedure, we eliminated the
majority of FPs and statistically vetted 23 candidates. For this remaining set,
we performed a stellar neighbourhood analysis using Gaia Early Data Release 3
and centroid motion tests, greatly enhancing the on-target probability of 12 of
them. We then used publicly available high-resolution imaging data to confirm
their transit source and found five new, fully validated planets. For the
remaining candidates, we propose on-off photometry to further refine the list
of genuine candidates and prepare for the subsequent radial velocity follow-up.",2208.12276v1,astro-ph.EP,2022-08-25 18:00:09+00:00,"[arxiv.Result.Author('Giacomo Mantovan'), arxiv.Result.Author('Marco Montalto'), arxiv.Result.Author('Giampaolo Piotto'), arxiv.Result.Author('Thomas G. Wilson'), arxiv.Result.Author('Andrew Collier Cameron'), arxiv.Result.Author('Fatemeh Zahra Majidi'), arxiv.Result.Author('Luca Borsato'), arxiv.Result.Author('Valentina Granata'), arxiv.Result.Author('Valerio Nascimbeni')]",
1487,One-Shot Neural Architecture Search via Self-Evaluated Template Network,"Neural architecture search (NAS) aims to automate the search procedure of
architecture instead of manual design. Even if recent NAS approaches finish the
search within days, lengthy training is still required for a specific
architecture candidate to get the parameters for its accurate evaluation.
Recently one-shot NAS methods are proposed to largely squeeze the tedious
training process by sharing parameters across candidates. In this way, the
parameters for each candidate can be directly extracted from the shared
parameters instead of training them from scratch. However, they have no sense
of which candidate will perform better until evaluation so that the candidates
to evaluate are randomly sampled and the top-1 candidate is considered the
best. In this paper, we propose a Self-Evaluated Template Network (SETN) to
improve the quality of the architecture candidates for evaluation so that it is
more likely to cover competitive candidates. SETN consists of two components:
(1) an evaluator, which learns to indicate the probability of each individual
architecture being likely to have a lower validation loss. The candidates for
evaluation can thus be selectively sampled according to this evaluator. (2) a
template network, which shares parameters among all candidates to amortize the
training cost of generated candidates. In experiments, the architecture found
by SETN achieves state-of-the-art performance on CIFAR and ImageNet benchmarks
within comparable computation costs. Code is publicly available on GitHub:
https://github.com/D-X-Y/AutoDL-Projects.",1910.05733v4,cs.CV,2019-10-13 11:25:40+00:00,"[arxiv.Result.Author('Xuanyi Dong'), arxiv.Result.Author('Yi Yang')]",
1488,ComPRASS: a Combined Planck-RASS catalogue of X-ray-SZ clusters,"We present the first all-sky catalogue of galaxy clusters and cluster
candidates obtained from joint X-ray-SZ detections using observations from the
Planck satellite and the ROSAT all-sky survey (RASS). The catalogue contains
2323 objects and has been validated by careful cross-identification with
previously known clusters. This validation shows that 1597 candidates
correspond to already known clusters, 212 coincide with other cluster
candidates still to be confirmed, and the remaining 514 are completely new
detections. With respect to Planck catalogues, the ComPRASS catalogue is
simultaneously more pure and more complete. Based on the validation results in
the SPT and SDSS footprints, the expected purity of the catalogue is at least
84.5%, meaning that more than 365 clusters are expected to be found among the
new or still to be confirmed candidates with future validation efforts or
specific follow-ups.",1901.00873v2,astro-ph.CO,2019-01-03 19:00:24+00:00,"[arxiv.Result.Author('Paula Tarrío'), arxiv.Result.Author('Jean-Baptiste Melin'), arxiv.Result.Author('Monique Arnaud')]","A&A 626, A7 (2019)"
1489,Negative Selection Approach to support Formal Verification and Validation of BlackBox Models' Input Constraints,"Generating unsafe sub-requirements from a partitioned input space to support
verification-guided test cases for formal verification of black-box models is a
challenging problem for researchers. The size of the search space makes
exhaustive search computationally impractical. This paper investigates a
meta-heuristic approach to search for unsafe candidate sub-requirements in
partitioned input space. We present a Negative Selection Algorithm (NSA) for
identifying the candidates' unsafe regions within given safety properties. The
Meta-heuristic capability of the NSA algorithm made it possible to estimate
vast unsafe regions while validating a subset of these regions. We utilize a
parallel execution of partitioned input space to produce safe areas. The NSA
based on the prior knowledge of the safe regions is used to identify candidate
unsafe region areas and the Marabou framework is then used to validate the NSA
results. Our preliminary experimentation and evaluation show that the procedure
finds candidate unsafe sub-requirements when validated with the Marabou
framework with high precision.",2209.01411v1,cs.LG,2022-09-03 12:28:21+00:00,"[arxiv.Result.Author('Abdul-Rauf Nuhu'), arxiv.Result.Author('Kishor Datta Gupta'), arxiv.Result.Author('Wendwosen Bellete Bedada'), arxiv.Result.Author('Mahmoud Nabil'), arxiv.Result.Author('Lydia Asrat Zeleke'), arxiv.Result.Author('Abdollah Homaifar'), arxiv.Result.Author('Edward Tunstel')]",
1490,Exoplanet Validation with Machine Learning: 50 new validated Kepler planets,"Over 30% of the ~4000 known exoplanets to date have been discovered using
'validation', where the statistical likelihood of a transit arising from a
false positive (FP), non-planetary scenario is calculated. For the large
majority of these validated planets calculations were performed using the vespa
algorithm (Morton et al. 2016). Regardless of the strengths and weaknesses of
vespa, it is highly desirable for the catalogue of known planets not to be
dependent on a single method. We demonstrate the use of machine learning
algorithms, specifically a gaussian process classifier (GPC) reinforced by
other models, to perform probabilistic planet validation incorporating prior
probabilities for possible FP scenarios. The GPC can attain a mean log-loss per
sample of 0.54 when separating confirmed planets from FPs in the Kepler
threshold crossing event (TCE) catalogue. Our models can validate thousands of
unseen candidates in seconds once applicable vetting metrics are calculated,
and can be adapted to work with the active TESS mission, where the large number
of observed targets necessitates the use of automated algorithms. We discuss
the limitations and caveats of this methodology, and after accounting for
possible failure modes newly validate 50 Kepler candidates as planets, sanity
checking the validations by confirming them with vespa using up to date stellar
information. Concerning discrepancies with vespa arise for many other
candidates, which typically resolve in favour of our models. Given such issues,
we caution against using single-method planet validation with either method
until the discrepancies are fully understood.",2008.10516v1,astro-ph.EP,2020-08-24 15:35:21+00:00,"[arxiv.Result.Author('David J. Armstrong'), arxiv.Result.Author('Jevgenij Gamper'), arxiv.Result.Author('Theodoros Damoulas')]",
1491,Fighting Noise with Noise: Causal Inference with Many Candidate Instruments,"Instrumental variable methods provide useful tools for inferring causal
effects in the presence of unmeasured confounding. To apply these methods with
large-scale data sets, a major challenge is to find valid instruments from a
possibly large candidate set. In practice, most of the candidate instruments
are often not relevant for studying a particular exposure of interest.
Moreover, not all relevant candidate instruments are valid as they may directly
influence the outcome of interest. In this article, we propose a data-driven
method for causal inference with many candidate instruments that addresses
these two challenges simultaneously. A key component of our proposal is a novel
resampling method, which constructs pseudo variables to remove irrelevant
candidate instruments having spurious correlations with the exposure. Synthetic
data analyses show that the proposed method performs favourably compared to
existing methods. We apply our method to a Mendelian randomization study
estimating the effect of obesity on health-related quality of life.",2203.09330v2,stat.ME,2022-03-17 13:56:30+00:00,"[arxiv.Result.Author('Xinyi Zhang'), arxiv.Result.Author('Linbo Wang'), arxiv.Result.Author('Stanislav Volgushev'), arxiv.Result.Author('Dehan Kong')]",
1492,275 Candidates and 149 Validated Planets Orbiting Bright Stars in K2 Campaigns 0-10,"Since 2014, NASA's K2 mission has observed large portions of the ecliptic
plane in search of transiting planets and has detected hundreds of planet
candidates. With observations planned until at least early 2018, K2 will
continue to identify more planet candidates. We present here 275 planet
candidates observed during Campaigns 0-10 of the K2 mission that are orbiting
stars brighter than 13 mag (in Kepler band) and for which we have obtained
high-resolution spectra (R = 44,000). These candidates are analyzed using the
VESPA package (Morton 2012, 2015b) in order to calculate their false-positive
probabilities (FPP). We find that 149 candidates are validated with an FPP
lower than 0.1%, 39 of which were previously only candidates and 56 of which
were previously undetected. The processes of data reduction, candidate
identification, and statistical validation are described, and the demographics
of the candidates and newly validated planets are explored. We show tentative
evidence of a gap in the planet radius distribution of our candidate sample.
Comparing our sample to the Kepler candidate sample investigated by Fulton et
al. (2017), we conclude that more planets are required to quantitatively
confirm the gap with K2 candidates or validated planets. This work, in addition
to increasing the population of validated K2 planets by nearly 50% and
providing new targets for follow-up observations, will also serve as a
framework for validating candidates from upcoming K2 campaigns and the
Transiting Exoplanet Survey Satellite, expected to launch in 2018.",1802.05277v2,astro-ph.EP,2018-02-14 19:00:02+00:00,"[arxiv.Result.Author('Andrew W. Mayo'), arxiv.Result.Author('Andrew Vanderburg'), arxiv.Result.Author('David W. Latham'), arxiv.Result.Author('Allyson Bieryla'), arxiv.Result.Author('Timothy D. Morton'), arxiv.Result.Author('Lars A. Buchhave'), arxiv.Result.Author('Courtney D. Dressing'), arxiv.Result.Author('Charles Beichman'), arxiv.Result.Author('Perry Berlind'), arxiv.Result.Author('Michael L. Calkins'), arxiv.Result.Author('David R. Ciardi'), arxiv.Result.Author('Ian J. M. Crossfield'), arxiv.Result.Author('Gilbert A. Esquerdo'), arxiv.Result.Author('Mark E. Everett'), arxiv.Result.Author('Erica J. Gonzales'), arxiv.Result.Author('Lea A. Hirsch'), arxiv.Result.Author('Elliott P. Horch'), arxiv.Result.Author('Andrew W. Howard'), arxiv.Result.Author('Steve B. Howell'), arxiv.Result.Author('John Livingston'), arxiv.Result.Author('Rahul Patel'), arxiv.Result.Author('Erik A. Petigura'), arxiv.Result.Author('Joshua E. Schlieder'), arxiv.Result.Author('Nicholas J. Scott'), arxiv.Result.Author('Clea F. Schumer'), arxiv.Result.Author('Evan Sinukoff'), arxiv.Result.Author('Johanna Teske'), arxiv.Result.Author('Jennifer G. Winters')]",2018 AJ 155 3
1493,Dancing with Donald: Polarity in the 2016 Presidential Election,"In almost every election cycle, the validity of the United States Electoral
College is brought into question. The 2016 Presidential Election again brought
up the issue of a candidate winning the popular vote but not winning the
Electoral College, with Hillary Clinton receiving close to three million more
votes than Donald Trump. However, did the popular vote actually determine the
most liked candidate in the election? In this paper, we demonstrate that
different voting policies can alter which candidate is elected. Additionally,
we explore the trade-offs between each of these mechanisms. Finally, we
introduce two novel mechanisms with the intent of electing the least polarizing
candidate.",1901.07542v1,econ.GN,2019-01-22 02:43:28+00:00,"[arxiv.Result.Author('Robert Chuchro'), arxiv.Result.Author(""Kyle D'Souza""), arxiv.Result.Author('Darren Mei')]",
1494,Personalized News Recommendation with Knowledge-aware Interactive Matching,"The most important task in personalized news recommendation is accurate
matching between candidate news and user interest. Most of existing news
recommendation methods model candidate news from its textual content and user
interest from their clicked news in an independent way. However, a news article
may cover multiple aspects and entities, and a user usually has different kinds
of interest. Independent modeling of candidate news and user interest may lead
to inferior matching between news and users. In this paper, we propose a
knowledge-aware interactive matching method for news recommendation. Our method
interactively models candidate news and user interest to facilitate their
accurate matching. We design a knowledge-aware news co-encoder to interactively
learn representations for both clicked news and candidate news by capturing
their relatedness in both semantic and entities with the help of knowledge
graphs. We also design a user-news co-encoder to learn candidate news-aware
user interest representation and user-aware candidate news representation for
better interest matching. Experiments on two real-world datasets validate that
our method can effectively improve the performance of news recommendation.",2104.10083v3,cs.IR,2021-04-20 16:05:16+00:00,"[arxiv.Result.Author('Tao Qi'), arxiv.Result.Author('Fangzhao Wu'), arxiv.Result.Author('Chuhan Wu'), arxiv.Result.Author('Yongfeng Huang')]",
1495,Decompositional Generation Process for Instance-Dependent Partial Label Learning,"Partial label learning (PLL) is a typical weakly supervised learning problem,
where each training example is associated with a set of candidate labels among
which only one is true. Most existing PLL approaches assume that the incorrect
labels in each training example are randomly picked as the candidate labels and
model the generation process of the candidate labels in a simple way. However,
these approaches usually do not perform as well as expected due to the fact
that the generation process of the candidate labels is always
instance-dependent. Therefore, it deserves to be modeled in a refined way. In
this paper, we consider instance-dependent PLL and assume that the generation
process of the candidate labels could decompose into two sequential parts,
where the correct label emerges first in the mind of the annotator but then the
incorrect labels related to the feature are also selected with the correct
label as candidate labels due to uncertainty of labeling. Motivated by this
consideration, we propose a novel PLL method that performs Maximum A
Posterior(MAP) based on an explicitly modeled generation process of candidate
labels via decomposed probability distribution models. Experiments on benchmark
and real-world datasets validate the effectiveness of the proposed method.",2204.03845v2,cs.LG,2022-04-08 05:18:51+00:00,"[arxiv.Result.Author('Congyu Qiao'), arxiv.Result.Author('Ning Xu'), arxiv.Result.Author('Xin Geng')]",
1496,Identify 46 New Open Clusters Candidates In Gaia EDR3 Using pyUPMASK and Random Forest Hybrid Method,"Open clusters (OCs) are regarded as tracers to understand stellar evolution
theory and validate stellar models. In this study, we presented a robust
approach to identifying OCs. A hybrid method of pyUPMASK and RF is first used
to remove field stars and determine more reliable members. An identification
model based on the RF algorithm built based on 3714 OC samples from Gaia DR2
and EDR3 is then applied to identify OC candidates. The OC candidates are
obtained after isochrone fitting, the advanced stellar population synthesis
(ASPS) model fitting, and visual inspection. Using the proposed approach, we
revisited 868 candidates and preliminarily clustered them by the
friends-of-friends algorithm in Gaia EDR3. Excluding the open clusters that
have already been reported, we focused on the remaining 300 unknown candidates.
From high to low fitting quality, these unrevealed candidates were further
classified into Class A (59), Class B (21), and Class C (220), respectively. As
a result, 46 new reliable open cluster candidates among classes A and B are
identified after visual inspection.",2212.11569v1,astro-ph.SR,2022-12-22 09:46:52+00:00,"[arxiv.Result.Author('Huanbin Chi'), arxiv.Result.Author('Shoulin Wei'), arxiv.Result.Author('Feng Wang'), arxiv.Result.Author('Zhongmu Li')]",
1497,On High-Dimensional Gaussian Comparisons For Cross-Validation,"We derive high-dimensional Gaussian comparison results for the standard
$V$-fold cross-validated risk estimates. Our result combines a recent
stability-based argument for the low-dimensional central limit theorem of
cross-validation with the high-dimensional Gaussian comparison framework for
sums of independent random variables. These results give new insights into the
joint sampling distribution of cross-validated risks in the context of model
comparison and tuning parameter selection, where the number of candidate models
and tuning parameters can be larger than the fitting sample size. As a
consequence, our results provide theoretical support for a recent
methodological development that constructs model confidence sets using
cross-validation.",2211.04958v1,math.ST,2022-11-09 15:24:32+00:00,"[arxiv.Result.Author('Nicholas Kissel'), arxiv.Result.Author('Jing Lei')]",
1498,High-resolution Multi-band Imaging for Validation and Characterization of Small Kepler Planets,"High-resolution ground-based optical speckle and near-infrared adaptive
optics images are taken to search for stars in close angular proximity to host
stars of candidate planets identified by the NASA Kepler Mission. Neighboring
stars are a potential source of false positive signals. These stars also blend
into Kepler light curves, affecting estimated planet properties, and are
important for an understanding of planets in multiple star systems. Deep images
with high angular resolution help to validate candidate planets by excluding
potential background eclipsing binaries as the source of the transit signals. A
study of 18 Kepler Object of Interest stars hosting a total of 28 candidate and
validated planets is presented. Validation levels are determined for 18 planets
against the likelihood of a false positive from a background eclipsing binary.
Most of these are validated at the 99% level or higher, including 5
newly-validated planets in two systems: Kepler-430 and Kepler-431. The stellar
properties of the candidate host stars are determined by supplementing existing
literature values with new spectroscopic characterizations. Close neighbors of
7 of these stars are examined using multi-wavelength photometry to determine
their nature and influence on the candidate planet properties. Most of the
close neighbors appear to be gravitationally-bound secondaries, while a few are
best explained as closely co-aligned field stars. Revised planet properties are
derived for each candidate and validated planet, including cases where the
close neighbors are the potential host stars.",1411.3621v2,astro-ph.EP,2014-11-13 17:27:20+00:00,"[arxiv.Result.Author('Mark E. Everett'), arxiv.Result.Author('Thomas Barclay'), arxiv.Result.Author('David R. Ciardi'), arxiv.Result.Author('Elliott P. Horch'), arxiv.Result.Author('Steve B. Howell'), arxiv.Result.Author('Justin R. Crepp'), arxiv.Result.Author('David R. Silva')]",
1499,SPINN: a straightforward machine learning solution to the pulsar candidate selection problem,"We describe SPINN (Straightforward Pulsar Identification using Neural
Networks), a high-performance machine learning solution developed to process
increasingly large data outputs from pulsar surveys. SPINN has been
cross-validated on candidates from the southern High Time Resolution Universe
(HTRU) survey and shown to identify every known pulsar found in the survey data
while maintaining a false positive rate of 0.64%. Furthermore, it ranks 99% of
pulsars among the top 0.11% of candidates, and 95% among the top 0.01%. In
conjunction with the PEASOUP pipeline (Barr et al., in prep.), it has already
discovered four new pulsars in a re-processing of the intermediate Galactic
latitude area of HTRU, three of which have spin periods shorter than 5
milliseconds. SPINN's ability to reduce the amount of candidates to visually
inspect by up to four orders of magnitude makes it a very promising tool for
future large-scale pulsar surveys. In an effort to provide a common testing
ground for pulsar candidate selection tools and stimulate interest in their
development, we also make publicly available the set of candidates on which
SPINN was cross-validated.",1406.3627v2,astro-ph.IM,2014-06-13 20:00:04+00:00,"[arxiv.Result.Author('V. Morello'), arxiv.Result.Author('E. D. Barr'), arxiv.Result.Author('M. Bailes'), arxiv.Result.Author('C. M. Flynn'), arxiv.Result.Author('E. F. Keane'), arxiv.Result.Author('W. van Straten')]",
1500,Planetary candidates transiting cool dwarf stars from Campaigns 12 to 15 of K2,"We analyzed the photometry of 20038 cool stars from campaigns 12, 13, 14 and
15 of the K2 mission in order to detect, characterize and validate new
planetary candidates transiting low-mass stars. We present a catalogue of 25
new periodic transit-like signals in 22 stars, of which we computed the
parameters of the stellar host for 19 stars and the planetary parameters for 21
signals. We acquired speckle and AO images, and also inspected archival
Pan-STARRS1 images and Gaia DR2 to discard the presence of close stellar
companions and to check possible transit dilutions due to nearby stars. False
positive probability (FPP) was computed for 22 signals, obtaining FPP < $1\%$
for 17. We consider 12 of them as statistically validated planets. One signal
is a false positive and the remaining 12 signals are considered as planet
candidates. 20 signals have orbital period P$_{\rm orb} < 10$ $d$, 2 have $10$
$d < $ P$_{\rm orb} < 20$ $d$ and 3 have P$_{\rm orb} > 20$ $d$. Regarding
radii, 11 candidates and validated planets have computed radius R $<2
R_{\oplus}$, 9 have $2 R_{\oplus} <$ R $< 4 R_{\oplus}$, and 1 has R $>4
R_{\oplus}$. 2 validated planets and 2 candidates are located in moderately
bright stars ($m_{kep}<13$) and 2 validated planets and 3 candidates have
derived orbital radius within the habitable zone according to optimistic
models. Of special interest is the validated warm super-Earth EPIC 248616368b
(T$\rm_{eq} = 318^{+24}_{-43} \, K$, S$_{\rm p} = 1.7\pm 0.2 \, S_{\oplus}$,
R$_{\rm p} = 2.1\pm 0.1 \, R_{\oplus} $), located in a m$\rm_{kep}$ = 14.13
star.",2007.12744v2,astro-ph.EP,2020-07-24 19:30:03+00:00,"[arxiv.Result.Author('A. Castro González'), arxiv.Result.Author('E. Díez Alonso'), arxiv.Result.Author('J. Menéndez Blanco'), arxiv.Result.Author('John H. Livingston'), arxiv.Result.Author('Jerome P. de Leon'), arxiv.Result.Author('S. L. Suárez Gómez'), arxiv.Result.Author('C. González Gutiérrez'), arxiv.Result.Author('F. García Riesgo'), arxiv.Result.Author('L. Bonavera'), arxiv.Result.Author('F. J. Iglesias Rodríguez'), arxiv.Result.Author('R. Muñiz'), arxiv.Result.Author('Mark E. Everett'), arxiv.Result.Author('N. J. Scott'), arxiv.Result.Author('Steve B. Howell'), arxiv.Result.Author('David R. Ciardi'), arxiv.Result.Author('Erica J. Gonzales'), arxiv.Result.Author('Joshua E. Schlieder'), arxiv.Result.Author('F. J. de Cos Juez')]",
1501,"In elections, irrelevant alternatives provide relevant data","The electoral criterion of independence of irrelevant alternatives, or IIA,
states that a voting system is unacceptable if it would choose a different
winner if votes were recounted after one of the losers had dropped out. But IIA
confuses the candidate who withdrew with the data which was generated by that
candidate. This paper reports a wide variety of simulation studies which
consistently show that data from dropout candidates can be very useful in
choosing the best of the remaining candidates. These studies use well-validated
spatial models in which the most centrist candidates are considered to be the
best candidates. Thus IIA should be abandoned. The majority judgment or MJ
voting system was created specifically to satisfy IIA. Some of these studies
also show the substantial inferiority of MJ to other voting systems.
Discussions of IIA have usually treated dropouts as strictly hypothetical, but
our conclusions about the usefulness of dropout data may apply even to real
dropouts.",1706.01083v1,stat.ME,2017-06-04 14:43:52+00:00,[arxiv.Result.Author('Richard B. Darlington')],
1502,Quantum dissociation of a vortex-antivortex pair in a long Josephson junction,"We report a theoretical analysis and experimental observation of the quantum
dynamics of a single vortex-antivortex (VAV) pair confined in a long narrow
annular Josephson junction. The switching of the junction from the
superconducting state to the resistive state occurs via the dissociation of a
pinned VAV pair. The pinning potential is controlled by external magnetic field
$H$ and dc bias current $I$. We predict a specific magnetic field dependence of
the oscillatory energy levels of the pinned VAV state and the crossover to a
{\it macroscopic quantum tunneling} mechanism of VAV dissociation at low
temperatures. Our analysis explains the experimentally observed {\it increase}
of the width of the switching current distribution $P(I)$ with $H$ and the
crossover to the quantum regime at the temperature of about 100 mK.",cond-mat/0307705v1,cond-mat.supr-con,2003-07-29 13:42:41+00:00,"[arxiv.Result.Author('M. V. Fistul'), arxiv.Result.Author('A. Wallraff'), arxiv.Result.Author('Y. Koval'), arxiv.Result.Author('A. Lukashenko'), arxiv.Result.Author('B. A. Malomed'), arxiv.Result.Author('A. V. Ustinov')]",
1503,Vortex modes supported by spin-orbit coupling in a laser with saturable absorption,"We introduce a system of two component two-dimensional (2D) complex
Ginzburg-Landau equations (CGLEs) with spin-orbit-coupling (SOC) describing a
wide-aperture microcavity laser with saturable gain and absorption. We report
families of two-component self-trapped dissipative laser solitons in this
system. The SOC terms are represented by the second-order differential
operators, which sets the difference, $|\Delta S|=2$, between the vorticities
of the two components. We have found stable solitons of two types:
vortex-antivortex (VAV) and semi-vortex (SV) bound states, featuring
vorticities $\left( -1,+1\right) $ and $\left( 0,2\right) $, respectively. In
previous works, 2D localized states of these types were found only in models
including a trapping potential, while we are dealing with the self-trapping
effect in the latteraly unconfined (free-space) model. The SV states are stable
in a narrow interval of values of the gain coefficients. The stability interval
is broader for VAV states, and it may be expanded by making SOC stronger
(although the system without SOC features a stability interval too). We have
found three branches of stationary solutions of both VAV and SV types, two
unstable and one stable. The latter one is an attractor, as the unstable states
spontaneously transform into the stable one, while retaining vorticities of
their components. Unlike previously known 2D localized states, maintained by
the combination of the trapping potential and SOC, in the present system the
VAV and SV complexes are stable in the absence of diffusion. In contrast with
the bright solitons in conservative models, chemical potentials of the
dissipative solitons reported here are positive.",1810.12208v1,nlin.PS,2018-10-29 15:56:47+00:00,"[arxiv.Result.Author('Thawatchai Mayteevarunyoo'), arxiv.Result.Author('Boris A. Malomed'), arxiv.Result.Author('Dmitry V. Skryabin')]",
1504,On the coarse-geometric detection of subgroups,"We generalize [Vav] to give sufficient conditions, primarily on coarse
geometry, to ensure that a subset of a Cayley graph is a finite Hausdorff
distance from a subgroup. Using this result, we prove a partial converse to the
Flat Torus Theorem for CAT(0) groups. Also using this result, we give
sufficient conditions for subgroups and splittings to be invariant under
quasi-isometries.",1006.2114v1,math.GR,2010-06-10 18:37:37+00:00,[arxiv.Result.Author('Diane M. Vavrichek')],
1505,Vanishing of the Brauer group of a del Pezzo surface of degree 4,"We explicitly construct a del Pezzo surface $X$ of degree 4 over a field $k$
such that $\operatorname{H}^1(k,\operatorname{Pic}\overline X)$ is isomorphic
to $\mathbb{ZZ}/2\mathbb{Z}$ while $\operatorname{Br} X/\operatorname{Br} k$ is
trivial. This proves that the algorithm to compute the Brauer group in [VAV]
cannot be generalized in some cases.",1907.08810v1,math.NT,2019-07-20 13:35:25+00:00,[arxiv.Result.Author('Manar Riman')],
1506,Nonlinear response of wrinkled premixed flames to time- and space-dependent forcing and stretch,"Premixed-flame wrinkling is studied via a Michelson-Sivashinsky (MS) type of
evolution equation retaining the Darrieus-Landau (DL) instability, a curvature
effect and a geometric nonlinearity. Here it also keeps forcing by longitudinal
shearflow and wrinkle stretch by transverse flow; both imposed stimuli vary in
time and space as to make the front slope comprise a given fluctuating spatial
harmonics and unknown pole-decomposed pieces. A DL-free Burgers version is
examined in parallel, also with Neumann conditions and symmetry. As is shown
for both models, solving Ntot equations of motion for the poles in principle
yields the front dynamics, the arclength increment V(t) and its time-average
Vav. Yet this could be worked out analytically (or nearly so) only in
high-frequency HF or low-frequency LF limits. These tackle one or two pairs of
poles per cell, then a large number of pairs Ntot forming two piles viewed as
continua, one per crest. Despite ample pole motions that make some commute
between crests, Vav grows in a nearly parabolic way with the combined intensity
of forcing and stretch. LF stimuli and DL instability can induce multiple
branches and relaxation phenomena. Numerical t-averages are needed even if V(t)
is analytically known. For Ntot=1,2 and short wrinkles, or Burgers fronts, Vav
transitions from quadratic to sublinear as the forcing grows ; for longer
wrinkles Vav keeps its MS value at moderate forcing, then bifurcates to an
ultimately sublinear growth that depends on the stimulus phases. For very long
wrinkles, coupled integral equations give analytical slope and pole-density
profiles, but pile heights/contents need a t-dependent numerical search of up
to two roots to get V(t). A summary, a discussion and hints of generalizations
are provided, and open problems are evoked.",1909.07329v1,nlin.PS,2019-09-16 16:48:54+00:00,"[arxiv.Result.Author('Guy Joulin'), arxiv.Result.Author('Bruno Denet')]",
1507,Microwave impedance of a dc-biased Josephson Fluxonic Diode in the presence of magnetic field and rf drive,"The dependence of microwave impedance of a dc-biased Josephson Fluxonic Diode
(JFD) under application of both dc magnetic field and rf excitation is
calculated with a variety of conditions. For finite length of a JFD excited by
a very low microwave excitation below its plasma frequency, applied dc magnetic
field increases the rate of Vortex and Anti-Vortex (VAV) pair generation which
fine-tunes the microwave resistance up to several factors more than its zero
field microwave resistance (R0). Under this circumstance, adding a dc bias for
moving VAVs causes oscillation-like features in microwave impedance of JFD
either in forward or reverse bias. As a result, the microwave resistance
increases up to 30R0 in the forward bias despite the fact that damping
parameter (\b{eta}) can limit this increase. On the other hand, sharp phase
slips are seen in reverse bias mode on the reactance of overdamped JFD while
increasing the frequency or amplitude of microwave excitation leads to
unprecedented effects of resistance which is described.",1709.06595v1,cond-mat.supr-con,2017-09-19 18:23:53+00:00,"[arxiv.Result.Author('Hamed Mehrara'), arxiv.Result.Author('Alireza Erfanian'), arxiv.Result.Author('Farshid Raissi')]",
1508,Admissible sequences for positive operators,"A sequence of scalars is said to be admissible for a positive operator A on a
Hilbert space if it is the diagonal of VAV* for some partial isometry V having
as domain the closure of the range of A. When A is a projection, the celebrated
Kadison's carpenter theorem provides a sufficient condition for a sequence to
be admissible for A. We prove that the same condition is sufficient for the
sequence to be admissible for A when A is a sum of projections (converging in
the SOT). This provides an independent proof of Kadison's carpenter theorem.",1801.04509v1,math.OA,2018-01-14 04:34:51+00:00,"[arxiv.Result.Author('Victor Kaftal'), arxiv.Result.Author('David Larson')]",
1509,Risk Automatic Prediction for Social Economy Companies using Camels,"Governments have to supervise and inspect social economy enterprises (SEEs).
However, inspecting all SEEs is not possible due to the large number of SEEs
and the low number of inspectors in general. We proposed a prediction model
based on a machine learning approach. The method was trained with the random
forest algorithm with historical data provided by each SEE. Three consecutive
periods of data were concatenated. The proposed method uses these periods as
input data and predicts the risk of each SEE in the fourth period. The model
achieved 76\% overall accuracy. In addition, it obtained good accuracy in
predicting the high risk of a SEE. We found that the legal nature and the
variation of the past-due portfolio are good predictors of the future risk of a
SEE. Thus, the risk of a SEE in a future period can be predicted by a
supervised machine learning method. Predicting the high risk of a SEE improves
the daily work of each inspector by focusing only on high-risk SEEs.",2210.05052v1,cs.LG,2022-10-10 23:50:02+00:00,"[arxiv.Result.Author('Joseph Gallego-Mejia'), arxiv.Result.Author('Daniela Martin-Vega'), arxiv.Result.Author('Fabio Gonzalez')]",
1510,Triviality and the (Supersymmetric) See-Saw,"For the D=5 Majorana neutrino mass operator to have a see-saw ultraviolet
completion that is viable up to the Planck scale, the see-saw scale is bounded
above due to triviality limits on the see-saw couplings. For supersymmetric
see-saw models, with realistic neutrino mass textures, we compare constraints
on the see-saw scale from triviality bounds, with those arising from
experimental limits on induced charged-lepton flavour violation, for both the
CMSSM and for models with split supersymmetry.",hep-ph/0603053v2,hep-ph,2006-03-07 16:47:09+00:00,"[arxiv.Result.Author('Bruce A. Campbell'), arxiv.Result.Author('David W. Maybury')]","JHEP 0704:077,2007"
1511,Astronomical Seeing at Maidanak Observatory during the year 2018,"Astronomical seeing measurements were carried out at Maidanak observatory
during the period from August to November 2018 using DIMM (Differential Image
Motion Monitor). The median value of seeing for the entire period was
determined as 0.54 arcseconds. This value was compared to the seeing data of
the period 1996-2002.",2012.08110v1,astro-ph.IM,2020-12-15 06:19:17+00:00,"[arxiv.Result.Author('Y. A. Tillayev'), arxiv.Result.Author('A. M. Azimov'), arxiv.Result.Author('A. R. Hafizov')]",
1512,"The see-saw mechanism: neutrino mixing, leptogenesis and lepton flavor violation","The see-saw mechanism to generate small neutrino masses is reviewed. After
summarizing our current knowledge about the low energy neutrino mass matrix we
consider reconstructing the see-saw mechanism. Low energy neutrino physics is
not sufficient to reconstruct see-saw, a feature which we refer to as ``see-saw
degeneracy''. Indirect tests of see-saw are leptogenesis and lepton flavor
violation in supersymmetric scenarios, which together with neutrino mass and
mixing define the framework of see-saw phenomenology. Several examples are
given, both phenomenological and GUT-related. Variants of the see-saw mechanism
like the type II or triplet see-saw are also discussed. In particular, we
compare many general aspects regarding the dependence of LFV on low energy
neutrino parameters in the extreme cases of a dominating conventional see-saw
term or a dominating triplet term. For instance, the absence of mu -> e gamma
or tau -> e gamma in the pure triplet case means that CP is conserved in
neutrino oscillations. Scanning models, we also find that among the decays mu
-> e gamma, tau -> e gamma and tau -> mu gamma the latter one has the largest
branching ratio in (i) SO(10) type I see-saw models and in (ii) scenarios in
which the triplet term dominates in the neutrino mass matrix.",0804.3925v3,hep-ph,2008-04-24 13:44:29+00:00,[arxiv.Result.Author('Werner Rodejohann')],"Pramana 72:217-227,2009"
1513,Statistics of turbulence profile at Cerro Tololo,"Results of 3-month continuous monitoring of turbulence profile and seeing at
Cerro Tololo (Chile) in May-July 2002 are presented. Some 28000 low-resolution
profiles were measured by a new MASS single-star turbulence monitor,
accompanied by seeing data from DIMM. The median seeing was 0.95 arcseconds.
The first 500 m contribute 60% to the total seeing, the free-atmosphere median
seeing was 0.55 arcseconds. Free-atmosphere seeing is almost never better than
0.15 arcseconds because there is always some turbulence above 12 km. A 4-day
period of calm upper atmosphere with a stable free-atmosphere seeing of 0.2-0.3
arcseconds was noted. A gain in resolution from adaptive compensation of ground
layer will be 1.7 times typically and 2-3 times during such calm periods.
Correlations of the free-atmosphere turbulence with the wind speed at
tropopause and of the ground-layer turbulence with ground wind are studied.
Temporal evolution of turbulence is characterized by recurrent bursts, their
typical duration increases from 15 minutes in low layers to 1-2 hours in high
layers. The large data base of turbulence profiles can be used to test
meso-scale modeling of astronomical seeing.",astro-ph/0209432v1,astro-ph,2002-09-20 16:32:20+00:00,"[arxiv.Result.Author('A. Tokovinin'), arxiv.Result.Author('S. Baumont'), arxiv.Result.Author('J. Vasquez')]",Mon.Not.Roy.Astron.Soc. 340 (2003) 52
1514,The Spectrum of HD 3651B: An Extrasolar Nemesis?,This article has been withdrawn; see astro-ph/0611542,astro-ph/0609556v2,astro-ph,2006-09-20 00:36:50+00:00,[arxiv.Result.Author('Adam J. Burgasser')],
1515,Criticality versus q in the 2+1-dimensional $Z_q$ clock model,"Paper has been withdrawn, see comment.",cond-mat/0212255v2,cond-mat.supr-con,2002-12-11 17:32:31+00:00,"[arxiv.Result.Author('J. Hove'), arxiv.Result.Author('A. Sudbo')]",
1516,Closedness of the Space of AHE Metrics on 4-Manifolds,See comment above.,math/0012167v2,math.DG,2000-12-18 19:05:21+00:00,[arxiv.Result.Author('Michael T. Anderson')],
1517,A Machine Learning Approach to Correcting Atmospheric Seeing in Solar Flare Observations,"Current post-processing techniques for the correction of atmospheric seeing
in solar observations -- such as Speckle interferometry and Phase Diversity
methods -- have limitations when it comes to their reconstructive capabilities
of solar flare observations. This, combined with the sporadic nature of flares
meaning observers cannot wait until seeing conditions are optimal before taking
measurements, means that many ground-based solar flare observations are marred
with bad seeing. To combat this, we propose a method for dedicated flare seeing
correction based on training a deep neural network to learn to correct
artificial seeing from flare observations taken during good seeing conditions.
This model uses transfer learning, a novel technique in solar physics, to help
learn these corrections. Transfer learning is when another network already
trained on similar data is used to influence the learning of the new network.
Once trained, the model has been applied to two flare datasets: one from
AR12157 on 2014/09/06 and one from AR12673 on 2017/09/06. The results show good
corrections to images with bad seeing with a relative error assigned to the
estimate based on the performance of the model. Further discussion takes place
of improvements to the robustness of the error on these estimates.",2011.12814v1,astro-ph.SR,2020-11-25 15:17:26+00:00,"[arxiv.Result.Author('John A. Armstrong'), arxiv.Result.Author('Lyndsay Fletcher')]",
1518,Daytime Seeing and Solar Limb Positions,"A method to measure the seeing from video made during drift-scan solar
transits is proposed. The limb of the Sun is projected over a regular grid
evenly spaced. The temporal dispersion of the time intervals among the contacts
between solar limb and grid's rows is proportional to the atmospheric seeing.
Seeing effects on the position of the inflexion point of the limb's luminosity
profile are calculated numerically with Fast Fourier Transform. Observational
examples from Locarno and Paris Observatories are presented to show the
asymmetric contributions of the seeing at the beginning and the end of each
drift-scan transit.",1106.2539v1,astro-ph.IM,2011-06-13 19:58:47+00:00,[arxiv.Result.Author('Costantino Sigismondi')],
1519,The effect of aperture and seeing on the visibility of sunspots when using early modern and modern telescopes of modest size,"Using the convolution of seeing and diffraction, the relation between seeing
and aperture in the visibility of sunspots is explored. It is shown that even
telescopes with apertures smaller than 5 centimetres are significantly affected
by seeing. Although larger aperture instruments suffer more from seeing than
smaller ones, their level of detail always remains better under the same
atmospheric conditions.",2208.07244v3,astro-ph.SR,2022-08-15 15:00:51+00:00,"[arxiv.Result.Author('Nicolàs de Hilster'), arxiv.Result.Author('Siebren van der Werf')]",
1520,Typical duration of good seeing sequences at Concordia,"Context: The winter seeing at Concordia is essentially bimodal, excellent or
quite poor, with relative proportions that depend on altitude above the snow
surface. This paper studies the temporal behavior of the good seeing sequences.
Aims: An efficient exploitation of extremely good seeing with an adaptive
optics system needs long integrations. It is then important to explore the
temporal distribution of the fraction of time providing excellent seeing.
Methods: Temporal windows of good seeing are created by a simple binary
process. Good or bad. Their autocorrelations are corrected for those of the
existing data sets, since these are not continuous, being often interrupted by
technical problems in addition to the adverse weather gaps. At the end these
corrected autocorrelations provide the typical duration of good seeing
sequences. This study has to be a little detailed as its results depend on the
season, summer or winter. Results: Using a threshold of 0.5 arcsec to define
the ""good seeing"", three characteristic numbers are found to describe the
temporal evolution of the good seeing windows. The first number is the mean
duration of an uninterrupted good seeing sequence: it is $\tau_0=7.5$ hours at
8 m above the ground (15 hours at 20 m). These sequences are randomly
distributed in time, with a negative exponential law of damping time
$\tau_1=29$ hours (at elevation 8 m and 20 m). The third number is the mean
time between two 29 hours episodes. It is T=10 days at 8 m high (5 days at 20
m).",1003.3583v1,astro-ph.IM,2010-03-18 14:09:06+00:00,"[arxiv.Result.Author('Eric Fossat'), arxiv.Result.Author('Eric Aristidi'), arxiv.Result.Author('Karim Agabi'), arxiv.Result.Author('Erick Bondoux'), arxiv.Result.Author('Zalpha Challita'), arxiv.Result.Author('Francois Jeanneaux'), arxiv.Result.Author('Djamel Mekarnia')]",
1521,Excellent daytime seeing at Dome Fuji on the Antarctic plateau,"Context. Dome Fuji, the second highest region on the Antarctic plateau, is
expected to have some of the best astronomical seeing on Earth. However, site
testing at Dome Fuji is still in its very early stages.
  Aims. To investigate the astronomical seeing in the free atmosphere above
Dome Fuji, and to determine the height of the surface boundary layer.
  Methods. A Differential Image Motion Monitor was used to measure the seeing
in the visible (472 nm) at a height of 11 m above the snow surface at Dome Fuji
during the austral summer of 2012/2013.
  Results. Seeing below 0.2'' has been observed. The seeing often has a local
minimum of ~0.3'' near 18 h local time. Some periods of excellent seeing, 0.3''
or smaller, were also observed, sometimes extending for several hours at local
midnight. The median seeing is higher, at 0.52''---this large value is believed
to be caused by periods when the telescope was within the turbulent boundary
layer.
  Conclusions. The diurnal variation of the daytime seeing at Dome Fuji is
similar to that reported for Dome C, and the height of the surface boundary
layer is consistent with previous simulations for Dome Fuji. The free
atmosphere seeing is ~0.2'', and the height of the surface boundary layer can
be as low as ~11 m.",1305.5109v1,astro-ph.IM,2013-05-22 12:38:07+00:00,"[arxiv.Result.Author('H. Okita'), arxiv.Result.Author('T. Ichikawa'), arxiv.Result.Author('M. C. B. Ashley'), arxiv.Result.Author('N. Takato')]",
1522,Affine automata verifiers,"We initiate the study of the verification power of AfAs as part of
Arthur-Merlin (AM) proof systems. We show that every unary language is verified
by a real-valued AfA verifier. Then, we focus on the verifiers restricted to
have only integer-valued or rational-valued transitions. We observe that
rational-valued verifiers can be simulated by integer-valued verifiers, and,
their protocols can be simulated in nondeterministic polynomial time. We show
that this bound tight by presenting an AfA verifier for NP-complete problem
SUBSETSUM. We also show that AfAs can verify certain non-affine and
non-stochastic unary languages.",2104.11192v1,cs.FL,2021-04-22 17:24:28+00:00,"[arxiv.Result.Author('Aliya Khadieva'), arxiv.Result.Author('Abuzer Yakaryılmaz')]",
1523,Some Proxy Signature and Designated verifier Signature Schemes over Braid Groups,"Braids groups provide an alternative to number theoretic public cryptography
and can be implemented quite efficiently. The paper proposes five signature
schemes: Proxy Signature, Designated Verifier, Bi-Designated Verifier,
Designated Verifier Proxy Signature And Bi-Designated Verifier Proxy Signature
scheme based on braid groups. We also discuss the security aspects of each of
the proposed schemes.",0904.3422v1,cs.CR,2009-04-22 10:14:06+00:00,"[arxiv.Result.Author('Sunder Lal'), arxiv.Result.Author('Vandani Verma')]",
1524,Practical and Verifiable Electronic Sortition,"Existing verifiable e-sortition systems are impractical due to
computationally expensive verification (linear to the duration of the
registration phase, T) or the ease of being denial of service. Based on the
advance in verifiable delay functions, we propose a verifiable e-sortition
scheme whose result can be efficiently verified in constant time with respect
to T. We present the preliminary design and implementation, and explore future
directions to further enhance practicability.",2006.13920v1,cs.CR,2020-06-24 17:49:21+00:00,"[arxiv.Result.Author('Hsun Lee'), arxiv.Result.Author('Hsu-Chun Hsiao')]",
1525,Multi-signer Strong Designated Multi-verifier Signature Schemes based on Multiple Cryptographic Algorithms,"A designated verifier signature scheme allows a signer to generate a
signature that only the designated verifier can verify. This paper proposes
multi-signer strong designated multi-verifier signature schemes based on
multiple cryptographic algorithms and has proven their security in the random
oracle model.",2209.03682v1,cs.CR,2022-09-08 09:49:22+00:00,"[arxiv.Result.Author('Neha Arora'), arxiv.Result.Author('R. K. Sharma')]",
1526,DNNV: A Framework for Deep Neural Network Verification,"Despite the large number of sophisticated deep neural network (DNN)
verification algorithms, DNN verifier developers, users, and researchers still
face several challenges. First, verifier developers must contend with the
rapidly changing DNN field to support new DNN operations and property types.
Second, verifier users have the burden of selecting a verifier input format to
specify their problem. Due to the many input formats, this decision can greatly
restrict the verifiers that a user may run. Finally, researchers face
difficulties in re-using benchmarks to evaluate and compare verifiers, due to
the large number of input formats required to run different verifiers. Existing
benchmarks are rarely in formats supported by verifiers other than the one for
which the benchmark was introduced. In this work we present DNNV, a framework
for reducing the burden on DNN verifier researchers, developers, and users.
DNNV standardizes input and output formats, includes a simple yet expressive
DSL for specifying DNN properties, and provides powerful simplification and
reduction operations to facilitate the application, development, and comparison
of DNN verifiers. We show how DNNV increases the support of verifiers for
existing benchmarks from 30% to 74%.",2105.12841v1,cs.LG,2021-05-26 21:08:17+00:00,"[arxiv.Result.Author('David Shriver'), arxiv.Result.Author('Sebastian Elbaum'), arxiv.Result.Author('Matthew B. Dwyer')]",
1527,Single-Query Verifiable Proof-of-Sequential-Work,"We propose a proof-of-sequential-work (PoSW) that can be verified with only a
single query to the random oracle for each random challenge.
Proofs-of-sequential-work are protocols that facilitate a verifier to
efficiently verify if a prover has executed a specified number of computations
sequentially. Denoting this number of sequential computations with N , the
prover with poly(N) parallelism must take $\Omega(N)$-sequential time while the
verifier verifies the computation in O(log N)-sequential time using upto O(log
N) parallelism. We propose a PoSW that allows any verifier, even the one with
no parallelism, to verify using just a single sequential computation on a
single challenge. All the existing PoSWs [10, 5, 2, 6] mandate a prover to
compute a sequence of responses from a random oracle against N-rounds of
queries. Then the prover commits this sequence using a commitment scheme (e.g.,
Merkle root (like) commitment) predefined in the PoSWs. Now the verifier asks
the prover to provide a set of proofs against t randomly chosen checkpoints,
called challenges, in the computed sequence. The verifier finds out the
commitment from each of these proofs spending O(log N) rounds of queries to the
oracle. It can be reduced to a single round of queries only if the verifier
owns O(log N) parallelism [6]. The verifier in our PoSW demands no parallelism
but uses a single query to the random oracle in order to verify each of the t
challenges. The key observation is that the commitment schemes themselves in
the prior works demand O(log N ) oracle queries to verify.",2202.10295v2,cs.CR,2022-02-21 15:19:32+00:00,[arxiv.Result.Author('Souvik Sur')],
1528,A Novel Approach for Verifiable Secret Sharing by using a One Way Hash Function,"Threshold secret sharing schemes do not prevent any malicious behavior of the
dealer or shareholders and so we need verifiable secret sharing, to detect and
identify the cheaters, to achieve fair reconstruction of a secret. The problem
of verifiable secret sharing is to verify the shares distributed by the dealer.
A novel approach for verifiable secret sharing is presented in this paper where
both the dealer and shareholders are not assumed to be honest. In this paper,
we extend the term verifiable secret sharing to verify the shares, distributed
by a dealer as well as shares submitted by shareholders for secret
reconstruction, and to verify the reconstructed secret. Our proposed scheme
uses a one way hash function and probabilistic homomorphic encryption function
to provide verifiability and fair reconstruction of a secret.",1203.3620v1,cs.CR,2012-03-16 06:14:15+00:00,"[arxiv.Result.Author('Keyur Parmar'), arxiv.Result.Author('Devesh Jinwala')]",
1529,Measurement-only verifiable blind quantum computing with quantum input verification,"Verifiable blind quantum computing is a secure delegated quantum computing
where a client with a limited quantum technology delegates her quantum
computing to a server who has a universal quantum computer. The client's
privacy is protected (blindness) and the correctness of the computation is
verifiable by the client in spite of her limited quantum technology
(verifiability). There are mainly two types of protocols for verifiable blind
quantum computing: the protocol where the client has only to generate
single-qubit states, and the protocol where the client needs only the ability
of single-qubit measurements. The latter is called the measurement-only
verifiable blind quantum computing. If the input of the client's quantum
computing is a quantum state whose classical efficient description is not known
to the client, there was no way for the measurement-only client to verify the
correctness of the input. Here we introduce a new protocol of measurement-only
verifiable blind quantum computing where the correctness of the quantum input
is also verifiable.",1606.06467v1,quant-ph,2016-06-21 08:09:05+00:00,[arxiv.Result.Author('Tomoyuki Morimae')],"Phys. Rev. A 94, 042301 (2016)"
1530,Training verified learners with learned verifiers,"This paper proposes a new algorithmic framework, predictor-verifier training,
to train neural networks that are verifiable, i.e., networks that provably
satisfy some desired input-output properties. The key idea is to simultaneously
train two networks: a predictor network that performs the task at hand,e.g.,
predicting labels given inputs, and a verifier network that computes a bound on
how well the predictor satisfies the properties being verified. Both networks
can be trained simultaneously to optimize a weighted combination of the
standard data-fitting loss and a term that bounds the maximum violation of the
property. Experiments show that not only is the predictor-verifier architecture
able to train networks to achieve state of the art verified robustness to
adversarial examples with much shorter training times (outperforming previous
algorithms on small datasets like MNIST and SVHN), but it can also be scaled to
produce the first known (to the best of our knowledge) verifiably robust
networks for CIFAR-10.",1805.10265v2,cs.LG,2018-05-25 17:35:39+00:00,"[arxiv.Result.Author('Krishnamurthy Dvijotham'), arxiv.Result.Author('Sven Gowal'), arxiv.Result.Author('Robert Stanforth'), arxiv.Result.Author('Relja Arandjelovic'), arxiv.Result.Author(""Brendan O'Donoghue""), arxiv.Result.Author('Jonathan Uesato'), arxiv.Result.Author('Pushmeet Kohli')]",
1531,How hard are verifiable delay functions?,"Verifiable delay functions (VDF) are functions that take a specified number
of sequential steps to be evaluated but can be verified efficiently. In this
paper, we introduce a new complexity class that contains all the VDFs. We show
that this new class $\mathbf{VDF}$ is a subclass of $\mathbf{CLS}$ (continuous
local search) and Relaxed-Sink-of-Verifiable-Line is a complete problem for the
class $\mathbf{VDF}$.",2211.08181v1,cs.CR,2022-11-15 14:44:10+00:00,[arxiv.Result.Author('Souvik Sur')],
1532,Quantum Certificate Verification: Single versus Multiple Quantum Certificates,"The class MA consists of languages that can be efficiently verified by
classical probabilistic verifiers using a single classical certificate, and the
class QMA consists of languages that can be efficiently verified by quantum
verifiers using a single quantum certificate. Suppose that a verifier receives
not only one but multiple certificates. In the classical setting, it is obvious
that a classical verifier with multiple classical certificates is essentially
the same with the one with a single classical certificate. However, in the
quantum setting where a quantum verifier is given a set of quantum certificates
in tensor product form (i.e. each quantum certificate is not entangled with
others), the situation is different, because the quantum verifier might utilize
the structure of the tensor product form. This suggests a possibility of
another hierarchy of complexity classes, namely the QMA hierarchy. From this
point of view, we extend the definition of QMA to QMA(k) for the case quantum
verifiers use k quantum certificates, and analyze the properties of QMA(k).
  To compare the power of QMA(2) with that of QMA(1) = QMA, we show one
interesting property of ``quantum indistinguishability''. This gives a strong
evidence that QMA(2) is more powerful than QMA(1). Furthermore, we show that,
for any fixed positive integer $k \geq 2$, if a language L has a one-sided
bounded error QMA(k) protocol with a quantum verifier using k quantum
certificates, L necessarily has a one-sided bounded error QMA(2) protocol with
a quantum verifier using only two quantum certificates.",quant-ph/0110006v1,quant-ph,2001-10-01 10:05:26+00:00,"[arxiv.Result.Author('Hirotada Kobayashi'), arxiv.Result.Author('Keiji Matsumoto'), arxiv.Result.Author('Tomoyuki Yamakami')]",
1533,Distributed Verifiers in PCP,"Traditional proof systems involve a resource-bounded verifier communicating
with a powerful (but untrusted) prover. Distributed verifier proof systems are
a new family of proof models that involve a network of verifier nodes
communicating with a single independent prover that has access to the complete
network structure of the verifiers. The prover is tasked with convincing all
verifiers of some global property of the network graph. In addition, each
individual verifier may be given some input string they will be required to
verify during the course of computation. Verifier nodes are allowed to exchange
messaged with nodes a constant distance away, and accept / reject the input
after some computation.
  Because individual nodes are limited to a local view, communication with the
prover is potentially necessary to prove global properties about the network
graph of nodes, which only the prover has access to. In this system of models,
the entire model accepts the input if and only if every individual node has
accepted.
  There are three models in the distributed verifier proof system family:
$\mathsf{LCP}$, $\mathsf{dIP}$, and our proposed $\mathsf{dPCP}$, with the
fundamental difference between these coming from the type of communication
established between the verifiers and the prover. In this paper, we will first
go over the past work in the $\mathsf{LCP}$ and $\mathsf{dIP}$ space before
showing properties and proofs in our $\mathsf{dPCP}$ system.",2005.10749v1,cs.CC,2020-05-21 16:01:09+00:00,"[arxiv.Result.Author('Nagaganesh Jaladanki'), arxiv.Result.Author('Wilson Wu')]",
1534,Neural Network Verification using Residual Reasoning,"With the increasing integration of neural networks as components in
mission-critical systems, there is an increasing need to ensure that they
satisfy various safety and liveness requirements. In recent years, numerous
sound and complete verification methods have been proposed towards that end,
but these typically suffer from severe scalability limitations. Recent work has
proposed enhancing such verification techniques with abstraction-refinement
capabilities, which have been shown to boost scalability: instead of verifying
a large and complex network, the verifier constructs and then verifies a much
smaller network, whose correctness implies the correctness of the original
network. A shortcoming of such a scheme is that if verifying the smaller
network fails, the verifier needs to perform a refinement step that increases
the size of the network being verified, and then start verifying the new
network from scratch - effectively ""wasting"" its earlier work on verifying the
smaller network. In this paper, we present an enhancement to abstraction-based
verification of neural networks, by using residual reasoning: the process of
utilizing information acquired when verifying an abstract network, in order to
expedite the verification of a refined network. In essence, the method allows
the verifier to store information about parts of the search space in which the
refined network is guaranteed to behave correctly, and allows it to focus on
areas where bugs might be discovered. We implemented our approach as an
extension to the Marabou verifier, and obtained promising results.",2208.03083v2,cs.NE,2022-08-05 10:39:04+00:00,"[arxiv.Result.Author('Yizhak Yisrael Elboher'), arxiv.Result.Author('Elazar Cohen'), arxiv.Result.Author('Guy Katz')]",
1535,Measuring Verifiability in Online Information,"The verifiability of online information is important, but difficult to assess
systematically. We examine verifiability in the case of Wikipedia, one of the
world's largest and most consulted online information sources. We extend prior
work about quality of Wikipedia articles, knowledge production, and sources to
consider the quality of Wikipedia references. We propose a multidimensional
measure of verifiability that takes into account technical accuracy and
practical accessibility of sources. We calculate article verifiability scores
for a sample of 5,000 articles and 295,800 citations, and compare differently
weighted models to illustrate effects of emphasizing particular elements of
verifiability over others. We find that, while the quality of references in the
overall sample is reasonably high, verifiability varies significantly by
article, particularly when emphasizing the use of standard digital identifiers
and taking into account the practical availability of referenced sources. We
discuss the implications of these findings for measuring verifiability in
online information more generally.",1509.05631v2,cs.SI,2015-09-18 13:46:47+00:00,"[arxiv.Result.Author('Reed H. Harder'), arxiv.Result.Author('Alfredo J. Velasco'), arxiv.Result.Author('Michael S. Evans'), arxiv.Result.Author('Daniel N. Rockmore')]",
1536,Combining Symbolic Execution and Model Checking to Verify MPI Programs,"Message passing is the standard paradigm of programming in high-performance
computing. However, verifying Message Passing Interface (MPI) programs is
challenging, due to the complex program features (such as non-determinism and
non-blocking operations). In this work, we present MPI symbolic verifier
(MPI-SV), the first symbolic execution based tool for automatically verifying
MPI programs with non-blocking operations. MPI-SV combines symbolic execution
and model checking in a synergistic way to tackle the challenges in MPI program
verification. The synergy improves the scalability and enlarges the scope of
verifiable properties. We have implemented MPI-SV (footnote:
https://mpi-sv.github.io) and evaluated it with 111 real-world MPI verification
tasks. The pure symbolic execution-based technique successfully verifies 61 out
of the 111 tasks (55\%) within one hour, while in comparison, MPI-SV verifies
100 tasks (90\%). On average, compared with pure symbolic execution, MPI-SV
achieves 19x speedups on verifying the satisfaction of the critical property
and 5x speedups on finding violations.",1803.06300v2,cs.PL,2018-03-16 16:33:35+00:00,"[arxiv.Result.Author('Hengbiao Yu'), arxiv.Result.Author('Zhenbang Chen'), arxiv.Result.Author('Xianjin Fu'), arxiv.Result.Author('Ji Wang'), arxiv.Result.Author('Zhendong Su'), arxiv.Result.Author('Jun Sun'), arxiv.Result.Author('Chun Huang'), arxiv.Result.Author('Wei Dong')]",
1537,A Protocol for Generating Random Elements with their Probabilities,"We give an AM protocol that allows the verifier to sample elements x from a
probability distribution P, which is held by the prover. If the prover is
honest, the verifier outputs (x, P(x)) with probability close to P(x). In case
the prover is dishonest, one may hope for the following guarantee: if the
verifier outputs (x, p), then the probability that the verifier outputs x is
close to p. Simple examples show that this cannot be achieved. Instead, we show
that the following weaker condition holds (in a well defined sense) on average:
If (x, p) is output, then p is an upper bound on the probability that x is
output. Our protocol yields a new transformation to turn interactive proofs
where the verifier uses private random coins into proofs with public coins. The
verifier has better running time compared to the well-known Goldwasser-Sipser
transformation (STOC, 1986). For constant-round protocols, we only lose an
arbitrarily small constant in soundness and completeness, while our public-coin
verifier calls the private-coin verifier only once.",1312.2483v2,cs.CC,2013-12-09 16:02:40+00:00,"[arxiv.Result.Author('Thomas Holenstein'), arxiv.Result.Author('Robin Künzler')]",
1538,Formally Validating a Practical Verification Condition Generator (extended version),"A program verifier produces reliable results only if both the logic used to
justify the program's correctness is sound, and the implementation of the
program verifier is itself correct. Whereas it is common to formally prove
soundness of the logic, the implementation of a verifier typically remains
unverified. Bugs in verifier implementations may compromise the trustworthiness
of successful verification results. Since program verifiers used in practice
are complex, evolving software systems, it is generally not feasible to
formally verify their implementation.
  In this paper, we present an alternative approach: we validate successful
runs of the widely-used Boogie verifier by producing a certificate which proves
correctness of the obtained verification result. Boogie performs a complex
series of program translations before ultimately generating a verification
condition whose validity should imply the correctness of the input program. We
show how to certify three of Boogie's core transformation phases: the
elimination of cyclic control flow paths, the (SSA-like) replacement of
assignments by assumptions using fresh variables (passification), and the final
generation of verification conditions. Similar translations are employed by
other verifiers. Our implementation produces certificates in Isabelle, based on
a novel formalisation of the Boogie language.",2105.14381v1,cs.PL,2021-05-29 22:11:30+00:00,"[arxiv.Result.Author('Gaurav Parthasarathy'), arxiv.Result.Author('Peter Müller'), arxiv.Result.Author('Alexander J. Summers')]",
1539,Learning to Give Checkable Answers with Prover-Verifier Games,"Our ability to know when to trust the decisions made by machine learning
systems has not kept up with the staggering improvements in their performance,
limiting their applicability in high-stakes domains. We introduce
Prover-Verifier Games (PVGs), a game-theoretic framework to encourage learning
agents to solve decision problems in a verifiable manner. The PVG consists of
two learners with competing objectives: a trusted verifier network tries to
choose the correct answer, and a more powerful but untrusted prover network
attempts to persuade the verifier of a particular answer, regardless of its
correctness. The goal is for a reliable justification protocol to emerge from
this game. We analyze variants of the framework, including simultaneous and
sequential games, and narrow the space down to a subset of games which provably
have the desired equilibria. We develop instantiations of the PVG for two
algorithmic tasks, and show that in practice, the verifier learns a robust
decision rule that is able to receive useful and reliable information from an
untrusted prover. Importantly, the protocol still works even when the verifier
is frozen and the prover's messages are directly optimized to convince the
verifier.",2108.12099v1,cs.LG,2021-08-27 02:56:06+00:00,"[arxiv.Result.Author('Cem Anil'), arxiv.Result.Author('Guodong Zhang'), arxiv.Result.Author('Yuhuai Wu'), arxiv.Result.Author('Roger Grosse')]",
1540,Some Ideas for Program Verifier Tactics,"A program verifier is a tool that can be used to verify that a ""contract"" for
a program holds - i.e. given a precondition the program guarantees that a given
postcondition holds - by only working at the level of the annotated program. An
alternative approach is to use an interactive theorem prover, which enables
users to encode common proof patterns as special programs called ""tactics"".
This offers more flexibility than program verifiers, but at the expense of
skills required by the user. Here, we add such flexibility to program verifiers
by developing ""tactics"" as a form of program refactoring called DTacs. A formal
characterisation and set of examples are given, illustrated with a case study
from NASA.",1406.2824v1,cs.SE,2014-06-11 08:46:13+00:00,[arxiv.Result.Author('Gudmund Grov')],
1541,Secure and Verifiable Electronic Voting in Practice: the use of vVote in the Victorian State Election,"The November 2014 Australian State of Victoria election was the first
statutory political election worldwide at State level which deployed an
end-to-end verifiable electronic voting system in polling places. This was the
first time blind voters have been able to cast a fully secret ballot in a
verifiable way, and the first time a verifiable voting system has been used to
collect remote votes in a political election. The code is open source, and the
output from the election is verifiable. The system took 1121 votes from these
particular groups, an increase on 2010 and with fewer polling places.",1504.07098v1,cs.CR,2015-04-27 14:08:24+00:00,"[arxiv.Result.Author('Craig Burton'), arxiv.Result.Author('Chris Culnane'), arxiv.Result.Author('Steve Schneider')]",
1542,Affine automata verifiers,"We initiate the study of the verification power of AfAs as part of
Arthur-Merlin (AM) proof systems. We show that every unary language is verified
by a real-valued AfA verifier. Then, we focus on the verifiers restricted to
have only integer-valued or rational-valued transitions. We observe that
rational-valued verifiers can be simulated by integer-valued verifiers, and,
their protocols can be simulated in nondeterministic polynomial time. We show
that this bound tight by presenting an AfA verifier for NP-complete problem
SUBSETSUM. We also show that AfAs can verify certain non-affine and
non-stochastic unary languages.",2104.11192v1,cs.FL,2021-04-22 17:24:28+00:00,"[arxiv.Result.Author('Aliya Khadieva'), arxiv.Result.Author('Abuzer Yakaryılmaz')]",
1543,Single-Query Verifiable Proof-of-Sequential-Work,"We propose a proof-of-sequential-work (PoSW) that can be verified with only a
single query to the random oracle for each random challenge.
Proofs-of-sequential-work are protocols that facilitate a verifier to
efficiently verify if a prover has executed a specified number of computations
sequentially. Denoting this number of sequential computations with N , the
prover with poly(N) parallelism must take $\Omega(N)$-sequential time while the
verifier verifies the computation in O(log N)-sequential time using upto O(log
N) parallelism. We propose a PoSW that allows any verifier, even the one with
no parallelism, to verify using just a single sequential computation on a
single challenge. All the existing PoSWs [10, 5, 2, 6] mandate a prover to
compute a sequence of responses from a random oracle against N-rounds of
queries. Then the prover commits this sequence using a commitment scheme (e.g.,
Merkle root (like) commitment) predefined in the PoSWs. Now the verifier asks
the prover to provide a set of proofs against t randomly chosen checkpoints,
called challenges, in the computed sequence. The verifier finds out the
commitment from each of these proofs spending O(log N) rounds of queries to the
oracle. It can be reduced to a single round of queries only if the verifier
owns O(log N) parallelism [6]. The verifier in our PoSW demands no parallelism
but uses a single query to the random oracle in order to verify each of the t
challenges. The key observation is that the commitment schemes themselves in
the prior works demand O(log N ) oracle queries to verify.",2202.10295v2,cs.CR,2022-02-21 15:19:32+00:00,[arxiv.Result.Author('Souvik Sur')],
1544,Measurement-only verifiable blind quantum computing with quantum input verification,"Verifiable blind quantum computing is a secure delegated quantum computing
where a client with a limited quantum technology delegates her quantum
computing to a server who has a universal quantum computer. The client's
privacy is protected (blindness) and the correctness of the computation is
verifiable by the client in spite of her limited quantum technology
(verifiability). There are mainly two types of protocols for verifiable blind
quantum computing: the protocol where the client has only to generate
single-qubit states, and the protocol where the client needs only the ability
of single-qubit measurements. The latter is called the measurement-only
verifiable blind quantum computing. If the input of the client's quantum
computing is a quantum state whose classical efficient description is not known
to the client, there was no way for the measurement-only client to verify the
correctness of the input. Here we introduce a new protocol of measurement-only
verifiable blind quantum computing where the correctness of the quantum input
is also verifiable.",1606.06467v1,quant-ph,2016-06-21 08:09:05+00:00,[arxiv.Result.Author('Tomoyuki Morimae')],"Phys. Rev. A 94, 042301 (2016)"
1545,Practical and Verifiable Electronic Sortition,"Existing verifiable e-sortition systems are impractical due to
computationally expensive verification (linear to the duration of the
registration phase, T) or the ease of being denial of service. Based on the
advance in verifiable delay functions, we propose a verifiable e-sortition
scheme whose result can be efficiently verified in constant time with respect
to T. We present the preliminary design and implementation, and explore future
directions to further enhance practicability.",2006.13920v1,cs.CR,2020-06-24 17:49:21+00:00,"[arxiv.Result.Author('Hsun Lee'), arxiv.Result.Author('Hsu-Chun Hsiao')]",
1546,Quantum state and circuit distinguishability with single-qubit measurements,"We show that the Quantum State Distinguishability (QSD), which is a
QSZK-complete problem, and the Quantum Circuit Distinguishability (QCD), which
is a QIP-complete problem, can be solved by the verifier who can perform only
single-qubit measurements. To show these results, we use measurement-based
quantum computing: the honest prover sends a graph state to the verifier, and
the verifier can perform universal quantum computing on it with only
single-qubit measurements. If the prover is malicious, he does not necessarily
generate the correct graph state, but the verifier can verify the correctness
of the graph state by measuring the stabilizer operators.",1607.00574v1,quant-ph,2016-07-03 01:18:09+00:00,[arxiv.Result.Author('Tomoyuki Morimae')],
1547,Verifiable Computations with RAM-like Running Times,"Current and emerging trends such as cloud computing, fog computing, and more
recently, multi-access edge computing (MEC) increase the interest in finding
solutions to the verifiable computation problem. Furthermore, the number of
computationally weak devices have increased drastically in recent years due to
the ongoing realization of the Internet of Things. This work proposes a
solution which enjoys the following two desirable properties: (1) cost of input
preparation and verification is very low (low enough to allow verifiable
outsourcing of computations by resource-constrained devices on constrained
networks); (2) the running time of the verifiable computation is RAM-like.",1809.04174v1,cs.CR,2018-09-11 21:22:37+00:00,[arxiv.Result.Author('Tahsin Civan Mert Dönmez')],
1548,Distributed Verifiers in PCP,"Traditional proof systems involve a resource-bounded verifier communicating
with a powerful (but untrusted) prover. Distributed verifier proof systems are
a new family of proof models that involve a network of verifier nodes
communicating with a single independent prover that has access to the complete
network structure of the verifiers. The prover is tasked with convincing all
verifiers of some global property of the network graph. In addition, each
individual verifier may be given some input string they will be required to
verify during the course of computation. Verifier nodes are allowed to exchange
messaged with nodes a constant distance away, and accept / reject the input
after some computation.
  Because individual nodes are limited to a local view, communication with the
prover is potentially necessary to prove global properties about the network
graph of nodes, which only the prover has access to. In this system of models,
the entire model accepts the input if and only if every individual node has
accepted.
  There are three models in the distributed verifier proof system family:
$\mathsf{LCP}$, $\mathsf{dIP}$, and our proposed $\mathsf{dPCP}$, with the
fundamental difference between these coming from the type of communication
established between the verifiers and the prover. In this paper, we will first
go over the past work in the $\mathsf{LCP}$ and $\mathsf{dIP}$ space before
showing properties and proofs in our $\mathsf{dPCP}$ system.",2005.10749v1,cs.CC,2020-05-21 16:01:09+00:00,"[arxiv.Result.Author('Nagaganesh Jaladanki'), arxiv.Result.Author('Wilson Wu')]",
1549,Training verified learners with learned verifiers,"This paper proposes a new algorithmic framework, predictor-verifier training,
to train neural networks that are verifiable, i.e., networks that provably
satisfy some desired input-output properties. The key idea is to simultaneously
train two networks: a predictor network that performs the task at hand,e.g.,
predicting labels given inputs, and a verifier network that computes a bound on
how well the predictor satisfies the properties being verified. Both networks
can be trained simultaneously to optimize a weighted combination of the
standard data-fitting loss and a term that bounds the maximum violation of the
property. Experiments show that not only is the predictor-verifier architecture
able to train networks to achieve state of the art verified robustness to
adversarial examples with much shorter training times (outperforming previous
algorithms on small datasets like MNIST and SVHN), but it can also be scaled to
produce the first known (to the best of our knowledge) verifiably robust
networks for CIFAR-10.",1805.10265v2,cs.LG,2018-05-25 17:35:39+00:00,"[arxiv.Result.Author('Krishnamurthy Dvijotham'), arxiv.Result.Author('Sven Gowal'), arxiv.Result.Author('Robert Stanforth'), arxiv.Result.Author('Relja Arandjelovic'), arxiv.Result.Author(""Brendan O'Donoghue""), arxiv.Result.Author('Jonathan Uesato'), arxiv.Result.Author('Pushmeet Kohli')]",
1550,Verifiable Computation with Massively Parallel Interactive Proofs,"As the cloud computing paradigm has gained prominence, the need for
verifiable computation has grown increasingly urgent. The concept of verifiable
computation enables a weak client to outsource difficult computations to a
powerful, but untrusted, server. Protocols for verifiable computation aim to
provide the client with a guarantee that the server performed the requested
computations correctly, without requiring the client to perform the
computations herself. By design, these protocols impose a minimal computational
burden on the client. However, existing protocols require the server to perform
a large amount of extra bookkeeping in order to enable a client to easily
verify the results. Verifiable computation has thus remained a theoretical
curiosity, and protocols for it have not been implemented in real cloud
computing systems.
  Our goal is to leverage GPUs to reduce the server-side slowdown for
verifiable computation. To this end, we identify abundant data parallelism in a
state-of-the-art general-purpose protocol for verifiable computation,
originally due to Goldwasser, Kalai, and Rothblum, and recently extended by
Cormode, Mitzenmacher, and Thaler. We implement this protocol on the GPU,
obtaining 40-120x server-side speedups relative to a state-of-the-art
sequential implementation. For benchmark problems, our implementation reduces
the slowdown of the server to factors of 100-500x relative to the original
computations requested by the client. Furthermore, we reduce the already small
runtime of the client by 100x. Similarly, we obtain 20-50x server-side and
client-side speedups for related protocols targeted at specific streaming
problems. We believe our results demonstrate the immediate practicality of
using GPUs for verifiable computation, and more generally that protocols for
verifiable computation have become sufficiently mature to deploy in real cloud
computing systems.",1202.1350v3,cs.DC,2012-02-07 04:42:49+00:00,"[arxiv.Result.Author('Justin Thaler'), arxiv.Result.Author('Mike Roberts'), arxiv.Result.Author('Michael Mitzenmacher'), arxiv.Result.Author('Hanspeter Pfister')]",
1551,"Verifier-on-a-Leash: new schemes for verifiable delegated quantum computation, with quasilinear resources","The problem of reliably certifying the outcome of a computation performed by
a quantum device is rapidly gaining relevance. We present two protocols for a
classical verifier to verifiably delegate a quantum computation to two
non-communicating but entangled quantum provers. Our protocols have
near-optimal complexity in terms of the total resources employed by the
verifier and the honest provers, with the total number of operations of each
party, including the number of entangled pairs of qubits required of the honest
provers, scaling as $O(g\log g)$ for delegating a circuit of size $g$. This is
in contrast to previous protocols, which all require a prohibitively large
polynomial overhead. Our first protocol requires a number of rounds that is
linear in the depth of the circuit being delegated, and is blind, meaning
neither prover can learn the circuit being delegated. The second protocol is
not blind, but requires only a constant number of rounds of interaction. Our
main technical innovation is an efficient rigidity theorem which allows a
verifier to test that two entangled provers perform measurements specified by
an arbitrary $m$-qubit tensor product of single-qubit Clifford observables on
their respective halves of $m$ shared EPR pairs, with a robustness that is
independent of $m$. Our two-prover classical-verifier delegation protocols are
obtained by combining this rigidity theorem with a single-prover
quantum-verifier protocol for the verifiable delegation of a quantum
computation, introduced by Broadbent (Theory of Computing, 2018).",1708.07359v3,quant-ph,2017-08-24 11:48:25+00:00,"[arxiv.Result.Author('Andrea Coladangelo'), arxiv.Result.Author('Alex Grilo'), arxiv.Result.Author('Stacey Jeffery'), arxiv.Result.Author('Thomas Vidick')]",
1552,Quantum Certificate Verification: Single versus Multiple Quantum Certificates,"The class MA consists of languages that can be efficiently verified by
classical probabilistic verifiers using a single classical certificate, and the
class QMA consists of languages that can be efficiently verified by quantum
verifiers using a single quantum certificate. Suppose that a verifier receives
not only one but multiple certificates. In the classical setting, it is obvious
that a classical verifier with multiple classical certificates is essentially
the same with the one with a single classical certificate. However, in the
quantum setting where a quantum verifier is given a set of quantum certificates
in tensor product form (i.e. each quantum certificate is not entangled with
others), the situation is different, because the quantum verifier might utilize
the structure of the tensor product form. This suggests a possibility of
another hierarchy of complexity classes, namely the QMA hierarchy. From this
point of view, we extend the definition of QMA to QMA(k) for the case quantum
verifiers use k quantum certificates, and analyze the properties of QMA(k).
  To compare the power of QMA(2) with that of QMA(1) = QMA, we show one
interesting property of ``quantum indistinguishability''. This gives a strong
evidence that QMA(2) is more powerful than QMA(1). Furthermore, we show that,
for any fixed positive integer $k \geq 2$, if a language L has a one-sided
bounded error QMA(k) protocol with a quantum verifier using k quantum
certificates, L necessarily has a one-sided bounded error QMA(2) protocol with
a quantum verifier using only two quantum certificates.",quant-ph/0110006v1,quant-ph,2001-10-01 10:05:26+00:00,"[arxiv.Result.Author('Hirotada Kobayashi'), arxiv.Result.Author('Keiji Matsumoto'), arxiv.Result.Author('Tomoyuki Yamakami')]",
1553,Neural Network Verification using Residual Reasoning,"With the increasing integration of neural networks as components in
mission-critical systems, there is an increasing need to ensure that they
satisfy various safety and liveness requirements. In recent years, numerous
sound and complete verification methods have been proposed towards that end,
but these typically suffer from severe scalability limitations. Recent work has
proposed enhancing such verification techniques with abstraction-refinement
capabilities, which have been shown to boost scalability: instead of verifying
a large and complex network, the verifier constructs and then verifies a much
smaller network, whose correctness implies the correctness of the original
network. A shortcoming of such a scheme is that if verifying the smaller
network fails, the verifier needs to perform a refinement step that increases
the size of the network being verified, and then start verifying the new
network from scratch - effectively ""wasting"" its earlier work on verifying the
smaller network. In this paper, we present an enhancement to abstraction-based
verification of neural networks, by using residual reasoning: the process of
utilizing information acquired when verifying an abstract network, in order to
expedite the verification of a refined network. In essence, the method allows
the verifier to store information about parts of the search space in which the
refined network is guaranteed to behave correctly, and allows it to focus on
areas where bugs might be discovered. We implemented our approach as an
extension to the Marabou verifier, and obtained promising results.",2208.03083v2,cs.NE,2022-08-05 10:39:04+00:00,"[arxiv.Result.Author('Yizhak Yisrael Elboher'), arxiv.Result.Author('Elazar Cohen'), arxiv.Result.Author('Guy Katz')]",
1554,Secure and Verifiable Electronic Voting in Practice: the use of vVote in the Victorian State Election,"The November 2014 Australian State of Victoria election was the first
statutory political election worldwide at State level which deployed an
end-to-end verifiable electronic voting system in polling places. This was the
first time blind voters have been able to cast a fully secret ballot in a
verifiable way, and the first time a verifiable voting system has been used to
collect remote votes in a political election. The code is open source, and the
output from the election is verifiable. The system took 1121 votes from these
particular groups, an increase on 2010 and with fewer polling places.",1504.07098v1,cs.CR,2015-04-27 14:08:24+00:00,"[arxiv.Result.Author('Craig Burton'), arxiv.Result.Author('Chris Culnane'), arxiv.Result.Author('Steve Schneider')]",
1555,Multi-Matrix Verifiable Computation,"The problem of securely outsourcing computation to cloud servers has
attracted a large amount of attention in recent years. The verifiable
computation of Gennaro, Gentry, Parno (Crypto'10) allows a client to verify the
server's computation of a function with substantially less time than performing
the outsourced computation from scratch. In a multi-function model (Parno,
Raykova, Vaikuntanathan; TCC'12) of verifiable computation, the process of
encoding function and the process of preparing input are decoupled such that
any client can freely submit a computation request on its input, without having
to generate an encoding of the function in advance. In this paper, we propose a
multi-matrix verifiable computation scheme that allows the secure outsourcing
of the matrix functions over a finite field. Our scheme is outsourceable. When
it is used to outsource $m$ linear functions, the scheme is roughly $m$ times
faster and has less communication cost than the previously best known scheme by
Fiore and Gennaro (CCS'12), both in the client-side computation and in the
server-side computation. We also show the cost saving with detailed
implementations.",2104.14851v1,cs.CR,2021-04-30 09:10:18+00:00,"[arxiv.Result.Author('Yan He'), arxiv.Result.Author('Liang Feng Zhang')]",
1556,Combining Symbolic Execution and Model Checking to Verify MPI Programs,"Message passing is the standard paradigm of programming in high-performance
computing. However, verifying Message Passing Interface (MPI) programs is
challenging, due to the complex program features (such as non-determinism and
non-blocking operations). In this work, we present MPI symbolic verifier
(MPI-SV), the first symbolic execution based tool for automatically verifying
MPI programs with non-blocking operations. MPI-SV combines symbolic execution
and model checking in a synergistic way to tackle the challenges in MPI program
verification. The synergy improves the scalability and enlarges the scope of
verifiable properties. We have implemented MPI-SV (footnote:
https://mpi-sv.github.io) and evaluated it with 111 real-world MPI verification
tasks. The pure symbolic execution-based technique successfully verifies 61 out
of the 111 tasks (55\%) within one hour, while in comparison, MPI-SV verifies
100 tasks (90\%). On average, compared with pure symbolic execution, MPI-SV
achieves 19x speedups on verifying the satisfaction of the critical property
and 5x speedups on finding violations.",1803.06300v2,cs.PL,2018-03-16 16:33:35+00:00,"[arxiv.Result.Author('Hengbiao Yu'), arxiv.Result.Author('Zhenbang Chen'), arxiv.Result.Author('Xianjin Fu'), arxiv.Result.Author('Ji Wang'), arxiv.Result.Author('Zhendong Su'), arxiv.Result.Author('Jun Sun'), arxiv.Result.Author('Chun Huang'), arxiv.Result.Author('Wei Dong')]",
1557,A Protocol for Generating Random Elements with their Probabilities,"We give an AM protocol that allows the verifier to sample elements x from a
probability distribution P, which is held by the prover. If the prover is
honest, the verifier outputs (x, P(x)) with probability close to P(x). In case
the prover is dishonest, one may hope for the following guarantee: if the
verifier outputs (x, p), then the probability that the verifier outputs x is
close to p. Simple examples show that this cannot be achieved. Instead, we show
that the following weaker condition holds (in a well defined sense) on average:
If (x, p) is output, then p is an upper bound on the probability that x is
output. Our protocol yields a new transformation to turn interactive proofs
where the verifier uses private random coins into proofs with public coins. The
verifier has better running time compared to the well-known Goldwasser-Sipser
transformation (STOC, 1986). For constant-round protocols, we only lose an
arbitrarily small constant in soundness and completeness, while our public-coin
verifier calls the private-coin verifier only once.",1312.2483v2,cs.CC,2013-12-09 16:02:40+00:00,"[arxiv.Result.Author('Thomas Holenstein'), arxiv.Result.Author('Robin Künzler')]",
1558,Learning to Give Checkable Answers with Prover-Verifier Games,"Our ability to know when to trust the decisions made by machine learning
systems has not kept up with the staggering improvements in their performance,
limiting their applicability in high-stakes domains. We introduce
Prover-Verifier Games (PVGs), a game-theoretic framework to encourage learning
agents to solve decision problems in a verifiable manner. The PVG consists of
two learners with competing objectives: a trusted verifier network tries to
choose the correct answer, and a more powerful but untrusted prover network
attempts to persuade the verifier of a particular answer, regardless of its
correctness. The goal is for a reliable justification protocol to emerge from
this game. We analyze variants of the framework, including simultaneous and
sequential games, and narrow the space down to a subset of games which provably
have the desired equilibria. We develop instantiations of the PVG for two
algorithmic tasks, and show that in practice, the verifier learns a robust
decision rule that is able to receive useful and reliable information from an
untrusted prover. Importantly, the protocol still works even when the verifier
is frozen and the prover's messages are directly optimized to convince the
verifier.",2108.12099v1,cs.LG,2021-08-27 02:56:06+00:00,"[arxiv.Result.Author('Cem Anil'), arxiv.Result.Author('Guodong Zhang'), arxiv.Result.Author('Yuhuai Wu'), arxiv.Result.Author('Roger Grosse')]",
1559,On optimising quantum communication in verifiable quantum computing,"In the absence of any efficient classical schemes for verifying a universal
quantum computer, the importance of limiting the required quantum resources for
this task has been highlighted recently. Currently, most of efficient quantum
verification protocols are based on cryptographic techniques where an almost
classical verifier executes her desired encrypted quantum computation remotely
on an untrusted quantum prover. In this work we present a new protocol for
quantum verification by incorporating existing techniques in a non-standard
composition to reduce the required quantum communications between the verifier
and the prover.",1506.06943v1,quant-ph,2015-06-23 11:09:59+00:00,"[arxiv.Result.Author('Theodoros Kapourniotis'), arxiv.Result.Author('Vedran Dunjko'), arxiv.Result.Author('Elham Kashefi')]",
1560,Classical Verification of Quantum Computations,"We present the first protocol allowing a classical computer to interactively
verify the result of an efficient quantum computation. We achieve this by
constructing a measurement protocol, which enables a classical verifier to use
a quantum prover as a trusted measurement device. The protocol forces the
prover to behave as follows: the prover must construct an n qubit state of his
choice, measure each qubit in the Hadamard or standard basis as directed by the
verifier, and report the measurement results to the verifier. The soundness of
this protocol is enforced based on the assumption that the learning with errors
problem is computationally intractable for efficient quantum machines.",1804.01082v2,quant-ph,2018-04-03 17:53:05+00:00,[arxiv.Result.Author('Urmila Mahadev')],
1561,Interactive Verifiable Polynomial Evaluation,"Cloud computing platforms have created the possibility for computationally
limited users to delegate demanding tasks to strong but untrusted servers.
Verifiable computing algorithms help build trust in such interactions by
enabling the server to provide a proof of correctness of his results which the
user can check very efficiently. In this paper, we present a doubly-efficient
interactive algorithm for verifiable polynomial evaluation. Unlike the
mainstream literature on verifiable computing, the soundness of our algorithm
is information-theoretic and cannot be broken by a computationally unbounded
server. By relying on basic properties of error correcting codes, our algorithm
enforces a dishonest server to provide false results to problems which become
progressively easier to verify. After roughly $\log d$ rounds, the user can
verify the response of the server against a look-up table that has been
pre-computed during an initialization phase. For a polynomial of degree $d$, we
achieve a user complexity of $O(d^{\epsilon})$, a server complexity of
$O(d^{1+\epsilon})$, a round complexity of $O(\log d)$ and an initialization
complexity of $O(d^{1+\epsilon})$.",1907.04302v1,cs.CC,2019-07-09 17:40:46+00:00,"[arxiv.Result.Author('Saeid Sahraei'), arxiv.Result.Author('Mohammad Ali Maddah-Ali'), arxiv.Result.Author('Salman Avestimehr')]",
1562,Convergence Analysis of Distributed Stochastic Gradient Descent with Shuffling,"When using stochastic gradient descent to solve large-scale machine learning
problems, a common practice of data processing is to shuffle the training data,
partition the data across multiple machines if needed, and then perform several
epochs of training on the re-shuffled (either locally or globally) data. The
above procedure makes the instances used to compute the gradients no longer
independently sampled from the training data set. Then does the distributed SGD
method have desirable convergence properties in this practical situation? In
this paper, we give answers to this question. First, we give a mathematical
formulation for the practical data processing procedure in distributed machine
learning, which we call data partition with global/local shuffling. We observe
that global shuffling is equivalent to without-replacement sampling if the
shuffling operations are independent. We prove that SGD with global shuffling
has convergence guarantee in both convex and non-convex cases. An interesting
finding is that, the non-convex tasks like deep learning are more suitable to
apply shuffling comparing to the convex tasks. Second, we conduct the
convergence analysis for SGD with local shuffling. The convergence rate for
local shuffling is slower than that for global shuffling, since it will lose
some information if there's no communication between partitioned data. Finally,
we consider the situation when the permutation after shuffling is not uniformly
distributed (insufficient shuffling), and discuss the condition under which
this insufficiency will not influence the convergence rate. Our theoretical
results provide important insights to large-scale machine learning, especially
in the selection of data processing methods in order to achieve faster
convergence and good speedup. Our theoretical findings are verified by
extensive experiments on logistic regression and deep neural networks.",1709.10432v1,stat.ML,2017-09-29 14:44:05+00:00,"[arxiv.Result.Author('Qi Meng'), arxiv.Result.Author('Wei Chen'), arxiv.Result.Author('Yue Wang'), arxiv.Result.Author('Zhi-Ming Ma'), arxiv.Result.Author('Tie-Yan Liu')]",
1563,Infinite Self-Shuffling Words,"In this paper we introduce and study a new property of infinite words: An
infinite word $x\in A^\mathbb{N}$, with values in a finite set $A$, is said to
be $k$-self-shuffling $(k\geq 2)$ if $x$ admits factorizations:
$x=\prod_{i=0}^\infty U_i^{(1)}\cdots U_i^{(k)}=\prod_{i=0}^\infty
U_i^{(1)}=\cdots =\prod_{i=0}^\infty U_i^{(k)}$. In other words, there exists a
shuffle of $k$-copies of $x$ which produces $x$. We are particularly interested
in the case $k=2$, in which case we say $x$ is self-shuffling. This property of
infinite words is shown to be an intrinsic property of the word and not of its
language (set of factors). For instance, every aperiodic word contains a non
self-shuffling word in its shift orbit closure. While the property of being
self-shuffling is a relatively strong condition, many important words arising
in the area of symbolic dynamics are verified to be self-shuffling. They
include for instance the Thue-Morse word and all Sturmian words of intercept
$0<\rho <1$ (while those of intercept $\rho=0$ are not self-shuffling). Our
characterization of self-shuffling Sturmian words can be interpreted
arithmetically in terms of a dynamical embedding and defines an arithmetic
process we call the {\it stepping stone model}. One important feature of
self-shuffling words stems from its morphic invariance, which provides a useful
tool for showing that one word is not the morphic image of another. The notion
of self-shuffling has other unexpected applications particularly in the area of
substitutive dynamical systems. For example, as a consequence of our
characterization of self-shuffling Sturmian words, we recover a number
theoretic result, originally due to Yasutomi, on a classification of pure
morphic Sturmian words in the orbit of the characteristic.",1302.3844v3,math.CO,2013-02-15 18:42:20+00:00,"[arxiv.Result.Author('Émilie Charlier'), arxiv.Result.Author('Teturo Kamae'), arxiv.Result.Author('Svetlana Puzynina'), arxiv.Result.Author('Luca Q. Zamboni')]","J. Comb. Theory, Ser. A 128: 1-40 (2014)"
1564,Shuffle-QUDIO: accelerate distributed VQE with trainability enhancement and measurement reduction,"The variational quantum eigensolver (VQE) is a leading strategy that exploits
noisy intermediate-scale quantum (NISQ) machines to tackle chemical problems
outperforming classical approaches. To gain such computational advantages on
large-scale problems, a feasible solution is the QUantum DIstributed
Optimization (QUDIO) scheme, which partitions the original problem into $K$
subproblems and allocates them to $K$ quantum machines followed by the parallel
optimization. Despite the provable acceleration ratio, the efficiency of QUDIO
may heavily degrade by the synchronization operation. To conquer this issue,
here we propose Shuffle-QUDIO to involve shuffle operations into local
Hamiltonians during the quantum distributed optimization. Compared with QUDIO,
Shuffle-QUDIO significantly reduces the communication frequency among quantum
processors and simultaneously achieves better trainability. Particularly, we
prove that Shuffle-QUDIO enables a faster convergence rate over QUDIO.
Extensive numerical experiments are conducted to verify that Shuffle-QUDIO
allows both a wall-clock time speedup and low approximation error in the tasks
of estimating the ground state energy of molecule. We empirically demonstrate
that our proposal can be seamlessly integrated with other acceleration
techniques, such as operator grouping, to further improve the efficacy of VQE.",2209.12454v1,quant-ph,2022-09-26 06:51:20+00:00,"[arxiv.Result.Author('Yang Qian'), arxiv.Result.Author('Yuxuan Du'), arxiv.Result.Author('Dacheng Tao')]",
1565,A Non-Disjoint Group Shuffled Decoding for LDPC Codes,"To reduce the implementation complexity of a belief propagation (BP) based
low-density parity-check (LDPC) decoder, shuffled BP decoding schedules, which
serialize the decoding process by dividing a complete parallel message-passing
iteration into a sequence of sub-iterations, have been proposed. The so-called
group horizontal shuffled BP algorithm partitions the check nodes of the code
graph into groups to perform group-by-group message-passing decoding. This
paper proposes a new grouping technique to accelerate the message-passing rate.
Performance of the proposed algorithm is analyzed by a Gaussian approximation
approach. Both analysis and numerical experiments verify that the new algorithm
does yield a convergence rate faster than that of existing conventional or
group shuffled BP decoder with the same computing complexity constraint.",1202.1060v1,cs.IT,2012-02-06 07:27:02+00:00,"[arxiv.Result.Author('Yen-Cheng Hsu'), arxiv.Result.Author('Tofar C. -Y. Chang'), arxiv.Result.Author('Yu T. Su'), arxiv.Result.Author('Jian-Jia Weng')]",
1566,A Description and Proof of a Generalised and Optimised Variant of Wikström's Mixnet,"In this paper, we describe an optimised variant of Wikstr\""om's mixnet which
shuffles vectors of ElGamal ciphertexts in parallel. We then show in detail
that this construction is secure. Wikstr\""om's verifiable mixnet as we refer to
it here was first presented in ""Proofs of Restricted Shuffles"" by Terelius and
Wikstr\""om, building on Wikstr\""om's previous work. Specifically we take the
optimised variant for ElGamal which appears to be in common use; for instance,
it is presented in Haenni et al's ""Pseudo-Code Algorithms for Verifiable
Re-Encryption Mix-Nets"". We extend the mixnet to support parallel shuffles.
(The possibility of doing this is proven by the Wikstr\""om's result but we wish
to show that this particular instance with its optimisations is secure.)",1901.08371v1,cs.CR,2019-01-24 11:59:19+00:00,[arxiv.Result.Author('Thomas Haines')],
1567,Computing a pyramid partition generating function with dimer shuffling,"We verify a recent conjecture of Kenyon/Szendroi, arXiv:0705.3419, by
computing the generating function for pyramid partitions. Pyramid partitions
are closely related to Aztec Diamonds; their generating function turns out to
be the partition function for the Donaldson--Thomas theory of a non-commutative
resolution of the conifold singularity {x1x2 -x3x4 = 0}. The proof does not
require algebraic geometry; it uses a modified version of the domino shuffling
algorithm of Elkies, Kuperberg, Larsen and Propp.",0709.3079v2,math.CO,2007-09-19 17:57:16+00:00,[arxiv.Result.Author('Benjamin Young')],
1568,"AugShuffleNet: Communicate More, Compute Less","As a remarkable compact model, ShuffleNetV2 offers a good example to design
efficient ConvNets but its limit is rarely noticed. In this paper, we rethink
the design pattern of ShuffleNetV2 and find that the channel-wise redundancy
problem still constrains the efficiency improvement of Shuffle block in the
wider ShuffleNetV2. To resolve this issue, we propose another augmented variant
of shuffle block in the form of bottleneck-like structure and more implicit
short connections. To verify the effectiveness of this building block, we
further build a more powerful and efficient model family, termed as
AugShuffleNets. Evaluated on the CIFAR-10 and CIFAR-100 datasets, AugShuffleNet
consistently outperforms ShuffleNetV2 in terms of accuracy with less
computational cost and fewer parameter count.",2203.06589v2,cs.CV,2022-03-13 07:01:23+00:00,[arxiv.Result.Author('Longqing Ye')],
1569,"An exotic shuffle relation of $ζ(\{2\}^m)$ and $ζ(\{3,1\}^n)$","In this short note we will provide a new and shorter proof of the following
exotic shuffle relation of multiple zeta values:
  $$\zeta(\{2\}^m \sha\{3,1\}^n)={2n+m\choose m}
  \frac{\pi^{4n+2m}}{(2n+1)\cdot (4n+2m+1)!}.$$ This was proved by Zagier when
n=0, by Broadhurst when $m=0$, and by Borwein, Bradley, and Broadhurst when
m=1. In general this was proved by Bowman and Bradley in \emph{The algebra and
combinatorics of shuffles and multiple zeta values}, J. of Combinatorial
Theory, Series A, Vol. \textbf{97} (1)(2002), 43--63. Our idea in the general
case is to use the method of Borwein et al. to reduce the above general
relation to some families of combinatorial identities which can be verified by
WZ-method.",0707.3244v1,math.NT,2007-07-23 10:34:21+00:00,[arxiv.Result.Author('Jianqiang Zhao')],"Arch. Math. (Basel) 91 (5)(2008), pp. 409-415"
1570,Improved mixing time bounds for the Thorp shuffle and L-reversal chain,"We prove a theorem that reduces bounding the mixing time of a card shuffle to
verifying a condition that involves only pairs of cards, then we use it to
obtain improved bounds for two previously studied models.
  E. Thorp introduced the following card shuffling model in 1973. Suppose the
number of cards n is even. Cut the deck into two equal piles. Drop the first
card from the left pile or from the right pile according to the outcome of a
fair coin flip. Then drop from the other pile. Continue this way until both
piles are empty. We obtain a mixing time bound of O(log^4 n). Previously, the
best known bound was O(log^{29} n) and previous proofs were only valid for n a
power of 2.
  We also analyze the following model, called the L-reversal chain, introduced
by Durrett. There are n cards arrayed in a circle. Each step, an interval of
cards of length at most L is chosen uniformly at random and its order is
reversed. Durrett has conjectured that the mixing time is O(max(n, n^3/L^3) log
n). We obtain a bound that is within a factor O(log^2 n) of this,the first
bound within a poly log factor of the conjecture.",0802.0339v1,math.PR,2008-02-04 06:44:31+00:00,[arxiv.Result.Author('Ben Morris')],
1571,Verifying Handcoded Probabilistic Inference Procedures,"Researchers have recently proposed several systems that ease the process of
performing Bayesian probabilistic inference. These include systems for
automatic inference algorithm synthesis as well as stronger abstractions for
manual algorithm development. However, existing systems whose performance
relies on the developer manually constructing a part of the inference algorithm
have limited support for reasoning about the correctness of the resulting
algorithm.
  In this paper, we present Shuffle, a programming language for manually
developing inference procedures that 1) enforces the basic rules of probability
theory, 2) enforces the statistical dependencies of the algorithm's
corresponding probabilistic model, and 3) generates an optimized
implementation. We have used Shuffle to develop inference algorithms for
several standard probabilistic models. Our results demonstrate that Shuffle
enables a developer to deliver correct and performant implementations of these
algorithms.",1805.01863v1,cs.PL,2018-05-04 17:13:15+00:00,"[arxiv.Result.Author('Eric Atkinson'), arxiv.Result.Author('Cambridge Yang'), arxiv.Result.Author('Michael Carbin')]",
1572,Computations about formal multiple zeta spaces defined by binary extended double shuffle relations,"The formal multiple zeta space we consider with a computer is an
$\mathbb{F}_2$-vector space generated by $2^{k-2}$ formal symbols for a given
weight $k$, where the symbols satisfy binary extended double shuffle relations.
Up to weight $k=22$, we compute the dimensions of the formal multiple zeta
spaces, and verify the dimension conjecture on original extended double shuffle
relations of real multiple zeta values. Our computations adopt Gaussian forward
elimination and give information for spaces filtered by depth. We can observe
that the dimensions of the depth-graded formal multiple zeta spaces have a
Pascal triangle pattern expected by the Hoffman mult-indices.",2205.13751v3,math.NT,2022-05-27 03:30:54+00:00,[arxiv.Result.Author('Tomoya Machide')],
1573,Automorphism Shuffles for Graphs and Hypergraphs and Its Applications,"In card-based cryptography, a deck of physical cards is used to achieve
secure computation. A shuffle, which randomly permutes a card-sequence along
with some probability distribution, ensures the security of a card-based
protocol. The authors proposed a new class of shuffles called graph shuffles,
which randomly permutes a card-sequence by an automorphism of a directed graph
(New Generation Computing 2022). For a directed graph $G$ with $n$ vertices and
$m$ edges, such a shuffle could be implemented with pile-scramble shuffles with
$2(n+m)$ cards. In this paper, we study graph shuffles and give an
implementation, an application, and a slight generalization of them. First, we
propose a new protocol for graph shuffles with $2n+m$ cards. Second, as a new
application of graph shuffles, we show that any cyclic group shuffle, which is
a shuffle over a cyclic group, is a graph shuffle associated with some graph.
Third, we define a hypergraph shuffle, which is a shuffle by an automorphism of
a hypergraph, and show that any hypergraph shuffle can also be implemented with
pile-scramble shuffles.",2205.04774v2,cs.CR,2022-05-10 09:52:19+00:00,"[arxiv.Result.Author('Kazumasa Shinagawa'), arxiv.Result.Author('Kengo Miyamoto')]",
1574,Cyclic shuffle-compatibility via cyclic shuffle algebras,"A permutation statistic $\operatorname{st}$ is said to be shuffle-compatible
if the distribution of $\operatorname{st}$ over the set of shuffles of two
disjoint permutations $\pi$ and $\sigma$ depends only on
$\operatorname{st}\pi$, $\operatorname{st}\sigma$, and the lengths of $\pi$ and
$\sigma$. Shuffle-compatibility is implicit in Stanley's early work on
$P$-partitions, and was first explicitly studied by Gessel and Zhuang, who
developed an algebraic framework for shuffle-compatibility centered around
their notion of the shuffle algebra of a shuffle-compatible statistic. For a
family of statistics called descent statistics, these shuffle algebras are
isomorphic to quotients of the algebra of quasisymmetric functions.
  Recently, Domagalski, Liang, Minnich, Sagan, Schmidt, and Sietsma defined a
version of shuffle-compatibility for statistics on cyclic permutations, and
studied cyclic shuffle-compatibility through purely combinatorial means. In
this paper, we define the cyclic shuffle algebra of a cyclic shuffle-compatible
statistic, and develop an algebraic framework for cyclic shuffle-compatibility
in which the role of quasisymmetric functions is replaced by the cyclic
quasisymmetric functions recently introduced by Adin, Gessel, Reiner, and
Roichman. We use our theory to provide explicit descriptions for the cyclic
shuffle algebras of various cyclic permutation statistics, which in turn gives
algebraic proofs for their cyclic shuffle-compatibility.",2212.14522v1,math.CO,2022-12-30 02:49:43+00:00,"[arxiv.Result.Author('Jinting Liang'), arxiv.Result.Author('Bruce E. Sagan'), arxiv.Result.Author('Yan Zhuang')]",
1575,Shuffle Private Linear Contextual Bandits,"Differential privacy (DP) has been recently introduced to linear contextual
bandits to formally address the privacy concerns in its associated personalized
services to participating users (e.g., recommendations). Prior work largely
focus on two trust models of DP: the central model, where a central server is
responsible for protecting users sensitive data, and the (stronger) local
model, where information needs to be protected directly on user side. However,
there remains a fundamental gap in the utility achieved by learning algorithms
under these two privacy models, e.g., $\tilde{O}(\sqrt{T})$ regret in the
central model as compared to $\tilde{O}(T^{3/4})$ regret in the local model, if
all users are unique within a learning horizon $T$. In this work, we aim to
achieve a stronger model of trust than the central model, while suffering a
smaller regret than the local model by considering recently popular shuffle
model of privacy. We propose a general algorithmic framework for linear
contextual bandits under the shuffle trust model, where there exists a trusted
shuffler in between users and the central server, that randomly permutes a
batch of users data before sending those to the server. We then instantiate
this framework with two specific shuffle protocols: one relying on privacy
amplification of local mechanisms, and another incorporating a protocol for
summing vectors and matrices of bounded norms. We prove that both these
instantiations lead to regret guarantees that significantly improve on that of
the local model, and can potentially be of the order $\tilde{O}(T^{3/5})$ if
all users are unique. We also verify this regret behavior with simulations on
synthetic data. Finally, under the practical scenario of non-unique users, we
show that the regret of our shuffle private algorithm scale as
$\tilde{O}(T^{2/3})$, which matches that the central model could achieve in
this case.",2202.05567v1,cs.LG,2022-02-11 11:53:22+00:00,"[arxiv.Result.Author('Sayak Ray Chowdhury'), arxiv.Result.Author('Xingyu Zhou')]",International Conference in Machine Learning (2022)
1576,A Formally Verified HOL Algebra for Dynamic Reliability Block Diagrams,"Dynamic reliability block diagrams (DRBDs) are introduced to overcome the
modeling limitations of traditional reliability block diagrams, such as the
inability to capture redundant components. However, so far there is no
algebraic framework that allows conducting the analysis of a given DRBD based
on its structure function and enables verifying its soundness using
higher-order logic (HOL) theorem proving. In this work, we propose a new
algebra to formally express the structure function and the reliability of a
DRBD with spare constructs based on basic system blocks and newly introduced
DRBD operators. We present several simplification properties that allow
reducing the structure of a given DRBD. We provide the HOL formalization of the
proposed algebra, and formally verify its corresponding properties using the
HOL4 theorem prover. This includes formally verifying generic reliability
expressions of the spare construct, series, parallel and deeper structures in
an extensible manner that allows verifying the reliability of complex systems.
Finally, we demonstrate the applicability of this algebra by formally analyzing
the terminal reliability analysis of a shuffle-exchange network in HOL4.",1908.01930v1,cs.LO,2019-08-06 02:13:34+00:00,"[arxiv.Result.Author('Yassmeen Elderhalli'), arxiv.Result.Author('Osman Hasan'), arxiv.Result.Author('Sofiene Tahar')]",
1577,Proactive Defense for Internet-of-Things: Integrating Moving Target Defense with Cyberdeception,"Resource constrained Internet-of-Things (IoT) devices are highly likely to be
compromised by attackers because strong security protections may not be
suitable to be deployed. This requires an alternative approach to protect
vulnerable components in IoT networks. In this paper, we propose an integrated
defense technique to achieve intrusion prevention by leveraging cyberdeception
(i.e., a decoy system) and moving target defense (i.e., network topology
shuffling). We verify the effectiveness and efficiency of our proposed
technique analytically based on a graphical security model in a software
defined networking (SDN)-based IoT network. We develop four strategies (i.e.,
fixed/random and adaptive/hybrid) to address ""when"" to perform network topology
shuffling and three strategies (i.e., genetic algorithm/decoy attack path-based
optimization/random) to address ""how"" to perform network topology shuffling on
a decoy-populated IoT network, and analyze which strategy can best achieve a
system goal such as prolonging the system lifetime, maximizing deception
effectiveness, maximizing service availability, or minimizing defense cost. Our
results demonstrate that a software defined IoT network running our intrusion
prevention technique at the optimal parameter setting prolongs system lifetime,
increases attack complexity of compromising critical nodes, and maintains
superior service availability compared with a counterpart IoT network without
running our intrusion prevention technique. Further, when given a single goal
or a multi-objective goal (e.g., maximizing the system lifetime and service
availability while minimizing the defense cost) as input, the best combination
of ""how"" and ""how"" strategies is identified for executing our proposed
technique under which the specified goal can be best achieved.",2005.04220v1,cs.CR,2020-05-08 09:30:19+00:00,"[arxiv.Result.Author('Mengmeng Ge'), arxiv.Result.Author('Jin-Hee Cho'), arxiv.Result.Author('Dong Seong Kim'), arxiv.Result.Author('Gaurav Dixit'), arxiv.Result.Author('Ing-Ray Chen')]",
1578,PUF-RLA: A PUF-based Reliable and Lightweight Authentication Protocol employing Binary String Shuffling,"Physically unclonable functions (PUFs) can be employed for device
identification, authentication, secret key storage, and other security tasks.
However, PUFs are susceptible to modeling attacks if a number of PUFs'
challenge-response pairs (CRPs) are exposed to the adversary. Furthermore, many
of the embedded devices requiring authentication have stringent resource
constraints and thus require a lightweight authentication mechanism. We propose
PUF-RLA, a PUF-based lightweight, highly reliable authentication scheme
employing binary string shuffling. The proposed scheme enhances the reliability
of PUF as well as alleviates the resource constraints by employing error
correction in the server instead of the device without compromising the
security. The proposed PUF-RLA is robust against brute force, replay, and
modeling attacks. In PUF-RLA, we introduce an inexpensive yet secure stream
authentication scheme inside the device which authenticates the server before
the underlying PUF can be invoked. This prevents an adversary from brute
forcing the device's PUF to acquire CRPs essentially locking out the device
from unauthorized model generation. Additionally, we also introduce a
lightweight CRP obfuscation mechanism involving XOR and shuffle operations.
Results and security analysis verify that the PUF-RLA is secure against brute
force, replay, and modeling attacks, and provides ~99% reliable authentication.
In addition, PUF-RLA provides a reduction of 63% and 74% for look-up tables
(LUTs) and register count, respectively, in FPGA compared to a recently
proposed approach while providing additional authentication advantages.",2007.09588v1,cs.CR,2020-07-19 04:24:38+00:00,"[arxiv.Result.Author('Mahmood Azhar Qureshi'), arxiv.Result.Author('Arslan Munir')]",
1579,Shuffle product formulas of multiple zeta values,"Using the combinatorial description of shuffle product, we prove or
reformulate several shuffle product formulas of multiple zeta values, including
a general formula of the shuffle product of two multiple zeta values, some
restricted shuffle product formulas of the product of two multiple zeta values,
and a restricted shuffle product formula of the product of $n$ multiple zeta
values.",1603.05786v2,math.NT,2016-03-18 07:44:04+00:00,"[arxiv.Result.Author('Zhonghua Li'), arxiv.Result.Author('Chen Qin')]",
1580,Dynamic Dependability Analysis of Shuffle-exchange Networks using HOL Theorem Proving,"Dynamic dependability models, such as dynamic fault trees (DFTs) and dynamic
reliability block diagrams (DRBDs), are introduced to overcome the modeling
limitations of traditional models. Recently, higher-order logic (HOL)
formalizations of both models have been conducted, which allow the analysis of
these models formally, within a theorem prover. In this report, we provide the
formal dynamic dependability analysis of shuffle-exchange networks, which are
multistage interconnection networks that are commonly used in multiprocessor
systems. We use DFTs and DRBDs to model the terminal, broadcast and network
reliability with dynamic spare gates and constructs in several generic
versions. We verify generic expressions of probability of failure and
reliability of these systems, which can be instantiated with any number of
system components and failure rates to reason about the failure behavior of
these networks.",1910.11203v1,cs.LO,2019-10-24 15:01:53+00:00,"[arxiv.Result.Author('Yassmeen Elderhalli'), arxiv.Result.Author('Osman Hasan'), arxiv.Result.Author('Sofiene Tahar')]",
1581,Discrete Distribution Estimation under User-level Local Differential Privacy,"We study discrete distribution estimation under user-level local differential
privacy (LDP). In user-level $\varepsilon$-LDP, each user has $m\ge1$ samples
and the privacy of all $m$ samples must be preserved simultaneously. We resolve
the following dilemma: While on the one hand having more samples per user
should provide more information about the underlying distribution, on the other
hand, guaranteeing the privacy of all $m$ samples should make the estimation
task more difficult. We obtain tight bounds for this problem under almost all
parameter regimes. Perhaps surprisingly, we show that in suitable parameter
regimes, having $m$ samples per user is equivalent to having $m$ times more
users, each with only one sample. Our results demonstrate interesting phase
transitions for $m$ and the privacy parameter $\varepsilon$ in the estimation
risk. Finally, connecting with recent results on shuffled DP, we show that
combined with random shuffling, our algorithm leads to optimal error guarantees
(up to logarithmic factors) under the central model of user-level DP in certain
parameter regimes. We provide several simulations to verify our theoretical
findings.",2211.03757v1,cs.LG,2022-11-07 18:29:32+00:00,"[arxiv.Result.Author('Jayadev Acharya'), arxiv.Result.Author('Yuhan Liu'), arxiv.Result.Author('Ziteng Sun')]",
1582,Molière radius measurement using a compact prototype of LumiCal in a test set-up,"The FCAL collaboration has performed a design study for luminometers at
future electronpositron colliders. Compact sampling calorimeters with precisely
positioned silicon sensors and a fast readout will reach the necessary
performance even in the presence of background from beamstrahlung and
two-photon processes. A prototype calorimeter has been built with special focus
on ultra-thin fully instrumented sensor planes to ensure a very small effective
Moli\`ere radius. Preliminary results of measurements in a 5 GeV electron beam
are presented.",1811.11432v1,physics.ins-det,2018-11-28 08:01:53+00:00,[arxiv.Result.Author('Veta Ghenescu')],
1583,Cutting out the middleman: measuring nuclear area in histopathology slides without segmentation,"The size of nuclei in histological preparations from excised breast tumors is
predictive of patient outcome (large nuclei indicate poor outcome).
Pathologists take into account nuclear size when performing breast cancer
grading. In addition, the mean nuclear area (MNA) has been shown to have
independent prognostic value. The straightforward approach to measuring nuclear
size is by performing nuclei segmentation. We hypothesize that given an image
of a tumor region with known nuclei locations, the area of the individual
nuclei and region statistics such as the MNA can be reliably computed directly
from the image data by employing a machine learning model, without the
intermediate step of nuclei segmentation. Towards this goal, we train a deep
convolutional neural network model that is applied locally at each nucleus
location, and can reliably measure the area of the individual nuclei and the
MNA. Furthermore, we show how such an approach can be extended to perform
combined nuclei detection and measurement, which is reminiscent of
granulometry.",1606.06127v1,cs.CV,2016-06-20 14:10:32+00:00,"[arxiv.Result.Author('Mitko Veta'), arxiv.Result.Author('Paul J. van Diest'), arxiv.Result.Author('Josien P. W. Pluim')]",
1584,Dynamical transitions between equilibria in a dissipative Klein-Gordon lattice,"We consider the energy landscape of a dissipative Klein-Gordon lattice with a
$\phi^4$ on-site potential. Our analysis is based on suitable energy arguments,
combined with a discrete version of the \L{}ojasiewicz inequality, in order to
justify the convergence to a single, nontrivial equilibrium for all initial
configurations of the lattice. Then, global bifurcation theory is explored, to
illustrate that in the discrete regime all linear states lead to nonlinear
generalizations of equilibrium states. Direct numerical simulations reveal the
rich structure of the equilibrium set, consisting of non-trivial topological
(kink-shaped) interpolations between the adjacent minima of the on-site
potential, and the wealth of dynamical convergence possibilities. These
dynamical evolution results also provide insight on the potential stability of
the equilibrium branches, and glimpses of the emerging global bifurcation
structure, elucidating the role of the interplay between discreteness,
nonlinearity and dissipation.",1809.07995v2,nlin.PS,2018-09-21 09:17:36+00:00,"[arxiv.Result.Author('D. J. Frantzeskakis'), arxiv.Result.Author('N. I. Karachalios'), arxiv.Result.Author('P. G. Kevrekidis'), arxiv.Result.Author('V. Koukouloyannis'), arxiv.Result.Author('K. Vetas')]",
1585,Excitation of Peregrine-type waveforms from vanishing initial conditions in the presence of periodic forcing,"We show by direct numerical simulations that spatiotemporally localized wave
forms, strongly reminiscent of the Peregrine rogue wave, can be excited by
vanishing initial conditions for the periodically driven nonlinear
Schr\""odinger equation. The emergence of the Peregrine-type waveforms can be
potentially justified, in terms of the existence and modulational instability
of spatially homogeneous solutions of the model, and the continuous dependence
of the localized initial data for small time intervals. We also comment on the
persistence of the above dynamics, under the presence of small damping effects,
and justify, that this behavior should be considered as far from approximations
of the corresponding integrable limit.",1811.09812v3,nlin.PS,2018-11-24 10:56:47+00:00,"[arxiv.Result.Author('Nikos I. Karachalios'), arxiv.Result.Author('Paris Kyriazopoulos'), arxiv.Result.Author('Konstantinos Vetas')]",
1586,Extreme wave events for a nonlinear Schrödinger equation with linear damping and Gaussian driving,"We perform a numerical study of the initial-boundary value problem, with
vanishing boundary conditions, of a driven nonlinear Schr\""odinger equation
(NLS) with linear damping and a Gaussian driver. We identify Peregrine-like
rogue waveforms, excited by two different types of vanishing initial data
decaying at an algebraic or exponential rate. The observed extreme events
emerge on top of a decaying support. Depending on the spatial/temporal scales
of the driver, the transient dynamics -- prior to the eventual decay of the
solutions -- may resemble the one in the semiclassical limit of the integrable
NLS, or may, e.g., lead to large-amplitude breather-like patterns. The effects
of the damping strength and driving amplitude, in suppressing or enhancing
respectively the relevant features, as well as of the phase of the driver in
the construction of a diverse array of spatiotemporal patterns, are numerically
analyzed.",1812.05439v3,nlin.PS,2018-12-12 11:33:08+00:00,"[arxiv.Result.Author('G. Fotopoulos'), arxiv.Result.Author('D. J. Frantzeskakis'), arxiv.Result.Author('N. I. Karachalios'), arxiv.Result.Author('P. G. Kevrekidis'), arxiv.Result.Author('V. Koukouloyannis'), arxiv.Result.Author('K. Vetas')]",
1587,Compact LumiCal prototype tests for future $e^+e^-$ colliders,"The FCAL collaboration is preparing large-scale prototypes of special
calorimeters to be used in the very forward region at future electron-positron
colliders for instant luminosity measurement and a precise measurement of
integrated luminosity and for assisting beam-tuning. LumiCal is designed as
silicon-tungsten sandwich calorimeter with very thin sensor planes to keep the
Moli\`ere radius small, thus facilitating the measurement of electron showers
in the presence of background. Dedicated FE electronics has been developed to
match the timing and dynamic range requirements. A partially instrumented
prototype was investigated in a 1 to 5 GeV electron beam at the DESY II
synchrotron. In the recent beam tests, a multi-plane compact prototype equipped
with thin detector planes fully assembled with readout electronics were
installed in 1 mm gaps between tungsten plates of one radiation length
thickness. High statistics data were used to perform sensor alignment, and to
measure the longitudinal and transversal shower development. In addition,
Geant4 MC simulations were done and compared to the data.",2112.01816v1,physics.ins-det,2021-12-03 10:01:49+00:00,[arxiv.Result.Author('Veta Ghenescu')],
1588,Collapse dynamics for the discrete nonlinear Schrödinger equation with gain and loss,"We discuss the finite-time collapse, also referred as blow-up, of the
solutions of a discrete nonlinear Schr\""{o}dinger (DNLS) equation incorporating
linear and nonlinear gain and loss. This DNLS system appears in many inherently
discrete physical contexts as a more realistic generalization of the
Hamiltonian DNLS lattice. By using energy arguments in finite and infinite
dimensional phase spaces (as guided by the boundary conditions imposed), we
prove analytical upper and lower bounds for the collapse time, valid for both
the defocusing and focusing cases of the model. In addition, the existence of a
critical value in the linear loss parameter is underlined, separating finite
time-collapse from energy decay. The numerical simulations, performed for a
wide class of initial data, not only verified the validity of our bounds, but
also revealed that the analytical bounds can be useful in identifying two
distinct types of collapse dynamics, namely, extended or localized. Pending on
the discreteness /amplitude regime, the system exhibits either type of collapse
and the actual blow-up times approach, and in many cases are in excellent
agreement, with the upper or the lower bound respectively. When these times lie
between the analytical bounds, they are associated with a nontrivial mixing of
the above major types of collapse dynamics, due to the corroboration of
defocusing/focusing effects and energy gain/loss, in the presence of
discreteness and nonlinearity.",1809.08025v2,nlin.PS,2018-09-21 10:35:47+00:00,"[arxiv.Result.Author('G. Fotopoulos'), arxiv.Result.Author('N. I. Karachalios'), arxiv.Result.Author('V. Koukouloyannis'), arxiv.Result.Author('K. Vetas')]",
1589,Detector Challenges of the strong-field QED experiment LUXE at the European XFEL,"The LUXE experiment aims at studying high-field QED in electron-laser and
photon-laser interactions, with the 16.5 GeV electron beam of the European XFEL
and a laser beam with power of up to 350 TW. The experiment will measure the
spectra of electrons, positrons and photons in the expected range of
${10}^{-3}$ to ${10}^9$ per 1 Hz bunch crossing, depending on the laser power
and focus. These measurements have to be performed in the presence of
low-energy high radiation-background. To meet these challenges, for high-rate
electron and photon fluxes, the experiment will use Cherenkov radiation
detectors, scintillator screens, sapphire sensors as well as lead-glass
monitors for backscattering off the beam-dump. A four-layer silicon-pixel
tracker and a compact electromagnetic tungsten calorimeter with GaAs sensors
will be used to measure the positron spectra. The layout of the experiment and
the expected performance under the harsh radiation conditions, together with
the test of the Cherenkov detector and the electromagnetic (EM) calorimeter
performed recently at DESY, are presented. The experiment received a stage 0
critical approval (CD0) from the DESY management and is in the process of
preparing its technical design report (TDR). It is expected to start running in
2025/2026.",2208.11338v1,hep-ex,2022-08-24 07:38:30+00:00,[arxiv.Result.Author('Veta Ghenescu')],
1590,Assessment of algorithms for mitosis detection in breast cancer histopathology images,"The proliferative activity of breast tumors, which is routinely estimated by
counting of mitotic figures in hematoxylin and eosin stained histology
sections, is considered to be one of the most important prognostic markers.
However, mitosis counting is laborious, subjective and may suffer from low
inter-observer agreement. With the wider acceptance of whole slide images in
pathology labs, automatic image analysis has been proposed as a potential
solution for these issues. In this paper, the results from the Assessment of
Mitosis Detection Algorithms 2013 (AMIDA13) challenge are described. The
challenge was based on a data set consisting of 12 training and 11 testing
subjects, with more than one thousand annotated mitotic figures by multiple
observers. Short descriptions and results from the evaluation of eleven methods
are presented. The top performing method has an error rate that is comparable
to the inter-observer agreement among pathologists.",1411.5825v1,cs.CV,2014-11-21 11:00:38+00:00,"[arxiv.Result.Author('Mitko Veta'), arxiv.Result.Author('Paul J. van Diest'), arxiv.Result.Author('Stefan M. Willems'), arxiv.Result.Author('Haibo Wang'), arxiv.Result.Author('Anant Madabhushi'), arxiv.Result.Author('Angel Cruz-Roa'), arxiv.Result.Author('Fabio Gonzalez'), arxiv.Result.Author('Anders B. L. Larsen'), arxiv.Result.Author('Jacob S. Vestergaard'), arxiv.Result.Author('Anders B. Dahl'), arxiv.Result.Author('Dan C. Cireşan'), arxiv.Result.Author('Jürgen Schmidhuber'), arxiv.Result.Author('Alessandro Giusti'), arxiv.Result.Author('Luca M. Gambardella'), arxiv.Result.Author('F. Boray Tek'), arxiv.Result.Author('Thomas Walter'), arxiv.Result.Author('Ching-Wei Wang'), arxiv.Result.Author('Satoshi Kondo'), arxiv.Result.Author('Bogdan J. Matuszewski'), arxiv.Result.Author('Frederic Precioso'), arxiv.Result.Author('Violet Snell'), arxiv.Result.Author('Josef Kittler'), arxiv.Result.Author('Teofilo E. de Campos'), arxiv.Result.Author('Adnan M. Khan'), arxiv.Result.Author('Nasir M. Rajpoot'), arxiv.Result.Author('Evdokia Arkoumani'), arxiv.Result.Author('Miangela M. Lacle'), arxiv.Result.Author('Max A. Viergever'), arxiv.Result.Author('Josien P. W. Pluim')]",
1591,Exploring the similarity of medical imaging classification problems,"Supervised learning is ubiquitous in medical image analysis. In this paper we
consider the problem of meta-learning -- predicting which methods will perform
well in an unseen classification problem, given previous experience with other
classification problems. We investigate the first step of such an approach: how
to quantify the similarity of different classification problems. We
characterize datasets sampled from six classification problems by performance
ranks of simple classifiers, and define the similarity by the inverse of
Euclidean distance in this meta-feature space. We visualize the similarities in
a 2D space, where meaningful clusters start to emerge, and show that the
proposed representation can be used to classify datasets according to their
origin with 89.3\% accuracy. These findings, together with the observations of
recent trends in machine learning, suggest that meta-learning could be a
valuable tool for the medical imaging community.",1706.03509v1,cs.CV,2017-06-12 08:28:17+00:00,"[arxiv.Result.Author('Veronika Cheplygina'), arxiv.Result.Author('Pim Moeskops'), arxiv.Result.Author('Mitko Veta'), arxiv.Result.Author('Behdad Dasht Bozorg'), arxiv.Result.Author('Josien Pluim')]",
1592,The Lefever-Lejeune nonlinear lattice: convergence dynamics and the structure of equilibrium states,"We consider the Lefever-Lejeune nonlinear lattice, a spatially discrete
propagation-inhibition model describing the growth of vegetation densities in
dry-lands. We analytically identify parametric regimes distinguishing between
decay (associated with spatial extinction of vegetation patches) and
potentially non-trivial time-asymptotics. To gain insight on the convergence
dynamics, a stability analysis of spatially uniform states is performed,
revealing the existence of a threshold for the discretization parameter which
depends on the lattice parameters, below which their destabilization occurs and
spatially non-uniform equilibrium states may emerge. Direct numerical
simulations justified that the analytical stability criteria and parametric
thresholds effectively describe the above transition dynamics and revealed the
rich structure of the equilibrium set. Connections with the continuous sibling
Lefever-Lejeune partial differential equation are also discussed.",1907.00566v1,nlin.PS,2019-07-01 06:30:29+00:00,"[arxiv.Result.Author('Nikos I. Karachalios'), arxiv.Result.Author('Paris Kyriazopoulos'), arxiv.Result.Author('Konstantinos Vetas')]",
1593,Deep learning-based prediction of kinetic parameters from myocardial perfusion MRI,"The quantification of myocardial perfusion MRI has the potential to provide a
fast, automated and user-independent assessment of myocardial ischaemia.
However, due to the relatively high noise level and low temporal resolution of
the acquired data and the complexity of the tracer-kinetic models, the model
fitting can yield unreliable parameter estimates. A solution to this problem is
the use of Bayesian inference which can incorporate prior knowledge and improve
the reliability of the parameter estimation. This, however, uses Markov chain
Monte Carlo sampling to approximate the posterior distribution of the kinetic
parameters which is extremely time intensive. This work proposes training
convolutional networks to directly predict the kinetic parameters from the
signal-intensity curves that are trained using estimates obtained from the
Bayesian inference. This allows fast estimation of the kinetic parameters with
a similar performance to the Bayesian inference.",1907.11899v1,eess.IV,2019-07-27 11:58:43+00:00,"[arxiv.Result.Author('Cian M. Scannell'), arxiv.Result.Author('Piet van den Bosch'), arxiv.Result.Author('Amedeo Chiribiri'), arxiv.Result.Author('Jack Lee'), arxiv.Result.Author('Marcel Breeuwer'), arxiv.Result.Author('Mitko Veta')]",
1594,Adversarial training and dilated convolutions for brain MRI segmentation,"Convolutional neural networks (CNNs) have been applied to various automatic
image segmentation tasks in medical image analysis, including brain MRI
segmentation. Generative adversarial networks have recently gained popularity
because of their power in generating images that are difficult to distinguish
from real images.
  In this study we use an adversarial training approach to improve CNN-based
brain MRI segmentation. To this end, we include an additional loss function
that motivates the network to generate segmentations that are difficult to
distinguish from manual segmentations. During training, this loss function is
optimised together with the conventional average per-voxel cross entropy loss.
  The results show improved segmentation performance using this adversarial
training procedure for segmentation of two different sets of images and using
two different network architectures, both visually and in terms of Dice
coefficients.",1707.03195v1,cs.CV,2017-07-11 09:37:11+00:00,"[arxiv.Result.Author('Pim Moeskops'), arxiv.Result.Author('Mitko Veta'), arxiv.Result.Author('Maxime W. Lafarge'), arxiv.Result.Author('Koen A. J. Eppenhof'), arxiv.Result.Author('Josien P. W. Pluim')]",
1595,Domain-adversarial neural networks to address the appearance variability of histopathology images,"Preparing and scanning histopathology slides consists of several steps, each
with a multitude of parameters. The parameters can vary between pathology labs
and within the same lab over time, resulting in significant variability of the
tissue appearance that hampers the generalization of automatic image analysis
methods. Typically, this is addressed with ad-hoc approaches such as staining
normalization that aim to reduce the appearance variability. In this paper, we
propose a systematic solution based on domain-adversarial neural networks. We
hypothesize that removing the domain information from the model representation
leads to better generalization. We tested our hypothesis for the problem of
mitosis detection in breast cancer histopathology images and made a comparative
analysis with two other approaches. We show that combining color augmentation
with domain-adversarial training is a better alternative than standard
approaches to improve the generalization of deep learning methods.",1707.06183v1,cs.CV,2017-07-19 16:21:59+00:00,"[arxiv.Result.Author('Maxime W. Lafarge'), arxiv.Result.Author('Josien P. W. Pluim'), arxiv.Result.Author('Koen A. J. Eppenhof'), arxiv.Result.Author('Pim Moeskops'), arxiv.Result.Author('Mitko Veta')]",
1596,Inferring a Third Spatial Dimension from 2D Histological Images,"Histological images are obtained by transmitting light through a tissue
specimen that has been stained in order to produce contrast. This process
results in 2D images of the specimen that has a three-dimensional structure. In
this paper, we propose a method to infer how the stains are distributed in the
direction perpendicular to the surface of the slide for a given 2D image in
order to obtain a 3D representation of the tissue. This inference is achieved
by decomposition of the staining concentration maps under constraints that
ensure realistic decomposition and reconstruction of the original 2D images.
Our study shows that it is possible to generate realistic 3D images making this
method a potential tool for data augmentation when training deep learning
models.",1801.03431v1,cs.CV,2018-01-10 15:59:12+00:00,"[arxiv.Result.Author('Maxime W. Lafarge'), arxiv.Result.Author('Josien P. W. Pluim'), arxiv.Result.Author('Koen A. J. Eppenhof'), arxiv.Result.Author('Pim Moeskops'), arxiv.Result.Author('Mitko Veta')]",
1597,The linearly damped nonlinear Schrödinger equation with localized driving: spatiotemporal decay estimates and the emergence of extreme wave events,"We prove spatiotemporal algebraically decaying estimates for the density of
the solutions of the linearly damped nonlinear Schr\""odinger equation with
localized driving, when supplemented with vanishing boundary conditions. Their
derivation is made via a scheme, which incorporates suitable weighted Sobolev
spaces and a time-weighted energy method. Numerical simulations examining the
dynamics (in the presence of physically relevant examples of driver types and
driving amplitude/linear loss regimes), showcase that the suggested decaying
rates, are proved relevant in describing the transient dynamics of the
solutions, prior their decay: they support the emergence of waveforms
possessing an algebraic space-time localization (reminiscent of the Peregrine
soliton) as first events of the dynamics, but also effectively capture the
space-time asymptotics of the numerical solutions.",1910.08425v2,math-ph,2019-10-17 12:42:21+00:00,"[arxiv.Result.Author('G. Fotopoulos'), arxiv.Result.Author('N. I. Karachalios'), arxiv.Result.Author('V. Koukouloyannis'), arxiv.Result.Author('K. Vetas')]",
1598,Orientation-Disentangled Unsupervised Representation Learning for Computational Pathology,"Unsupervised learning enables modeling complex images without the need for
annotations. The representation learned by such models can facilitate any
subsequent analysis of large image datasets.
  However, some generative factors that cause irrelevant variations in images
can potentially get entangled in such a learned representation causing the risk
of negatively affecting any subsequent use. The orientation of imaged objects,
for instance, is often arbitrary/irrelevant, thus it can be desired to learn a
representation in which the orientation information is disentangled from all
other factors.
  Here, we propose to extend the Variational Auto-Encoder framework by
leveraging the group structure of rotation-equivariant convolutional networks
to learn orientation-wise disentangled generative factors of histopathology
images. This way, we enforce a novel partitioning of the latent space, such
that oriented and isotropic components get separated.
  We evaluated this structured representation on a dataset that consists of
tissue regions for which nuclear pleomorphism and mitotic activity was assessed
by expert pathologists. We show that the trained models efficiently disentangle
the inherent orientation information of single-cell images. In comparison to
classical approaches, the resulting aggregated representation of
sub-populations of cells produces higher performances in subsequent tasks.",2008.11673v1,eess.IV,2020-08-26 16:57:45+00:00,"[arxiv.Result.Author('Maxime W. Lafarge'), arxiv.Result.Author('Josien P. W. Pluim'), arxiv.Result.Author('Mitko Veta')]",
1599,"Domain-Adversarial Learning for Multi-Centre, Multi-Vendor, and Multi-Disease Cardiac MR Image Segmentation","Cine cardiac magnetic resonance (CMR) has become the gold standard for the
non-invasive evaluation of cardiac function. In particular, it allows the
accurate quantification of functional parameters including the chamber volumes
and ejection fraction. Deep learning has shown the potential to automate the
requisite cardiac structure segmentation. However, the lack of robustness of
deep learning models has hindered their widespread clinical adoption. Due to
differences in the data characteristics, neural networks trained on data from a
specific scanner are not guaranteed to generalise well to data acquired at a
different centre or with a different scanner. In this work, we propose a
principled solution to the problem of this domain shift. Domain-adversarial
learning is used to train a domain-invariant 2D U-Net using labelled and
unlabelled data. This approach is evaluated on both seen and unseen domains
from the M\&Ms challenge dataset and the domain-adversarial approach shows
improved performance as compared to standard training. Additionally, we show
that the domain information cannot be recovered from the learned features.",2008.11776v1,eess.IV,2020-08-26 19:40:55+00:00,"[arxiv.Result.Author('Cian M. Scannell'), arxiv.Result.Author('Amedeo Chiribiri'), arxiv.Result.Author('Mitko Veta')]",
1600,Predicting breast tumor proliferation from whole-slide images: the TUPAC16 challenge,"Tumor proliferation is an important biomarker indicative of the prognosis of
breast cancer patients. Assessment of tumor proliferation in a clinical setting
is highly subjective and labor-intensive task. Previous efforts to automate
tumor proliferation assessment by image analysis only focused on mitosis
detection in predefined tumor regions. However, in a real-world scenario,
automatic mitosis detection should be performed in whole-slide images (WSIs)
and an automatic method should be able to produce a tumor proliferation score
given a WSI as input. To address this, we organized the TUmor Proliferation
Assessment Challenge 2016 (TUPAC16) on prediction of tumor proliferation scores
from WSIs. The challenge dataset consisted of 500 training and 321 testing
breast cancer histopathology WSIs. In order to ensure fair and independent
evaluation, only the ground truth for the training dataset was provided to the
challenge participants. The first task of the challenge was to predict mitotic
scores, i.e., to reproduce the manual method of assessing tumor proliferation
by a pathologist. The second task was to predict the gene expression based
PAM50 proliferation scores from the WSI. The best performing automatic method
for the first task achieved a quadratic-weighted Cohen's kappa score of
$\kappa$ = 0.567, 95% CI [0.464, 0.671] between the predicted scores and the
ground truth. For the second task, the predictions of the top method had a
Spearman's correlation coefficient of r = 0.617, 95% CI [0.581 0.651] with the
ground truth. This was the first study that investigated tumor proliferation
assessment from WSIs. The achieved results are promising given the difficulty
of the tasks and weakly-labelled nature of the ground truth. However, further
research is needed to improve the practical utility of image analysis methods
for this task.",1807.08284v2,cs.CV,2018-07-22 13:46:03+00:00,"[arxiv.Result.Author('Mitko Veta'), arxiv.Result.Author('Yujing J. Heng'), arxiv.Result.Author('Nikolas Stathonikos'), arxiv.Result.Author('Babak Ehteshami Bejnordi'), arxiv.Result.Author('Francisco Beca'), arxiv.Result.Author('Thomas Wollmann'), arxiv.Result.Author('Karl Rohr'), arxiv.Result.Author('Manan A. Shah'), arxiv.Result.Author('Dayong Wang'), arxiv.Result.Author('Mikael Rousson'), arxiv.Result.Author('Martin Hedlund'), arxiv.Result.Author('David Tellez'), arxiv.Result.Author('Francesco Ciompi'), arxiv.Result.Author('Erwan Zerhouni'), arxiv.Result.Author('David Lanyi'), arxiv.Result.Author('Matheus Viana'), arxiv.Result.Author('Vassili Kovalev'), arxiv.Result.Author('Vitali Liauchuk'), arxiv.Result.Author('Hady Ahmady Phoulady'), arxiv.Result.Author('Talha Qaiser'), arxiv.Result.Author('Simon Graham'), arxiv.Result.Author('Nasir Rajpoot'), arxiv.Result.Author('Erik Sjöblom'), arxiv.Result.Author('Jesper Molin'), arxiv.Result.Author('Kyunghyun Paeng'), arxiv.Result.Author('Sangheum Hwang'), arxiv.Result.Author('Sunggyun Park'), arxiv.Result.Author('Zhipeng Jia'), arxiv.Result.Author('Eric I-Chao Chang'), arxiv.Result.Author('Yan Xu'), arxiv.Result.Author('Andrew H. Beck'), arxiv.Result.Author('Paul J. van Diest'), arxiv.Result.Author('Josien P. W. Pluim')]",
1601,Deep learning assessment of breast terminal duct lobular unit involution: towards automated prediction of breast cancer risk,"Terminal ductal lobular unit (TDLU) involution is the regression of
milk-producing structures in the breast. Women with less TDLU involution are
more likely to develop breast cancer. A major bottleneck in studying TDLU
involution in large cohort studies is the need for labor-intensive manual
assessment of TDLUs. We developed a computational pathology solution to
automatically capture TDLU involution measures. Whole slide images (WSIs) of
benign breast biopsies were obtained from the Nurses' Health Study (NHS). A
first set of 92 WSIs was annotated for TDLUs, acini and adipose tissue to train
deep convolutional neural network (CNN) models for detection of acini, and
segmentation of TDLUs and adipose tissue. These networks were integrated into a
single computational method to capture TDLU involution measures including
number of TDLUs per tissue area, median TDLU span and median number of acini
per TDLU. We validated our method on 40 additional WSIs by comparing with
manually acquired measures. Our CNN models detected acini with an F1 score of
0.73$\pm$0.09, and segmented TDLUs and adipose tissue with Dice scores of
0.86$\pm$0.11 and 0.86$\pm$0.04, respectively. The inter-observer ICC scores
for manual assessments on 40 WSIs of number of TDLUs per tissue area, median
TDLU span, and median acini count per TDLU were 0.71, 95% CI [0.51, 0.83],
0.81, 95% CI [0.67, 0.90], and 0.73, 95% CI [0.54, 0.85], respectively.
Intra-observer reliability was evaluated on 10/40 WSIs with ICC scores of >0.8.
Inter-observer ICC scores between automated results and the mean of the two
observers were: 0.80, 95% CI [0.63, 0.90] for number of TDLUs per tissue area,
0.57, 95% CI [0.19, 0.77] for median TDLU span, and 0.80, 95% CI [0.62, 0.89]
for median acini count per TDLU. TDLU involution measures evaluated by manual
and automated assessment were inversely associated with age and menopausal
status.",1911.00036v1,eess.IV,2019-10-31 18:12:44+00:00,"[arxiv.Result.Author('Suzanne C Wetstein'), arxiv.Result.Author('Allison M Onken'), arxiv.Result.Author('Christina Luffman'), arxiv.Result.Author('Gabrielle M Baker'), arxiv.Result.Author('Michael E Pyle'), arxiv.Result.Author('Kevin H Kensler'), arxiv.Result.Author('Ying Liu'), arxiv.Result.Author('Bart Bakker'), arxiv.Result.Author('Ruud Vlutters'), arxiv.Result.Author('Marinus B van Leeuwen'), arxiv.Result.Author('Laura C Collins'), arxiv.Result.Author('Stuart J Schnitt'), arxiv.Result.Author('Josien PW Pluim'), arxiv.Result.Author('Rulla M Tamimi'), arxiv.Result.Author('Yujing J Heng'), arxiv.Result.Author('Mitko Veta')]",
1602,Realization Scheme for Visual Cryptography with Computer-generated Holograms,"We propose to realize visual cryptography in an indirect way with the help of
computer-generated hologram. At present, the recovery method of visual
cryptography is mainly superimposed on transparent film or superimposed by
computer equipment, which greatly limits the application range of visual
cryptography. In this paper, the shares of the visual cryptography were encoded
with computer-generated hologram, and the shares is reproduced by optical
means, and then superimposed and decrypted. This method can expand the
application range of visual cryptography and further increase the security of
visual cryptography.",2212.11233v1,eess.IV,2022-12-10 04:59:55+00:00,"[arxiv.Result.Author('Tao Yu'), arxiv.Result.Author('Jinge Ma'), arxiv.Result.Author('Guilin Li'), arxiv.Result.Author('Dongyu Yang'), arxiv.Result.Author('Rui Ma'), arxiv.Result.Author('Yishi Shi')]",
1603,Full Restoration of Visual Encrypted Color Images,"While strictly black and white images have been the basis for visual
cryptography, there has been a lack of an easily implemented format for colour
images. This paper establishes a simple, yet secure way of implementing visual
cryptography with colour, assuming a binary data representation.",1111.4450v1,cs.CR,2011-11-18 18:33:50+00:00,"[arxiv.Result.Author('Simeon Persson'), arxiv.Result.Author('Kristian Várnai')]",
1604,Design and Implementation of Hierarchical Visual cryptography with Expansion less Shares,"Novel idea of hierarchical visual cryptography is stated in this paper. The
key concept of hierarchical visual cryptography is based upon visual
cryptography. Visual cryptography encrypts secret information into two pieces
called as shares. These two shares are stacked together by logical XOR
operation to reveal the original secret. Hierarchical visual cryptography
encrypts the secret in various levels. The encryption in turn is expansionless.
The original secret size is retained in the shares at all levels. In this paper
secret is encrypted at two different levels. Four shares are generated out of
hierarchical visual cryptography. Any three shares are collectively taken to
form the key share. All shares generated are meaningless giving no information
by visual inspection. Performance analysis is also obtained based upon various
categories of secrets. The greying effect is completely removed while revealing
the secret Removal of greying effect do not change the meaning of secret.",1402.2745v1,cs.CR,2014-02-12 06:53:39+00:00,"[arxiv.Result.Author('Pallavi Vijay Chavan'), arxiv.Result.Author('Dr. Mohammad Atique'), arxiv.Result.Author('Dr. Latesh Malik')]","International Journal of Network Security & Its Applications
  (IJNSA), Vol.6, No.1, January 2014"
1605,Recursive Information Hiding in Visual Cryptography,"Visual Cryptography is a secret sharing scheme that uses the human visual
system to perform computations. This paper presents a recursive hiding scheme
for 3 out of 5 secret sharing. The idea used is to hide smaller secrets in the
shares of a larger secret without an expansion in the size of the latter.",1004.4914v2,cs.CR,2010-04-27 20:56:02+00:00,[arxiv.Result.Author('Sandeep Katta')],
1606,Image Authentication using Visual Cryptography,"This report gives a novel technique of image encryption and authentication by
combining elements of Visual Cryptography and Public Key Cryptography. A
prominent attack involving generation of fake shares to cheat honest users has
been described and a demonstration of the proposed system employing a
centralised server to generate shares and authenticate them on the basis of
requests is made as a counter to the described attack.",1711.09032v1,cs.CR,2017-11-24 16:17:12+00:00,"[arxiv.Result.Author('Rahul Saranjame'), arxiv.Result.Author('Manik Lal Das')]",
1607,A New Approach to Enhance Security of Visual Cryptography Using Steganography (VisUS),"Steganography is a process that hides secrete message or secrete hologram or
secrete video or secrete image whose mere presence within the source data
should be undetectable and use for transmitting secret information over public
media. Visual cryptography is a cryptographic technique in which no
cryptographic computation is needed at the decryption end and the decryption is
performed by the human visual system (HVS). In this paper, both Steganography
and visual cryptography have been selected to provide more secure data
transmission over the public media with less hazard of computation. This
technique generates shares with less space overhead as well as without
increasing the computational complexity compared to existing techniques and may
provide better security. It is also easy to implement like other techniques of
visual cryptography. Finally, experimental results are given to establish the
security criteria.",2103.09477v1,cs.CR,2021-03-17 07:15:27+00:00,"[arxiv.Result.Author('Uttam Kr. Mondal'), arxiv.Result.Author('Shamayita Pal'), arxiv.Result.Author('AmitRanjan Dutta'), arxiv.Result.Author('J. K. Mandal')]",
1608,Can audio-visual integration strengthen robustness under multimodal attacks?,"In this paper, we propose to make a systematic study on machines multisensory
perception under attacks. We use the audio-visual event recognition task
against multimodal adversarial attacks as a proxy to investigate the robustness
of audio-visual learning. We attack audio, visual, and both modalities to
explore whether audio-visual integration still strengthens perception and how
different fusion mechanisms affect the robustness of audio-visual models. For
interpreting the multimodal interactions under attacks, we learn a
weakly-supervised sound source visual localization model to localize sounding
regions in videos. To mitigate multimodal attacks, we propose an audio-visual
defense approach based on an audio-visual dissimilarity constraint and external
feature memory banks. Extensive experiments demonstrate that audio-visual
models are susceptible to multimodal adversarial attacks; audio-visual
integration could decrease the model robustness rather than strengthen under
multimodal attacks; even a weakly-supervised sound source visual localization
model can be successfully fooled; our defense method can improve the
invulnerability of audio-visual networks without significantly sacrificing
clean model performance.",2104.02000v1,cs.CV,2021-04-05 16:46:45+00:00,"[arxiv.Result.Author('Yapeng Tian'), arxiv.Result.Author('Chenliang Xu')]",
1609,Extended visual cryptography systems,"Visual cryptography schemes have been introduced in 1994 by Naor and Shamir.
Their idea was to encode a secret image into $n$ shadow images and to give
exactly one such shadow image to each member of a group $P$ of $n$ persons.
Whereas most work in recent years has been done concerning the problem of
qualified and forbidden subsets of $P$ or the question of contrast optimizing,
in this paper we study extended visual cryptography schemes, i.e. shared secret
systems where any subset of $P$ shares its own secret.",math/0302043v1,math.CO,2003-02-04 15:19:12+00:00,"[arxiv.Result.Author('Andreas Klein'), arxiv.Result.Author('Markus Wessler')]",
1610,Bounds for Visual Cryptography Schemes,"In this paper, we investigate the best pixel expansion of the various models
of visual cryptography schemes. In this regard, we consider visual cryptography
schemes introduced by Tzeng and Hu [13]. In such a model, only minimal
qualified sets can recover the secret image and that the recovered secret image
can be darker or lighter than the background. Blundo et al. [4] introduced a
lower bound for the best pixel expansion of this scheme in terms of minimal
qualified sets. We present another lower bound for the best pixel expansion of
the scheme. As a corollary, we introduce a lower bound, based on an induced
matching of hypergraph of qualified sets, for the best pixel expansion of the
aforementioned model and the traditional model of visual cryptography realized
by basis matrices. Finally, we study access structures based on graphs and we
present an upper bound for the smallest pixel expansion in terms of strong
chromatic index.",0710.4828v5,cs.CR,2007-10-25 12:17:15+00:00,"[arxiv.Result.Author('Hossein Hajiabolhassan'), arxiv.Result.Author('Abbas Cheraghi')]",
1611,Secure Iris Authentication Using Visual Cryptography,"Biometrics deal with automated methods of identifying a person or verifying
the identity of a person based on physiological or behavioral characteristics.
Visual cryptography is a secret sharing scheme where a secret image is
encrypted into the shares which independently disclose no information about the
original secret image. As biometric template are stored in the centralized
database, due to security threats biometric template may be modified by
attacker. If biometric template is altered authorized user will not be allowed
to access the resource. To deal this issue visual cryptography schemes can be
applied to secure the iris template. Visual cryptography provides great means
for helping such security needs as well as extra layer of authentication.",1004.1748v1,cs.CR,2010-04-10 22:33:24+00:00,"[arxiv.Result.Author('P. S. Revenkar'), arxiv.Result.Author('Anisa Anjum'), arxiv.Result.Author('W. Z. Gandhare')]","IJCSIS, Vol. 7 No. 3, March 2010, 217-221"
1612,Visual Analysis of Photo Policy Misconfigurations Using Treemaps,"Online photo privacy is a major concern for social media users. Numerous
visualization tools have been proposed to help the users easily compose and
understand policies on social networks. However, these tools do not incorporate
the ability to quickly identify and fix unintended photo sharing. We propose a
tool that displays the photo albums w.r.t their policy misconfigurations using
a Treemap visualization.",1903.02612v1,cs.HC,2019-03-06 21:09:31+00:00,"[arxiv.Result.Author('Yousra Javed'), arxiv.Result.Author('Mohamed Shehab')]",
1613,Enhanced Security of Symmetric Encryption Using Combination of Steganography with Visual Cryptography,"Data security is required when communications over untrusted networks takes
place. Security tools such as cryptography and steganography are applied to
achieve such objectives, but both have limitations and susceptible to attacks
if they were used individually. To overcome these limitations, we proposed a
powerful and secured system based on the integration of cryptography and
steganography. The secret message is encrypted with blowfish cipher and visual
cryptography. Finally, the encrypted data is embedded into two innocent cover
images for future transmission. An extended analysis was made to prove the
efficiency of the proposed model by measuring Mean-Square-Error (MSE),
Peak-Signal-to-noise-Ratio (PSNR), and image histogram. The robustness was
examined by launching statistical and 8-bit plane visual attacks. The proposed
model provides a secure mean to transmit or store highly classified data that
could be applied to the public security sector.",1902.11167v1,cs.CR,2019-02-28 15:48:07+00:00,"[arxiv.Result.Author('Sherief H. Murad'), arxiv.Result.Author('Amr M. Gody'), arxiv.Result.Author('Tamer M. Barakat')]","International Journal of Engineering Trends and Technology
  (IJETT)2018"
1614,On the Analysis and Generalization of Extended Visual Cryptography Schemes,"An Extended Visual Cryptography Scheme (EVCS) was proposed by Ateniese et al.
[3] to protect a binary secret image with meaningful (innocent-looking) shares.
This is implemented by concatenating an extended matrix to each basis matrix.
The minimum size of the extended matrix was obtained from a hypergraph coloring
model and the scheme was designed for binary images only [3]. In this paper, we
give a more concise derivation for this matrix extension for color images.
Furthermore, we present a (k, n) scheme to protect multiple color images with
meaningful shares. This scheme is an extension of the (n, n) VCS for multiple
binary images proposed in Droste scheme [2].",cs/0610172v1,cs.CR,2006-10-31 03:43:13+00:00,"[arxiv.Result.Author('DaoShun Wang'), arxiv.Result.Author('Feng Yi'), arxiv.Result.Author('Xiaobo Li'), arxiv.Result.Author('Ping Luo'), arxiv.Result.Author('Yiqi Dai')]",
1615,Systematic Literature Review on Cyber Situational Awareness Visualizations,"The dynamics of cyber threats are increasingly complex, making it more
challenging than ever for organizations to obtain in-depth insights into their
cyber security status. Therefore, organizations rely on Cyber Situational
Awareness (CSA) to support them in better understanding the threats and
associated impacts of cyber events. Due to the heterogeneity and complexity of
cyber security data, often with multidimensional attributes, sophisticated
visualization techniques are needed to achieve CSA. However, there have been no
previous attempts to systematically review and analyze the scientific
literature on CSA visualizations. In this paper, we systematically select and
review 54 publications that discuss visualizations to support CSA. We extract
data from these papers to identify key stakeholders, information types, data
sources, and visualization techniques. Furthermore, we analyze the level of CSA
supported by the visualizations, alongside examining the maturity of the
visualizations, challenges, and practices related to CSA visualizations to
prepare a full analysis of the current state of CSA in an organizational
context. Our results reveal certain gaps in CSA visualizations. For instance,
the largest focus is on operational-level staff, and there is a clear lack of
visualizations targeting other types of stakeholders such as managers,
higher-level decision makers, and non-expert users. Most papers focus on threat
information visualization, and there is a dearth of papers that visualize
impact information, response plans, and information shared within teams. Based
on the results that highlight the important concerns in CSA visualizations, we
recommend a list of future research directions.",2112.10354v3,cs.CR,2021-12-20 06:31:53+00:00,"[arxiv.Result.Author('Liuyue Jiang'), arxiv.Result.Author('Asangi Jayatilaka'), arxiv.Result.Author('Mehwish Nasim'), arxiv.Result.Author('Marthie Grobler'), arxiv.Result.Author('Mansooreh Zahedi'), arxiv.Result.Author('M. Ali Babar')]",
1616,Federated Visualization: A Privacy-preserving Strategy for Aggregated Visual Query,"We present a novel privacy preservation strategy for decentralized
visualization. The key idea is to imitate the flowchart of the federated
learning framework, and reformulate the visualization process within a
federated infrastructure. The federation of visualization is fulfilled by
leveraging a shared global module that composes the encrypted externalizations
of transformed visual features of data pieces in local modules. We design two
implementations of federated visualization: a prediction-based scheme, and a
query-based scheme. We demonstrate the effectiveness of our approach with a set
of visual forms, and verify its robustness with evaluations. We report the
value of federated visualization in real scenarios with an expert review.",2007.15227v2,cs.GR,2020-07-30 04:57:26+00:00,"[arxiv.Result.Author('Wei Chen'), arxiv.Result.Author('Yating Wei'), arxiv.Result.Author('Zhiyong Wang'), arxiv.Result.Author('Shuyue Zhou'), arxiv.Result.Author('Bingru Lin'), arxiv.Result.Author('Zhiguang Zhou')]",
1617,PiouCrypt: Decentralized Lattice-based Method for Visual Symmetric Cryptography,"In recent years, establishing secure visual communications has turned into
one of the essential problems for security engineers and researchers. However,
only limited novel solutions are provided for image encryption, and limiting
the visual cryptography to only limited schemes can bring up negative
consequences, especially with emerging quantum computational systems. This
paper presents a novel algorithm for establishing secure private visual
communication. The proposed method has a layered architecture with several
cohesive components, and corresponded with an NP-hard problem, despite its
symmetric structure. This two-step technique is not limited to gray-scale
pictures, and furthermore, utilizing a lattice structure causes to proposed
method has optimal resistance for the post-quantum era, and is relatively
secure from the theoretical dimension.",2204.08017v1,cs.CR,2022-04-17 13:28:32+00:00,"[arxiv.Result.Author('Navid Abapour'), arxiv.Result.Author('Mohsen Ebadpour')]",
1618,A Recursive Threshold Visual Cryptography Scheme,"This paper presents a recursive hiding scheme for 2 out of 3 secret sharing.
In recursive hiding of secrets, the user encodes additional information about
smaller secrets in the shares of a larger secret without an expansion in the
size of the latter, thereby increasing the efficiency of secret sharing. We
present applications of our proposed protocol to images as well as text.",0902.2487v1,cs.CR,2009-02-14 20:39:12+00:00,"[arxiv.Result.Author('Abhishek Parakh'), arxiv.Result.Author('Subhash Kak')]",
1619,Visual cryptography in single-pixel imaging,"Two novel visual cryptography (VC) schemes are proposed by combining VC with
single-pixel imaging (SPI) for the first time. It is pointed out that the
overlapping of visual key images in VC is similar to the superposition of pixel
intensities by a single-pixel detector in SPI. In the first scheme, QR-code VC
is designed by using opaque sheets instead of transparent sheets. The secret
image can be recovered when identical illumination patterns are projected onto
multiple visual key images and a single detector is used to record the total
light intensities. In the second scheme, the secret image is shared by multiple
illumination pattern sequences and it can be recovered when the visual key
patterns are projected onto identical items. The application of VC can be
extended to more diversified scenarios by our proposed schemes.",1911.05033v1,eess.IV,2019-11-12 17:49:50+00:00,"[arxiv.Result.Author('Shuming Jiao'), arxiv.Result.Author('Jun Feng'), arxiv.Result.Author('Yang Gao'), arxiv.Result.Author('Ting Lei'), arxiv.Result.Author('Xiaocong Yuan')]",
1620,NgViz: Detecting DNS Tunnels through N-Gram Visualization and Quantitative Analysis,"This paper introduced NgViz, a tool that examines DNS traffic and shows
anomalies in n-gram frequencies. This is accomplished by comparing input files
against a fingerprint of legitimate traffic. Both quantitative analysis and
visual aids are provided that allow the user to make determinations about the
legitimacy of the DNS traffic.",1004.4359v1,cs.CR,2010-04-25 15:40:52+00:00,"[arxiv.Result.Author('Kenton Born'), arxiv.Result.Author('David Gustafson')]",
1621,Visualization and Attack Prevention for a Sensor-Based Agricultural Monitoring System,"This project proposes a sensor-based visual agricultural monitoring system.
Distinguished from traditional agricultural monitoring systems, this system
further analyzes basic agricultural data and prevents and monitors common
wireless network attacks such as Selective Forwarding, Black Hole Attacks,
Sinkhole Attacks, Flooding Attacks and Misdirection Attacks. Experimental
verification and evaluation of the attack prevention and monitoring are also
conducted.",2111.14032v1,cs.CR,2021-11-28 03:08:13+00:00,"[arxiv.Result.Author('Yifan Zhou'), arxiv.Result.Author('Zhendong Shi'), arxiv.Result.Author('Ruoxi Sun')]",
1622,FASTEN: Fair and Secure Distributed Voting Using Smart Contracts,"Electing democratic representatives via voting has been a common mechanism
since the 17th century. However, these mechanisms raise concerns about
fairness, privacy, vote concealment, fair calculations of tally, and proxies
voting on their behalf for the voters. Ballot voting, and in recent times,
electronic voting via electronic voting machines (EVMs) improves fairness by
relying on centralized trust. Homomorphic encryption-based voting protocols
also assure fairness but cannot scale to large scale elections such as
presidential elections. In this paper, we leverage the blockchain technology of
distributing trust to propose a smart contract-based protocol, namely, \proto.
There are many existing protocols for voting using smart contracts. We observe
that these either are not scalable or leak the vote tally during the voting
stage, i.e., do not provide vote concealment. In contrast, we show that FASTEN
preserves voter's privacy ensures vote concealment, immutability, and avoids
double voting. We prove that the probability of privacy breaches is negligibly
small. Further, our cost analysis of executing FASTEN over Ethereum is
comparable to most of the existing cost of elections.",2102.10594v1,cs.CR,2021-02-21 12:29:23+00:00,"[arxiv.Result.Author('Sankarshan Damle'), arxiv.Result.Author('Sujit Gujar'), arxiv.Result.Author('Moin Hussain Moti')]",
1623,How Private Are Commonly-Used Voting Rules?,"Differential privacy has been widely applied to provide privacy guarantees by
adding random noise to the function output. However, it inevitably fails in
many high-stakes voting scenarios, where voting rules are required to be
deterministic. In this work, we present the first framework for answering the
question: ""How private are commonly-used voting rules?"" Our answers are
two-fold. First, we show that deterministic voting rules provide sufficient
privacy in the sense of distributional differential privacy (DDP). We show that
assuming the adversarial observer has uncertainty about individual votes, even
publishing the histogram of votes achieves good DDP. Second, we introduce the
notion of exact privacy to compare the privacy preserved in various
commonly-studied voting rules, and obtain dichotomy theorems of exact DDP
within a large subset of voting rules called generalized scoring rules.",1805.05750v2,cs.CR,2018-05-15 13:21:33+00:00,"[arxiv.Result.Author('Ao Liu'), arxiv.Result.Author('Yun Lu'), arxiv.Result.Author('Lirong Xia'), arxiv.Result.Author('Vassilis Zikas')]","Proceedings of the 36th Conference on Uncertainty in Artificial
  Intelligence (UAI), in Proceedings of Machine Learning Research 124:629-638
  (2020)"
1624,Towards Better Privacy-preserving Electronic Voting System,"This paper presents two approaches of privacy-preserving voting system: Blind
Signature-based Voting (BSV) and Homorphic Encryption Based Voting (HEV). BSV
is simple, stable, and scalable, but requires additional anonymous property in
the communication with the blockchain. HEV simultaneously protects voting
privacy against traffic-analysis attacks, prevents cooperation interruption by
malicious voters with a high probability, but the scalability is limited. We
further apply sampling to mitigate the scalability problem in HEV and simulate
the performance under different voting group size and number of samples.",2205.12094v1,cs.CR,2022-05-24 14:17:52+00:00,"[arxiv.Result.Author('Zipeng Yan'), arxiv.Result.Author('Zichao Jiang'), arxiv.Result.Author('Yiyuan Li')]",
1625,Transparent Voting Platform Based on Permissioned Blockchain,"Since 2004, different research was handling the challenges in the centralized
voting systems, e-voting protocols and recently the decentralized voting. So
electronic voting puts forward some difficulties regarding the voter anonymity,
the secure casting of the votes and to prevent the voting process from
frauding. The Decentralized property of the technology called ""blockchain""
could have the solution for many of the challenges in voting research area and
brings a new secure mechanism of safe and transparent voting. In this paper, a
broad comparison between ongoing voting systems has studied by analyzing their
structure and the drawbacks that should consider in future to improve the whole
election process from keeping the privacy of the voter, casting a vote with the
possibility to check if it was counted correctly to publishing the results. The
result of the paper will give a new approach to extend the target of the
election from small scale to large scale despite the fact of Ethereum
limitation which can cast on the blockchain just five votes per minute. The
primary challenge is to find an answer for this question: ""How to balance
between voter privacy and transparency without breaking the important rule
where the voter can proof for a specific candidate that he voted for him in a
bribe situation?"".",1802.10134v1,cs.CY,2018-02-22 14:20:35+00:00,[arxiv.Result.Author('Nazim Faour')],
1626,Towards quantum-based privacy and voting,"The privacy of communicating participants is often of paramount importance,
but in some situations it is an essential condition. A typical example is a
fair (secret) voting. We analyze in detail communication privacy based on
quantum resources, and we propose new quantum protocols. Possible
generalizations that would lead to voting schemes are discussed.",quant-ph/0505041v2,quant-ph,2005-05-06 16:16:27+00:00,"[arxiv.Result.Author('Mark Hillery'), arxiv.Result.Author('Mario Ziman'), arxiv.Result.Author('Vladimir Buzek'), arxiv.Result.Author('Martina Bielikova')]",
1627,Blockchain-Based Electronic Voting System for Elections in Turkey,"Traditional elections satisfy neither citizens nor political authorities in
recent years. They are not fully secure since it is easy to attack votes. It
threatens also privacy and transparency of voters. Additionally, it takes too
much time to count the votes. This paper proposes a solution using Blockchain
to eliminate all the disadvantages of conventional elections. Security and data
integrity of votes are absolutely provided theoretically. Voter privacy is
another requirement that is ensured in the system. Lastly, the waiting time for
results decreased significantly in the proposed Blockchain voting system.",1911.09903v1,cs.CR,2019-11-22 07:40:34+00:00,"[arxiv.Result.Author('Rumeysa Bulut'), arxiv.Result.Author('Alperen Kantarcı'), arxiv.Result.Author('Safa Keskin'), arxiv.Result.Author('Şerif Bahtiyar')]","2019 4th International Conference on Computer Science and
  Engineering (UBMK) (2019) 183-188"
1628,Ballot stuffing and participation privacy in pollsite voting,"We study the problem of simultaneously addressing both ballot stuffing and
participation privacy for pollsite voting systems. Ballot stuffing is the
attack where fake ballots (not cast by any eligible voter) are inserted into
the system. Participation privacy is about hiding which eligible voters have
actually cast their vote. So far, the combination of ballot stuffing and
participation privacy has been mostly studied for internet voting, where voters
are assumed to own trusted computing devices. Such approaches are inapplicable
to pollsite voting where voters typically vote bare handed. We present an
eligibility audit protocol to detect ballot stuffing in pollsite voting
protocols. This is done while protecting participation privacy from a remote
observer - one who does not physically observe voters during voting. Our
protocol can be instantiated as an additional layer on top of most existing
pollsite E2E-V voting protocols. To achieve our guarantees, we develop an
efficient zero-knowledge proof (ZKP), that, given a value $v$ and a set $\Phi$
of commitments, proves $v$ is committed by some commitment in $\Phi$, without
revealing which one. We call this a ZKP of reverse set membership because of
its relationship to the popular ZKPs of set membership. This ZKP may be of
independent interest.",2210.14833v1,cs.CR,2022-10-26 16:29:23+00:00,"[arxiv.Result.Author('Prashant Agrawal'), arxiv.Result.Author('Abhinav Nakarmi'), arxiv.Result.Author('Mahabir Prasad Jhanwar'), arxiv.Result.Author('Subodh Sharma'), arxiv.Result.Author('Subhashis Banerjee')]",
1629,"In Differential Privacy, There is Truth: On Vote Leakage in Ensemble Private Learning","When learning from sensitive data, care must be taken to ensure that training
algorithms address privacy concerns. The canonical Private Aggregation of
Teacher Ensembles, or PATE, computes output labels by aggregating the
predictions of a (possibly distributed) collection of teacher models via a
voting mechanism. The mechanism adds noise to attain a differential privacy
guarantee with respect to the teachers' training data. In this work, we observe
that this use of noise, which makes PATE predictions stochastic, enables new
forms of leakage of sensitive information. For a given input, our adversary
exploits this stochasticity to extract high-fidelity histograms of the votes
submitted by the underlying teachers. From these histograms, the adversary can
learn sensitive attributes of the input such as race, gender, or age. Although
this attack does not directly violate the differential privacy guarantee, it
clearly violates privacy norms and expectations, and would not be possible at
all without the noise inserted to obtain differential privacy. In fact,
counter-intuitively, the attack becomes easier as we add more noise to provide
stronger differential privacy. We hope this encourages future work to consider
privacy holistically rather than treat differential privacy as a panacea.",2209.10732v1,cs.LG,2022-09-22 02:07:21+00:00,"[arxiv.Result.Author('Jiaqi Wang'), arxiv.Result.Author('Roei Schuster'), arxiv.Result.Author('Ilia Shumailov'), arxiv.Result.Author('David Lie'), arxiv.Result.Author('Nicolas Papernot')]",
1630,Self-tallying Quantum Anonymous Voting,"Anonymous voting is a voting method of hiding the link between a vote and a
voter, the context of which ranges from governmental elections to decision
making in small groups like councils or companies. In this paper, we propose a
quantum anonymous voting protocol assisted by two kinds of entangled quantum
states. Particularly, we provide a mechanism of opening and permuting the
ordered votes of all the voters in an anonymous manner; any party, who is
interested in the voting results, can acquire a permutation copy, and then
obtains the voting result through simple calculation. Unlike all previous
quantum works on anonymous voting, our quantum anonymous protocol firstly
possesses the properties of privacy, self-tallying, non-reusability,
verifiability and fairness at the same time. Besides, we demonstrate that the
entanglement of the novel quantum states used in our protocol makes the attack
from outside eavesdropper and inside dishonest voters impossible. We also
generalize our protocol to execute tasks of anonymous multi-party computation,
such as anonymous broadcast and anonymous ranking.",1605.07942v1,quant-ph,2016-05-25 15:48:21+00:00,"[arxiv.Result.Author('Qingle Wang'), arxiv.Result.Author('Chaohua Yu'), arxiv.Result.Author('Fei Gao'), arxiv.Result.Author('Haoyu Qi'), arxiv.Result.Author('Qiaoyan Wen')]","Phys. Rev. A 94, 022333 (2016)"
1631,Verification of STAR-Vote and Evaluation of FDR and ProVerif,"We present the first automated privacy analysis of STAR-Vote, a real world
voting system design with sophisticated ""end-to-end"" cryptography, using FDR
and ProVerif. We also evaluate the effectiveness of these tools. Despite the
complexity of the voting system, we were able to verify that our abstracted
formal model of STAR-Vote provides ballot-secrecy using both formal approaches.
Notably, ProVerif is radically faster than FDR, making it more suitable for
rapid iteration and refinement of the formal model.",1705.00782v1,cs.CR,2017-05-02 03:13:22+00:00,"[arxiv.Result.Author('Murat Moran'), arxiv.Result.Author('Dan S. Wallach')]",
1632,Information-Theoretically Secure Voting Without an Honest Majority,"We present three voting protocols with unconditional privacy and
information-theoretic correctness, without assuming any bound on the number of
corrupt voters or voting authorities. All protocols have polynomial complexity
and require private channels and a simultaneous broadcast channel. Our first
protocol is a basic voting scheme which allows voters to interact in order to
compute the tally. Privacy of the ballot is unconditional, but any voter can
cause the protocol to fail, in which case information about the tally may
nevertheless transpire. Our second protocol introduces voting authorities which
allow the implementation of the first protocol, while reducing the interaction
and limiting it to be only between voters and authorities and among the
authorities themselves. The simultaneous broadcast is also limited to the
authorities. As long as a single authority is honest, the privacy is
unconditional, however, a single corrupt authority or a single corrupt voter
can cause the protocol to fail. Our final protocol provides a safeguard against
corrupt voters by enabling a verification technique to allow the authorities to
revoke incorrect votes. We also discuss the implementation of a simultaneous
broadcast channel with the use of temporary computational assumptions, yielding
versions of our protocols achieving everlasting security.",0806.1931v1,cs.CR,2008-06-11 18:51:04+00:00,"[arxiv.Result.Author('Anne Broadbent'), arxiv.Result.Author('Alain Tapp')]",
1633,An Overview of End-to-End Verifiable Voting Systems,"Advances in E2E verifiable voting have the potential to fundamentally restore
trust in elections and democratic processes in society. In this chapter, we
provide a comprehensive introduction to the field. We trace the evolution of
privacy and verifiability properties in the research literature and describe
the operations of current state-of-the-art E2E voting systems. We also discuss
outstanding challenges to the deployment of E2E voting systems, including
technical, legal, and usability constraints.
  Our intention, in writing this chapter, has been to make the innovations in
this domain accessible to a wider audience. We have therefore eschewed
description of complex cryptographic mechanisms and instead attempt to
communicate the fundamental intuition behind the design of E2E voting systems.
We hope our work serves as a useful resource and assists in the future
development of E2E voting.",1605.08554v1,cs.CR,2016-05-27 09:25:01+00:00,"[arxiv.Result.Author('Syed Taha Ali'), arxiv.Result.Author('Judy Murray')]",
1634,SBvote: Scalable Self-Tallying Blockchain-Based Voting,"Decentralized electronic voting solutions represent a promising advancement
in electronic voting. One of the e-voting paradigms, the self-tallying scheme,
offers strong protection of the voters' privacy while making the whole voting
process verifiable. Decentralized smart contract platforms became interesting
practical instantiation of the immutable bulletin board that this scheme
requires to preserve its properties. Existing smart contract-based approaches
employing the self-tallying scheme (such as OVN or BBB-Voting) are only
suitable for a boardroom voting scenario due to their scalability limitation.
The goal of our work is to build on existing solutions to achieve scalability
without losing privacy guarantees and verifiability. We present SBvote, a
blockchain-based self-tallying voting protocol that is scalable in the number
of voters and therefore suitable for large-scale elections. The evaluation of
our proof-of-concept implementation shows that the protocol's scalability is
limited only by the underlying blockchain platform. We evaluated the
scalability of SBvote on two public smart contract platforms -- Gnosis and
Harmony. Despite the limitations imposed by the throughput of the blockchain
platform, SBvote can accommodate elections with millions of voters.",2206.06019v1,cs.CR,2022-06-13 10:18:00+00:00,"[arxiv.Result.Author('Ivana Stančíková'), arxiv.Result.Author('Ivan Homoliak')]",
1635,"A privacy-preserving, decentralized and functional Bitcoin e-voting protocol","Bitcoin, as a decentralized digital currency, has caused extensive research
interest. There are many studies based on related protocols on Bitcoin,
Bitcoin-based voting protocols also received attention in related literature.
In this paper, we propose a Bitcoin-based decentralized privacy-preserving
voting mechanism. It is assumed that there are n voters and m candidates. The
candidate who obtains t ballots can get x Bitcoins from each voter, namely nx
Bitcoins in total. We use a shuffling mechanism to protect voter's voting
privacy, at the same time, decentralized threshold signatures were used to
guarantee security and assign voting rights. The protocol can achieve
correctness, decentralization and privacy-preservings. By contrast with other
schemes, our protocol has a smaller number of transactions and can achieve a
more functional voting method.",1809.08362v1,cs.CR,2018-09-22 01:35:38+00:00,"[arxiv.Result.Author('Zijian Bao'), arxiv.Result.Author('Bin Wang'), arxiv.Result.Author('Wenbo Shi')]","2018 IEEE SmartWorld, Ubiquitous Intelligence & Computing,
  Advanced & Trusted Computing, Scalable Computing & Communications, Cloud &
  Big Data Computing, Internet of People and Smart City Innovation"
1636,Making Code Voting Secure against Insider Threats using Unconditionally Secure MIX Schemes and Human PSMT Protocols,"Code voting was introduced by Chaum as a solution for using a possibly
infected-by-malware device to cast a vote in an electronic voting application.
Chaum's work on code voting assumed voting codes are physically delivered to
voters using the mail system, implicitly requiring to trust the mail system.
This is not necessarily a valid assumption to make - especially if the mail
system cannot be trusted. When conspiring with the recipient of the cast
ballots, privacy is broken.
  It is clear to the public that when it comes to privacy, computers and
""secure"" communication over the Internet cannot fully be trusted. This
emphasizes the importance of using: (1) Unconditional security for secure
network communication. (2) Reduce reliance on untrusted computers.
  In this paper we explore how to remove the mail system trust assumption in
code voting. We use PSMT protocols (SCN 2012) where with the help of visual
aids, humans can carry out $\mod 10$ addition correctly with a 99\% degree of
accuracy. We introduce an unconditionally secure MIX based on the combinatorics
of set systems.
  Given that end users of our proposed voting scheme construction are humans we
\emph{cannot use} classical Secure Multi Party Computation protocols.
  Our solutions are for both single and multi-seat elections achieving:
\begin{enumerate}[i)]
  \item An anonymous and perfectly secure communication network secure against
a $t$-bounded passive adversary used to deliver voting,
  \item The end step of the protocol can be handled by a human to evade the
threat of malware. \end{enumerate} We do not focus on active adversaries.",1506.04429v1,cs.CR,2015-06-14 19:07:51+00:00,"[arxiv.Result.Author('Yvo Desmedt'), arxiv.Result.Author('Stelios Erotokritou')]",
1637,Private Multi-Winner Voting for Machine Learning,"Private multi-winner voting is the task of revealing $k$-hot binary vectors
satisfying a bounded differential privacy (DP) guarantee. This task has been
understudied in machine learning literature despite its prevalence in many
domains such as healthcare. We propose three new DP multi-winner mechanisms:
Binary, $\tau$, and Powerset voting. Binary voting operates independently per
label through composition. $\tau$ voting bounds votes optimally in their
$\ell_2$ norm for tight data-independent guarantees. Powerset voting operates
over the entire binary vector by viewing the possible outcomes as a power set.
Our theoretical and empirical analysis shows that Binary voting can be a
competitive mechanism on many tasks unless there are strong correlations
between labels, in which case Powerset voting outperforms it. We use our
mechanisms to enable privacy-preserving multi-label learning in the central
setting by extending the canonical single-label technique: PATE. We find that
our techniques outperform current state-of-the-art approaches on large,
real-world healthcare data and standard multi-label benchmarks. We further
enable multi-label confidential and private collaborative (CaPC) learning and
show that model performance can be significantly improved in the multi-site
setting.",2211.15410v1,cs.LG,2022-11-23 20:06:46+00:00,"[arxiv.Result.Author('Adam Dziedzic'), arxiv.Result.Author('Christopher A Choquette-Choo'), arxiv.Result.Author('Natalie Dullerud'), arxiv.Result.Author('Vinith Menon Suriyakumar'), arxiv.Result.Author('Ali Shahin Shamsabadi'), arxiv.Result.Author('Muhammad Ahmad Kaleem'), arxiv.Result.Author('Somesh Jha'), arxiv.Result.Author('Nicolas Papernot'), arxiv.Result.Author('Xiao Wang')]",
1638,The New South Wales iVote System: Security Failures and Verification Flaws in a Live Online Election,"In the world's largest-ever deployment of online voting, the iVote Internet
voting system was trusted for the return of 280,000 ballots in the 2015 state
election in New South Wales, Australia. During the election, we performed an
independent security analysis of parts of the live iVote system and uncovered
severe vulnerabilities that could be leveraged to manipulate votes, violate
ballot privacy, and subvert the verification mechanism. These vulnerabilities
do not seem to have been detected by the election authorities before we
disclosed them, despite a pre-election security review and despite the system
having run in a live state election for five days. One vulnerability, the
result of including analytics software from an insecure external server,
exposed some votes to complete compromise of privacy and integrity. At least
one parliamentary seat was decided by a margin much smaller than the number of
votes taken while the system was vulnerable. We also found protocol flaws,
including vote verification that was itself susceptible to manipulation. This
incident underscores the difficulty of conducting secure elections online and
carries lessons for voters, election officials, and the e-voting research
community.",1504.05646v2,cs.CR,2015-04-22 03:42:36+00:00,"[arxiv.Result.Author('J. Alex Halderman'), arxiv.Result.Author('Vanessa Teague')]",
1639,Breaching the Privacy of Israel's Paper Ballot Voting System,"An election is a process through which citizens in liberal democracies select
their governing bodies, usually through voting. For elections to be truly
honest, people must be able to vote freely without being subject to coercion;
that is why voting is usually done in a private manner. In this paper we
analyze the security offered by a paper-ballot voting system that is used in
Israel, as well as in several other countries around the world. we provide an
algorithm which, based on publicly available information, breaks the privacy of
the voters participating in such elections. Simulations based on real data
collected in Israel show that our algorithm performs well, and can correctly
recover the vote of up to 96% of the voters.",1608.08020v1,cs.CR,2016-08-29 12:27:12+00:00,"[arxiv.Result.Author('Tomer Ashur'), arxiv.Result.Author('Orr Dunkelman'), arxiv.Result.Author('Nimrod Talmon')]",
1640,Security Survey and Analysis of Vote-by-Mail Systems,"Voting by mail has been gaining traction for decades in the United States and
has emerged as the preferred voting method during the COVID-19 pandemic. In
this paper, we examine the security of electronic systems used in the process
of voting by mail, including online voter registration and online ballot
tracking systems. The goals of these systems, to facilitate voter registration
and increase public confidence in elections, are laudable. They indisputably
provide a critical public good. It is for these reasons that understanding the
security and privacy posture of the mail-in voting process is paramount. We
find that online voter registration systems in some states have vulnerabilities
that allow adversaries to alter or effectively prevent a voter's registration.
We additionally find that ballot tracking systems raise serious privacy
questions surrounding ease of access to voter data. While the vulnerabilities
discussed here are unlikely to enable an adversary to modify votes, several
could have the effect of disenfranchising voters and reducing voter confidence
in U.S. elections infrastructure, thereby undermining the very purpose of these
systems.",2005.08427v2,cs.CY,2020-05-18 02:18:15+00:00,"[arxiv.Result.Author('Jenny Blessing'), arxiv.Result.Author('Julian Gomez'), arxiv.Result.Author('McCoy Patiño'), arxiv.Result.Author('Tran Nguyen')]",
1641,BBB-Voting: 1-out-of-k Blockchain-Based Boardroom Voting,"Voting is a means to agree on a collective decision based on available
choices (e.g., candidates), where participants (voters) agree to abide by their
outcome. To improve some features of e-voting, decentralized solutions based on
a blockchain can be employed, where the blockchain represents a public bulletin
board that in contrast to a centralized bulletin board provides $100\%$
availability and censorship resistance. A blockchain ensures that all entities
in the voting system have the same view of the actions made by others due to
its immutable and append-only log. The existing blockchain-based boardroom
voting solution called Open Voting Network (OVN) provides the privacy of votes
and perfect ballot secrecy, but it supports only two candidates. We present
BBB-Voting, an equivalent blockchain-based approach for decentralized voting
than OVN, but in contrast to it, BBB-Voting supports 1-out-of-$k$ choices and
provides a fault tolerance mechanism that enables recovery from stalling
participants. We provide a cost-optimized implementation using Ethereum, which
we compare with OVN and show that our work decreases the costs for voters by
$13.5\%$ in terms of gas consumption. Next, we outline the extension of our
implementation scaling to magnitudes higher number of participants than in a
boardroom voting, while preserving the costs paid by the authority and
participants -- we made proof-of-concept experiments with up to 1000
participants.",2010.09112v3,cs.CR,2020-10-18 21:34:58+00:00,"[arxiv.Result.Author('Sarad Venugopalan'), arxiv.Result.Author('Ivan Homoliak'), arxiv.Result.Author('Zengpeng Li'), arxiv.Result.Author('Pawel Szalachowski')]",
1642,"Proportional Approval Method using Squared loads, Approval removal and Coin-flip approval transformation (PAMSAC) - a new system of proportional representation using approval voting","Several multi-winner systems that use approval voting have been developed but
they each suffer from various problems. Six of these methods are discussed in
this paper. They are Satisfaction Approval Voting, Minimax Approval Voting,
Proportional Approval Voting, Monroe's Fully Proportional Representation,
Chamberlin-Courant's Rule, and Ebert's method. They all fail at least one of
Proportional Representation (PR), strong PR, monotonicity or positive support.
However, the new method described in this paper - Proportional Approval Method
using Squared loads, Approval removal and Coin-flip approval transformation
(PAMSAC) - passes them all. PAMSAC uses the squared loads of Ebert's method,
but removes non-beneficial approvals to restore monotonicity. It also uses the
Coin-Flip Approval Transformation (CFAT), where voters are ""split"" into two for
each candidate they approve, and where one half of this split voter approves
and the other half does not approve each candidate approved on the ballot. This
restores positive support, and also makes the method equivalent to the D'Hondt
party-list method for party voting. PAMSAC reduces to simple approval voting in
the single-winner case. A score voting version is described that also reduces
to simple score voting in the single-winner case.",1602.05248v2,cs.GT,2016-02-17 00:10:34+00:00,[arxiv.Result.Author('Toby Pereira')],
1643,A punishment voting algorithm based on super categories construction for acoustic scene classification,"In acoustic scene classification researches, audio segment is usually split
into multiple samples. Majority voting is then utilized to ensemble the results
of the samples. In this paper, we propose a punishment voting algorithm based
on the super categories construction method for acoustic scene classification.
Specifically, we propose a DenseNet-like model as the base classifier. The base
classifier is trained by the CQT spectrograms generated from the raw audio
segments. Taking advantage of the results of the base classifier, we propose a
super categories construction method using the spectral clustering. Super
classifiers corresponding to the constructed super categories are further
trained. Finally, the super classifiers are utilized to enhance the majority
voting of the base classifier by punishment voting. Experiments show that the
punishment voting obviously improves the performances on both the DCASE2017
Development dataset and the LITIS Rouen dataset.",1807.04073v2,cs.SD,2018-07-11 11:14:19+00:00,"[arxiv.Result.Author('Weiping Zheng'), arxiv.Result.Author('Zhenyao Mo'), arxiv.Result.Author('Jiantao Yi')]",
1644,False-Name Manipulation in Weighted Voting Games is Hard for Probabilistic Polynomial Time,"False-name manipulation refers to the question of whether a player in a
weighted voting game can increase her power by splitting into several players
and distributing her weight among these false identities. Analogously to this
splitting problem, the beneficial merging problem asks whether a coalition of
players can increase their power in a weighted voting game by merging their
weights. Aziz et al. [ABEP11] analyze the problem of whether merging or
splitting players in weighted voting games is beneficial in terms of the
Shapley-Shubik and the normalized Banzhaf index, and so do Rey and Rothe [RR10]
for the probabilistic Banzhaf index. All these results provide merely
NP-hardness lower bounds for these problems, leaving the question about their
exact complexity open. For the Shapley--Shubik and the probabilistic Banzhaf
index, we raise these lower bounds to hardness for PP, ""probabilistic
polynomial time"", and provide matching upper bounds for beneficial merging and,
whenever the number of false identities is fixed, also for beneficial
splitting, thus resolving previous conjectures in the affirmative. It follows
from our results that beneficial merging and splitting for these two power
indices cannot be solved in NP, unless the polynomial hierarchy collapses,
which is considered highly unlikely.",1303.1691v1,cs.GT,2013-03-07 14:05:03+00:00,"[arxiv.Result.Author('Anja Rey'), arxiv.Result.Author('Jörg Rothe')]",
1645,A multi-candidate electronic voting scheme with unlimited participants,"In this paper a new multi-candidate electronic voting scheme is constructed
with unlimited participants. The main idea is to express a ballot to allow
voting for up to k out of the m candidates and unlimited participants. The
purpose of vote is to select more than one winner among $m$ candidates. Our
result is complementary to the result by Sun peiyong$'$ s scheme, in the sense,
their scheme is not amenable for large-scale electronic voting due to flaw of
ballot structure. In our scheme the vote is split and hidden, and tallying is
made for $G\ddot{o}del$ encoding in decimal base without any trusted third
party, and the result does not rely on any traditional cryptography or
computational intractable assumption. Thus the proposed scheme not only solves
the problem of ballot structure, but also achieves the security including
perfect ballot secrecy, receipt-free, robustness, fairness and
dispute-freeness.",1712.10193v1,cs.CR,2017-12-29 11:52:23+00:00,"[arxiv.Result.Author('Xi Zhao'), arxiv.Result.Author('Yong Ding'), arxiv.Result.Author('Quanyu Zhao')]",
1646,Worst-case Bounds on Power vs. Proportion in Weighted Voting Games with Application to False-name Manipulation,"Weighted voting games apply to a wide variety of multi-agent settings. They
enable the formalization of power indices which quantify the coalitional power
of players. We take a novel approach to the study of the power of big vs.~small
players in these games. We model small (big) players as having single
(multiple) votes. The aggregate relative power of big players is measured
w.r.t.~their votes proportion. For this ratio, we show small constant
worst-case bounds for the Shapley-Shubik and the Deegan-Packel indices. In
sharp contrast, this ratio is unbounded for the Banzhaf index. As an
application, we define a false-name strategic normal form game where each big
player may split its votes between false identities, and study its various
properties. Together, our results provide foundations for the implications of
players' size, modeled as their ability to split, on their relative power.",2108.09216v1,cs.GT,2021-08-20 15:16:24+00:00,"[arxiv.Result.Author('Yotam Gafni'), arxiv.Result.Author('Ron Lavi'), arxiv.Result.Author('Moshe Tennenholtz')]",
1647,ESCAPE to Precaution against Leader Failures,"Leader-based consensus protocols must undergo a view-change phase to elect a
new leader when the current leader fails. The new leader is often decided upon
a candidate server that collects votes from a quorum of servers. However,
voting-based election mechanisms intrinsically cause competition in leadership
candidacy when each candidate collects only partial votes. This split-vote
scenario can result in no leadership winner and prolong the undesired
view-change period. In this paper, we investigate a case study of Raft's leader
election mechanism and propose a new leader election protocol, called ESCAPE,
that fundamentally solves split votes by prioritizing servers based on their
log responsiveness. ESCAPE dynamically assigns servers with a configuration
that offers different priorities through Raft's periodic heartbeat. In each
assignment, ESCAPE keeps track of server log responsiveness and assigns
configurations that are inclined to win an election to more up-to-date servers,
thereby preparing a pool of prioritized candidates. Consequently, when the next
election takes place, the candidate with the highest priority will defeat its
counterparts and becomes the next leader without competition. The evaluation
results show that ESCAPE progressively reduces the leader election time when
the cluster scales up, and the improvement becomes more significant under
message loss.",2202.09434v1,cs.DC,2022-02-18 21:33:44+00:00,"[arxiv.Result.Author('Gengrui Zhang'), arxiv.Result.Author('Hans-Arno Jacobsen')]",
1648,A Voting Power Measure for Liquid Democracy with Multiple Delegation,"We generalize the classical model of liquid democracy by proposing a voting
power measure that allows each agent to split and delegate their vote to
multiple agents. We prove that this measure is well defined and inherits the
most important properties of the classical model. Among these properties we
prove the so-called delegation property, which guarantees us that delegating
power to an agent is equivalent to copying her delegation profile. Secondly we
study the existence of equilibrium states in a delegation game using the
proposed measure, for which we prove the existence of pure strategy Nash
equilibria.",2209.14128v1,cs.MA,2022-09-28 14:25:36+00:00,[arxiv.Result.Author('Francisco Bersetche')],
1649,Collective Bias Models in Two-Tier Voting Systems and the Democracy Deficit,"We analyse optimal voting weights in two-tier voting systems. In our model,
the overall population (or union) is split in groups (or member states) of
different sizes. The individuals comprising the overall population constitute
the first tier, and the council is the second tier. Each group has a
representative in the council that casts votes on their behalf. By ""optimal
weights"", we mean voting weights in the council which minimise the democracy
deficit, i.e. the expected deviation of the council vote from a (hypothetical)
popular vote. We assume that the voters within each group interact via what we
call a local collective bias or common belief (through tradition, common
values, strong religious beliefs, etc.). We allow in addition an interaction
across group borders via a global bias. Thus, the voting behaviour of each
voter depends on the behaviour of all other voters. This correlation may be
stronger between voters in the same group, but is in general not zero for
voters in different groups. We call the respective voting measure a Collective
Bias Model (CBM). The ""simple CBM"" introduced in [12] and in particular the
Impartial Culture and the Impartial Anonymous Culture are special cases of our
general model. We compute the optimal weights in the large population limit.
Those optimal weights are unique as long as there is no ""complete"" correlation
between the groups. In this case, we obtain optimal weights which are the sum
of a common constant equal for all groups and a summand which is proportional
to the population of each group. We also analyse the conditions under which the
optimal weights are negative, thus making it impossible to reach the
theoretical minimum of the democracy deficit. This is a new aspect of the model
owed to the correlation between votes belonging to different groups.",2102.12704v3,math.PR,2021-02-25 06:31:39+00:00,"[arxiv.Result.Author('Werner Kirsch'), arxiv.Result.Author('Gabor Toth')]",Mathematical Social Sciences 119 (2022) 118-137
1650,"False name manipulations in weighted voting games: splitting, merging and annexation","An important aspect of mechanism design in social choice protocols and
multiagent systems is to discourage insincere and manipulative behaviour. We
examine the computational complexity of false-name manipulation in weighted
voting games which are an important class of coalitional voting games. Weighted
voting games have received increased interest in the multiagent community due
to their compact representation and ability to model coalitional formation
scenarios. Bachrach and Elkind in their AAMAS 2008 paper examined divide and
conquer false-name manipulation in weighted voting games from the point of view
of Shapley-Shubik index. We analyse the corresponding case of the Banzhaf index
and check how much the Banzhaf index of a player increases or decreases if it
splits up into sub-players. A pseudo-polynomial algorithm to find the optimal
split is also provided. Bachrach and Elkind also mentioned manipulation via
merging as an open problem. In the paper, we examine the cases where a player
annexes other players or merges with them to increase their Banzhaf index or
Shapley-Shubik index payoff. We characterize the computational complexity of
such manipulations and provide limits to the manipulation. The annexation
non-monotonicity paradox is also discovered in the case of the Banzhaf index.
The results give insight into coalition formation and manipulation.",0905.3348v1,cs.GT,2009-05-20 16:28:58+00:00,"[arxiv.Result.Author('Haris Aziz'), arxiv.Result.Author('Mike Paterson')]",
1651,Asymmetry in Political Geography and Compactness in Districting: a Computational Analysis of Bias,"We investigate the distribution of partisanship in a cross-section of ten
diverse States to elucidate how votes translate into seats won and other
metrics. Markov chain simulations taking into account partisanship distribution
agree surprisingly well with a simple model covering only equal voting
population-weighted distributions of precinct results containing no spatial
information. We find asymmetries where Democrats win fewer precincts than
Republicans but do so with large marjorities. This skew accounts for persistent
Republican control of State Legislatures and Congressional seats even in some
states with statewide vote majorities for Democrats.
  Despite overall results showing Republican advantages in many states based on
mean results from simulations covering many random scenarios, the simulations
yield a wide range in metrics, suggesting bias can be minimized better by
selecting districting plans with low values for efficiency gap than by
selecting plans with values near the means for the ensemble of random
simulations.
  We examine constraints on county splits to achieve higher compactness and
investigate policies requiring cohesiveness for communities of interest as to
screen out the most obvious gerrymanders. Minimizing county splits does not
necessarily reduce partisan bias, except for Pennsylvania, where limiting
county splits appears to reduce bias.",2103.01735v1,physics.soc-ph,2021-03-02 14:11:47+00:00,"[arxiv.Result.Author('Constantine'), arxiv.Result.Author('Gonatas')]",
1652,Split Cycle: A New Condorcet Consistent Voting Method Independent of Clones and Immune to Spoilers,"We propose a Condorcet consistent voting method that we call Split Cycle.
Split Cycle belongs to the small family of known voting methods that
significantly narrow the choice of winners in the presence of majority cycles
while also satisfying independence of clones. In this family, only Split Cycle
satisfies a new criterion we call immunity to spoilers, which concerns adding
candidates to elections, as well as the known criteria of positive involvement
and negative involvement, which concern adding voters to elections. Thus, in
contrast to other clone-independent methods, Split Cycle mitigates both
""spoiler effects"" and ""strong no show paradoxes.""",2004.02350v8,cs.GT,2020-04-05 23:20:17+00:00,"[arxiv.Result.Author('Wesley H. Holliday'), arxiv.Result.Author('Eric Pacuit')]",
1653,Weighting Experts with Inaccurate Judges,"We consider the problem of aggregating binary votes from an ensemble of
experts to reveal an underlying binary ground truth where each expert votes
correctly with some independent probability. We focus on settings where the
number of agents is too small for asymptotic results to apply, many experts may
vote correctly with low probability, and there is no central authority who
knows the experts' competences, or their probabilities of voting correctly. Our
approach is to designate a second type of agent -- a judge -- to weight the
experts to improve overall accuracy. The catch is that the judge has imperfect
competence just like the experts. We demonstrate that having a single minimally
competent judge is often better than having none at all. Using an ensemble of
judges to weight the experts can provide a better weighting than any single
judge; even the optimal weighting under the right conditions. As our results
show, the ability of the judge(s) to distinguish between competent and
incompetent experts is paramount. Lastly, given a fixed set of agents with
unknown competences drawn i.i.d. from a common distribution, we show how the
optimal split of the agents between judges and experts depends on the
distribution.",2211.08494v1,cs.LG,2022-11-15 20:47:14+00:00,"[arxiv.Result.Author('Ben Abramowitz'), arxiv.Result.Author('Nicholas Mattei')]",
1654,A Communication-Efficient Parallel Algorithm for Decision Tree,"Decision tree (and its extensions such as Gradient Boosting Decision Trees
and Random Forest) is a widely used machine learning algorithm, due to its
practical effectiveness and model interpretability. With the emergence of big
data, there is an increasing need to parallelize the training process of
decision tree. However, most existing attempts along this line suffer from high
communication costs. In this paper, we propose a new algorithm, called
\emph{Parallel Voting Decision Tree (PV-Tree)}, to tackle this challenge. After
partitioning the training data onto a number of (e.g., $M$) machines, this
algorithm performs both local voting and global voting in each iteration. For
local voting, the top-$k$ attributes are selected from each machine according
to its local data. Then, globally top-$2k$ attributes are determined by a
majority voting among these local candidates. Finally, the full-grained
histograms of the globally top-$2k$ attributes are collected from local
machines in order to identify the best (most informative) attribute and its
split point. PV-Tree can achieve a very low communication cost (independent of
the total number of attributes) and thus can scale out very well. Furthermore,
theoretical analysis shows that this algorithm can learn a near optimal
decision tree, since it can find the best attribute with a large probability.
Our experiments on real-world datasets show that PV-Tree significantly
outperforms the existing parallel decision tree algorithms in the trade-off
between accuracy and efficiency.",1611.01276v1,cs.LG,2016-11-04 07:09:03+00:00,"[arxiv.Result.Author('Qi Meng'), arxiv.Result.Author('Guolin Ke'), arxiv.Result.Author('Taifeng Wang'), arxiv.Result.Author('Wei Chen'), arxiv.Result.Author('Qiwei Ye'), arxiv.Result.Author('Zhi-Ming Ma'), arxiv.Result.Author('Tie-Yan Liu')]",
1655,Optimal Legislative County Clustering in North Carolina,"North Carolina's constitution requires that state legislative districts
should not split counties. However, counties must be split to comply with the
""one person, one vote"" mandate of the U.S. Supreme Court. Given that counties
must be split, the North Carolina legislature and courts have provided
guidelines that seek to reduce counties split across districts while also
complying with the ""one person, one vote"" criteria. Under these guidelines, the
counties are separated into clusters. The primary goal of this work is to
develop, present, and publicly release an algorithm to optimally cluster
counties according to the guidelines set by the court in 2015. We use this tool
to investigate the optimality and uniqueness of the enacted clusters under the
2017 redistricting process. We verify that the enacted clusters are optimal,
but find other optimal choices. We emphasize that the tool we provide lists
\textit{all} possible optimal county clusterings. We also explore the stability
of clustering under changing statewide populations and project what the county
clusters may look like in the next redistricting cycle beginning in 2020/2021.",1908.11801v1,cs.CY,2019-08-30 15:48:26+00:00,"[arxiv.Result.Author('Daniel Carter'), arxiv.Result.Author('Zach Hunter'), arxiv.Result.Author('Dan Teague'), arxiv.Result.Author('Gregory Herschlag'), arxiv.Result.Author('Jonathan Mattingly')]",
1656,What did the 2016 Brexit referendum data really say?,"The Brexit referendum took place in the UK in June, 2016. The unweighted
percentage of leavers over the whole population was 51.9%. In this paper,
first, we demonstrate that a 52%-48% split represents only a difference that is
not sufficiently different from a 50-50 split to claim a majority for either
side. Second, and most important, on this basis of the unweighted percentage,
statement like: The country voted to leave the EU, were made. When a statement
about a population is made based on a subset of it (the turnout rate for Brexit
was only 72% and therefore 37% of the eligible population voted Leave), it
comes with an element of uncertainty that should not be ignored. The unweighted
average disregards, not only between-region heterogeneity but also
within-region variability. Our analysis, controlling for both, finds that the
split of the Brexit is of negligible material significance and do not indicate
majority for either side.",1608.06552v3,stat.AP,2016-08-23 15:49:12+00:00,"[arxiv.Result.Author('Nicholas Donaldson'), arxiv.Result.Author('Nora Donaldson'), arxiv.Result.Author('Grace Yang')]",
1657,Towards the Typology of Elections at Russia,"A distinction in reasons and motives for choosing a particular political
leader establishes the key difference between older and young democracy. The
former is based on electoral history, while the latter is based on feelings and
personal attitude. Besides, a comparatively abundant number of political
figures (persons or parties and associations) is specific for young
democracies. The problem of a reference votes' distribution is analyzed.
Lefevbre's theory of a reflexive control is supposed to make the basis for
indifferent choice of political figures. This theory yields a golden section
split of votes (or the series of Fibonacci numbers, for the case of multiple
choice). A typology of political campaigns based on this theory is proposed. A
proximity of ratings of competing persons means the highest electoral tension,
a leadership of a person means a high level of mobilization; a neutral
situation corresponds to Fibonacci numbers distribution of votes.",0706.3521v1,physics.soc-ph,2007-06-24 15:31:55+00:00,"[arxiv.Result.Author('Michael G. Sadovsky'), arxiv.Result.Author('Alexander A. Gliskov')]",
1658,Untangling the Dueling Expert Witnesses: Comparing Ensemble Methods in Pennsylvania's Redistricting Plans,"Ensembles of random legislative districts are a valuable tool for assessing
whether a proposed district plan is an outlier or gerrymander. Expert witnesses
have presented these in litigation using various methods, and unsurprisingly,
they often disagree.
  Recent open source methods now permit independent validation of expert
witness testimony. Here, we compare ensembles for the Pennsylvania House and
Congressional districts calculated using ""Redist"" and ""Gerrychain"" further
incorporating constraints restricting county and municipal boundary splitting,
as required by Pennsylvania for legal plans.
  We compare results to expert witness testimony submitted by Republican and
Democratic parties. We confirm some of the testimony but could not reproduce
all of it, struggling with metrics based on a heuristic ""sum of votes index""
rathern than a straightforward average of metrics across multiple elections. We
recommend against relying on analytics based on summing votes from multiple
elections to create vote incides and derivative metrics as these are inherently
poorly behaved. To promote transparency, we recommend that where possible,
expert witness testimony be based solely on publicly available election data as
opposed to proprietary data closely held by political parties.",2208.12609v1,cs.CY,2022-08-18 00:03:40+00:00,"[arxiv.Result.Author('P. Dingus'), arxiv.Result.Author('C. Zhu'), arxiv.Result.Author('C. Gonatas')]",
1659,Generating Single Peaked Votes,"We discuss how to generate singled peaked votes uniformly from the Impartial
Culture model.",1503.02766v1,cs.GT,2015-03-10 04:15:23+00:00,[arxiv.Result.Author('Toby Walsh')],
1660,Normalized Range Voting Broadly Resists Control,"We study the behavior of Range Voting and Normalized Range Voting with
respect to electoral control. Electoral control encompasses attempts from an
election chair to alter the structure of an election in order to change the
outcome. We show that a voting system resists a case of control by proving that
performing that case of control is computationally infeasible. Range Voting is
a natural extension of approval voting, and Normalized Range Voting is a simple
variant which alters each vote to maximize the potential impact of each voter.
We show that Normalized Range Voting has among the largest number of control
resistances among natural voting systems.",1005.5698v3,cs.GT,2010-05-31 15:34:11+00:00,[arxiv.Result.Author('Curtis Menton')],
1661,Strategic Voting Under Uncertainty About the Voting Method,"Much of the theoretical work on strategic voting makes strong assumptions
about what voters know about the voting situation. A strategizing voter is
typically assumed to know how other voters will vote and to know the rules of
the voting method. A growing body of literature explores strategic voting when
there is uncertainty about how others will vote. In this paper, we study
strategic voting when there is uncertainty about the voting method. We
introduce three notions of manipulability for a set of voting methods: sure,
safe, and expected manipulability. With the help of a computer program, we
identify voting scenarios in which uncertainty about the voting method may
reduce or even eliminate a voter's incentive to misrepresent her preferences.
Thus, it may be in the interest of an election designer who wishes to reduce
strategic voting to leave voters uncertain about which of several reasonable
voting methods will be used to determine the winners of an election.",1907.09110v1,cs.MA,2019-07-22 03:17:19+00:00,"[arxiv.Result.Author('Wesley H. Holliday'), arxiv.Result.Author('Eric Pacuit')]","EPTCS 297, 2019, pp. 252-272"
